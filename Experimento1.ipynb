{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisPerez/NN_Tests_DG/blob/main/Experimento1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjAzjEYyZdeB"
      },
      "source": [
        "# Experimento 1: Estudio de todos los métodos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5BsElnuhMMO"
      },
      "source": [
        "**Propósito:** Estudiar el desempeño y la velocidad de convergencia basado en epochs de los métodos cíclicos y el método decreciente (propio) combinados con la estrategia de Momentum\n",
        "\n",
        "\n",
        "> **Nota:** Si se utilizará Google Colab como ambiente para las pruebas, se debe tomar la referencia al repositorio para que la libreta tenga acceso a los archivos que requiere\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQc6T5wylcvf",
        "outputId": "94e00873-49a1-409b-b8e7-05b0c3d80ad6"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/DenisPerez/NN_Tests_DG.git\n",
        "# %cd NN_Tests_DG\n",
        "# %ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDBoEOe9hDan"
      },
      "source": [
        "Al tener disponible los archivos a referenciar, se realizan las importaciones necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F4gP7LPQTtg7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from get_images import get_images\n",
        "from classes import CyclicLRGiselt_Denis\n",
        "\n",
        "# PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mULGvWTthB"
      },
      "source": [
        "### Extracción del conjunto de datos: MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTSn33p6aEQ4"
      },
      "source": [
        "Este conjundo de datos esta basado en 60.000 imágenes en el conjunto de entrenamiento y 10.000 en el conjunto de prueba de 28x28 píxeles\n",
        "que representan dígitos del 0 al 9 escritos a mano y es considerado el \"Hola Mundo\" en el\n",
        "área de la ciencia de datos. Sin embargo, **10.000  de las muestras del conjunto de entrenamiento serán destinadas al conjunto de validación** con el que se te tomará la precisión en el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9vdIQd58TthD"
      },
      "outputs": [],
      "source": [
        "MNIST_PATH = './Dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "slQPSqQeTthE"
      },
      "outputs": [],
      "source": [
        "x_train_num, y_train_num, x_test_num, y_test_num = get_images(MNIST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HFnaRwd-TthE"
      },
      "outputs": [],
      "source": [
        "# Segmento para el conjunto de entrenamiento\n",
        "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)/255 ##Convert the traint set into a (50000, 28x28) matrix normalized\n",
        "y_train = y_train_num[:50000].reshape(50000,1)\n",
        "\n",
        "# Segmento para el conjunto de validacion\n",
        "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)/255\n",
        "y_val = y_train_num[50000:].reshape(10000,1)\n",
        "\n",
        "# Segmento para el conjunto de prueba\n",
        "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)/255\n",
        "y_test = y_test_num.copy().reshape(10000,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZz8hG0OTthF"
      },
      "source": [
        "### Normalización de la muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_kFtDZs6TthG"
      },
      "outputs": [],
      "source": [
        "def normalize(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn6S5bBIaKxH"
      },
      "source": [
        "Se toma la desviación estandar y la media de cada conjunto de datos y se llama a la función *normalize*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KYhJenIZTthG"
      },
      "outputs": [],
      "source": [
        "# Calculo para el conjunto de entrenamiento\n",
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "x_train = normalize(x_mean, x_std, x_train)\n",
        "\n",
        "# Calculo para el conjunto de validación\n",
        "x_mean = x_val.mean()\n",
        "x_std = x_val.std()\n",
        "x_val = normalize(x_mean, x_std, x_val)\n",
        "\n",
        "# Calculo para el conjunto de prueba\n",
        "x_mean = x_test.mean()\n",
        "x_std = x_test.std()\n",
        "x_test = normalize(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRx3THErTthH",
        "outputId": "c6b2ab37-c232-4ad5-fa79-7fdea49d898e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8.5686665e-08, 0.9999983)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMAv3EVXTthJ"
      },
      "source": [
        "### Visualización de la muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHHAe687TthJ",
        "outputId": "02321b8c-7152-4c47-c846-98c76582b7dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimensiones del conjunto de datos de entrenamiento\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_FPmhofTthK",
        "outputId": "b1eb16b6-c223-4e60-f67d-ebb8bbd14f13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dimensiones del conjunto de datos de prueba:\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w4HfkSTqTthK"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "7TQtWTpZTthL",
        "outputId": "b08d0ae9-11e1-4713-8c45-d787f243e4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La imagen muestreada representa un: 6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
        "plot_number(x_test_num[rnd_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVo-PF6cTthM"
      },
      "source": [
        "### Creación de mini lotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ym639R_PTthM"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(x, y, mb_size, shuffle = True):\n",
        "    '''\n",
        "    x  #muestras, input_layer\n",
        "    y #muestras, 1\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle: \n",
        "        idxs = np.arange(total_data, dtype=float)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]  \n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Ypqe6nTthN"
      },
      "source": [
        "### Conversión de arreglo a tensores para todos los conjuntos de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6quE_eQ9TthO"
      },
      "outputs": [],
      "source": [
        "# Conversion para el conjunto de entrenamiento\n",
        "x_train_tensor = torch.Tensor(x_train.copy())\n",
        "y_train_tensor = torch.Tensor(y_train.copy())\n",
        "\n",
        "# Conversion para el conjunto de validación\n",
        "x_val_tensor = torch.Tensor(x_val.copy())\n",
        "y_val_tensor = torch.Tensor(y_val.copy())\n",
        "\n",
        "# Conversion para el conjunto de prueba\n",
        "x_test_tensor = torch.Tensor(x_test.copy())\n",
        "y_test_tensor = torch.Tensor(y_test.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqPgXB1DTthP"
      },
      "source": [
        "### Habilitar el uso del CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QedBceD4c-SO"
      },
      "source": [
        "Primero se consulta si se tiene la plataforma CUDA disponible para la utilización de los recursos de GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1oc0PTWTthQ",
        "outputId": "c235088b-06ec-43e7-d1c5-2eb12450abfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhsDToTedAlu"
      },
      "source": [
        "En caso de no tenerse, se asigna el trabajo de computo al CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZebY-iBHTthQ",
        "outputId": "df88dceb-bac9-46cd-b594-4e1882afa1c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estamos usando: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Estamos usando: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHO4wesKdDzV"
      },
      "source": [
        "# Funciones "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L66abJ9WTthR"
      },
      "source": [
        "### Precisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Zt6iiZyuTthR"
      },
      "outputs": [],
      "source": [
        "def accuracy(model: nn.Sequential, x: torch.tensor, y: torch.tensor, mb_size: int):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) # mb_size, 10\n",
        "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
        "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
        "            num_total += pred.size(0)\n",
        "\n",
        "            return float(num_correct)/num_total  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4DuKf3TthR"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HtRDD6Nu0507"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler: None, mb_size):\n",
        "    model = model.to(device=device)\n",
        "    unregistered = True\n",
        "    epoch_acc = 0.0\n",
        "    iter_found = 0\n",
        "    i = 0\n",
        "    #plot lists\n",
        "    acc_list = [0.0]\n",
        "    cost_list = [0.0]\n",
        "    lr_list = [0.0]\n",
        "    while (i < 100):\n",
        "        if (epoch_acc >= 0.95 and unregistered):\n",
        "          iter_found = i\n",
        "          unregistered = False\n",
        "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "            # cost function\n",
        "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
        "            optimizer.zero_grad()\n",
        "            cost.backward()\n",
        "            for name, param in model.named_parameters():\n",
        "              ik = str(name)+'_'+str(i)\n",
        "              prev_ik = str(name)+'_'+str(i-1)\n",
        "            optimizer.step()\n",
        "        if (scheduler != None):\n",
        "          scheduler.step()\n",
        "          lr = scheduler.get_last_lr()\n",
        "          lr_list.append(lr[0])\n",
        "        else: \n",
        "          lr = optimizer.param_groups[0]['lr']\n",
        "          lr_list.append(lr)\n",
        "        i+=1\n",
        "        epoch_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
        "        epoch_cost = cost.item()\n",
        "\n",
        "        #append\n",
        "        acc_list.append(epoch_acc)\n",
        "        cost_list.append(epoch_cost)\n",
        "        print(f'Epoch: {len(acc_list) - 1}, learning_rate:{lr},costo: {epoch_cost}, accuracy: {epoch_acc}')\n",
        "    return acc_list, cost_list, lr_list, iter_found"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgICBmLcfGaN"
      },
      "source": [
        "### Operaciones en las trazas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3CrTwzYWfGaO"
      },
      "outputs": [],
      "source": [
        "def SumList(first: list, second: list) -> list:\n",
        "    return [x + y for x, y in zip(first[::-1], second[::-1])][::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wtgpbpnufGaO"
      },
      "outputs": [],
      "source": [
        "def DivideList(dic_list: list, number: int) -> list:\n",
        "    return [x / number for x in dic_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wIPWRLiJfGaO"
      },
      "outputs": [],
      "source": [
        "def DeleteZerosFromList(dic_list: list) -> list:\n",
        "    return list(filter(lambda num: num != 0, dic_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "015SGTIaTthS"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ2qa3c-eS1L"
      },
      "source": [
        "### Variables globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WBDuey1VQTm4"
      },
      "outputs": [],
      "source": [
        "MAX_ITERATIONS = 15\n",
        "\n",
        "layer1 = 1000 \n",
        "layer2 = 1000\n",
        "lr = 1e-2\n",
        "epochs = 100\n",
        "mb_size = 4096\n",
        "input_layer = 784\n",
        "first_i = 0\n",
        "dropout = 0.25\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "resultados = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKKLswGF1fN2"
      },
      "source": [
        "## Tasa de aprendizaje fija"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_K2LxlTdfwm"
      },
      "source": [
        "Mantiene un $\\alpha$ constante durante todo el entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVbs8IkEdy-1"
      },
      "source": [
        "![fija.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbAAAAFLCAYAAAC3G9nwAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAACxMAAAsTAQCanBgAACitSURBVHhe7d0HuGNlncfxizAwMkNxlCpIr64uOAoosuIuy4oiWLBhAxXLSrHirggoip0FQUBYsIBYEHQtKE2wUZ1RQYqICFgoShlAERhg9vdNcp49e0kyudfJzX2T7+d5fs89OZOcJCeZ8z/ve96cMyZJkiRJkiRJkiRJkiRJkiRNG89IDm5OFuH85PHNyaGxRfK15mTD5xPm/T0+lvxbc1KShtNjk0uS9Ru3Hul7tZyXnFW7vUMy1RYlGzYnh8b2yR+akw1PS1ZuTk7ak5PVm5PT2nOSo5qTS8QeyQHNSUmj4FPJe5uTj7BdLTcnb6/dXi2ZatOhgC3d+rukjC9go4SC85Pm5BLx/uSLzUlNJ0u1/koTtXuyc8Je/Z+SE5MfJ5XnJR9Intq41dkNyRuSc5NNk32SdZL7kx8lRycPJnxX/z2hhbZscmvyweT6ZJvk9cmayV+T7yZ0mXXy8uQlCYWL1839N0p+k8xIeD0UAJ6H98Rr4PWMx/O9K6H4sayfJkckf0nwleTbyb8mtErZqB6ePJDQncde/dcTXsv85MPJKxLW6+zkZ8lhyT0JLZ8vJx9NXpfMTOgirDasyyXsCGyb3J5cnLwvWSsBr+UTCc/znaQqmKxXHsvzsu7Y6dgs4d+vSP4r+XMC3ts5yRmNW2NjOyWsyznJr5JPJnwu7TwpeVOybnJv8tnkzGRWsm+ydcI65rXxnliftKT4Hl2VPDdhvfIaaN2Df39NwnfwroTP8tqEdb52wjp4KGF9dvuOdFu3WyWnJMsnlyc3JSyH1/3WhNfNa6X34HPJw4mkaY4NBxuXf0rek8xL2EhX2HD+LeE/fjcUsKrbkGL3quRZyYuSCxM27qAL7PvJjgkttRcnT0jwLwn347W8Mvl58sykHTZIvFbu988JxaneAqOAsrHneXhdpyVseNvhMWzMKHasCzbub0sqvDdeM//Gxp5/3ysBj2FD/qGE9/uPyW4JG3A2uPw7G+RDErDh53VSJLg/6/+ahGKPNydnJzwPz8cOQb0FVl/PrJuqxXtScllCwaQQsVFmvVB0T08oepUfJBR3UCh5b7xmXg/3OyFph1b1BQnFnvfFcbTq8zkw4Xl4bS9I2Gnh9YOWFMV4v4TPlgLP8UqKLkWGYsznzvugwFFM+L5xP4oN86vn6fYd6bZuWScUW9Yty6t2yD6SHJ+wrnhuivEuiaQCrJLQQsGqCf/hn9241cQGho0Ce7zd1DesKyQrJtUG6uMJe7VgA3R1wnGYRyVsqKrnZw+cPWLw90tJp0Ek7GWz5839aGVQqKoCxvOyB88GdpmEf39ZUu3xj/fo5DEJr4eW294JG9gK741WIi0clveW5KIEbMhpidHq5PGEgkCB4P7cfnrCHj+vo9rIstHl3yg4tEwodqC1QaHleXg8rd9OBazC58V747Xw3nkPfK4sn+fcNaGFW6kXMIorz8HnwGN5fbTE23UB06rhsXxPqufh9fM8vEbeA8/HZ05B/2oCChj/vkbC4zimSiuNosLntyChFcb75btQfQfadSF2+44sbt2O70LkM+dzoVXJ6+b9vDupXremCB+WNBlbJscktBjYQ6Ubhm6bChsV3Nf624uVkv9M2CMn7NlWLQz2tr+V0MX1jYRiwMYabODY8P1PcmpCd1H1uPHoHmPvnG4kupfqxYmN3HrJ/gnL+mZCUdo4aYcNLi02npP7vzYZ/7zs6bPRpRv00oTnr7AB/nVCtxNhnbKx573zXikQtGrZYFfoVuS+dKfdllBwwHLpwuR5eD7u1w1dpocmn04uSNiAsz2g9UF3Gs//joSWdLvtBK+VAsd7p8uO5bADUnVZ1rGhvzKhwPE8CxNeP+ubHRyKOp8F3xVax09MKhQKjpPyOIowhYrvCfdl/dD1yfeBlmq9B2C8Xr4jndbteHzPKdSMyuQ7wvOzo9Ppe6I+sYBpMvjPS3cLGz5aSbRq2DhVLSKwt3xLwrGJXnFMiI0ThZEuGlok1TLZ2B+Z0FVF1w0tMrobwWugIDFwhMexEay/ljo2TjxHhRZfhS49CgAj2HhPhILaqWuIY3IUjv9OeF6OZ41/3vHPxfGsCi2w+jGTu5OTk+q52SjTlcf8Co+p8FhaAOj2vsajcHAsiWNZbHwpKKAYsF6/kPB+aP2yk9BuO8FrYuNdvVZCy5UW7Hh8B2i1jMf6pnAtbh1VqnXFe+ZxvE6O0XGckGUclIBiN14v35FO63b88njvfE8oYNV7p+v4jYmmkAVMk8EGkL1N9vgpYux50z1UR/fXDxM2NL1iYAMDBuhu+l1Cd2GFrjY2bhyvYWAFG9bqt1scl6Cri+djz7neyhmPIfu0HNj7ppVYP75Fy4WWB8fJGMBANxSDEzq1Iv8h4Tgfr5f7cRxrPPbM2ZNnHdH9xvN3wsABnpsiwHPzGlh/vK7FYbm03ngeno9BNu2wUWYDTquGHQEKX2WThH/nOBTrud37qfBaOS5JFx+vlZYm25N6sa1QKOmeo6uS5fM50mXL++JnFLRy6Ypkx+jVCa36xaEg8jnTdc3nzrEyWpW4M2EdVC10TOQ7Mh7Lo4eBbkzQKqTlzvqh1cb/gd8m9QKoKWAB02T8PqEbhr149uD54XL9WAkYZMEe8kSwQWUjR5cUe9NsnCps3GiRsHHj+AUtMgZbgJZZteFjY8jxi064Dxvc4xIef0dSx/EOjm0xIIENL11jnTbkHBehpUlLhNGF49cBOG7H62ODz7ESWgud0PJj48hfRsnRsmPgQC9oEVOQeR6ejy67dtjRoKVVDeCofn/HfD5LXiNdmDw3repOON7DhptWCOuJlmN1zGg8umxppfDZ8NnyvWCd0rJhEAfdeyyP5+Qzr457dsN7pRuZ10y3IDsTfAbgeCAFuuoGxkS+I+MxgIPuYl4731EKFce8KPh8B1gmLbwNEk2hao9CmiiOFVUDNOgqZM+fIdRsOChoHKtiiHV9D78djkWw0WIvl24gNgpsnHgc89jTZu+ev2wgKC5071B4OH5EC4W9bf6NjS+FjRYTe98Uj3YYvcixGjagFB1ad+xR05pip47WGRt0lsfG6o+tjMdgAB5L64HH8v5ZbjVQg2M2DG2nlcJ7Ys+/OuZFK5ZWQHXfCo9nvXJ/npsiwmtkA8q6ogVRdWnRYq3WOa+bVvHjElo2fCb111KtZ14n0+NbxhyfY7mbJ3yWLIPXzTKr5+QvxzurHRN2KliXvFaWx2dS3+mo47PlM2JdcV/eE6+Rz4mWE8f5WC8U8BsT0OqhuPH5V9jB4bNiGbxWBlyA7wvrlm5JtmsUtKoblULb7TuyuHXLY1genzfrj+OxPJadF4670apkefQadCv6kgrAf2o2LqOu3ci/UlGk6NrkmJw0LdiFqH7geMREumg0vdFapCuOFg7HPSVJQ45uqXaj70pDFxqDMCYy8EGSJEntjPQgjk033fT8N72p01mCJElT4e1vf3v9LD49G+kCts022yy66KLxg8AkSVNpqWhNTshID+JYuLA6AYEkqTSOQpQkFckCJkkqkgVMklQkC5gkqUgWMElSkSxgkqQiWcAkSUWygEmSimQBkyQVyQImSSqSBUySVCQLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKZAGTJBXJAiZJKpIFTJJUJAuYJKlIFjBJUpEsYJKkIlnAJElFsoBJkopkAZMkFckCJkkqkgVMklQkC5gkqUgWMElSkSxgkqQiWcAkSUXqdwHbKjk5OSXZnRnjzEgOTvj3Y5PVE6yYHJ58L9mPGTUbJ59NeMw+yVJJ3UuT85OVGrckSUOpnwWMZR+SnJ4ck+yZrJPU7ZysnRyZXJdUxWpR8rPkimQjZtQclPwwOSp5dkKRrKyavDDZLKE4SpKGVD8LGEVk+eTM5MKEYrRjUrdbckZySUKLitu0qO5NvpVcndQ9Ntki+UZycfKjZJek8o7k1OS+xi1J0tDqZwFbP7kxoZjQoroy2TSp4/blzcmxW5JlE7oPH0ruSh5O6tZM7kzubtxqFsVqmdsmKyfnNG51RqvvOLJgwYLGDElSefpZwJZL7m9ONjDNvLr6fShyDybduv46LZPQ/chxtL8k3cxPjiezZs1qzJAklaefBey2hGNSlVUS5tXV77N0QkWpWlftcH+WU6mWyXG0bZIDk68kzKdIzUnGuzmhiM2fMcPDZJJUqn4WsMuSDZI1kmWSnZLzkjpuV8ewtk/oTnygcau9mxJaaZsnHCt7fsIyKEovTz6ZHJFQBOkmXFxrTJJUqPFD0Jcklr1vsl2yMLk1OSBhmPs1CQM71ksOTeg+nJnQBXhuAlpSHEejFfXz5F0Jx9RekTDYg+7DvyX7J7cndTckT03Gt/j+n7lz5y6aN29e65YkaRCWitbkhPSzgIHis2HC8zBIgwK0bnJPQtGhBchoxdkJRe6qpBpBSJcg3Yrch1YXLTpGJ66QMHCD+Xck1ybj8Vi6CVlmRxYwSRq86VrApjULmCQN3mQLWD+PgUmS1DcWMElSkSxgkqQiWcAkSUWygEmSimQBkyQVyQImSSqSBUySVCQLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKZAGTJBXJAiZJKpIFTJJUJAuYJKlIFjBJUpEsYJKkIlnAJElFsoBJkopkAZMkFckCJkkqkgVMklQkC5gkqUgWMElSkSxgkqQiWcAkSUWygEmSimQBkyQVyQImSSqSBUySVCQLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKZAGTJBXJAiZJKlK/C9hWycnJKcnuzBhnRnJwwr8fm6yeYMXk8OR7yX7MqNk4+WzCY/ZJlkrw5uSk5MTkg8nsRJI0pPpZwFj2IcnpyTHJnsk6Sd3OydrJkcl1SVWsFiU/S65INmJGzUHJD5OjkmcnFEncmVAEyUrJaxNJ0pDqZwHbLFk+OTO5MKEY7ZjU7ZackVyS0KLiNi2qe5NvJVcndY9Ntki+kVyc/CjZJcHZCfPmJfOTuYkkaUj1s4Ctn9yY3JfQoroy2TSp4/blzcmxW5JlE7oPH0ruSh5O6tZMaGnd3bjVLIrVMpnP82Db5BfNyUeg1XccWbBgQWOGJKk8/SxgyyX3NycbmGZeXf0+FJ8HE46LddLLMl+VrJqc2rj1SLTOjiezZs1qzJAklafXArZaUnXJUTDoGlyc2xIKSWWVhHl19fssnVBRqtZVO9yf5VTGL/M5ycsTBnHQomvn5oQiNn/GjG61UpI0nfVSwOhy+1jyocatZjH7SHOyq8uSDZI1kmWSnZLzkjpuV8ewtk/oTnygcau9mxJaaZsnHCt7flItk8Ecb0sOS37ODEnS8OqlgL0lYWTf4xu3xsb+nDyzOdkVB5joqmO0IEPpOQZGy4fRiM9IwHyGxTOA49+TjyeVryTMo1X1tYQRjBS3Tya0sHgMx8gYBIIPJBwP2yPhed+RSJKGVPUbqm5+mtC6YVj7lgldfbRwnpwszpxkw4TnoUuPQR3rJvcktycUUEYr8puthclVCYM+sE3Cc3EfWl206BiduEJCoWL+Hcm1CbZOmMdyQFfkr5uT7c2dO3fRvHkMWpQkDcpS0ZqckF4eRGuG310dkLwmeUHyuIQfDhfNAiZJgzfZAtZLFyLdevww+IaEAkbrqd7VJ0nSlOu16jEQg+5A0G3HSL7i2QKTpMHrRxfi+1vhvIPVD4TrOMZ0WnJB41aBLGCSNHj9KGDbJT9OGEY/HgWN32wx4u+5zCiRBUySBq8fBYzTOjFsfWbj1iPxK+Bdky82bhXIAiZJgzfZAtZtEEf1g2LOaXhEwgl0v518N+EM8wzm+GYiSdKU62UU4oEJRWu95MPJpQm/4QJFTJKkKddLAeN6XOcknDj3BwmtseqsHJIkDUQvBYwzY3B2Cy44+caEwR1cl0uSpIHppYBxEl9O6XRoQsvrKcnBiSRJA9NLAWO0IeECkfwm7ITEY1+SpIHqpYAdlHBG+bUSTidFV+JbE0mSBqaXAsaZ4s9OPpFwzS4wtF6SpIHppYD9LeH3X5yVnmt5cX2wXh4nSVLf9FKI+M3XXxIuqXJ4QuvLFpgkaaB6KWDVlY0ZSs9Ajs8k7c6PKEnSlOlWwPZu/X1FwhD6Kq9LdkwkSRqYbgXst62/XOb/6jaRJGlgup0BeIWE33ut3Lj1SAtaf4vl2eglafD6cTmVTheyrLy+9bdYFjBJGrx+XE7l6wmXUKGIkbNaeTh5KJEkaWC6FbBzW2HIPJdROaOVj7TmSZI0MN0KGGehJ3OS5ZO/tvLoxLPRS5IGqpd+x92TFyZ0G3J/Qtfil5OieQxMkgavH4M4KoxG3CRZqXFrbOyu5FcJZ+comgVMkgavH4M4KnQjUrw4G/06yebJixJJkgamlwLGoA0K1urJ41p/iSRJA9NLs21+8upk/EUsf9/6Wyy7ECVp8PrZhXhtQjciBaseSZIGppcCxnGvU5KTkxMTztDBX0mSBqaXZtvzE377xYUt66eW+k7rb7HsQpSkwetnF+I5yfXJ0gln5vhpckUiSdLA9FLAXpbskXB9MI6F8Zj3JZIkDUwvBYwRiFyFedXGrbGx25O5zUlJkgajlwLGj5h/mTzYuNV8DN2JkiQNTC8F7LzkncnsZOfkiKT4ARySpLItroAxMuTU5ObkwmSrhB82H51IkjQwiytgDJt/R/K95IPJF5LTkj8mkiQNTC9diDOT1ZLrWrkzkSRpoHopYGsnnIXjS4ln4pAkTQsTORMHvwF7mBktvQzk4JjZPgmF8oyEIlg3I3lvsnFyd/KB5JZkxdb0psmZyaeSCvf9j2S55OLk0wldnVy37OCEM+WzDB4//gTE/89kz8Rx7rnnjp1wwgljt95669iKK/JS8+LvvntstdVWG9t6663HLrnkkkf822Tu52NG931P5jGj+r4n85hRfd+TecxE7veGN7xhbIcddmjMm4jJnomjF3QhPinhysyvaE0zb3EoWhSfFyTbJpzRg/Mq1nGl5xOSrZN3JVy6BRQjfn/2iYQCVffF5LXJNsnXEx4Lfmj9sYTb/H1r0hUFbKLOOeecRVtsscWimTNnUjQXzZgxoxGmmbfmmmu2/bfJ3K8+PaqP6eey69PD8Jh+Lrs+PQyP6eey69PD8JiJ3I9tI9vIicrj++Y1ydcSzr5BvppQXBbnicmPEood1fXwZK+kjpMEU8SwRsKZ77kvvzPj92evS+oF7LEJp7Fqlv2xsbclhzYnxy5ItmxONv5yu6vJFLDtt99+0aMe9ajGB2aMMeb/wraRbeRE5bGT0ssxsDck/PaLlg85MhlfiNpZP7kxoeuRF3hlQpdgHbcvb042uv2WTShODyV3JfUuS6yZMIiE7kZQzKplbpTwHLgq4XY7/JbtOLJgwYLGjIm4+OKLxx5+ePzLkiSxbWQbOVV6KWC0hjgTxw2tMN3LmTg4RnV/c7KBaebV1e9DkeNsHxwX66TbMil+DzQnG/M7LYffsR1PZs2a1ZgxESutRMNQktTOVG4jeylgtHhOShg48Z6E34JxPkQGZ5BObkuq8ydilYR5dfX7UBSpKFXrqh3uz3Iq9WXyOuliBH87DffnR9kUsfkzZnSrle3tvffeY8stN74OS5LYNrKNnCq9FLDzk18kXA+M7sDLkh8mVb9nJ9xvg4RjW8skOyWclqqO27s0J8e2T+hOrFpR7dyU0ErbPOFYGSMkq2XyOrkN/v6gOblk7bXXXmP7779/Y8QNA2cYhUOYZt6uu+7a9t8mc7/69Kg+pp/Lrk8Pw2P6uez69DA8pp/Lrk8Pw2Mmcj+2jWwjp0ovQxcZlt4Nx67aYdn7JtslC5NbkwOSlybXJJyaar2EQRgUQgZ7HJtwzTF8JeE42pzk5wmjFDmmxkjI3RK6CSmq+ye0CBm4wfIpsjSRWC6Ft6PJDqNnKOn1118/dt99941VrbiFCxeOzZw5c2zOnDljd9xxxyP+bTL38zGj+74n85hRfd+Tecyovu/JPGYi91tvvfUahWyiUgB7qUWP0MuD1kooqQyB5zhThWH1i0Px2TDheSh0FKB1E36fRdGhBbhZwomCKXIMvqAAgWHydCtyH1pdtOjuTRhiz8AN5t+RMHIRrElaZhRClsGAjuoM+m15RWZJGrx+FjB+p0WXIS0dhtE/J6F4vCkpmgVMkgZvsgWsl2Ng/5hUZ904K+FHwnT9SZI0ML0UMH6TxQ+m/pAwEINzI9KtKEnSwPRSwDgPIceVaHk9O2EQxccTSZIGppd+RwZNMHiCofB0HTKw4vdJt99rFcFjYJI0eP08BsaIQboRGbb+q4TRfcUXL0lS2XopYJIkTTsWMElSkXopYIw4/K/kc41bzbNj9HI5FUmS+qaXAnZQcmlSXWuLU0Lt2ZyUJGkweilgT07OSKoT9/41qc76LknSQPRSwP6SMJS+KmDPSsZfFkWSpCnVSwH7RMI5EJ+QnJa8JeFHzZIkDUwvPx7jLBybJJwjn9+DcQb4q5PqrPHF8ofMkjR4/fgh80ta4eKQGydcGoWrJ3N5lOrCkZIkDUS3Akari+yQcI1oBnM8KXlr8s+JJEkD062AfbEVfvd1cHJiK+9PNkgkSRqYbgXshlZWTy5OrmuF6TUSSZIGppdRiOcnxyR7tML0eYkkSQPTSwE7LDk34cfL5JzWPEmSBqbXoYuzk5Wbk42rM/Pj5uI5jF6SBq+f1wMDBesPrQxF8ZIkla3XAiZJ0rRiAZMkFamXArZ58pnkewkDOBiByNnpJUkamF4K2IHJd5P1kg8nXBvs9kSSpIHppYBtlNDyuj/5QXJE8vhEkqSB6aWAcdb5hQln4Xhjsl3iBS0lSQPVSwH7ULJ0cmhCy+spCedGlCRpYHopYHQb0gL7RXJqwqmlzk4kSRqYXgrYRxMuarl8QsvrVcmeiSRJA9NLAds2YQAH1wBj9CGDOF6WSJI0ML0UsOUSzoPI1Zn/J/lZ8phEkqSB6aWAnZR8KuE42AUJ1wLjnIiSJA1MLwXsCwndhvyI+Z7kzuTdiSRJA9NLAbsrWSt5XrJ/sm9rWpKkgemlgL0veVLyyoTBHPyQ+QmJJEkD062A8eNl7JB8MWEY/VcThtJvnEiSNDDdChhnoMeM5PqErsRHJ79NbIFJkgaqWwGb2/r7rWSF5LiEwRy0xk5PJEkamG4FrPrtFy2v5yfLJpzQl/wp6cVWycnJKcnuzBiH1h1dkvz7scnqSYVjbszn8U9jRsuLk88ln092Y0bLhskxyQkJxXbTRJI0pLoVME4fxbGuFZP1k9WSO5I/J7OTxWHZhyS01igsnH5qnaRu52Tt5MiEwrhfAu63R0JROy1hOSyPa5K9OTkxoYuTAltd2uWdyS8T5l+WONRfkoZYtwJGsaK7sFMWZ7OEgR9nJhcmVyQ7JnW0oLi68yUJrS1uL5VwP+7P485KZiUsj6tDL0iYz2P4QXW1TIosLcN5CUV2pUSSNKS6FTDOvHFjckObMH9xKCjcj+uJLUquTMZ363H78ubk2C0J3ZS0+JhPAXs44fG/S1jercm6CS1A7rtJ8sQEn072Tjhj/j7J0Uk7tProYjxuwQJqoSSpRN0K2DtafyeLcyjyu7EK08yrq9+HIvdgwnGxTo+9KvluwmCSwxLOCsL9QSGjtXd462/9+Fjd/OR4MmsWDTtJUom6FbAft/5O1m3Jqs3JhlUS5tXV78PvzqgodyedHntvwjEuWlcM1rg5oXUGjrF9Nrko4d92TdrhMRSx+TNmVLVPklSabgWM1tDfg4EUGySc/HeZZKfkvKSO27s0J8e2T+hOfCBhPvenwvB4lsMFNfG3hAJ0U/L05NsJeI5qQAenvqIQSpKGFAMm+oVlc95ETj3F8TSOXx2QvDS5JmEgBqMKD03oPmTUI6MOz01oiTGfkY8UJlqDRyXcjxYY92X+TxJaWxTb1yf/lnDCYQaP8Pu1LycdzZ07d9G8eYz5kCQNylLRmpyQfhYwzEn4fRbPwyANBnUwCIMiw8UxaQEyupBBGRQ5jnExaAMMped3YRSt3ySMisSWCcWL+Qy95zgYGHVYPReDP65NeJ6OLGCSNHjTtYBNaxYwSRq8yRawbsfAJEmatixgkqQiWcAkSUWygEmSimQBkyQVyQImSSqSBUySVCQLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKZAGTJBXJAiZJKpIFTJJUJAuYJKlIFjBJUpEsYJKkIlnAJElFsoBJkopkAZMkFckCJkkqkgVMklQkC5gkqUgWMElSkSxgkqQiWcAkSUWygEmSimQBkyQVyQImSSqSBUySVCQLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKZAGTJBXJAiZJKpIFTJJUpH4XsK2Sk5NTkt2ZMc6M5OCEfz82WT2pvDJhPo9/GjNaXpx8Lvl8shszal6UnJTwb29ihiRpOPWzgLHsQ5LTk2OSPZN1krqdk7WTI5Prkv0ScL89EoraaQnLYXnrJW9OTkw+k7wkeXyCLZOXJsclRyfzEknSkOpnAdssWT45M7kwuSLZMamjBXVGcklCa4vbSyXcj/vzuLOSWQnL2zxZkDCfx/whqZb52uTs5KLkp8nliSRpSPWzgK2f3JjclyxKrkw2Teq4XRWaW5JlkxUT5lPAHk54/O8Slndrsm4yO+G+myRPTEB35coJra9PJRsk7dDqo5V23IIF1EJJUon6WcCWS+5vTjYwzby6+n0ocg8mHBfr9Nirku8mRySHJXcm3B8rJGslJyQXJ59MaM2NNz85nsyaRcNOklSifhaw25JVm5MNqyTMq6vfZ+mEinJ30umx9yYc+6KVRaG6OaF1Bv6d7kMK1HcSuhxXSsbjMdxn/owZVe2TJJWmnwXssoRuvDWSZZKdkvOSOm7v0pwc2z6hO/GBhPncnwrD41nOLxL8LaEA3ZQ8Pfl2gu8nDAgBhYvnpOBJkoZQuy62JYVl75tslyxMOH51QMJIwWsSBmIwqvDQhO7DmQmjDs9NaIkxf7WEQvTj5KiE+9EC477M/0lCS4yuxyckBybMp/CxfEY/djR37txF8+Y5WFGSBmmpaE1OSD8LGOYkGyY8D4M0GNTBIIx7ktsTWoB09TEogyLHMS4GbYCh9PwujKL1m+SOBAyXp0gxn6H3HAcDz8HgD5bF4A/+resoDQuYJA3edC1g05oFTJIGb7IFrJ/HwCRJ6hsLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKZAGTJBXJAiZJKpIFTJJUJAuYJKlIFjBJUpEsYJKkIlnAJElFsoBJkopkAZMkFckCJkkqkgVMklQkC5gkqUgWMElSkSxgkqQiWcAkSUWygEmSimQBkyQVyQImSSqSBUySVCQLmCSpSBYwSVKRLGCSpCJZwCRJRbKASZKKtFTr70iaPXv2gs033/zW1s2eLLPMMis9+OCDd7VujiTXgeug4npwHeDvXQeXXnrpN/Nn/+at3o10AYttk/uakz37bPK65uTIch24DiquB9cB/t51sDC5vDmpfprX+jvKXAeug4rrwXWAgawDj4FJkopkAZu477T+jjLXgeug4npwHcB1UIg1Wn9HmevAdVBxPbgO4DqQJEmSpKE26sPoJ2KrZJ+E44ZnJF9KRsGqyX8mj2ncGhv7dnJ6skJycLJ6ckvygeSeZJjx2R+X3JawTug2OShZMfl1cmjyYDKsZifvTtZLFiUfT36XjNL34CXJ8xLe/2+TjyWPTYb9e8BvtJ6eLEj2ZEZ02gZQV/ZOtkn4mdJHk2uTJc5BHL1hPR2SsOE+JuEDXCcZBcskFyZHJ59L+GLy3l+bPJQc1fr7mmTY7ZaskjypcWtsbL/kuuTIZO1k52SYvT35a/LphEJ+ZzJK34PHJfsmJyRsB/4h2SEZhe/BDQk/Nn5a41ZTp89+6+TZCfN/mFDcNUBPTH6UzEzYuzg82SsZBcsm7Hlj6eSc5J+SC5ItE/CX28OMwnVq8sqEEVd8D9irrA5evzA5pTk5lGYlP0/WbNxqvn92bkbpe/D4hBbnygn/F9igPz8Zhe/BSsmGyRWNW02dPntaoG9rTjZapVcmtFKXOFtgvVk/uTGhOUzXAR/IpskoeCD5S3OysRHnPzFdJxslrAdclXB7mL0z+Vryx8at5n/MGQldJ/hlMszfCVoWYC/7v5N3JRSwUfoe0HXMTgzfg68nbA/YoI/C94DTRI3vFu302fP+WQ+4O6GlXu34LFEWsN4sl9zfnGxgmnmj5NEJxzw+n9yc0DKjuIH1wX/iYUXfP3uQZzZuNfF++Q/NDg2G/TtBC2zd5JqE7kO6kV+djNL3gPf6hISuwsMSCvhmySh9D+o6ffZTtr20gPWGPS8GM1RoiTBvVPAflW4BChfnPKO/m72qqluAv9weVs9K6Pun5UF/Pt0lDOiha5WuJAz7d4L3Rovj+wmnDTov+ZdklL4HHNvhnH3syPw4ocuM7vRR+h7Udfrsp2x7aQHrzWXJBgn93GzMd0r4DzwKONbxnoT/pByUrb6I5yf0/4O/P2hODiW6jd6SHJGcllyffCWhm2T7BLskw/ydYOfl9wnHQkCX4u3JKH0PaG1wOKHabtIaY6M9St+Duk6fPe+f22w7Nk9ood6ULHE8gRaP9cToo+0S9sC4BMsBCSOyhh0j7hi4QddRNRSWlgj/mVkH7JXTPUAL7RfJsGNDxfEfRpoxAo3CxjrgO/LehNFaw4oh5Gyg+ez5zD+RsDEfle8Bxz0ZEs5ftgO0umiRM7hh2L8HByYMi39mcnbCiGR2atp99rTGONzAYQe6GRm9/eVkibOA9W5OwheVdcYBWwZ1jAL2uOkyqwZygEEc/N6DvStGZvIF5mDusP32pR1GoNH6YK+b9846oO+f9XN18nAyrGiFb5Lwf4DP/Fet6VH6HnAckO4xjnnxmbNjx0Z62L8HvD+++7xHdmAo0PTGdPrsGdDBNpP1wPdk2H8jKkmSJEmSJEmSJEmSNLochShNLc6hyQ+BObMFZ7Nod968PRKG6XPm7wrnlquPBP17/EdyUcKJVqVi+UNmaWpxKQ5+1FmdxaIdhmr/IflMLQxTXlI4Vx1nR5CKZgtMmhpvTjgdFWdx4VRE/CD08uRbyUlJ3fsTWlufbNz6P89J+DE9rTcu7cEPzL+QgB8ZP7c52bheHWcMwY7Jy5qTjUt+fDjhfJacVZ3f6RDObUhrjB+g8sNcls+PdLnqAq9RkjTCOBXZqxLOZM4ZDThjwVOTdteVo4BdknDdKUIhAV2L/HCW8+9RyDiVDz8s3jihmDGPfzs34YektOSYT2uP5+KirKCA0XU5N6G4cWYF8Po4SS335bx/1SVCpGnJLkRpatD64awEnAD2zwmXn+BYWKczunCMquo+rFpZ4Iq//BvL4YwPz2iF03xx4VHmM808Wnmct5Fr2fFcP0sqlybzE66wTSEDXZoULi7UeEfyp0SatixgUv9xCjJaUlzRmGNgXI6Di6Qyr9NlJjgGRtEh9XMLUlg4Dx/FkFP5cF4+TvfFNFcJIEwz7zEJxZL7o36KJ85jh3uT6jX8JKGLkVNGfTCh5SZNWxYwqf84dyYtKa5k8L6EgvKR1ryquPSK7r0VEooOLSwuqMhxKqaZx3np6EpkHi0uTj5MkQOPq7Q7Vx+PpVuSk6/SYmQ50rRlAZP6jwEZv0nokuPYFgWFwRu0rjqd9JVBGdUxMLJ6AoohxY+zgdMNSVfgTxOWdXwrPEfVcjsrOSY5Mdkv6YZjc8cmhySMVKyOjUnTkqMQpanBWbyrS60/JakfjxqPwRcMoKi3zmhpvTzZNjk6obXFZX2qy3aslVSDLugepAsSFD7Onl+dPZ0zg/M6uJYX3YugpcUFGuv3pSuSY2xLcvi+JGlEMQrx081JSZLKQQuJ4fGSJEmSJEmSJEmSJEmSJEmSJmls7H8BUwHDF9BTgBQAAAAASUVORK5CYII=)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MVrJ7coqfGaQ"
      },
      "outputs": [],
      "source": [
        "def Fixed():\n",
        "    modelFixed = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelFixed.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    start.record()\n",
        "    fixed_acc_list, fixed_cost_list, fixed_lr_list, fixed_epochs = train(modelFixed, optimizer,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    fixed_time = start.elapsed_time(end)\n",
        "\n",
        "    fixed_acc = accuracy(modelFixed, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return fixed_acc_list, fixed_cost_list, fixed_lr_list, fixed_time, fixed_acc, fixed_epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipwfv9PgTthT",
        "outputId": "db668725-72d2-49f6-8070-62fcddb6a29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:0.01,costo: 2.237377166748047, accuracy: 0.367431640625\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.164257049560547, accuracy: 0.5986328125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.08892822265625, accuracy: 0.693115234375\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0075948238372803, accuracy: 0.727294921875\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9098726511001587, accuracy: 0.7373046875\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.7974061965942383, accuracy: 0.751220703125\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6769201755523682, accuracy: 0.75927734375\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.5796570777893066, accuracy: 0.765380859375\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4700934886932373, accuracy: 0.780029296875\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3364646434783936, accuracy: 0.796875\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2016936540603638, accuracy: 0.8095703125\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.0900404453277588, accuracy: 0.811279296875\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0171849727630615, accuracy: 0.841552734375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9763191938400269, accuracy: 0.838623046875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9057559370994568, accuracy: 0.8515625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8564712405204773, accuracy: 0.852294921875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7976839542388916, accuracy: 0.85400390625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7656146883964539, accuracy: 0.876220703125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.6837974190711975, accuracy: 0.86376953125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.6891274452209473, accuracy: 0.877197265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6574486494064331, accuracy: 0.880126953125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.690099835395813, accuracy: 0.874267578125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.5966929793357849, accuracy: 0.879150390625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6522132754325867, accuracy: 0.882080078125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5272642970085144, accuracy: 0.885498046875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.594433069229126, accuracy: 0.884033203125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.58026522397995, accuracy: 0.8955078125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5426468253135681, accuracy: 0.8916015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5323852896690369, accuracy: 0.889892578125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5114670395851135, accuracy: 0.892333984375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5293988585472107, accuracy: 0.89599609375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5103921890258789, accuracy: 0.8955078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.49864524602890015, accuracy: 0.894775390625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.508764922618866, accuracy: 0.897705078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4586075246334076, accuracy: 0.8994140625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.49417218565940857, accuracy: 0.89501953125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.43741464614868164, accuracy: 0.8984375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.40740305185317993, accuracy: 0.900634765625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4522075653076172, accuracy: 0.90087890625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.440487802028656, accuracy: 0.901123046875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.44979873299598694, accuracy: 0.90234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.413849800825119, accuracy: 0.901123046875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.41332852840423584, accuracy: 0.900146484375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.47035056352615356, accuracy: 0.902099609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.45785078406333923, accuracy: 0.899658203125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.47197288274765015, accuracy: 0.907958984375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.4444686472415924, accuracy: 0.91357421875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.381305456161499, accuracy: 0.901123046875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.3719618022441864, accuracy: 0.9072265625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.376201868057251, accuracy: 0.903564453125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.38350462913513184, accuracy: 0.90576171875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.37091562151908875, accuracy: 0.911865234375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.4143226146697998, accuracy: 0.906494140625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.40553784370422363, accuracy: 0.912353515625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.40039101243019104, accuracy: 0.90966796875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.388042151927948, accuracy: 0.909912109375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.37439051270484924, accuracy: 0.9091796875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.385274201631546, accuracy: 0.907958984375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.41134417057037354, accuracy: 0.912353515625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.3586205542087555, accuracy: 0.916259765625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3707903027534485, accuracy: 0.912841796875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.398914635181427, accuracy: 0.912109375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.37135401368141174, accuracy: 0.908203125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3621845245361328, accuracy: 0.911376953125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.32659289240837097, accuracy: 0.917236328125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3612009584903717, accuracy: 0.915283203125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.4047786295413971, accuracy: 0.90869140625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.2923004627227783, accuracy: 0.9169921875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.34901148080825806, accuracy: 0.912353515625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.331487238407135, accuracy: 0.919189453125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3576955199241638, accuracy: 0.91015625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.32206428050994873, accuracy: 0.91845703125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3649068772792816, accuracy: 0.9228515625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.37399840354919434, accuracy: 0.921630859375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.34578028321266174, accuracy: 0.918701171875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.3287797272205353, accuracy: 0.91943359375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3637448847293854, accuracy: 0.915771484375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.36874958872795105, accuracy: 0.919921875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.36618858575820923, accuracy: 0.918701171875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.3967357575893402, accuracy: 0.9169921875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.3512445092201233, accuracy: 0.918701171875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.37303614616394043, accuracy: 0.916259765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.34732785820961, accuracy: 0.921142578125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3460882604122162, accuracy: 0.91845703125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.30880630016326904, accuracy: 0.921142578125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.3365325927734375, accuracy: 0.921630859375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.34415602684020996, accuracy: 0.916015625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.35820719599723816, accuracy: 0.9169921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3428005278110504, accuracy: 0.917724609375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3089636266231537, accuracy: 0.923828125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.3582146167755127, accuracy: 0.92138671875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.30952370166778564, accuracy: 0.920166015625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.3083975911140442, accuracy: 0.92333984375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.335978239774704, accuracy: 0.9228515625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3669116795063019, accuracy: 0.92529296875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.28926533460617065, accuracy: 0.921142578125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.35288116335868835, accuracy: 0.923095703125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.29294776916503906, accuracy: 0.925537109375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.3351878821849823, accuracy: 0.926513671875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.28788474202156067, accuracy: 0.925048828125\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.225146532058716, accuracy: 0.42529296875\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.157719850540161, accuracy: 0.616943359375\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.078035354614258, accuracy: 0.68603515625\n",
            "Epoch: 4, learning_rate:0.01,costo: 1.9922069311141968, accuracy: 0.717529296875\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9046622514724731, accuracy: 0.7314453125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.777213215827942, accuracy: 0.7431640625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6670175790786743, accuracy: 0.76611328125\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.540945291519165, accuracy: 0.7744140625\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.454725980758667, accuracy: 0.773193359375\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3207926750183105, accuracy: 0.797119140625\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.1896692514419556, accuracy: 0.8076171875\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.0633223056793213, accuracy: 0.8310546875\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0425087213516235, accuracy: 0.823974609375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9516555070877075, accuracy: 0.8359375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.8524163961410522, accuracy: 0.84423828125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8228645324707031, accuracy: 0.8486328125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.8292731642723083, accuracy: 0.855712890625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7324038147926331, accuracy: 0.851806640625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7298462390899658, accuracy: 0.86279296875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.6724265217781067, accuracy: 0.866455078125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6662552952766418, accuracy: 0.868408203125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6133774518966675, accuracy: 0.873779296875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.5979185700416565, accuracy: 0.8798828125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.5825390815734863, accuracy: 0.875732421875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5958863496780396, accuracy: 0.877685546875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5620787143707275, accuracy: 0.88427734375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5468972325325012, accuracy: 0.8818359375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5533947944641113, accuracy: 0.88525390625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5376213788986206, accuracy: 0.88720703125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.4863505959510803, accuracy: 0.891357421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5338046550750732, accuracy: 0.890625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.52494877576828, accuracy: 0.890625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5060768723487854, accuracy: 0.90087890625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4954587519168854, accuracy: 0.8974609375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4768153429031372, accuracy: 0.892333984375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4844664931297302, accuracy: 0.89404296875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4670822322368622, accuracy: 0.8984375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.45526123046875, accuracy: 0.895263671875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.45453158020973206, accuracy: 0.906005859375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.4475201368331909, accuracy: 0.901611328125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.43027058243751526, accuracy: 0.908203125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.45719435811042786, accuracy: 0.90576171875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4427771270275116, accuracy: 0.898193359375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.46921873092651367, accuracy: 0.902587890625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.39318567514419556, accuracy: 0.90576171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.4264044463634491, accuracy: 0.9033203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.4111178517341614, accuracy: 0.908203125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.4164147675037384, accuracy: 0.903076171875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.4488900303840637, accuracy: 0.905517578125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.3890998065471649, accuracy: 0.90576171875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.394368052482605, accuracy: 0.908447265625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.39286893606185913, accuracy: 0.909912109375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.3536418378353119, accuracy: 0.90966796875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.36557888984680176, accuracy: 0.910400390625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.42813989520072937, accuracy: 0.91162109375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.3643825352191925, accuracy: 0.90771484375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.3943331241607666, accuracy: 0.904541015625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.3882425129413605, accuracy: 0.912353515625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3617998957633972, accuracy: 0.91162109375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.4085901081562042, accuracy: 0.90478515625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3839525282382965, accuracy: 0.91455078125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.3566901683807373, accuracy: 0.912353515625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.3133385181427002, accuracy: 0.914794921875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.312915563583374, accuracy: 0.9130859375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3640801012516022, accuracy: 0.907470703125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.373267263174057, accuracy: 0.914794921875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3286486864089966, accuracy: 0.910400390625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3788066506385803, accuracy: 0.912353515625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3750513195991516, accuracy: 0.915283203125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.348758339881897, accuracy: 0.91162109375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3728613257408142, accuracy: 0.915283203125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.31510525941848755, accuracy: 0.914306640625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.38450777530670166, accuracy: 0.91259765625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3687504529953003, accuracy: 0.924560546875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.36339735984802246, accuracy: 0.913330078125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.33361873030662537, accuracy: 0.919921875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3498377203941345, accuracy: 0.91748046875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.36374104022979736, accuracy: 0.924560546875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.4472474157810211, accuracy: 0.91357421875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.361329048871994, accuracy: 0.92041015625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.34056106209754944, accuracy: 0.92236328125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.34109848737716675, accuracy: 0.918701171875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.28872379660606384, accuracy: 0.92333984375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3532079756259918, accuracy: 0.91650390625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.345130980014801, accuracy: 0.91845703125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.26907292008399963, accuracy: 0.92138671875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.29705336689949036, accuracy: 0.916748046875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.3510839641094208, accuracy: 0.919677734375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.2947077751159668, accuracy: 0.921142578125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.34435510635375977, accuracy: 0.92236328125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.2949780821800232, accuracy: 0.919677734375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.31953293085098267, accuracy: 0.923828125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.3772437572479248, accuracy: 0.92041015625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.30013594031333923, accuracy: 0.926513671875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.2719830572605133, accuracy: 0.9248046875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3332282602787018, accuracy: 0.92724609375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.25479477643966675, accuracy: 0.92236328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3396602272987366, accuracy: 0.925537109375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.35212159156799316, accuracy: 0.926025390625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.33847683668136597, accuracy: 0.92431640625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2437031269073486, accuracy: 0.32275390625\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1743078231811523, accuracy: 0.532470703125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.1025662422180176, accuracy: 0.641357421875\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.021784782409668, accuracy: 0.677490234375\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9262932538986206, accuracy: 0.710205078125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8190568685531616, accuracy: 0.7294921875\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7320683002471924, accuracy: 0.750244140625\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.5767525434494019, accuracy: 0.7666015625\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4746397733688354, accuracy: 0.777099609375\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3422456979751587, accuracy: 0.7802734375\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2510743141174316, accuracy: 0.798583984375\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.151883840560913, accuracy: 0.811767578125\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0140286684036255, accuracy: 0.818115234375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.976317286491394, accuracy: 0.836669921875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.953464925289154, accuracy: 0.83642578125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8358299732208252, accuracy: 0.85009765625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.8541487455368042, accuracy: 0.849609375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7620027661323547, accuracy: 0.85791015625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7115331888198853, accuracy: 0.85693359375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7178719639778137, accuracy: 0.86572265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.683843195438385, accuracy: 0.864501953125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.623271107673645, accuracy: 0.8740234375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6378474831581116, accuracy: 0.86669921875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6276747584342957, accuracy: 0.881591796875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.574609637260437, accuracy: 0.88037109375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.616959273815155, accuracy: 0.88232421875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5816504955291748, accuracy: 0.88232421875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5472010970115662, accuracy: 0.885498046875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.517785906791687, accuracy: 0.8876953125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.48371708393096924, accuracy: 0.8876953125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5062244534492493, accuracy: 0.886962890625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.4887823164463043, accuracy: 0.88720703125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.4951724708080292, accuracy: 0.89501953125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4674612581729889, accuracy: 0.89697265625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.45764121413230896, accuracy: 0.896728515625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4785289168357849, accuracy: 0.89794921875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4369402825832367, accuracy: 0.89599609375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.46561378240585327, accuracy: 0.90576171875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4997985363006592, accuracy: 0.902099609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.4526330828666687, accuracy: 0.8984375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.5080539584159851, accuracy: 0.90478515625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.45415014028549194, accuracy: 0.899169921875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.424109548330307, accuracy: 0.903076171875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.42781609296798706, accuracy: 0.904541015625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.47022172808647156, accuracy: 0.901611328125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.43858760595321655, accuracy: 0.902099609375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.3976673185825348, accuracy: 0.9013671875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.44095882773399353, accuracy: 0.905517578125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.4240924119949341, accuracy: 0.900634765625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.42426785826683044, accuracy: 0.911865234375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.35715311765670776, accuracy: 0.90283203125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.3959660530090332, accuracy: 0.9013671875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.35332536697387695, accuracy: 0.90625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.3824537396430969, accuracy: 0.9052734375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4176095128059387, accuracy: 0.90625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.36537832021713257, accuracy: 0.91259765625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.37139561772346497, accuracy: 0.91259765625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.3907829225063324, accuracy: 0.915283203125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.34937986731529236, accuracy: 0.905029296875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.3777707517147064, accuracy: 0.90185546875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3916918635368347, accuracy: 0.912841796875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.3762909471988678, accuracy: 0.9091796875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.3476592004299164, accuracy: 0.914794921875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3998498022556305, accuracy: 0.91162109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.38932085037231445, accuracy: 0.913818359375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3850290775299072, accuracy: 0.90966796875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3714727759361267, accuracy: 0.9091796875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3480418920516968, accuracy: 0.91455078125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3172503709793091, accuracy: 0.914306640625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.3423211872577667, accuracy: 0.912109375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3745167851448059, accuracy: 0.9130859375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.3335719704627991, accuracy: 0.91455078125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3329576551914215, accuracy: 0.91357421875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.35989314317703247, accuracy: 0.91552734375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.34400245547294617, accuracy: 0.909912109375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.3432370722293854, accuracy: 0.918212890625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3554089367389679, accuracy: 0.919189453125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3556358516216278, accuracy: 0.91748046875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.33926236629486084, accuracy: 0.91796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.33168312907218933, accuracy: 0.9169921875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.39816540479660034, accuracy: 0.914306640625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.300273060798645, accuracy: 0.921875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.28789839148521423, accuracy: 0.91796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.332669198513031, accuracy: 0.916748046875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.3184563219547272, accuracy: 0.918701171875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.294749915599823, accuracy: 0.922119140625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.31229713559150696, accuracy: 0.92626953125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.3299916088581085, accuracy: 0.9208984375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3333929479122162, accuracy: 0.925048828125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.36876940727233887, accuracy: 0.9267578125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.3247426152229309, accuracy: 0.920166015625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3165789544582367, accuracy: 0.9189453125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.34121638536453247, accuracy: 0.92333984375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.294486939907074, accuracy: 0.924072265625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3340896666049957, accuracy: 0.9189453125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3110676407814026, accuracy: 0.919921875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.37892791628837585, accuracy: 0.924072265625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.31613996624946594, accuracy: 0.926513671875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.29927700757980347, accuracy: 0.928466796875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.30469441413879395, accuracy: 0.924072265625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.23404860496521, accuracy: 0.35302734375\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1570682525634766, accuracy: 0.6455078125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0855889320373535, accuracy: 0.7197265625\n",
            "Epoch: 4, learning_rate:0.01,costo: 1.995557427406311, accuracy: 0.74462890625\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9157861471176147, accuracy: 0.760986328125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.7876942157745361, accuracy: 0.765625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6958445310592651, accuracy: 0.77197265625\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.5678541660308838, accuracy: 0.789306640625\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.449163794517517, accuracy: 0.798095703125\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.324234127998352, accuracy: 0.802978515625\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2351740598678589, accuracy: 0.812255859375\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.0891607999801636, accuracy: 0.826904296875\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0063685178756714, accuracy: 0.82470703125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9708301424980164, accuracy: 0.834228515625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9060186147689819, accuracy: 0.835693359375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8367983102798462, accuracy: 0.851318359375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7965505123138428, accuracy: 0.853515625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7270352244377136, accuracy: 0.86474609375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7101444005966187, accuracy: 0.867431640625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7134019136428833, accuracy: 0.8701171875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.674248993396759, accuracy: 0.869384765625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.7087035179138184, accuracy: 0.873779296875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6193875074386597, accuracy: 0.87109375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6507593393325806, accuracy: 0.87451171875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.6263310313224792, accuracy: 0.87841796875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5548218488693237, accuracy: 0.8779296875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.6130987405776978, accuracy: 0.87744140625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5721642971038818, accuracy: 0.884765625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5639181733131409, accuracy: 0.883056640625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5316309928894043, accuracy: 0.89453125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5181117653846741, accuracy: 0.88623046875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5151678919792175, accuracy: 0.8896484375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5427783131599426, accuracy: 0.88916015625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.5010581612586975, accuracy: 0.897216796875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4706067740917206, accuracy: 0.895751953125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.46769458055496216, accuracy: 0.900146484375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4535137116909027, accuracy: 0.894775390625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.4883275628089905, accuracy: 0.890869140625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.44470909237861633, accuracy: 0.899169921875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.4527069330215454, accuracy: 0.89990234375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4134063720703125, accuracy: 0.900146484375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4191085398197174, accuracy: 0.899169921875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4533807933330536, accuracy: 0.9013671875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.3992560803890228, accuracy: 0.89794921875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.4306659400463104, accuracy: 0.901611328125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.39950838685035706, accuracy: 0.901611328125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.43035873770713806, accuracy: 0.9013671875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.3831242024898529, accuracy: 0.897705078125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.39172109961509705, accuracy: 0.902587890625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.3863683044910431, accuracy: 0.906005859375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.3948199152946472, accuracy: 0.903564453125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.42890465259552, accuracy: 0.90576171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.4127258062362671, accuracy: 0.903076171875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.41358205676078796, accuracy: 0.906005859375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4136945605278015, accuracy: 0.904052734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.3881532549858093, accuracy: 0.906982421875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.3844251334667206, accuracy: 0.908935546875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.39256593585014343, accuracy: 0.91259765625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3703635632991791, accuracy: 0.911865234375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.38010191917419434, accuracy: 0.910400390625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3999122977256775, accuracy: 0.908447265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.36600056290626526, accuracy: 0.912353515625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.35545989871025085, accuracy: 0.909423828125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.40755772590637207, accuracy: 0.913818359375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3631986975669861, accuracy: 0.909423828125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3902258276939392, accuracy: 0.913818359375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.36736708879470825, accuracy: 0.905517578125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3606889843940735, accuracy: 0.92138671875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.363529771566391, accuracy: 0.9189453125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.34619542956352234, accuracy: 0.911865234375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.35388532280921936, accuracy: 0.916259765625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.36612164974212646, accuracy: 0.9130859375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3967423439025879, accuracy: 0.91845703125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.37563446164131165, accuracy: 0.91943359375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3155475854873657, accuracy: 0.917724609375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.36783844232559204, accuracy: 0.91064453125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.37862759828567505, accuracy: 0.916015625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3765006959438324, accuracy: 0.913818359375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.32982751727104187, accuracy: 0.91650390625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.30574196577072144, accuracy: 0.917724609375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.4196242690086365, accuracy: 0.9189453125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.33921298384666443, accuracy: 0.92236328125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.33633890748023987, accuracy: 0.919677734375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3537026047706604, accuracy: 0.918701171875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.3890301585197449, accuracy: 0.9189453125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.2960308790206909, accuracy: 0.92578125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.32826435565948486, accuracy: 0.917724609375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.30077219009399414, accuracy: 0.92236328125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3020044267177582, accuracy: 0.925048828125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.32738617062568665, accuracy: 0.920654296875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.2982710003852844, accuracy: 0.925537109375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3360207676887512, accuracy: 0.91650390625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.33835330605506897, accuracy: 0.9248046875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.3009690046310425, accuracy: 0.9189453125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.29778003692626953, accuracy: 0.921875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.28429242968559265, accuracy: 0.92236328125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.3628872334957123, accuracy: 0.923095703125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.32557493448257446, accuracy: 0.928466796875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.2783977687358856, accuracy: 0.919921875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.33528396487236023, accuracy: 0.9208984375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2444047927856445, accuracy: 0.40576171875\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.176081895828247, accuracy: 0.592529296875\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.11920428276062, accuracy: 0.671142578125\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0188961029052734, accuracy: 0.716064453125\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9349089860916138, accuracy: 0.739013671875\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.824683666229248, accuracy: 0.744140625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7296175956726074, accuracy: 0.757568359375\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.6106836795806885, accuracy: 0.767578125\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4953185319900513, accuracy: 0.787353515625\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3614548444747925, accuracy: 0.793701171875\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2618166208267212, accuracy: 0.812255859375\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.1206313371658325, accuracy: 0.82568359375\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0625596046447754, accuracy: 0.829345703125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9985114932060242, accuracy: 0.833251953125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9368555545806885, accuracy: 0.84716796875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8483890891075134, accuracy: 0.854248046875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.849539577960968, accuracy: 0.853515625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7709002494812012, accuracy: 0.85791015625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7797098755836487, accuracy: 0.86181640625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7220538258552551, accuracy: 0.86572265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6371323466300964, accuracy: 0.872802734375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6578159928321838, accuracy: 0.871826171875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6475302577018738, accuracy: 0.87646484375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6060497164726257, accuracy: 0.869384765625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5709165334701538, accuracy: 0.8837890625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.6233986616134644, accuracy: 0.883056640625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5417053699493408, accuracy: 0.880126953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5948916077613831, accuracy: 0.884765625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5371520519256592, accuracy: 0.88037109375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5237852334976196, accuracy: 0.88232421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.4891164302825928, accuracy: 0.892333984375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5018733739852905, accuracy: 0.886474609375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.4738134443759918, accuracy: 0.88623046875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.5015475153923035, accuracy: 0.895751953125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4778191149234772, accuracy: 0.890625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4652160406112671, accuracy: 0.8994140625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4772263765335083, accuracy: 0.895751953125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.5033522844314575, accuracy: 0.89453125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.47608059644699097, accuracy: 0.894775390625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.46160611510276794, accuracy: 0.903564453125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4449244737625122, accuracy: 0.905029296875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4491552710533142, accuracy: 0.89990234375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4447999596595764, accuracy: 0.89794921875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.4264231324195862, accuracy: 0.90478515625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.37996914982795715, accuracy: 0.902099609375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.4186905324459076, accuracy: 0.912353515625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.39292559027671814, accuracy: 0.907958984375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.4463070333003998, accuracy: 0.909912109375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.397874116897583, accuracy: 0.905029296875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.43019863963127136, accuracy: 0.899658203125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.41689956188201904, accuracy: 0.899169921875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.383378267288208, accuracy: 0.9013671875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.3988872170448303, accuracy: 0.904296875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.43204283714294434, accuracy: 0.901123046875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.42789629101753235, accuracy: 0.907958984375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.40737566351890564, accuracy: 0.913330078125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.3932732939720154, accuracy: 0.907958984375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.3953956365585327, accuracy: 0.90478515625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.38452476263046265, accuracy: 0.9052734375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.411118745803833, accuracy: 0.90625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.45180127024650574, accuracy: 0.912109375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.3860650658607483, accuracy: 0.913818359375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.4004133343696594, accuracy: 0.90673828125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.38646700978279114, accuracy: 0.904541015625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.37886470556259155, accuracy: 0.905517578125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.33982446789741516, accuracy: 0.9150390625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3575286567211151, accuracy: 0.907958984375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3495999872684479, accuracy: 0.912841796875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.39004242420196533, accuracy: 0.9140625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.41528892517089844, accuracy: 0.915283203125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.39359837770462036, accuracy: 0.91015625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.3485828638076782, accuracy: 0.915771484375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3325153887271881, accuracy: 0.9091796875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.37093058228492737, accuracy: 0.91552734375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3345630466938019, accuracy: 0.917236328125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.3430923521518707, accuracy: 0.913330078125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3474964201450348, accuracy: 0.922119140625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3051757514476776, accuracy: 0.9189453125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.35992592573165894, accuracy: 0.919921875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.3490851819515228, accuracy: 0.919921875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.2747328281402588, accuracy: 0.9248046875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.3530082404613495, accuracy: 0.916015625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.3833097517490387, accuracy: 0.91796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.30474624037742615, accuracy: 0.918701171875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.3389817774295807, accuracy: 0.920654296875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.3507911264896393, accuracy: 0.919189453125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3422919809818268, accuracy: 0.9248046875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.2915666997432709, accuracy: 0.92236328125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.33899831771850586, accuracy: 0.91650390625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.36307600140571594, accuracy: 0.92431640625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.39021143317222595, accuracy: 0.91943359375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.34156909584999084, accuracy: 0.923583984375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.30871501564979553, accuracy: 0.917724609375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.31427186727523804, accuracy: 0.92041015625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.33026883006095886, accuracy: 0.922607421875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.2995421886444092, accuracy: 0.919189453125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.288857638835907, accuracy: 0.918212890625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3163793087005615, accuracy: 0.920654296875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.3310016393661499, accuracy: 0.923095703125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.2934713363647461, accuracy: 0.922119140625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.239579677581787, accuracy: 0.331298828125\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1653614044189453, accuracy: 0.56005859375\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.075406312942505, accuracy: 0.646728515625\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0005435943603516, accuracy: 0.703857421875\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9056217670440674, accuracy: 0.72119140625\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.7837599515914917, accuracy: 0.736083984375\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.691885232925415, accuracy: 0.751953125\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.5640228986740112, accuracy: 0.766357421875\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4297963380813599, accuracy: 0.783447265625\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.315161108970642, accuracy: 0.794921875\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2389346361160278, accuracy: 0.809326171875\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.10032320022583, accuracy: 0.822021484375\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0319178104400635, accuracy: 0.826416015625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9501886963844299, accuracy: 0.833251953125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.8948760628700256, accuracy: 0.841552734375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.843883752822876, accuracy: 0.85107421875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7955776453018188, accuracy: 0.854248046875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7684037089347839, accuracy: 0.86572265625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7312583923339844, accuracy: 0.862060546875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.6816823482513428, accuracy: 0.86572265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.7068514823913574, accuracy: 0.865234375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6371632814407349, accuracy: 0.87060546875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.5977502465248108, accuracy: 0.873779296875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6135379076004028, accuracy: 0.87841796875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.6089525818824768, accuracy: 0.881103515625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5571959018707275, accuracy: 0.88525390625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5864574313163757, accuracy: 0.8798828125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5255557298660278, accuracy: 0.88525390625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.56053626537323, accuracy: 0.887451171875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5041309595108032, accuracy: 0.8916015625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5345956683158875, accuracy: 0.89892578125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.532735288143158, accuracy: 0.889892578125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.43692871928215027, accuracy: 0.904541015625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.5177255868911743, accuracy: 0.90185546875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.48907381296157837, accuracy: 0.90185546875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4702306091785431, accuracy: 0.89306640625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4478243589401245, accuracy: 0.897216796875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.46258264780044556, accuracy: 0.898193359375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.46804511547088623, accuracy: 0.901611328125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.4626465141773224, accuracy: 0.904541015625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4019816815853119, accuracy: 0.9052734375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4647553861141205, accuracy: 0.90087890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.3784574866294861, accuracy: 0.903076171875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.4445187449455261, accuracy: 0.901611328125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.45070555806159973, accuracy: 0.907958984375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.41949257254600525, accuracy: 0.8984375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.4277564287185669, accuracy: 0.910400390625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.40953633189201355, accuracy: 0.905029296875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.38340428471565247, accuracy: 0.905029296875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.3922078013420105, accuracy: 0.90185546875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.38372939825057983, accuracy: 0.907958984375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.39604878425598145, accuracy: 0.912353515625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.44657739996910095, accuracy: 0.908203125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.36520275473594666, accuracy: 0.906494140625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.39214664697647095, accuracy: 0.909912109375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.39093154668807983, accuracy: 0.910888671875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.38167497515678406, accuracy: 0.908203125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.4052259624004364, accuracy: 0.90576171875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3899536728858948, accuracy: 0.907958984375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.36854952573776245, accuracy: 0.910888671875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.39245688915252686, accuracy: 0.910888671875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.386517196893692, accuracy: 0.911865234375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.35484176874160767, accuracy: 0.910888671875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.40487292408943176, accuracy: 0.908447265625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3831663727760315, accuracy: 0.909423828125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.30813083052635193, accuracy: 0.906005859375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3014935851097107, accuracy: 0.91748046875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3329518139362335, accuracy: 0.9169921875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3656482994556427, accuracy: 0.912841796875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.33848318457603455, accuracy: 0.913818359375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.36571380496025085, accuracy: 0.90966796875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.37459811568260193, accuracy: 0.91552734375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3053189814090729, accuracy: 0.909912109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3694828450679779, accuracy: 0.918212890625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3396570086479187, accuracy: 0.911865234375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.33340927958488464, accuracy: 0.91748046875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3696763515472412, accuracy: 0.917724609375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3462160527706146, accuracy: 0.914306640625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.34669771790504456, accuracy: 0.916748046875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.3512828052043915, accuracy: 0.91455078125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.35277730226516724, accuracy: 0.919677734375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.3657183051109314, accuracy: 0.92431640625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.29113948345184326, accuracy: 0.921630859375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.33781781792640686, accuracy: 0.92041015625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.4130590260028839, accuracy: 0.9228515625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.32351943850517273, accuracy: 0.91796875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3491690158843994, accuracy: 0.92236328125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.3060271739959717, accuracy: 0.91796875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3356485664844513, accuracy: 0.92138671875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.32715266942977905, accuracy: 0.920166015625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.33283209800720215, accuracy: 0.916015625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3237776458263397, accuracy: 0.919921875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.2592943608760834, accuracy: 0.91796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.29724594950675964, accuracy: 0.916015625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.33977580070495605, accuracy: 0.914306640625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.32288625836372375, accuracy: 0.91748046875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.3419448137283325, accuracy: 0.923583984375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.32885831594467163, accuracy: 0.919921875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.29441145062446594, accuracy: 0.921875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.33788278698921204, accuracy: 0.922119140625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2430367469787598, accuracy: 0.354736328125\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.158661365509033, accuracy: 0.5888671875\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0779032707214355, accuracy: 0.6708984375\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0218732357025146, accuracy: 0.707275390625\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.912957787513733, accuracy: 0.7373046875\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8037097454071045, accuracy: 0.748291015625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6847642660140991, accuracy: 0.7626953125\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.580863118171692, accuracy: 0.764892578125\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4457621574401855, accuracy: 0.78369140625\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3655198812484741, accuracy: 0.788330078125\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2173807621002197, accuracy: 0.793701171875\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.1400693655014038, accuracy: 0.8115234375\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0515797138214111, accuracy: 0.830810546875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9958754777908325, accuracy: 0.83203125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9312564730644226, accuracy: 0.842529296875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8478015661239624, accuracy: 0.853271484375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7922036647796631, accuracy: 0.848388671875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7188617587089539, accuracy: 0.853271484375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7407740354537964, accuracy: 0.86279296875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7484492063522339, accuracy: 0.868408203125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.7037866115570068, accuracy: 0.87109375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6667254567146301, accuracy: 0.8681640625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6628583073616028, accuracy: 0.871826171875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6283483505249023, accuracy: 0.876708984375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.608958899974823, accuracy: 0.87451171875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5817949771881104, accuracy: 0.882568359375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5472567677497864, accuracy: 0.880859375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5770381093025208, accuracy: 0.88916015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.507121205329895, accuracy: 0.886962890625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.565249502658844, accuracy: 0.889404296875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5394004583358765, accuracy: 0.895263671875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.4606987237930298, accuracy: 0.884765625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.4474528729915619, accuracy: 0.88720703125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.5078095197677612, accuracy: 0.895751953125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.48877695202827454, accuracy: 0.895263671875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4603285491466522, accuracy: 0.893798828125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4827025830745697, accuracy: 0.8955078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.4717114269733429, accuracy: 0.895751953125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4560219347476959, accuracy: 0.895263671875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.4724401831626892, accuracy: 0.8994140625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4542117118835449, accuracy: 0.900390625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4682461619377136, accuracy: 0.90576171875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.42111748456954956, accuracy: 0.897705078125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.43414896726608276, accuracy: 0.9033203125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.42625299096107483, accuracy: 0.9013671875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.4488692283630371, accuracy: 0.898193359375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.4327385723590851, accuracy: 0.90576171875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.4215145409107208, accuracy: 0.907470703125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.42035916447639465, accuracy: 0.903564453125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.4341529309749603, accuracy: 0.908935546875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.3959865868091583, accuracy: 0.9013671875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.4094786047935486, accuracy: 0.9052734375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.4206427335739136, accuracy: 0.91162109375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.40194615721702576, accuracy: 0.90625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.44071921706199646, accuracy: 0.9072265625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.341754287481308, accuracy: 0.90966796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.3979971408843994, accuracy: 0.913330078125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.41894805431365967, accuracy: 0.914306640625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.40925028920173645, accuracy: 0.910888671875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.40252164006233215, accuracy: 0.91064453125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.41056808829307556, accuracy: 0.914794921875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.4054766595363617, accuracy: 0.914794921875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.38155001401901245, accuracy: 0.906494140625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3648732602596283, accuracy: 0.9130859375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3958894610404968, accuracy: 0.91015625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.34944775700569153, accuracy: 0.90869140625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.39237070083618164, accuracy: 0.917724609375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.38121071457862854, accuracy: 0.913818359375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.36427822709083557, accuracy: 0.919189453125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.37549978494644165, accuracy: 0.9140625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3624357283115387, accuracy: 0.91552734375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.3160404562950134, accuracy: 0.917236328125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3879763185977936, accuracy: 0.91455078125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3412421643733978, accuracy: 0.915283203125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.36621370911598206, accuracy: 0.915283203125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.35095053911209106, accuracy: 0.9111328125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.34874671697616577, accuracy: 0.918212890625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.2867039442062378, accuracy: 0.920166015625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3325422406196594, accuracy: 0.91357421875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.29202479124069214, accuracy: 0.920654296875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.33999720215797424, accuracy: 0.92138671875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.32664865255355835, accuracy: 0.923828125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.36300256848335266, accuracy: 0.91845703125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.313770055770874, accuracy: 0.922607421875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.34979310631752014, accuracy: 0.918212890625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.3344818353652954, accuracy: 0.920166015625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.31199321150779724, accuracy: 0.92041015625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.30759239196777344, accuracy: 0.92236328125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.2938753664493561, accuracy: 0.921630859375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3141925036907196, accuracy: 0.923583984375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.28443479537963867, accuracy: 0.918212890625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.31178560853004456, accuracy: 0.925048828125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.3230067491531372, accuracy: 0.91748046875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.3649224638938904, accuracy: 0.916748046875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3459831178188324, accuracy: 0.9248046875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.2935938835144043, accuracy: 0.919921875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.31305745244026184, accuracy: 0.91845703125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3284742832183838, accuracy: 0.91943359375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.3181409239768982, accuracy: 0.929443359375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.3559010922908783, accuracy: 0.919677734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.247206449508667, accuracy: 0.38525390625\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.166437864303589, accuracy: 0.609130859375\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.108819007873535, accuracy: 0.67236328125\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0209319591522217, accuracy: 0.70263671875\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.924646019935608, accuracy: 0.71533203125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8042805194854736, accuracy: 0.725341796875\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7363674640655518, accuracy: 0.752685546875\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.6177222728729248, accuracy: 0.77001953125\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.5060174465179443, accuracy: 0.7783203125\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3796968460083008, accuracy: 0.7919921875\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2701797485351562, accuracy: 0.804931640625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.1468636989593506, accuracy: 0.820556640625\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.050400733947754, accuracy: 0.826171875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9619154930114746, accuracy: 0.84130859375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.8789425492286682, accuracy: 0.8525390625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8985086679458618, accuracy: 0.848388671875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.8005511164665222, accuracy: 0.8515625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.8098098635673523, accuracy: 0.858642578125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7518796920776367, accuracy: 0.87158203125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7278677225112915, accuracy: 0.873291015625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6718193888664246, accuracy: 0.86669921875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6707295775413513, accuracy: 0.869873046875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6209949254989624, accuracy: 0.87451171875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6300899386405945, accuracy: 0.8798828125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5910513997077942, accuracy: 0.8818359375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5702621936798096, accuracy: 0.889404296875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5890209078788757, accuracy: 0.8896484375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5879808664321899, accuracy: 0.88818359375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5723052620887756, accuracy: 0.89013671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5428822636604309, accuracy: 0.8876953125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5137766003608704, accuracy: 0.892822265625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.4782623052597046, accuracy: 0.89501953125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.4838588535785675, accuracy: 0.890380859375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4554068148136139, accuracy: 0.890380859375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.5026512145996094, accuracy: 0.89794921875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.48984140157699585, accuracy: 0.899658203125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4682343304157257, accuracy: 0.906982421875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.4575768709182739, accuracy: 0.897216796875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4511474370956421, accuracy: 0.89404296875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.45586809515953064, accuracy: 0.90185546875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4455829858779907, accuracy: 0.89599609375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.45732876658439636, accuracy: 0.892822265625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4104917049407959, accuracy: 0.897705078125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.43151095509529114, accuracy: 0.901611328125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.42659515142440796, accuracy: 0.903076171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.3893308937549591, accuracy: 0.90771484375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.42289999127388, accuracy: 0.907958984375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.4256386160850525, accuracy: 0.907470703125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.4307841658592224, accuracy: 0.90771484375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.39835241436958313, accuracy: 0.908447265625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.37871676683425903, accuracy: 0.9072265625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.4347097873687744, accuracy: 0.904541015625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.4349455237388611, accuracy: 0.905029296875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.382520467042923, accuracy: 0.912353515625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4173077344894409, accuracy: 0.910400390625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.41121649742126465, accuracy: 0.904296875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.4084949195384979, accuracy: 0.909912109375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.4404122829437256, accuracy: 0.91259765625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.37484389543533325, accuracy: 0.91455078125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.3738653361797333, accuracy: 0.912841796875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3820261061191559, accuracy: 0.914794921875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.36429768800735474, accuracy: 0.91162109375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.4078654646873474, accuracy: 0.91162109375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.33564043045043945, accuracy: 0.918212890625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.4105968773365021, accuracy: 0.914306640625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.4070760905742645, accuracy: 0.910400390625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.36934608221054077, accuracy: 0.916748046875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3354349434375763, accuracy: 0.9111328125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.37631428241729736, accuracy: 0.917724609375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.38757482171058655, accuracy: 0.91650390625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3400784730911255, accuracy: 0.912109375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.36664342880249023, accuracy: 0.917236328125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3941363990306854, accuracy: 0.9111328125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3333512544631958, accuracy: 0.90625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3809545040130615, accuracy: 0.917724609375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.4079732596874237, accuracy: 0.916748046875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.34748539328575134, accuracy: 0.916259765625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3301669657230377, accuracy: 0.919677734375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3167775571346283, accuracy: 0.920654296875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.37122541666030884, accuracy: 0.91796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.3660622239112854, accuracy: 0.91943359375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.37424081563949585, accuracy: 0.92138671875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.3666081428527832, accuracy: 0.913330078125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.36123400926589966, accuracy: 0.912841796875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.38298454880714417, accuracy: 0.91845703125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.3891093134880066, accuracy: 0.916748046875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3513457477092743, accuracy: 0.917724609375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.32189708948135376, accuracy: 0.918701171875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.312812864780426, accuracy: 0.92138671875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.41387590765953064, accuracy: 0.920654296875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.37885627150535583, accuracy: 0.921630859375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.33132848143577576, accuracy: 0.921630859375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.30692607164382935, accuracy: 0.921142578125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.2977606952190399, accuracy: 0.920654296875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.41547343134880066, accuracy: 0.922607421875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.2886812388896942, accuracy: 0.92529296875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.3048023581504822, accuracy: 0.925048828125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.34373682737350464, accuracy: 0.921142578125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.2955555319786072, accuracy: 0.92578125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.30344146490097046, accuracy: 0.919677734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2383079528808594, accuracy: 0.399169921875\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.170956611633301, accuracy: 0.599609375\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.095324993133545, accuracy: 0.679443359375\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0077414512634277, accuracy: 0.70849609375\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9111063480377197, accuracy: 0.72705078125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8150994777679443, accuracy: 0.732177734375\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7265123128890991, accuracy: 0.740966796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.591901183128357, accuracy: 0.7578125\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4716209173202515, accuracy: 0.7841796875\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3611867427825928, accuracy: 0.788330078125\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2280937433242798, accuracy: 0.806640625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.139914870262146, accuracy: 0.810791015625\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0161818265914917, accuracy: 0.821533203125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9492252469062805, accuracy: 0.830810546875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9336738586425781, accuracy: 0.842529296875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8796539902687073, accuracy: 0.8515625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.8285729289054871, accuracy: 0.851318359375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.758350670337677, accuracy: 0.856689453125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7125528454780579, accuracy: 0.864990234375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.72487872838974, accuracy: 0.861328125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6645482778549194, accuracy: 0.86328125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6521413326263428, accuracy: 0.88525390625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6175842881202698, accuracy: 0.87451171875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6244829297065735, accuracy: 0.87744140625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5844207406044006, accuracy: 0.87646484375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5638827085494995, accuracy: 0.87646484375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5779048204421997, accuracy: 0.882080078125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.632625162601471, accuracy: 0.887451171875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.546977698802948, accuracy: 0.887939453125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5088455080986023, accuracy: 0.88232421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5293079018592834, accuracy: 0.89208984375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.49142104387283325, accuracy: 0.900634765625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5340481400489807, accuracy: 0.898193359375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.5259415507316589, accuracy: 0.896484375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.444584459066391, accuracy: 0.8935546875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.49261966347694397, accuracy: 0.89794921875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4937135577201843, accuracy: 0.89892578125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.47434481978416443, accuracy: 0.89697265625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.5034846067428589, accuracy: 0.905517578125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.43234196305274963, accuracy: 0.9052734375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4903026521205902, accuracy: 0.89697265625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.45966577529907227, accuracy: 0.898681640625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.3904325067996979, accuracy: 0.89697265625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.4422219395637512, accuracy: 0.896484375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.4592897295951843, accuracy: 0.89599609375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.41816064715385437, accuracy: 0.901123046875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.3991575837135315, accuracy: 0.9072265625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.43842387199401855, accuracy: 0.9052734375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.40206125378608704, accuracy: 0.90380859375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.40233856439590454, accuracy: 0.90625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.3809489607810974, accuracy: 0.899658203125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.4365389943122864, accuracy: 0.90673828125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.4284972548484802, accuracy: 0.9052734375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.4240090250968933, accuracy: 0.903076171875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4382225275039673, accuracy: 0.910888671875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.39050763845443726, accuracy: 0.90869140625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.4498802423477173, accuracy: 0.908203125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.3710351586341858, accuracy: 0.908935546875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3443620204925537, accuracy: 0.9111328125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.35327091813087463, accuracy: 0.91259765625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.39304545521736145, accuracy: 0.9072265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.34788423776626587, accuracy: 0.90966796875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.39364778995513916, accuracy: 0.91162109375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.354799747467041, accuracy: 0.916748046875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.4056984484195709, accuracy: 0.912353515625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.34102335572242737, accuracy: 0.907470703125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3453211784362793, accuracy: 0.9140625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.39937588572502136, accuracy: 0.912109375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3488650321960449, accuracy: 0.906494140625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.3983531594276428, accuracy: 0.913330078125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3837960362434387, accuracy: 0.911865234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.3940069377422333, accuracy: 0.906982421875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.34441494941711426, accuracy: 0.911376953125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3182644248008728, accuracy: 0.9150390625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3592926561832428, accuracy: 0.916748046875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.3593825101852417, accuracy: 0.9169921875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.33883756399154663, accuracy: 0.913818359375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.36043494939804077, accuracy: 0.912841796875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3856706917285919, accuracy: 0.91748046875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.3878593444824219, accuracy: 0.925048828125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.34676218032836914, accuracy: 0.912109375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.35624125599861145, accuracy: 0.91796875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.33197227120399475, accuracy: 0.9169921875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.415348619222641, accuracy: 0.918212890625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.347692608833313, accuracy: 0.918701171875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.338437557220459, accuracy: 0.920654296875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3458581864833832, accuracy: 0.92333984375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.3205297291278839, accuracy: 0.92333984375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3143879175186157, accuracy: 0.925537109375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3885963261127472, accuracy: 0.916259765625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.3127971291542053, accuracy: 0.91748046875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.28170886635780334, accuracy: 0.92724609375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.36364656686782837, accuracy: 0.92333984375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.28123676776885986, accuracy: 0.917724609375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.37369504570961, accuracy: 0.922119140625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3536072075366974, accuracy: 0.92431640625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.3649027347564697, accuracy: 0.917724609375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3597390055656433, accuracy: 0.926025390625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.3239166736602783, accuracy: 0.92529296875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.2858934998512268, accuracy: 0.92578125\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.228609800338745, accuracy: 0.33447265625\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1522538661956787, accuracy: 0.546142578125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0791354179382324, accuracy: 0.673583984375\n",
            "Epoch: 4, learning_rate:0.01,costo: 1.9847002029418945, accuracy: 0.72021484375\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.905573844909668, accuracy: 0.736083984375\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.7573249340057373, accuracy: 0.745361328125\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6651833057403564, accuracy: 0.756591796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.5313923358917236, accuracy: 0.772705078125\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.405698537826538, accuracy: 0.782958984375\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3103545904159546, accuracy: 0.79833984375\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.1892338991165161, accuracy: 0.81103515625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.0736955404281616, accuracy: 0.825439453125\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0264517068862915, accuracy: 0.841064453125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9620963931083679, accuracy: 0.833251953125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9145576357841492, accuracy: 0.8369140625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8386942744255066, accuracy: 0.848876953125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7825369834899902, accuracy: 0.85107421875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7758234739303589, accuracy: 0.857421875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7085690498352051, accuracy: 0.868408203125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7129493355751038, accuracy: 0.86669921875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6315512657165527, accuracy: 0.86865234375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6439801454544067, accuracy: 0.875732421875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.5903197526931763, accuracy: 0.874267578125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.5874440670013428, accuracy: 0.878173828125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.6161905527114868, accuracy: 0.8828125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5069168210029602, accuracy: 0.877685546875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5853052139282227, accuracy: 0.8876953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5428737998008728, accuracy: 0.888916015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5317109227180481, accuracy: 0.887451171875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5367117524147034, accuracy: 0.89404296875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.4862629175186157, accuracy: 0.887939453125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5291750431060791, accuracy: 0.890625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5011776089668274, accuracy: 0.892333984375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.5175307393074036, accuracy: 0.89501953125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4550061821937561, accuracy: 0.892822265625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4820639491081238, accuracy: 0.893798828125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4807775616645813, accuracy: 0.89697265625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.4711548388004303, accuracy: 0.8984375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4603317975997925, accuracy: 0.89892578125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.46745797991752625, accuracy: 0.900390625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4514041543006897, accuracy: 0.90283203125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4265632629394531, accuracy: 0.897216796875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4439326524734497, accuracy: 0.901611328125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.4283522963523865, accuracy: 0.90185546875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.4916638731956482, accuracy: 0.902587890625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.399186909198761, accuracy: 0.90087890625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.39456242322921753, accuracy: 0.904541015625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.40307652950286865, accuracy: 0.9033203125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.40015071630477905, accuracy: 0.906005859375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.3817460536956787, accuracy: 0.909423828125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.41821712255477905, accuracy: 0.908203125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.39121437072753906, accuracy: 0.90576171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.4038437604904175, accuracy: 0.91064453125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.44146472215652466, accuracy: 0.90576171875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.391470342874527, accuracy: 0.90673828125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.39229458570480347, accuracy: 0.9130859375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.456411212682724, accuracy: 0.904296875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.3649437725543976, accuracy: 0.9111328125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3788312077522278, accuracy: 0.908935546875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.36426401138305664, accuracy: 0.908447265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3945172429084778, accuracy: 0.907470703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.3857190012931824, accuracy: 0.910888671875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.36168941855430603, accuracy: 0.9169921875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.37151679396629333, accuracy: 0.91796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3489474952220917, accuracy: 0.91259765625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.36368435621261597, accuracy: 0.91357421875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.41164064407348633, accuracy: 0.915771484375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.37809112668037415, accuracy: 0.914794921875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.36976832151412964, accuracy: 0.919189453125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.31497207283973694, accuracy: 0.916259765625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3497351109981537, accuracy: 0.914306640625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.41165971755981445, accuracy: 0.91259765625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.3465995788574219, accuracy: 0.91552734375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.32248231768608093, accuracy: 0.914306640625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3479759693145752, accuracy: 0.922607421875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.3139412999153137, accuracy: 0.917236328125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3255414664745331, accuracy: 0.91064453125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.37265142798423767, accuracy: 0.917724609375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3698267638683319, accuracy: 0.914306640625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.33007192611694336, accuracy: 0.916259765625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.34854188561439514, accuracy: 0.919189453125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.3499791622161865, accuracy: 0.922119140625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.33216580748558044, accuracy: 0.920166015625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3168870508670807, accuracy: 0.91943359375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.30168235301971436, accuracy: 0.9169921875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.35116785764694214, accuracy: 0.916748046875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.33700594305992126, accuracy: 0.9228515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.31711941957473755, accuracy: 0.9169921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3400786817073822, accuracy: 0.9140625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3319314420223236, accuracy: 0.91796875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.32093241810798645, accuracy: 0.92333984375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3393970727920532, accuracy: 0.926513671875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.30175814032554626, accuracy: 0.922119140625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.275770366191864, accuracy: 0.919189453125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3436419665813446, accuracy: 0.91796875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3057505488395691, accuracy: 0.923095703125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.2828249931335449, accuracy: 0.921875\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3000267744064331, accuracy: 0.9248046875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.2613619267940521, accuracy: 0.92333984375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.298163503408432, accuracy: 0.915771484375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.237806558609009, accuracy: 0.3818359375\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1706318855285645, accuracy: 0.567626953125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0921623706817627, accuracy: 0.66015625\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0149266719818115, accuracy: 0.70849609375\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9065577983856201, accuracy: 0.733642578125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8428045511245728, accuracy: 0.75390625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7150793075561523, accuracy: 0.763427734375\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.5932470560073853, accuracy: 0.76416015625\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.464205026626587, accuracy: 0.78466796875\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3430085182189941, accuracy: 0.792236328125\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.216878890991211, accuracy: 0.81494140625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.1270368099212646, accuracy: 0.8125\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0714612007141113, accuracy: 0.824951171875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9731563329696655, accuracy: 0.83740234375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.893671452999115, accuracy: 0.841064453125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8388248682022095, accuracy: 0.844970703125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7836112976074219, accuracy: 0.85107421875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.8003526926040649, accuracy: 0.859619140625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.739986777305603, accuracy: 0.863525390625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.6847125887870789, accuracy: 0.860595703125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6700251698493958, accuracy: 0.86572265625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6742123365402222, accuracy: 0.870849609375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.686689555644989, accuracy: 0.881591796875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.5777493119239807, accuracy: 0.875244140625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5901486277580261, accuracy: 0.88671875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5825950503349304, accuracy: 0.876708984375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5820262432098389, accuracy: 0.882080078125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5594022870063782, accuracy: 0.886962890625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5463676452636719, accuracy: 0.88525390625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5783398151397705, accuracy: 0.89404296875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.4893171191215515, accuracy: 0.8955078125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5602495074272156, accuracy: 0.89599609375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5004283785820007, accuracy: 0.899658203125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.48475000262260437, accuracy: 0.89794921875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4911384582519531, accuracy: 0.895263671875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4459252953529358, accuracy: 0.902099609375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.42429426312446594, accuracy: 0.897216796875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.5060907006263733, accuracy: 0.901123046875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.44419530034065247, accuracy: 0.892333984375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.4984610974788666, accuracy: 0.896240234375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4347671568393707, accuracy: 0.90283203125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4603014886379242, accuracy: 0.8984375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4902782738208771, accuracy: 0.89453125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.41821786761283875, accuracy: 0.89794921875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.4087585508823395, accuracy: 0.89892578125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.46954086422920227, accuracy: 0.899169921875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.4180920720100403, accuracy: 0.898681640625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.39849260449409485, accuracy: 0.905517578125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.41993775963783264, accuracy: 0.906494140625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.37701013684272766, accuracy: 0.90869140625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.41145095229148865, accuracy: 0.907958984375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.43347856402397156, accuracy: 0.91259765625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.3774479627609253, accuracy: 0.904296875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.43903788924217224, accuracy: 0.908935546875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4289969205856323, accuracy: 0.90576171875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.4067476987838745, accuracy: 0.903076171875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.40227627754211426, accuracy: 0.908203125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.36265507340431213, accuracy: 0.91259765625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.39498764276504517, accuracy: 0.91259765625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.3934561312198639, accuracy: 0.91748046875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3915615677833557, accuracy: 0.911865234375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.37503594160079956, accuracy: 0.91552734375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.4057202935218811, accuracy: 0.91015625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3623652458190918, accuracy: 0.91259765625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.34437665343284607, accuracy: 0.912841796875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3659745752811432, accuracy: 0.906005859375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3869445323944092, accuracy: 0.916748046875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.31003817915916443, accuracy: 0.911376953125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3627375364303589, accuracy: 0.91455078125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.3538050651550293, accuracy: 0.906982421875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3513288199901581, accuracy: 0.9169921875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.36029335856437683, accuracy: 0.922607421875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.39603811502456665, accuracy: 0.91357421875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.33467501401901245, accuracy: 0.92333984375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3515682518482208, accuracy: 0.9072265625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.34902775287628174, accuracy: 0.920166015625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3464895188808441, accuracy: 0.916748046875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3153954744338989, accuracy: 0.91357421875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3275226056575775, accuracy: 0.913330078125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.33556094765663147, accuracy: 0.914306640625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.3199131488800049, accuracy: 0.9208984375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.3552277088165283, accuracy: 0.916259765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.3225838243961334, accuracy: 0.921630859375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3675246834754944, accuracy: 0.92041015625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.33586567640304565, accuracy: 0.920654296875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.3129948079586029, accuracy: 0.916748046875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.35450851917266846, accuracy: 0.918701171875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.33931833505630493, accuracy: 0.921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.2972365915775299, accuracy: 0.914306640625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3217814862728119, accuracy: 0.9228515625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.3513164520263672, accuracy: 0.92041015625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3557743430137634, accuracy: 0.920166015625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.32408881187438965, accuracy: 0.92041015625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.30346590280532837, accuracy: 0.91943359375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.31258100271224976, accuracy: 0.9208984375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3621313273906708, accuracy: 0.923095703125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.32920849323272705, accuracy: 0.9208984375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.35044005513191223, accuracy: 0.921142578125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.27553868293762207, accuracy: 0.92529296875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.3243253827095032, accuracy: 0.91943359375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2341718673706055, accuracy: 0.329833984375\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1550567150115967, accuracy: 0.618408203125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0810184478759766, accuracy: 0.6796875\n",
            "Epoch: 4, learning_rate:0.01,costo: 1.9997113943099976, accuracy: 0.706787109375\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.8967905044555664, accuracy: 0.7177734375\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.786247730255127, accuracy: 0.73291015625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6621068716049194, accuracy: 0.73974609375\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.531221628189087, accuracy: 0.76123046875\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.419339895248413, accuracy: 0.785400390625\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.2885208129882812, accuracy: 0.794677734375\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.1772125959396362, accuracy: 0.801025390625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.1016888618469238, accuracy: 0.81201171875\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0178501605987549, accuracy: 0.83544921875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9644136428833008, accuracy: 0.834228515625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.8677354454994202, accuracy: 0.84375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8796989917755127, accuracy: 0.847900390625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.7754753828048706, accuracy: 0.84716796875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7788702845573425, accuracy: 0.859375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7545305490493774, accuracy: 0.85888671875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7189546227455139, accuracy: 0.8583984375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6476354598999023, accuracy: 0.869384765625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.5916270613670349, accuracy: 0.86767578125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6350972652435303, accuracy: 0.873779296875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.611419677734375, accuracy: 0.874755859375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5921745896339417, accuracy: 0.87939453125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5763370394706726, accuracy: 0.882568359375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5913029909133911, accuracy: 0.882568359375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5438715815544128, accuracy: 0.88916015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5823002457618713, accuracy: 0.896484375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5449420213699341, accuracy: 0.8935546875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5168425440788269, accuracy: 0.89501953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5575903654098511, accuracy: 0.88427734375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.4788047969341278, accuracy: 0.889404296875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4901282489299774, accuracy: 0.893310546875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.46534934639930725, accuracy: 0.8955078125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4720172584056854, accuracy: 0.90087890625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.4209790527820587, accuracy: 0.889892578125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.4929417073726654, accuracy: 0.898193359375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4537668526172638, accuracy: 0.894775390625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.405707985162735, accuracy: 0.898193359375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4561859667301178, accuracy: 0.901123046875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.3890708088874817, accuracy: 0.900390625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.38344770669937134, accuracy: 0.899658203125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.45277342200279236, accuracy: 0.898193359375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.4563528895378113, accuracy: 0.904052734375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.3985268175601959, accuracy: 0.9052734375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.39476409554481506, accuracy: 0.906494140625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.39285579323768616, accuracy: 0.910400390625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.41019558906555176, accuracy: 0.90576171875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.4220680594444275, accuracy: 0.909423828125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.41355010867118835, accuracy: 0.90771484375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.4048003852367401, accuracy: 0.904541015625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.39694225788116455, accuracy: 0.908935546875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.39146122336387634, accuracy: 0.90966796875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4212561547756195, accuracy: 0.90673828125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.35399502515792847, accuracy: 0.908447265625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.40672096610069275, accuracy: 0.9072265625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.39752811193466187, accuracy: 0.904541015625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3840104341506958, accuracy: 0.9111328125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.40493035316467285, accuracy: 0.912109375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.319293737411499, accuracy: 0.90625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.3719978928565979, accuracy: 0.908447265625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.3655107915401459, accuracy: 0.910400390625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.39412620663642883, accuracy: 0.908935546875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.37465474009513855, accuracy: 0.90673828125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.37656018137931824, accuracy: 0.9111328125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3506079912185669, accuracy: 0.91552734375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3927512764930725, accuracy: 0.91552734375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.36607494950294495, accuracy: 0.9150390625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.37633058428764343, accuracy: 0.91357421875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3858487010002136, accuracy: 0.914306640625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.34628385305404663, accuracy: 0.9072265625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.31390270590782166, accuracy: 0.920166015625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3553221821784973, accuracy: 0.917236328125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.32997170090675354, accuracy: 0.918212890625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.32016924023628235, accuracy: 0.917236328125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3636842370033264, accuracy: 0.907470703125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3311557173728943, accuracy: 0.91650390625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.36875662207603455, accuracy: 0.915771484375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.3592223525047302, accuracy: 0.919921875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.3216495215892792, accuracy: 0.916259765625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.32787179946899414, accuracy: 0.918212890625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.35123082995414734, accuracy: 0.91943359375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3219622075557709, accuracy: 0.915283203125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.3435863256454468, accuracy: 0.91552734375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.3605065941810608, accuracy: 0.92529296875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3306525945663452, accuracy: 0.91943359375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.3191496729850769, accuracy: 0.91650390625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.3330218493938446, accuracy: 0.924560546875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3591310679912567, accuracy: 0.9228515625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.3489486277103424, accuracy: 0.91845703125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3292413353919983, accuracy: 0.923583984375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.33786511421203613, accuracy: 0.922607421875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.3462566137313843, accuracy: 0.914306640625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3135325610637665, accuracy: 0.9267578125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3445219099521637, accuracy: 0.920654296875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.3186511695384979, accuracy: 0.92236328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.31530463695526123, accuracy: 0.914794921875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.3435450494289398, accuracy: 0.925537109375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.2790706157684326, accuracy: 0.915283203125\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2394392490386963, accuracy: 0.428466796875\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1702873706817627, accuracy: 0.59814453125\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.098430633544922, accuracy: 0.670166015625\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.008025884628296, accuracy: 0.70751953125\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.923508882522583, accuracy: 0.71435546875\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8124209642410278, accuracy: 0.73193359375\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7132344245910645, accuracy: 0.74462890625\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.594160556793213, accuracy: 0.7509765625\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.4510982036590576, accuracy: 0.77490234375\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3657262325286865, accuracy: 0.78857421875\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2497657537460327, accuracy: 0.8056640625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.1394187211990356, accuracy: 0.81787109375\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0440994501113892, accuracy: 0.82568359375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9565467834472656, accuracy: 0.833740234375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9168278574943542, accuracy: 0.839111328125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8426300883293152, accuracy: 0.845458984375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.8196114301681519, accuracy: 0.855712890625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7768669724464417, accuracy: 0.849853515625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.7003076076507568, accuracy: 0.85693359375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.6624916195869446, accuracy: 0.865234375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6577474474906921, accuracy: 0.8720703125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6132250428199768, accuracy: 0.867431640625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.6512212157249451, accuracy: 0.86962890625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.6384142637252808, accuracy: 0.877197265625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.6009933352470398, accuracy: 0.876220703125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.571467936038971, accuracy: 0.88037109375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5583518147468567, accuracy: 0.884521484375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.4935014545917511, accuracy: 0.8837890625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5414830446243286, accuracy: 0.88671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5321652293205261, accuracy: 0.880859375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5020723342895508, accuracy: 0.886474609375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5233291983604431, accuracy: 0.8876953125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5059452652931213, accuracy: 0.8876953125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4166228175163269, accuracy: 0.891845703125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.4308203458786011, accuracy: 0.9013671875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.5083565711975098, accuracy: 0.892578125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.494672954082489, accuracy: 0.90185546875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.472005158662796, accuracy: 0.893310546875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.4290604591369629, accuracy: 0.897216796875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.47923213243484497, accuracy: 0.895263671875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4691304862499237, accuracy: 0.90185546875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4300149083137512, accuracy: 0.90380859375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.4251934885978699, accuracy: 0.900146484375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.4712185859680176, accuracy: 0.897216796875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.398764044046402, accuracy: 0.9052734375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.4082321524620056, accuracy: 0.900390625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.463439404964447, accuracy: 0.8994140625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.44764983654022217, accuracy: 0.896728515625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.40591055154800415, accuracy: 0.902099609375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.3905070722103119, accuracy: 0.905517578125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.37949424982070923, accuracy: 0.9091796875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.43602824211120605, accuracy: 0.90576171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.3786240816116333, accuracy: 0.91015625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.4054071605205536, accuracy: 0.9033203125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.3863895833492279, accuracy: 0.91064453125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.3861870765686035, accuracy: 0.912353515625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.4076542258262634, accuracy: 0.912109375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.3846827447414398, accuracy: 0.9072265625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.3690870702266693, accuracy: 0.9130859375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.37704193592071533, accuracy: 0.9072265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3630158007144928, accuracy: 0.908203125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.4063229560852051, accuracy: 0.91357421875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.3902338147163391, accuracy: 0.91015625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3682270050048828, accuracy: 0.908447265625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3572078347206116, accuracy: 0.90771484375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3707970380783081, accuracy: 0.912841796875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.4452982246875763, accuracy: 0.911865234375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.37142688035964966, accuracy: 0.9150390625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3795984089374542, accuracy: 0.91748046875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.33515310287475586, accuracy: 0.912353515625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3885882794857025, accuracy: 0.9130859375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.37449774146080017, accuracy: 0.9130859375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.32371455430984497, accuracy: 0.911865234375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.37702906131744385, accuracy: 0.912353515625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3861468434333801, accuracy: 0.916259765625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.3342670798301697, accuracy: 0.91845703125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3775901198387146, accuracy: 0.919189453125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3228030800819397, accuracy: 0.9130859375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3526460528373718, accuracy: 0.911865234375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.3330173194408417, accuracy: 0.914306640625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.33013632893562317, accuracy: 0.91845703125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.3191925585269928, accuracy: 0.9189453125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.32052192091941833, accuracy: 0.9248046875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.3490009009838104, accuracy: 0.917724609375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.38422879576683044, accuracy: 0.921630859375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.294924259185791, accuracy: 0.925048828125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3172890543937683, accuracy: 0.9169921875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.33767324686050415, accuracy: 0.91748046875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.31855151057243347, accuracy: 0.91552734375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.31596043705940247, accuracy: 0.919189453125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.35066723823547363, accuracy: 0.927734375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3162354528903961, accuracy: 0.91552734375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.3218429982662201, accuracy: 0.918212890625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.37153902649879456, accuracy: 0.924072265625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3048965036869049, accuracy: 0.924560546875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.32076263427734375, accuracy: 0.920166015625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.2960246801376343, accuracy: 0.923828125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.2846694588661194, accuracy: 0.920654296875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.33457332849502563, accuracy: 0.9248046875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.3905514180660248, accuracy: 0.921630859375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2442667484283447, accuracy: 0.267333984375\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1748673915863037, accuracy: 0.5185546875\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0987844467163086, accuracy: 0.63818359375\n",
            "Epoch: 4, learning_rate:0.01,costo: 2.0308284759521484, accuracy: 0.66455078125\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9471428394317627, accuracy: 0.6982421875\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.8644076585769653, accuracy: 0.7265625\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.7276798486709595, accuracy: 0.741455078125\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.6195510625839233, accuracy: 0.756591796875\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.5178862810134888, accuracy: 0.765625\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.3611782789230347, accuracy: 0.77978515625\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.2680398225784302, accuracy: 0.808349609375\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.176655650138855, accuracy: 0.821533203125\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0804288387298584, accuracy: 0.819580078125\n",
            "Epoch: 14, learning_rate:0.01,costo: 1.0221216678619385, accuracy: 0.846435546875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.9196455478668213, accuracy: 0.8369140625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.8809980750083923, accuracy: 0.846435546875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.8328133225440979, accuracy: 0.847900390625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.8149755001068115, accuracy: 0.8544921875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.696663498878479, accuracy: 0.8603515625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.7374321818351746, accuracy: 0.86376953125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6587569713592529, accuracy: 0.869384765625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6084563732147217, accuracy: 0.865966796875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.658525288105011, accuracy: 0.873291015625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.58238285779953, accuracy: 0.87646484375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.5895861387252808, accuracy: 0.872802734375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5654802322387695, accuracy: 0.881591796875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.5555774569511414, accuracy: 0.879638671875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.559402346611023, accuracy: 0.883544921875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5507546663284302, accuracy: 0.888671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5027617812156677, accuracy: 0.88330078125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.520358145236969, accuracy: 0.89453125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.533672034740448, accuracy: 0.8955078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.5354058146476746, accuracy: 0.89404296875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4972953200340271, accuracy: 0.892578125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.47858694195747375, accuracy: 0.8974609375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4860311448574066, accuracy: 0.891845703125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.5058870911598206, accuracy: 0.893798828125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.47947436571121216, accuracy: 0.901123046875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.45054084062576294, accuracy: 0.896728515625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.44889119267463684, accuracy: 0.89794921875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.4649692177772522, accuracy: 0.900390625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.47209370136260986, accuracy: 0.90380859375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.40414533019065857, accuracy: 0.898193359375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.46956533193588257, accuracy: 0.896240234375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.45191654562950134, accuracy: 0.8984375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.4366779923439026, accuracy: 0.90869140625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.42700380086898804, accuracy: 0.903564453125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.4151321053504944, accuracy: 0.896484375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.38806504011154175, accuracy: 0.908935546875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.4277864992618561, accuracy: 0.907470703125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.405830055475235, accuracy: 0.904541015625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.43252310156822205, accuracy: 0.906494140625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.3782600462436676, accuracy: 0.91162109375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.4465442895889282, accuracy: 0.909912109375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.4146764576435089, accuracy: 0.908203125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.42474380135536194, accuracy: 0.914306640625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.36633747816085815, accuracy: 0.908935546875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.37118425965309143, accuracy: 0.912109375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.38126909732818604, accuracy: 0.905029296875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.3927183449268341, accuracy: 0.9130859375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.44504913687705994, accuracy: 0.90869140625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.36950287222862244, accuracy: 0.9130859375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.38126203417778015, accuracy: 0.91064453125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3755333423614502, accuracy: 0.9052734375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.3872798681259155, accuracy: 0.911376953125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3595602512359619, accuracy: 0.9111328125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.37942832708358765, accuracy: 0.914306640625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.3283868432044983, accuracy: 0.91748046875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.31324678659439087, accuracy: 0.917236328125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.37782928347587585, accuracy: 0.9150390625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.3843224048614502, accuracy: 0.91259765625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.3521083891391754, accuracy: 0.920166015625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.42146751284599304, accuracy: 0.91845703125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.3473309278488159, accuracy: 0.911865234375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.36514145135879517, accuracy: 0.921630859375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.37397995591163635, accuracy: 0.914306640625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3168329894542694, accuracy: 0.910400390625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.3415745198726654, accuracy: 0.918701171875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.36216968297958374, accuracy: 0.917236328125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.32800722122192383, accuracy: 0.920166015625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.3802375793457031, accuracy: 0.9189453125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.3869859278202057, accuracy: 0.919189453125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.2946055233478546, accuracy: 0.919189453125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.352619469165802, accuracy: 0.919677734375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.305391788482666, accuracy: 0.91552734375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.2989729344844818, accuracy: 0.910888671875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.339848130941391, accuracy: 0.91748046875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.33568793535232544, accuracy: 0.920654296875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.36007535457611084, accuracy: 0.9208984375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.3336559534072876, accuracy: 0.922119140625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.296222984790802, accuracy: 0.918701171875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.35780036449432373, accuracy: 0.919921875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.35782289505004883, accuracy: 0.923828125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.38387537002563477, accuracy: 0.919921875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.3599663972854614, accuracy: 0.93017578125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3192013204097748, accuracy: 0.918701171875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.33490872383117676, accuracy: 0.917724609375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3020891845226288, accuracy: 0.920166015625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.2868354320526123, accuracy: 0.923583984375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.3478386104106903, accuracy: 0.92822265625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.2309114933013916, accuracy: 0.401611328125\n",
            "Epoch: 2, learning_rate:0.01,costo: 2.1649861335754395, accuracy: 0.6416015625\n",
            "Epoch: 3, learning_rate:0.01,costo: 2.0726115703582764, accuracy: 0.700927734375\n",
            "Epoch: 4, learning_rate:0.01,costo: 1.993506669998169, accuracy: 0.74072265625\n",
            "Epoch: 5, learning_rate:0.01,costo: 1.9160188436508179, accuracy: 0.736328125\n",
            "Epoch: 6, learning_rate:0.01,costo: 1.7592391967773438, accuracy: 0.740234375\n",
            "Epoch: 7, learning_rate:0.01,costo: 1.6413155794143677, accuracy: 0.758056640625\n",
            "Epoch: 8, learning_rate:0.01,costo: 1.520520806312561, accuracy: 0.775390625\n",
            "Epoch: 9, learning_rate:0.01,costo: 1.399251103401184, accuracy: 0.787109375\n",
            "Epoch: 10, learning_rate:0.01,costo: 1.2713325023651123, accuracy: 0.804443359375\n",
            "Epoch: 11, learning_rate:0.01,costo: 1.136094093322754, accuracy: 0.81640625\n",
            "Epoch: 12, learning_rate:0.01,costo: 1.0577301979064941, accuracy: 0.82080078125\n",
            "Epoch: 13, learning_rate:0.01,costo: 1.0257220268249512, accuracy: 0.83056640625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.9584994912147522, accuracy: 0.835693359375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.906928539276123, accuracy: 0.85205078125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.7778322696685791, accuracy: 0.85205078125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.772293210029602, accuracy: 0.863525390625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.7356370687484741, accuracy: 0.863037109375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.6637736558914185, accuracy: 0.86474609375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.6738471984863281, accuracy: 0.865478515625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.6356907486915588, accuracy: 0.86767578125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.6219448447227478, accuracy: 0.878662109375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.5987454652786255, accuracy: 0.882568359375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.5796473622322083, accuracy: 0.88623046875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.6127233505249023, accuracy: 0.888916015625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.5720704793930054, accuracy: 0.880859375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.6004006266593933, accuracy: 0.883544921875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.5228403806686401, accuracy: 0.8935546875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.5598612427711487, accuracy: 0.89208984375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.5314324498176575, accuracy: 0.889892578125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.5365596413612366, accuracy: 0.896240234375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.5297640562057495, accuracy: 0.895263671875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.48113906383514404, accuracy: 0.897705078125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.4831455647945404, accuracy: 0.8974609375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.485476016998291, accuracy: 0.8984375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.4295285642147064, accuracy: 0.894287109375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.501891016960144, accuracy: 0.90087890625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.41971299052238464, accuracy: 0.893310546875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.44558194279670715, accuracy: 0.904052734375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.45051059126853943, accuracy: 0.8974609375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.470838338136673, accuracy: 0.90576171875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.4536878168582916, accuracy: 0.904541015625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.37857311964035034, accuracy: 0.90625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.4288439154624939, accuracy: 0.900634765625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.4445101320743561, accuracy: 0.9013671875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.4087175726890564, accuracy: 0.902587890625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.44321736693382263, accuracy: 0.905517578125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.45572996139526367, accuracy: 0.9072265625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.40150219202041626, accuracy: 0.900146484375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.38836440443992615, accuracy: 0.897705078125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.36894604563713074, accuracy: 0.90380859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.4538729190826416, accuracy: 0.90576171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.37867599725723267, accuracy: 0.91064453125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.39767709374427795, accuracy: 0.90625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.41631364822387695, accuracy: 0.908203125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.35056114196777344, accuracy: 0.9052734375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.37248268723487854, accuracy: 0.910888671875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.37672924995422363, accuracy: 0.90380859375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.35699379444122314, accuracy: 0.912353515625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.4248124659061432, accuracy: 0.912353515625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.3436160683631897, accuracy: 0.906982421875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.36623677611351013, accuracy: 0.906005859375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.3879517912864685, accuracy: 0.90966796875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.3727935254573822, accuracy: 0.912109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.39090508222579956, accuracy: 0.91064453125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.3738359808921814, accuracy: 0.91015625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.3949401378631592, accuracy: 0.90771484375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.37690332531929016, accuracy: 0.91552734375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.3743436634540558, accuracy: 0.915283203125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.37559202313423157, accuracy: 0.91796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.4157654345035553, accuracy: 0.913330078125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.37386804819107056, accuracy: 0.9140625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.34539884328842163, accuracy: 0.91162109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.35214585065841675, accuracy: 0.912841796875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.3434685468673706, accuracy: 0.9150390625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.32926470041275024, accuracy: 0.921630859375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.3805573880672455, accuracy: 0.919677734375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.31727203726768494, accuracy: 0.919677734375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.3506670594215393, accuracy: 0.919189453125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.33051276206970215, accuracy: 0.912353515625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.3761124610900879, accuracy: 0.915283203125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.353933721780777, accuracy: 0.918212890625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.3569605052471161, accuracy: 0.919921875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.34529542922973633, accuracy: 0.91943359375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.3435284495353699, accuracy: 0.91259765625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.32969313859939575, accuracy: 0.9189453125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.3651883006095886, accuracy: 0.91357421875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.29586899280548096, accuracy: 0.92431640625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.34480586647987366, accuracy: 0.918212890625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.30574142932891846, accuracy: 0.916748046875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.27884337306022644, accuracy: 0.930419921875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.3521944582462311, accuracy: 0.917236328125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.3183113634586334, accuracy: 0.92333984375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.3018465042114258, accuracy: 0.9189453125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.31484273076057434, accuracy: 0.926513671875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.3562283515930176, accuracy: 0.92626953125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.3055017292499542, accuracy: 0.91650390625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.3162819743156433, accuracy: 0.9189453125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.2797629237174988, accuracy: 0.924560546875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.29066309332847595, accuracy: 0.9189453125\n"
          ]
        }
      ],
      "source": [
        "\n",
        "resultados['fixed'] = {}\n",
        "resultados['fixed']['val_acc_list'] = [0] * epochs\n",
        "resultados['fixed']['test_acc'] = 0\n",
        "resultados['fixed']['cost'] = [0] * epochs\n",
        "resultados['fixed']['time'] = 0\n",
        "resultados['fixed']['epochs'] = 0\n",
        "\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    fixed_acc_list, fixed_cost_list, fixed_lr_list, fixed_time, fixed_acc, fixed_epochs = Fixed()\n",
        "    resultados['fixed']['val_acc_list'] = SumList(resultados['fixed']['val_acc_list'], fixed_acc_list)\n",
        "    resultados['fixed']['test_acc'] += fixed_acc\n",
        "    resultados['fixed']['cost'] = SumList(resultados['fixed']['cost'], fixed_cost_list)\n",
        "    resultados['fixed']['time'] += fixed_time\n",
        "    resultados['fixed']['epochs'] += fixed_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['fixed']['name'] = 'Fijo'\n",
        "resultados['fixed']['lr'] = fixed_lr_list\n",
        "resultados['fixed']['test_acc'] = resultados['fixed']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['fixed']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['fixed']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['fixed']['cost'] = DeleteZerosFromList(DivideList(resultados['fixed']['cost'], MAX_ITERATIONS))\n",
        "resultados['fixed']['time'] = resultados['fixed']['time']/ MAX_ITERATIONS\n",
        "resultados['fixed']['epochs'] = resultados['fixed']['epochs'] / MAX_ITERATIONS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EybNcRix9Krm"
      },
      "source": [
        "## Tasa de aprendizaje decreciente (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QJ1SWKZeDxO"
      },
      "source": [
        "Inicia con un $\\alpha$ inicial y va decreciendo en por un factor $gamma$. El decrecimiento se da un numero $l$ de epochs definidos\n",
        "\n",
        "$\\alpha: 1x10^{-2}$\n",
        "\n",
        "$gamma: 7x10^{-1}$\n",
        "\n",
        "$l: 10$ epochs\n",
        "\n",
        "![pytorch.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZkQsuESPfGaR"
      },
      "outputs": [],
      "source": [
        "def Decay():\n",
        "    modelDecay = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelDecay.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7, last_epoch=-1, verbose=False)\n",
        "\n",
        "    start.record()\n",
        "    decay_acc_list, decay_cost_list, decay_lr_list, decay_epochs = train(modelDecay,optimizer, scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    decay_time = start.elapsed_time(end)\n",
        "\n",
        "    decay_acc = accuracy(modelDecay, x_test_tensor,  y_test_tensor, mb_size)\n",
        "    \n",
        "    return decay_acc_list, decay_cost_list, decay_lr_list, decay_time, decay_acc, decay_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C69-CXmo9N3L",
        "outputId": "7f38e113-a43d-4892-865e-b21243f2e1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:[0.01],costo: 2.2538022994995117, accuracy: 0.396728515625\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.180420398712158, accuracy: 0.5908203125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.112757921218872, accuracy: 0.671630859375\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.017634630203247, accuracy: 0.722900390625\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9313502311706543, accuracy: 0.741943359375\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8183189630508423, accuracy: 0.7529296875\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7306828498840332, accuracy: 0.768310546875\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5712850093841553, accuracy: 0.781494140625\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.47537362575531, accuracy: 0.798095703125\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3526992797851562, accuracy: 0.798095703125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2331348657608032, accuracy: 0.8125\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.217726707458496, accuracy: 0.810546875\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1322588920593262, accuracy: 0.82666015625\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0512701272964478, accuracy: 0.82861328125\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.046996831893921, accuracy: 0.842041015625\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9355436563491821, accuracy: 0.851318359375\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9202584028244019, accuracy: 0.84423828125\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.870935320854187, accuracy: 0.8525390625\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.7892112135887146, accuracy: 0.85302734375\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7849733829498291, accuracy: 0.8642578125\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7708068490028381, accuracy: 0.86083984375\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7448367476463318, accuracy: 0.86572265625\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7519543766975403, accuracy: 0.86572265625\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.6836177110671997, accuracy: 0.87158203125\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.6993193030357361, accuracy: 0.859375\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7061419486999512, accuracy: 0.86962890625\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6393882036209106, accuracy: 0.872802734375\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6617850661277771, accuracy: 0.87158203125\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6491054892539978, accuracy: 0.86767578125\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6056417226791382, accuracy: 0.8759765625\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6655620336532593, accuracy: 0.871337890625\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6101834774017334, accuracy: 0.882080078125\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.5929035544395447, accuracy: 0.877685546875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.6122642159461975, accuracy: 0.8759765625\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.598578155040741, accuracy: 0.876953125\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.5839716196060181, accuracy: 0.881103515625\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.5982964634895325, accuracy: 0.884033203125\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.5941462516784668, accuracy: 0.8759765625\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5848584175109863, accuracy: 0.888916015625\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5561585426330566, accuracy: 0.88671875\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6423661708831787, accuracy: 0.87841796875\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.6139369010925293, accuracy: 0.8779296875\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5638396143913269, accuracy: 0.884765625\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5286812782287598, accuracy: 0.885009765625\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.6490160822868347, accuracy: 0.890869140625\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5519243478775024, accuracy: 0.882080078125\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5811165571212769, accuracy: 0.8828125\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5586340427398682, accuracy: 0.8916015625\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5446646809577942, accuracy: 0.891845703125\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5303990244865417, accuracy: 0.88330078125\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5418635010719299, accuracy: 0.883544921875\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5707005262374878, accuracy: 0.884033203125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5516548752784729, accuracy: 0.884521484375\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5653448104858398, accuracy: 0.886962890625\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5105635523796082, accuracy: 0.88720703125\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.536796510219574, accuracy: 0.888427734375\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5831857323646545, accuracy: 0.88818359375\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5579785108566284, accuracy: 0.88916015625\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.536939799785614, accuracy: 0.893310546875\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5205080509185791, accuracy: 0.889404296875\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5154441595077515, accuracy: 0.88916015625\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5316197276115417, accuracy: 0.88623046875\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5199249386787415, accuracy: 0.89013671875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5152353644371033, accuracy: 0.887939453125\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.538473904132843, accuracy: 0.894775390625\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5293009281158447, accuracy: 0.888427734375\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5303182601928711, accuracy: 0.88720703125\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.4903525710105896, accuracy: 0.880126953125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.521564245223999, accuracy: 0.894775390625\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.4986099302768707, accuracy: 0.895263671875\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.49164074659347534, accuracy: 0.885498046875\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5128788948059082, accuracy: 0.894775390625\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5308260321617126, accuracy: 0.8876953125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5379239320755005, accuracy: 0.890869140625\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.49940216541290283, accuracy: 0.8916015625\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5059803128242493, accuracy: 0.89306640625\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5090797543525696, accuracy: 0.888916015625\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.47844061255455017, accuracy: 0.893310546875\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.4995231032371521, accuracy: 0.895751953125\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5331980586051941, accuracy: 0.892822265625\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5054553151130676, accuracy: 0.894775390625\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5067974925041199, accuracy: 0.897705078125\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.4874589741230011, accuracy: 0.895263671875\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.47934526205062866, accuracy: 0.895263671875\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5189641118049622, accuracy: 0.894287109375\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5016664266586304, accuracy: 0.8857421875\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5140981674194336, accuracy: 0.892578125\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.5044196248054504, accuracy: 0.89501953125\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.48348233103752136, accuracy: 0.894775390625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5003064274787903, accuracy: 0.891845703125\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.4721658229827881, accuracy: 0.887451171875\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5036258101463318, accuracy: 0.89013671875\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.49237367510795593, accuracy: 0.893798828125\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.5272626876831055, accuracy: 0.89404296875\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5224682688713074, accuracy: 0.8974609375\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5140131115913391, accuracy: 0.89013671875\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.46620044112205505, accuracy: 0.897216796875\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4904041588306427, accuracy: 0.89306640625\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5022398233413696, accuracy: 0.893798828125\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.47525373101234436, accuracy: 0.88916015625\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.2536404132843018, accuracy: 0.3017578125\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1784744262695312, accuracy: 0.517578125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.101382255554199, accuracy: 0.657958984375\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.024200439453125, accuracy: 0.701904296875\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9334379434585571, accuracy: 0.7216796875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8225549459457397, accuracy: 0.742431640625\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7139368057250977, accuracy: 0.757568359375\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.574164867401123, accuracy: 0.757080078125\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4705404043197632, accuracy: 0.78466796875\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3747663497924805, accuracy: 0.79150390625\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2476749420166016, accuracy: 0.806884765625\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.1599982976913452, accuracy: 0.816650390625\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.0996366739273071, accuracy: 0.8212890625\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.086184024810791, accuracy: 0.828857421875\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0036907196044922, accuracy: 0.8310546875\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.97667396068573, accuracy: 0.839599609375\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9393051266670227, accuracy: 0.84619140625\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8434920907020569, accuracy: 0.84912109375\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8399004936218262, accuracy: 0.857666015625\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7951173782348633, accuracy: 0.861328125\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.8509746789932251, accuracy: 0.855224609375\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7600343227386475, accuracy: 0.859619140625\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7458509206771851, accuracy: 0.866455078125\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7628055214881897, accuracy: 0.86669921875\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7319743037223816, accuracy: 0.855712890625\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7219462990760803, accuracy: 0.871826171875\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.7234128713607788, accuracy: 0.86572265625\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6805167198181152, accuracy: 0.8662109375\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6501848697662354, accuracy: 0.861083984375\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6193842887878418, accuracy: 0.8671875\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6586167216300964, accuracy: 0.87548828125\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6635261178016663, accuracy: 0.875244140625\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6296057105064392, accuracy: 0.878662109375\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.643471896648407, accuracy: 0.87255859375\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.5950461030006409, accuracy: 0.88037109375\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6250322461128235, accuracy: 0.8798828125\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6207969784736633, accuracy: 0.878662109375\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.5981062650680542, accuracy: 0.876953125\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5492058396339417, accuracy: 0.880615234375\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5789995193481445, accuracy: 0.88134765625\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6047579050064087, accuracy: 0.8798828125\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5853697657585144, accuracy: 0.879638671875\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5890378952026367, accuracy: 0.883056640625\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5972380638122559, accuracy: 0.879638671875\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.610044538974762, accuracy: 0.87158203125\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5755446553230286, accuracy: 0.883056640625\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5500026941299438, accuracy: 0.885986328125\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5285845994949341, accuracy: 0.880126953125\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5578529238700867, accuracy: 0.886474609375\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5561383962631226, accuracy: 0.88330078125\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5845198035240173, accuracy: 0.88232421875\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5063591599464417, accuracy: 0.88232421875\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.55618816614151, accuracy: 0.889404296875\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5649455189704895, accuracy: 0.88720703125\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5298558473587036, accuracy: 0.88330078125\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.57375568151474, accuracy: 0.878173828125\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5784334540367126, accuracy: 0.879638671875\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5384265184402466, accuracy: 0.88720703125\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5860926508903503, accuracy: 0.890380859375\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.48819372057914734, accuracy: 0.890869140625\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5177935361862183, accuracy: 0.887939453125\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5357286334037781, accuracy: 0.887939453125\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5756667852401733, accuracy: 0.881103515625\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5352168679237366, accuracy: 0.89013671875\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5529614686965942, accuracy: 0.891357421875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.48943495750427246, accuracy: 0.887939453125\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5665873885154724, accuracy: 0.885986328125\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5317145586013794, accuracy: 0.885009765625\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.49736231565475464, accuracy: 0.8896484375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5242161750793457, accuracy: 0.88720703125\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5164899230003357, accuracy: 0.88623046875\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.543031632900238, accuracy: 0.889892578125\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5300889611244202, accuracy: 0.887939453125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.537429690361023, accuracy: 0.887451171875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5480908155441284, accuracy: 0.883056640625\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5355901122093201, accuracy: 0.88818359375\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5068984031677246, accuracy: 0.892822265625\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5498626828193665, accuracy: 0.894287109375\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.48121896386146545, accuracy: 0.880859375\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5072384476661682, accuracy: 0.891845703125\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5687057375907898, accuracy: 0.888916015625\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5354138612747192, accuracy: 0.892822265625\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.47313740849494934, accuracy: 0.893798828125\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5294803977012634, accuracy: 0.887451171875\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5221404433250427, accuracy: 0.887451171875\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.50434809923172, accuracy: 0.88525390625\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5273760557174683, accuracy: 0.8876953125\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.5233815312385559, accuracy: 0.891357421875\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.49576637148857117, accuracy: 0.894775390625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.46744924783706665, accuracy: 0.88427734375\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5001057386398315, accuracy: 0.889892578125\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5176163911819458, accuracy: 0.890380859375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5101544857025146, accuracy: 0.884033203125\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.4891773760318756, accuracy: 0.885009765625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5301665663719177, accuracy: 0.890869140625\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5631611943244934, accuracy: 0.8916015625\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.5213701725006104, accuracy: 0.891845703125\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4839538335800171, accuracy: 0.89453125\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5686342120170593, accuracy: 0.891845703125\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.4947063624858856, accuracy: 0.8857421875\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.240283250808716, accuracy: 0.328125\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1624906063079834, accuracy: 0.64111328125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.071687698364258, accuracy: 0.69677734375\n",
            "Epoch: 4, learning_rate:[0.01],costo: 1.9954843521118164, accuracy: 0.732421875\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.893556833267212, accuracy: 0.74658203125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.797859787940979, accuracy: 0.753662109375\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.6885690689086914, accuracy: 0.760986328125\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5598971843719482, accuracy: 0.7763671875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4185317754745483, accuracy: 0.789306640625\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.2939164638519287, accuracy: 0.793212890625\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2605842351913452, accuracy: 0.80322265625\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.1384490728378296, accuracy: 0.809326171875\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1103594303131104, accuracy: 0.822265625\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0497323274612427, accuracy: 0.822265625\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0054354667663574, accuracy: 0.828125\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9224724769592285, accuracy: 0.842041015625\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.8976030349731445, accuracy: 0.838623046875\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.847100019454956, accuracy: 0.8466796875\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8191975951194763, accuracy: 0.844482421875\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.798559844493866, accuracy: 0.857177734375\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7567911744117737, accuracy: 0.8525390625\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7828356027603149, accuracy: 0.85595703125\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7041710019111633, accuracy: 0.8603515625\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7312740087509155, accuracy: 0.857421875\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7298815250396729, accuracy: 0.8603515625\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.69087153673172, accuracy: 0.853515625\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6830378174781799, accuracy: 0.869140625\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6831967830657959, accuracy: 0.87255859375\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6630733609199524, accuracy: 0.871826171875\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6712764501571655, accuracy: 0.8720703125\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6476001143455505, accuracy: 0.873046875\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6551163792610168, accuracy: 0.86376953125\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6165248155593872, accuracy: 0.864013671875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.5945647358894348, accuracy: 0.87158203125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.5840116739273071, accuracy: 0.873291015625\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6017029881477356, accuracy: 0.868896484375\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.5863821506500244, accuracy: 0.87939453125\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.6169641017913818, accuracy: 0.880126953125\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.6164494156837463, accuracy: 0.8798828125\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5824270248413086, accuracy: 0.87890625\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6103185415267944, accuracy: 0.88037109375\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.6026990413665771, accuracy: 0.879150390625\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5973727107048035, accuracy: 0.87548828125\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5624703764915466, accuracy: 0.88134765625\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5732985734939575, accuracy: 0.885986328125\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5699793100357056, accuracy: 0.88720703125\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5474205613136292, accuracy: 0.885498046875\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5228800773620605, accuracy: 0.889892578125\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5989040732383728, accuracy: 0.887451171875\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.55361008644104, accuracy: 0.878662109375\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5743932127952576, accuracy: 0.88427734375\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5622522830963135, accuracy: 0.882080078125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5441028475761414, accuracy: 0.88330078125\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5306499004364014, accuracy: 0.890869140625\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5641580820083618, accuracy: 0.890380859375\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.556325376033783, accuracy: 0.886962890625\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.51961749792099, accuracy: 0.88818359375\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5142032504081726, accuracy: 0.883544921875\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5525113344192505, accuracy: 0.885009765625\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5513935089111328, accuracy: 0.8935546875\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5515767335891724, accuracy: 0.885986328125\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5503343939781189, accuracy: 0.888916015625\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5434290170669556, accuracy: 0.884765625\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5259129405021667, accuracy: 0.890869140625\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5141081213951111, accuracy: 0.88232421875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5629076957702637, accuracy: 0.889892578125\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.537873387336731, accuracy: 0.888671875\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.4885421395301819, accuracy: 0.889404296875\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5755641460418701, accuracy: 0.889892578125\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5790054202079773, accuracy: 0.885009765625\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5068656802177429, accuracy: 0.900390625\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5368715524673462, accuracy: 0.890625\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5279386639595032, accuracy: 0.891845703125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5166637301445007, accuracy: 0.887939453125\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5575258731842041, accuracy: 0.88671875\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5527812242507935, accuracy: 0.888671875\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5139544010162354, accuracy: 0.892333984375\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5096589922904968, accuracy: 0.88671875\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.5541151165962219, accuracy: 0.89306640625\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5599392056465149, accuracy: 0.885009765625\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5490022301673889, accuracy: 0.891845703125\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.4667539894580841, accuracy: 0.88916015625\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5436767339706421, accuracy: 0.890625\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.496957927942276, accuracy: 0.8857421875\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.4699252247810364, accuracy: 0.881103515625\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5649967193603516, accuracy: 0.892333984375\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5622376799583435, accuracy: 0.888671875\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.49686411023139954, accuracy: 0.889892578125\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.46738728880882263, accuracy: 0.8818359375\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5381139516830444, accuracy: 0.889892578125\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.48429200053215027, accuracy: 0.891357421875\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5216561555862427, accuracy: 0.890380859375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.47713541984558105, accuracy: 0.8955078125\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.474313884973526, accuracy: 0.893310546875\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5183171033859253, accuracy: 0.89013671875\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.46873044967651367, accuracy: 0.88427734375\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.516241192817688, accuracy: 0.89111328125\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4990094006061554, accuracy: 0.90478515625\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.520942211151123, accuracy: 0.89208984375\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.5207690596580505, accuracy: 0.89453125\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.235779047012329, accuracy: 0.380126953125\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.152641773223877, accuracy: 0.572021484375\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.096240282058716, accuracy: 0.667724609375\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.0078442096710205, accuracy: 0.71875\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.912669062614441, accuracy: 0.74560546875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.7957367897033691, accuracy: 0.74462890625\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7066295146942139, accuracy: 0.7568359375\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5674543380737305, accuracy: 0.766357421875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4254831075668335, accuracy: 0.793212890625\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3209105730056763, accuracy: 0.798095703125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2305492162704468, accuracy: 0.803955078125\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.14535391330719, accuracy: 0.80810546875\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1097025871276855, accuracy: 0.820068359375\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.034303069114685, accuracy: 0.834716796875\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 0.9904046058654785, accuracy: 0.839111328125\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9538533687591553, accuracy: 0.837646484375\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.876064658164978, accuracy: 0.848388671875\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8939533829689026, accuracy: 0.852294921875\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.807135283946991, accuracy: 0.85302734375\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7755039930343628, accuracy: 0.85400390625\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7673026919364929, accuracy: 0.853515625\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7485337257385254, accuracy: 0.863525390625\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7438279390335083, accuracy: 0.86083984375\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7537000179290771, accuracy: 0.869384765625\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.69084632396698, accuracy: 0.868896484375\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.6942471861839294, accuracy: 0.864990234375\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.7158951759338379, accuracy: 0.872314453125\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6527773141860962, accuracy: 0.8779296875\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6630103588104248, accuracy: 0.867431640625\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6418615579605103, accuracy: 0.8759765625\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6552789211273193, accuracy: 0.870361328125\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.654786229133606, accuracy: 0.873291015625\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6064509153366089, accuracy: 0.875732421875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.6178109049797058, accuracy: 0.876953125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6460990309715271, accuracy: 0.869873046875\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6005923748016357, accuracy: 0.875244140625\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.5794131755828857, accuracy: 0.884521484375\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.5677679181098938, accuracy: 0.8759765625\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5913043022155762, accuracy: 0.8828125\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5825381278991699, accuracy: 0.880859375\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6036800742149353, accuracy: 0.88330078125\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.577090859413147, accuracy: 0.882568359375\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5723045468330383, accuracy: 0.885498046875\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5702781677246094, accuracy: 0.887451171875\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5872264504432678, accuracy: 0.8828125\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5590323209762573, accuracy: 0.88818359375\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5705764293670654, accuracy: 0.892822265625\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5831997990608215, accuracy: 0.884033203125\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5319498777389526, accuracy: 0.884521484375\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.550055742263794, accuracy: 0.88818359375\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5446373820304871, accuracy: 0.891357421875\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.502415657043457, accuracy: 0.887939453125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5975493788719177, accuracy: 0.88427734375\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5383864045143127, accuracy: 0.89208984375\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5207347273826599, accuracy: 0.887939453125\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.49918657541275024, accuracy: 0.894775390625\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5109978318214417, accuracy: 0.890625\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5583689212799072, accuracy: 0.892822265625\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.49501460790634155, accuracy: 0.8916015625\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.48651352524757385, accuracy: 0.88916015625\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5259947180747986, accuracy: 0.88818359375\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5231270790100098, accuracy: 0.887939453125\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5162354707717896, accuracy: 0.890869140625\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.47206979990005493, accuracy: 0.8876953125\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.45698240399360657, accuracy: 0.89794921875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5232162475585938, accuracy: 0.886474609375\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5420780777931213, accuracy: 0.88330078125\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5408206582069397, accuracy: 0.887451171875\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.49315524101257324, accuracy: 0.893798828125\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5176646709442139, accuracy: 0.890625\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.549358069896698, accuracy: 0.890869140625\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5052178502082825, accuracy: 0.89990234375\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5150966644287109, accuracy: 0.89599609375\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5229337215423584, accuracy: 0.8935546875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.521702229976654, accuracy: 0.893310546875\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5078333616256714, accuracy: 0.884765625\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5334855318069458, accuracy: 0.891357421875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.495082288980484, accuracy: 0.88916015625\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.5053666830062866, accuracy: 0.8935546875\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5154891014099121, accuracy: 0.891357421875\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5456413626670837, accuracy: 0.89208984375\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5379149317741394, accuracy: 0.8916015625\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5559601187705994, accuracy: 0.889892578125\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5181717872619629, accuracy: 0.89453125\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5095610618591309, accuracy: 0.893798828125\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.529835045337677, accuracy: 0.894287109375\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.4855932593345642, accuracy: 0.895263671875\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.5253834128379822, accuracy: 0.89208984375\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.4893457293510437, accuracy: 0.900146484375\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.4933605492115021, accuracy: 0.890625\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5161954760551453, accuracy: 0.8916015625\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5056389570236206, accuracy: 0.89111328125\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5034846663475037, accuracy: 0.89453125\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.4714095890522003, accuracy: 0.896728515625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5199753642082214, accuracy: 0.890625\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5438940525054932, accuracy: 0.893798828125\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.5299957394599915, accuracy: 0.896728515625\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.49102962017059326, accuracy: 0.88916015625\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5094781517982483, accuracy: 0.893798828125\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.4829597473144531, accuracy: 0.89306640625\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.2391483783721924, accuracy: 0.376708984375\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1638896465301514, accuracy: 0.6201171875\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.0974979400634766, accuracy: 0.671142578125\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.0020792484283447, accuracy: 0.711669921875\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9256561994552612, accuracy: 0.728759765625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8011730909347534, accuracy: 0.76416015625\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7009189128875732, accuracy: 0.761962890625\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5751577615737915, accuracy: 0.770751953125\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4269099235534668, accuracy: 0.785400390625\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3122574090957642, accuracy: 0.802490234375\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2295210361480713, accuracy: 0.81591796875\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.176600694656372, accuracy: 0.82763671875\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1159493923187256, accuracy: 0.823974609375\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0395416021347046, accuracy: 0.8271484375\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 0.9556096196174622, accuracy: 0.83740234375\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9540199637413025, accuracy: 0.8427734375\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.8877806067466736, accuracy: 0.854736328125\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8298755884170532, accuracy: 0.854248046875\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8172618746757507, accuracy: 0.858154296875\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7760937809944153, accuracy: 0.866455078125\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.797053873538971, accuracy: 0.8505859375\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7781820297241211, accuracy: 0.864990234375\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7362778186798096, accuracy: 0.859375\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.6941003799438477, accuracy: 0.85888671875\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.6726073026657104, accuracy: 0.86767578125\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7078885436058044, accuracy: 0.87158203125\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6977607011795044, accuracy: 0.872314453125\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6366594433784485, accuracy: 0.874267578125\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6815310120582581, accuracy: 0.873779296875\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6034675240516663, accuracy: 0.872802734375\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.5972164273262024, accuracy: 0.87255859375\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6285644173622131, accuracy: 0.876708984375\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.5945777297019958, accuracy: 0.875244140625\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.60481196641922, accuracy: 0.87548828125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.5836024880409241, accuracy: 0.87939453125\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.561468780040741, accuracy: 0.87451171875\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6157676577568054, accuracy: 0.873291015625\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.608874499797821, accuracy: 0.878662109375\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5335383415222168, accuracy: 0.873779296875\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5766564011573792, accuracy: 0.875244140625\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.5830796360969543, accuracy: 0.8837890625\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5366266965866089, accuracy: 0.8818359375\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5887224674224854, accuracy: 0.88818359375\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.6264685988426208, accuracy: 0.878662109375\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5745946168899536, accuracy: 0.876708984375\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5635136365890503, accuracy: 0.891845703125\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5822374820709229, accuracy: 0.888427734375\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5445583462715149, accuracy: 0.87646484375\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5196644067764282, accuracy: 0.8837890625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5299462676048279, accuracy: 0.8857421875\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.6030484437942505, accuracy: 0.882568359375\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5516869425773621, accuracy: 0.88818359375\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5543505549430847, accuracy: 0.8896484375\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5604642033576965, accuracy: 0.884765625\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5494610667228699, accuracy: 0.885986328125\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5630074143409729, accuracy: 0.8828125\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5159187316894531, accuracy: 0.8828125\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.498521625995636, accuracy: 0.87939453125\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5440938472747803, accuracy: 0.8896484375\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.541820228099823, accuracy: 0.892333984375\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5903737545013428, accuracy: 0.892578125\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5002053380012512, accuracy: 0.887939453125\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5559315085411072, accuracy: 0.890380859375\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5297606587409973, accuracy: 0.8896484375\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.4935280382633209, accuracy: 0.893798828125\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5172359943389893, accuracy: 0.88671875\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.4990515410900116, accuracy: 0.890625\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.4776396155357361, accuracy: 0.89306640625\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5781618356704712, accuracy: 0.88818359375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5284856557846069, accuracy: 0.892333984375\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5067705512046814, accuracy: 0.8896484375\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.4865579903125763, accuracy: 0.887451171875\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5352234244346619, accuracy: 0.892578125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5412659049034119, accuracy: 0.887451171875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5608641505241394, accuracy: 0.888916015625\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.533591091632843, accuracy: 0.890380859375\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.48814305663108826, accuracy: 0.88818359375\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5121874809265137, accuracy: 0.895751953125\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.509405791759491, accuracy: 0.893310546875\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5016431212425232, accuracy: 0.88720703125\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5130559802055359, accuracy: 0.89599609375\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5781673192977905, accuracy: 0.890625\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5615962743759155, accuracy: 0.892333984375\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5091233849525452, accuracy: 0.8935546875\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.49510088562965393, accuracy: 0.89697265625\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5484595894813538, accuracy: 0.89208984375\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5440792441368103, accuracy: 0.892333984375\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.5388054847717285, accuracy: 0.883544921875\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.5033782720565796, accuracy: 0.897705078125\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.4690617322921753, accuracy: 0.8935546875\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.4907621741294861, accuracy: 0.8935546875\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5195986032485962, accuracy: 0.889892578125\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.4669218361377716, accuracy: 0.890380859375\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.533301055431366, accuracy: 0.894287109375\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5496452450752258, accuracy: 0.8798828125\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5376733541488647, accuracy: 0.89208984375\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.5031675696372986, accuracy: 0.89404296875\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.568240225315094, accuracy: 0.888427734375\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5370885133743286, accuracy: 0.89208984375\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.4798184931278229, accuracy: 0.89208984375\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.2579612731933594, accuracy: 0.359130859375\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.196106195449829, accuracy: 0.5517578125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.121894598007202, accuracy: 0.6171875\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.074941873550415, accuracy: 0.668212890625\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.965837836265564, accuracy: 0.70068359375\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.873612403869629, accuracy: 0.72216796875\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7784368991851807, accuracy: 0.7333984375\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.6572216749191284, accuracy: 0.748779296875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.531964898109436, accuracy: 0.762451171875\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.4200702905654907, accuracy: 0.769287109375\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.327053189277649, accuracy: 0.78857421875\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.259163498878479, accuracy: 0.802734375\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1642752885818481, accuracy: 0.803955078125\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.1136728525161743, accuracy: 0.814453125\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0184394121170044, accuracy: 0.82177734375\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 1.026328206062317, accuracy: 0.826171875\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9495679140090942, accuracy: 0.831298828125\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8908340930938721, accuracy: 0.832275390625\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8794693946838379, accuracy: 0.85498046875\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.8210670948028564, accuracy: 0.850341796875\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.8133725523948669, accuracy: 0.8603515625\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7470661997795105, accuracy: 0.85595703125\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.792934775352478, accuracy: 0.8623046875\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7518453001976013, accuracy: 0.85986328125\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.735846996307373, accuracy: 0.857666015625\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7180720567703247, accuracy: 0.86962890625\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6828224658966064, accuracy: 0.86669921875\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6998468041419983, accuracy: 0.873046875\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.681869387626648, accuracy: 0.865966796875\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6448658108711243, accuracy: 0.865966796875\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6675941944122314, accuracy: 0.871337890625\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6924885511398315, accuracy: 0.873779296875\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6184968948364258, accuracy: 0.869873046875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.5890361666679382, accuracy: 0.87841796875\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6148171424865723, accuracy: 0.87158203125\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.664237916469574, accuracy: 0.88037109375\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6320845484733582, accuracy: 0.87646484375\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.6208165884017944, accuracy: 0.87158203125\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5868721604347229, accuracy: 0.877197265625\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5796833634376526, accuracy: 0.8779296875\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6063489317893982, accuracy: 0.88037109375\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.6057194471359253, accuracy: 0.87939453125\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.6056520938873291, accuracy: 0.875244140625\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5651195049285889, accuracy: 0.878662109375\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5914171934127808, accuracy: 0.884521484375\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5742615461349487, accuracy: 0.873046875\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5821108222007751, accuracy: 0.8759765625\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.6212733387947083, accuracy: 0.886474609375\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5290912389755249, accuracy: 0.886962890625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5500426888465881, accuracy: 0.881103515625\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5693261623382568, accuracy: 0.887451171875\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.6217747926712036, accuracy: 0.879638671875\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5239402651786804, accuracy: 0.8828125\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5652672648429871, accuracy: 0.880859375\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5376958847045898, accuracy: 0.885009765625\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5468411445617676, accuracy: 0.88037109375\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5165110230445862, accuracy: 0.883056640625\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5444461703300476, accuracy: 0.885986328125\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5561298727989197, accuracy: 0.893798828125\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5414161086082458, accuracy: 0.887939453125\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5482096672058105, accuracy: 0.8876953125\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.550277590751648, accuracy: 0.88671875\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5298998355865479, accuracy: 0.88671875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5648729205131531, accuracy: 0.895263671875\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.523125410079956, accuracy: 0.88623046875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5170568227767944, accuracy: 0.888916015625\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.49372929334640503, accuracy: 0.890869140625\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5698124766349792, accuracy: 0.89111328125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.536117672920227, accuracy: 0.8896484375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5390001535415649, accuracy: 0.886474609375\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5382142066955566, accuracy: 0.8916015625\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5398334860801697, accuracy: 0.890625\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.512831449508667, accuracy: 0.89111328125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5129331350326538, accuracy: 0.890380859375\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5660607814788818, accuracy: 0.893798828125\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5093672275543213, accuracy: 0.8916015625\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5388770699501038, accuracy: 0.886474609375\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5383275151252747, accuracy: 0.88671875\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.5348415374755859, accuracy: 0.88720703125\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5073121190071106, accuracy: 0.8896484375\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.49705377221107483, accuracy: 0.896728515625\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.55031818151474, accuracy: 0.889404296875\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5565949082374573, accuracy: 0.892333984375\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5477083921432495, accuracy: 0.889404296875\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.46834003925323486, accuracy: 0.894775390625\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5199646949768066, accuracy: 0.894775390625\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5320088267326355, accuracy: 0.8876953125\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.4849180281162262, accuracy: 0.8876953125\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.5155842304229736, accuracy: 0.8896484375\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5471181869506836, accuracy: 0.89208984375\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5322348475456238, accuracy: 0.889892578125\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.4753741919994354, accuracy: 0.894287109375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5268121361732483, accuracy: 0.89013671875\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.5246905088424683, accuracy: 0.89697265625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5604408979415894, accuracy: 0.88671875\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.49941104650497437, accuracy: 0.88818359375\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.5156676769256592, accuracy: 0.8935546875\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4925619065761566, accuracy: 0.895751953125\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5119275450706482, accuracy: 0.896484375\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.49388188123703003, accuracy: 0.893310546875\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.2511463165283203, accuracy: 0.39501953125\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.18196702003479, accuracy: 0.593994140625\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.103715658187866, accuracy: 0.67529296875\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.0260753631591797, accuracy: 0.71630859375\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9497790336608887, accuracy: 0.7421875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8434717655181885, accuracy: 0.733642578125\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.734325647354126, accuracy: 0.75390625\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.6025809049606323, accuracy: 0.75927734375\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.482051968574524, accuracy: 0.7724609375\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3841150999069214, accuracy: 0.786376953125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2910897731781006, accuracy: 0.794677734375\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2176525592803955, accuracy: 0.802490234375\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1308099031448364, accuracy: 0.814697265625\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.040116548538208, accuracy: 0.82080078125\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0331251621246338, accuracy: 0.829833984375\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 1.0252717733383179, accuracy: 0.830078125\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9292498230934143, accuracy: 0.8349609375\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.9076684713363647, accuracy: 0.832275390625\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8453724980354309, accuracy: 0.846923828125\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7957534790039062, accuracy: 0.853271484375\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.8099282383918762, accuracy: 0.86279296875\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7831610441207886, accuracy: 0.85595703125\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7527437806129456, accuracy: 0.861328125\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.770896315574646, accuracy: 0.859375\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7294484972953796, accuracy: 0.86865234375\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7504910826683044, accuracy: 0.868408203125\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.697816014289856, accuracy: 0.867431640625\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6695687174797058, accuracy: 0.86767578125\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6950218677520752, accuracy: 0.86865234375\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6509925723075867, accuracy: 0.87158203125\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.5671886205673218, accuracy: 0.87939453125\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6312755942344666, accuracy: 0.8671875\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6006503701210022, accuracy: 0.876220703125\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.6232807040214539, accuracy: 0.87353515625\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6009243130683899, accuracy: 0.8779296875\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6355045437812805, accuracy: 0.871337890625\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6181480288505554, accuracy: 0.87255859375\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.599172830581665, accuracy: 0.880615234375\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5760816335678101, accuracy: 0.885498046875\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5658220052719116, accuracy: 0.884521484375\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6206616163253784, accuracy: 0.88427734375\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5399817824363708, accuracy: 0.880859375\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.577659547328949, accuracy: 0.882568359375\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5732877254486084, accuracy: 0.88330078125\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5566269755363464, accuracy: 0.882568359375\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5221174955368042, accuracy: 0.889404296875\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.579684317111969, accuracy: 0.88623046875\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5734350681304932, accuracy: 0.892578125\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5150508880615234, accuracy: 0.888427734375\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5607153177261353, accuracy: 0.885986328125\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5621303915977478, accuracy: 0.886962890625\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5855424404144287, accuracy: 0.88720703125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5387885570526123, accuracy: 0.888916015625\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5269038081169128, accuracy: 0.89208984375\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5240427255630493, accuracy: 0.886962890625\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5221575498580933, accuracy: 0.89013671875\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5140982270240784, accuracy: 0.891357421875\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.541756272315979, accuracy: 0.896728515625\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5060680508613586, accuracy: 0.8935546875\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5386952757835388, accuracy: 0.89111328125\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5682792067527771, accuracy: 0.893310546875\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5233281850814819, accuracy: 0.8916015625\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5394076108932495, accuracy: 0.8876953125\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5582723021507263, accuracy: 0.895263671875\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5479863286018372, accuracy: 0.894775390625\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5197529792785645, accuracy: 0.893798828125\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5358393788337708, accuracy: 0.8955078125\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5462982058525085, accuracy: 0.893310546875\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5320724844932556, accuracy: 0.89208984375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5160880088806152, accuracy: 0.8896484375\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5462659597396851, accuracy: 0.890625\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5395717024803162, accuracy: 0.88525390625\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5254846215248108, accuracy: 0.891845703125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.47718527913093567, accuracy: 0.891357421875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5066673755645752, accuracy: 0.89208984375\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.49044090509414673, accuracy: 0.89404296875\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5160652995109558, accuracy: 0.889404296875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.4983099699020386, accuracy: 0.888916015625\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.48326289653778076, accuracy: 0.89208984375\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5262298583984375, accuracy: 0.89697265625\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.528827428817749, accuracy: 0.890380859375\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5090423226356506, accuracy: 0.900146484375\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5434998273849487, accuracy: 0.8955078125\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5059648752212524, accuracy: 0.89501953125\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5207974314689636, accuracy: 0.89111328125\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5097419023513794, accuracy: 0.890380859375\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5190423727035522, accuracy: 0.89501953125\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.4790399670600891, accuracy: 0.896484375\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.4719848036766052, accuracy: 0.89599609375\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.4791760742664337, accuracy: 0.887939453125\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.45721760392189026, accuracy: 0.89697265625\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5318041443824768, accuracy: 0.898193359375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5416735410690308, accuracy: 0.889404296875\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.49836450815200806, accuracy: 0.890869140625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5088326930999756, accuracy: 0.89697265625\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5261187553405762, accuracy: 0.89453125\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.46981754899024963, accuracy: 0.896484375\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.5284456014633179, accuracy: 0.8935546875\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5389814376831055, accuracy: 0.89111328125\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.5195102095603943, accuracy: 0.899169921875\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.253924608230591, accuracy: 0.3291015625\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1894946098327637, accuracy: 0.59716796875\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.100736141204834, accuracy: 0.69384765625\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.0219008922576904, accuracy: 0.72705078125\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.941068410873413, accuracy: 0.727294921875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8428624868392944, accuracy: 0.742919921875\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7309820652008057, accuracy: 0.75634765625\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5970220565795898, accuracy: 0.76171875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4672406911849976, accuracy: 0.7880859375\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3703763484954834, accuracy: 0.803955078125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2586511373519897, accuracy: 0.80615234375\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2095410823822021, accuracy: 0.819580078125\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1498103141784668, accuracy: 0.830322265625\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0846753120422363, accuracy: 0.83837890625\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0338315963745117, accuracy: 0.845458984375\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9615779519081116, accuracy: 0.852294921875\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9241056442260742, accuracy: 0.8466796875\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.852363109588623, accuracy: 0.85888671875\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.845964252948761, accuracy: 0.857421875\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7957465052604675, accuracy: 0.861328125\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7618953585624695, accuracy: 0.863037109375\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7509002685546875, accuracy: 0.85693359375\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7345820665359497, accuracy: 0.864501953125\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7816343307495117, accuracy: 0.870849609375\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7274508476257324, accuracy: 0.86767578125\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7375345826148987, accuracy: 0.870361328125\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6825674772262573, accuracy: 0.87158203125\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.7000404000282288, accuracy: 0.875244140625\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6521395444869995, accuracy: 0.877197265625\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6397207975387573, accuracy: 0.86865234375\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.672802746295929, accuracy: 0.875\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6652384400367737, accuracy: 0.88232421875\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6407610177993774, accuracy: 0.873779296875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.640001118183136, accuracy: 0.882080078125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.607455849647522, accuracy: 0.8740234375\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6187820434570312, accuracy: 0.881591796875\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6142532229423523, accuracy: 0.878662109375\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.6031156778335571, accuracy: 0.884033203125\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5523368716239929, accuracy: 0.884033203125\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5528063774108887, accuracy: 0.88232421875\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6250910758972168, accuracy: 0.87841796875\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5920125246047974, accuracy: 0.8740234375\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5609554648399353, accuracy: 0.885986328125\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.6024791598320007, accuracy: 0.880615234375\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5717978477478027, accuracy: 0.890869140625\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5754719376564026, accuracy: 0.883056640625\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.543925940990448, accuracy: 0.8876953125\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5764808058738708, accuracy: 0.890625\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5841128826141357, accuracy: 0.8837890625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5474904775619507, accuracy: 0.885986328125\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5546000599861145, accuracy: 0.88720703125\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.540546178817749, accuracy: 0.892578125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5317688584327698, accuracy: 0.88916015625\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5528964996337891, accuracy: 0.8798828125\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.4978269040584564, accuracy: 0.888427734375\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5089074969291687, accuracy: 0.88134765625\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.530744731426239, accuracy: 0.8837890625\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.49212244153022766, accuracy: 0.890380859375\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5526690483093262, accuracy: 0.888916015625\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5526313185691833, accuracy: 0.89208984375\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5415084362030029, accuracy: 0.886474609375\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5554684996604919, accuracy: 0.88330078125\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5246865153312683, accuracy: 0.887451171875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5314040184020996, accuracy: 0.892578125\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5368711948394775, accuracy: 0.891357421875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5381671190261841, accuracy: 0.8935546875\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.49079185724258423, accuracy: 0.88427734375\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5154972076416016, accuracy: 0.8828125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5205608010292053, accuracy: 0.88720703125\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5065065026283264, accuracy: 0.896728515625\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5396907925605774, accuracy: 0.8955078125\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.50815749168396, accuracy: 0.893798828125\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5059877038002014, accuracy: 0.888916015625\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5161719918251038, accuracy: 0.889404296875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.524895429611206, accuracy: 0.89013671875\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.4964805841445923, accuracy: 0.89013671875\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5133000016212463, accuracy: 0.884033203125\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5382425785064697, accuracy: 0.89208984375\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.4844960570335388, accuracy: 0.889404296875\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5410199165344238, accuracy: 0.8896484375\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.4699127972126007, accuracy: 0.892333984375\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.526193380355835, accuracy: 0.893798828125\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5104452967643738, accuracy: 0.890625\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5238463878631592, accuracy: 0.8935546875\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.4971947968006134, accuracy: 0.89404296875\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.4999335706233978, accuracy: 0.895751953125\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5000510811805725, accuracy: 0.8837890625\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.488318532705307, accuracy: 0.886962890625\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.49010664224624634, accuracy: 0.890625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5257911086082458, accuracy: 0.886474609375\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.47764235734939575, accuracy: 0.887451171875\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.49633651971817017, accuracy: 0.891845703125\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.47561606764793396, accuracy: 0.8955078125\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.47670191526412964, accuracy: 0.888916015625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5242915749549866, accuracy: 0.885986328125\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5250465869903564, accuracy: 0.895263671875\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.4771650731563568, accuracy: 0.892822265625\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.5638023614883423, accuracy: 0.889404296875\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5122535824775696, accuracy: 0.89111328125\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.4873533546924591, accuracy: 0.898681640625\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.2405459880828857, accuracy: 0.2744140625\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1681272983551025, accuracy: 0.557861328125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.0992088317871094, accuracy: 0.67578125\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.008939266204834, accuracy: 0.71630859375\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9263782501220703, accuracy: 0.738525390625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8067560195922852, accuracy: 0.75537109375\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.6714415550231934, accuracy: 0.7763671875\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5509542226791382, accuracy: 0.783447265625\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.430657982826233, accuracy: 0.801025390625\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.306664228439331, accuracy: 0.8125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2458560466766357, accuracy: 0.80322265625\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.1497043371200562, accuracy: 0.824462890625\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.0742294788360596, accuracy: 0.828857421875\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0357134342193604, accuracy: 0.833251953125\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 0.9707515835762024, accuracy: 0.83056640625\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9697292447090149, accuracy: 0.840576171875\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.8932037949562073, accuracy: 0.845703125\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8514012694358826, accuracy: 0.861572265625\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8518468141555786, accuracy: 0.859130859375\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.8238027095794678, accuracy: 0.8583984375\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7838718295097351, accuracy: 0.867431640625\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7513654232025146, accuracy: 0.860595703125\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7231099605560303, accuracy: 0.86181640625\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7125051021575928, accuracy: 0.861328125\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.6558142900466919, accuracy: 0.864990234375\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.6879240870475769, accuracy: 0.86474609375\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6662277579307556, accuracy: 0.873291015625\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6842949986457825, accuracy: 0.870361328125\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6939502358436584, accuracy: 0.872802734375\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6304495930671692, accuracy: 0.8759765625\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6462042331695557, accuracy: 0.87109375\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6506873965263367, accuracy: 0.88134765625\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6802644729614258, accuracy: 0.876220703125\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.5871391296386719, accuracy: 0.872314453125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.5960119962692261, accuracy: 0.87939453125\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.5849743485450745, accuracy: 0.878173828125\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.643624484539032, accuracy: 0.87451171875\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.6508758068084717, accuracy: 0.87548828125\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5841277241706848, accuracy: 0.880615234375\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5819309949874878, accuracy: 0.878173828125\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.5805996060371399, accuracy: 0.884033203125\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5791229009628296, accuracy: 0.882080078125\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5945203304290771, accuracy: 0.881103515625\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5942631363868713, accuracy: 0.880859375\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5350090265274048, accuracy: 0.881103515625\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5708016157150269, accuracy: 0.879150390625\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5620839595794678, accuracy: 0.87939453125\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5065364837646484, accuracy: 0.876708984375\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5217611789703369, accuracy: 0.883056640625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5406749248504639, accuracy: 0.87451171875\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5431545972824097, accuracy: 0.8837890625\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5468814969062805, accuracy: 0.883056640625\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5374223589897156, accuracy: 0.891357421875\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5742424726486206, accuracy: 0.88232421875\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5718631148338318, accuracy: 0.886474609375\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5404897928237915, accuracy: 0.888427734375\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.554351806640625, accuracy: 0.885986328125\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5191931128501892, accuracy: 0.883544921875\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.4986950755119324, accuracy: 0.886474609375\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5400446653366089, accuracy: 0.887939453125\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5433136820793152, accuracy: 0.8916015625\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5342116355895996, accuracy: 0.880126953125\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.519321858882904, accuracy: 0.888671875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.6001941561698914, accuracy: 0.88623046875\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.4768618941307068, accuracy: 0.88818359375\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5489377975463867, accuracy: 0.881591796875\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.48253002762794495, accuracy: 0.88671875\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5158733129501343, accuracy: 0.883544921875\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.546972393989563, accuracy: 0.8896484375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5069301128387451, accuracy: 0.884033203125\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.4678677022457123, accuracy: 0.8896484375\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5352013111114502, accuracy: 0.892333984375\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.47361794114112854, accuracy: 0.883544921875\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.47502610087394714, accuracy: 0.881591796875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5173376798629761, accuracy: 0.894287109375\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5547114014625549, accuracy: 0.887939453125\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.4940670430660248, accuracy: 0.88623046875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.49421054124832153, accuracy: 0.8876953125\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.5105164051055908, accuracy: 0.888427734375\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5385532379150391, accuracy: 0.8876953125\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5244004726409912, accuracy: 0.893798828125\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.51347815990448, accuracy: 0.88232421875\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.4919447600841522, accuracy: 0.894775390625\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.48517465591430664, accuracy: 0.882568359375\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5286774635314941, accuracy: 0.889892578125\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.4869832396507263, accuracy: 0.88623046875\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5257761478424072, accuracy: 0.890625\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.49643319845199585, accuracy: 0.884033203125\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.4719323515892029, accuracy: 0.892822265625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5107321739196777, accuracy: 0.886962890625\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5430231094360352, accuracy: 0.88330078125\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5488199591636658, accuracy: 0.888427734375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.45534762740135193, accuracy: 0.889404296875\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.52620929479599, accuracy: 0.890625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.49045440554618835, accuracy: 0.888671875\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.52342289686203, accuracy: 0.883544921875\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.490987628698349, accuracy: 0.89501953125\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4950834810733795, accuracy: 0.8876953125\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.46970483660697937, accuracy: 0.89013671875\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.5026320815086365, accuracy: 0.889892578125\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.232532501220703, accuracy: 0.35693359375\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1835169792175293, accuracy: 0.58349609375\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.103288412094116, accuracy: 0.66650390625\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.026337146759033, accuracy: 0.7138671875\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.927997350692749, accuracy: 0.738525390625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8223856687545776, accuracy: 0.73974609375\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7093722820281982, accuracy: 0.759765625\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.6178991794586182, accuracy: 0.7705078125\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4963804483413696, accuracy: 0.789306640625\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3403031826019287, accuracy: 0.790283203125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2970504760742188, accuracy: 0.80322265625\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2057125568389893, accuracy: 0.807861328125\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1200039386749268, accuracy: 0.814453125\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0767812728881836, accuracy: 0.82763671875\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0442819595336914, accuracy: 0.838134765625\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9309581518173218, accuracy: 0.844482421875\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9090003967285156, accuracy: 0.8447265625\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8630974292755127, accuracy: 0.850830078125\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8678709268569946, accuracy: 0.845458984375\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7976439595222473, accuracy: 0.843505859375\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7605183720588684, accuracy: 0.85791015625\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7488657832145691, accuracy: 0.85107421875\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7866023182868958, accuracy: 0.863037109375\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.6868378520011902, accuracy: 0.863037109375\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7499542236328125, accuracy: 0.86328125\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.6774998307228088, accuracy: 0.86181640625\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.7156272530555725, accuracy: 0.863525390625\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6630345582962036, accuracy: 0.865966796875\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6923879981040955, accuracy: 0.867919921875\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6211488842964172, accuracy: 0.87451171875\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6721209287643433, accuracy: 0.87451171875\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6319544911384583, accuracy: 0.87353515625\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.616661548614502, accuracy: 0.879638671875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.5901433229446411, accuracy: 0.87548828125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6192349195480347, accuracy: 0.88671875\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.5970621705055237, accuracy: 0.87646484375\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6469992399215698, accuracy: 0.876953125\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.5941662788391113, accuracy: 0.876708984375\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.6016955375671387, accuracy: 0.8798828125\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.6027491688728333, accuracy: 0.8818359375\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.602828323841095, accuracy: 0.8818359375\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5609332919120789, accuracy: 0.87841796875\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.583358108997345, accuracy: 0.881591796875\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5933340191841125, accuracy: 0.878173828125\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5230087041854858, accuracy: 0.865966796875\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5478618741035461, accuracy: 0.87890625\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5451553463935852, accuracy: 0.885986328125\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5448073744773865, accuracy: 0.886474609375\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5238319039344788, accuracy: 0.886962890625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.6073399186134338, accuracy: 0.89404296875\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5887913703918457, accuracy: 0.8837890625\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5850475430488586, accuracy: 0.88427734375\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5495564341545105, accuracy: 0.884033203125\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.536627471446991, accuracy: 0.886962890625\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5462157130241394, accuracy: 0.877197265625\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5828732252120972, accuracy: 0.885986328125\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5085288286209106, accuracy: 0.88134765625\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.44742774963378906, accuracy: 0.882080078125\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5108471512794495, accuracy: 0.886474609375\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5592445731163025, accuracy: 0.88623046875\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5005254149436951, accuracy: 0.885009765625\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5772635340690613, accuracy: 0.884521484375\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5302067399024963, accuracy: 0.888916015625\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5303243398666382, accuracy: 0.87646484375\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.46939173340797424, accuracy: 0.882568359375\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5139070153236389, accuracy: 0.8837890625\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5809909701347351, accuracy: 0.89404296875\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.48567822575569153, accuracy: 0.884033203125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.49800750613212585, accuracy: 0.8837890625\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.4980776906013489, accuracy: 0.87548828125\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.510917067527771, accuracy: 0.886474609375\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5228205919265747, accuracy: 0.887451171875\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5362616777420044, accuracy: 0.88916015625\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.49029213190078735, accuracy: 0.88623046875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.556939423084259, accuracy: 0.895751953125\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.515967071056366, accuracy: 0.8837890625\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5073588490486145, accuracy: 0.8857421875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5100371837615967, accuracy: 0.889892578125\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.49759143590927124, accuracy: 0.890625\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.553313136100769, accuracy: 0.89453125\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.49874138832092285, accuracy: 0.888916015625\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.4894808530807495, accuracy: 0.8837890625\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5048471689224243, accuracy: 0.89404296875\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.49698972702026367, accuracy: 0.885009765625\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.4928550720214844, accuracy: 0.889404296875\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.47723057866096497, accuracy: 0.885986328125\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5189279913902283, accuracy: 0.895263671875\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.5071604251861572, accuracy: 0.888916015625\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.5007494688034058, accuracy: 0.888916015625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5128193497657776, accuracy: 0.89404296875\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.4965595006942749, accuracy: 0.897216796875\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.503622829914093, accuracy: 0.888427734375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5677765607833862, accuracy: 0.887451171875\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.49755099415779114, accuracy: 0.8896484375\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5022733211517334, accuracy: 0.8896484375\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.49733731150627136, accuracy: 0.886474609375\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.5128034353256226, accuracy: 0.884033203125\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.49070826172828674, accuracy: 0.894287109375\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5756940841674805, accuracy: 0.89013671875\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.46360859274864197, accuracy: 0.889404296875\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.243757486343384, accuracy: 0.28564453125\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1759157180786133, accuracy: 0.52294921875\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.109569549560547, accuracy: 0.636474609375\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.0096263885498047, accuracy: 0.69091796875\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.933803915977478, accuracy: 0.732177734375\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8192005157470703, accuracy: 0.748779296875\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.72797691822052, accuracy: 0.757568359375\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5972483158111572, accuracy: 0.754638671875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4569742679595947, accuracy: 0.785888671875\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3371186256408691, accuracy: 0.802001953125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2923643589019775, accuracy: 0.810302734375\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2225884199142456, accuracy: 0.81640625\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.116098403930664, accuracy: 0.823974609375\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0615350008010864, accuracy: 0.8310546875\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0412416458129883, accuracy: 0.835693359375\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9609053134918213, accuracy: 0.839599609375\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9020020961761475, accuracy: 0.85693359375\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8929718136787415, accuracy: 0.849365234375\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8377960324287415, accuracy: 0.85546875\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.808086097240448, accuracy: 0.8583984375\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7865352034568787, accuracy: 0.86572265625\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.819995641708374, accuracy: 0.863037109375\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7400488257408142, accuracy: 0.865478515625\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7431526780128479, accuracy: 0.869140625\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.715368390083313, accuracy: 0.865478515625\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7293002009391785, accuracy: 0.87353515625\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6975774168968201, accuracy: 0.87451171875\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6731650829315186, accuracy: 0.873779296875\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6429727673530579, accuracy: 0.8798828125\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6720467209815979, accuracy: 0.876220703125\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.64496910572052, accuracy: 0.874755859375\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6372920870780945, accuracy: 0.877197265625\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6534295678138733, accuracy: 0.8779296875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.5947318077087402, accuracy: 0.87841796875\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6597110629081726, accuracy: 0.8828125\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.5506696701049805, accuracy: 0.876953125\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.5527974367141724, accuracy: 0.8779296875\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.6222750544548035, accuracy: 0.88330078125\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.6201160550117493, accuracy: 0.884521484375\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.6089837551116943, accuracy: 0.8759765625\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6237162947654724, accuracy: 0.885009765625\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5939736366271973, accuracy: 0.883544921875\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5731687545776367, accuracy: 0.886474609375\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5192916989326477, accuracy: 0.889404296875\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5684505105018616, accuracy: 0.886962890625\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5881107449531555, accuracy: 0.889404296875\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5865615010261536, accuracy: 0.888427734375\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5411419868469238, accuracy: 0.884033203125\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5619246363639832, accuracy: 0.890869140625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5425308346748352, accuracy: 0.8857421875\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.532401978969574, accuracy: 0.8896484375\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.572105348110199, accuracy: 0.889404296875\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5519875288009644, accuracy: 0.888427734375\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5392225980758667, accuracy: 0.884521484375\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5209462642669678, accuracy: 0.894287109375\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5594662427902222, accuracy: 0.89013671875\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5360422134399414, accuracy: 0.886474609375\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5565136075019836, accuracy: 0.890380859375\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.4909997880458832, accuracy: 0.892333984375\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5352489352226257, accuracy: 0.891845703125\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.560652494430542, accuracy: 0.88671875\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5278700590133667, accuracy: 0.888916015625\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5372965931892395, accuracy: 0.888671875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.507805347442627, accuracy: 0.892578125\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5146294832229614, accuracy: 0.890869140625\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5086168050765991, accuracy: 0.892822265625\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.520861804485321, accuracy: 0.893310546875\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5448629856109619, accuracy: 0.8994140625\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5707274675369263, accuracy: 0.895263671875\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5247094035148621, accuracy: 0.892822265625\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5359165668487549, accuracy: 0.887451171875\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.4969708323478699, accuracy: 0.88134765625\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5585232377052307, accuracy: 0.888916015625\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.4944603145122528, accuracy: 0.898193359375\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.502495288848877, accuracy: 0.8974609375\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5123171210289001, accuracy: 0.886474609375\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5286485552787781, accuracy: 0.88916015625\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.4985157549381256, accuracy: 0.898193359375\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.56058669090271, accuracy: 0.89306640625\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.4949243366718292, accuracy: 0.89111328125\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5395361185073853, accuracy: 0.8955078125\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.4917789697647095, accuracy: 0.886474609375\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5295608639717102, accuracy: 0.895751953125\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.47754213213920593, accuracy: 0.896484375\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5318616628646851, accuracy: 0.893798828125\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.527495265007019, accuracy: 0.8916015625\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.4837113618850708, accuracy: 0.892333984375\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.48149600625038147, accuracy: 0.894287109375\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.4848825931549072, accuracy: 0.89697265625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5189871191978455, accuracy: 0.889892578125\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5383836030960083, accuracy: 0.884765625\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5340929627418518, accuracy: 0.886474609375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.4918481707572937, accuracy: 0.892333984375\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.4908446669578552, accuracy: 0.89453125\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.4651787579059601, accuracy: 0.8994140625\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5109997987747192, accuracy: 0.89501953125\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.439813494682312, accuracy: 0.89501953125\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4960184693336487, accuracy: 0.895263671875\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5096622109413147, accuracy: 0.892822265625\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.49822619557380676, accuracy: 0.895263671875\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.234435558319092, accuracy: 0.37841796875\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.1571972370147705, accuracy: 0.589111328125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.059685468673706, accuracy: 0.6787109375\n",
            "Epoch: 4, learning_rate:[0.01],costo: 1.9806848764419556, accuracy: 0.71142578125\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.899826169013977, accuracy: 0.748779296875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8120944499969482, accuracy: 0.77197265625\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.6437382698059082, accuracy: 0.757568359375\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5235525369644165, accuracy: 0.77587890625\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.406241536140442, accuracy: 0.7880859375\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3340522050857544, accuracy: 0.80419921875\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2462509870529175, accuracy: 0.81884765625\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.1782729625701904, accuracy: 0.825439453125\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.0729066133499146, accuracy: 0.825927734375\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0144835710525513, accuracy: 0.834716796875\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 0.988957941532135, accuracy: 0.831298828125\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9067320823669434, accuracy: 0.843994140625\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.8792382478713989, accuracy: 0.845458984375\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.849377453327179, accuracy: 0.8505859375\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8363397121429443, accuracy: 0.85205078125\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.7876853942871094, accuracy: 0.858154296875\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.800653338432312, accuracy: 0.85302734375\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7303872108459473, accuracy: 0.858642578125\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7478446364402771, accuracy: 0.86279296875\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7228713035583496, accuracy: 0.86572265625\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7083095908164978, accuracy: 0.85986328125\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7065783143043518, accuracy: 0.8642578125\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6478568911552429, accuracy: 0.86572265625\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.655342161655426, accuracy: 0.870849609375\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6485590934753418, accuracy: 0.87548828125\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6310089826583862, accuracy: 0.870361328125\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6518092155456543, accuracy: 0.873291015625\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.5916659832000732, accuracy: 0.874267578125\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.5869597792625427, accuracy: 0.873291015625\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.6049954891204834, accuracy: 0.875244140625\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6523069739341736, accuracy: 0.869140625\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.619205117225647, accuracy: 0.88037109375\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.5197808146476746, accuracy: 0.875\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.5745194554328918, accuracy: 0.878662109375\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.5571070909500122, accuracy: 0.880126953125\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.5493491291999817, accuracy: 0.887451171875\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.5616284012794495, accuracy: 0.876708984375\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.6075402498245239, accuracy: 0.882568359375\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5547592043876648, accuracy: 0.876220703125\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5633276700973511, accuracy: 0.882568359375\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5346189737319946, accuracy: 0.88525390625\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5703532099723816, accuracy: 0.8837890625\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5242670774459839, accuracy: 0.888427734375\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5344703197479248, accuracy: 0.8876953125\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5347856283187866, accuracy: 0.889404296875\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5833983421325684, accuracy: 0.885009765625\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5401847958564758, accuracy: 0.880126953125\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5394691824913025, accuracy: 0.89306640625\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5686311721801758, accuracy: 0.88720703125\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5244385004043579, accuracy: 0.884765625\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5523748993873596, accuracy: 0.889892578125\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5317291617393494, accuracy: 0.896728515625\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5496334433555603, accuracy: 0.889404296875\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5026639103889465, accuracy: 0.890380859375\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5220791101455688, accuracy: 0.886962890625\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.4968295097351074, accuracy: 0.891357421875\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5219283699989319, accuracy: 0.8896484375\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5179445147514343, accuracy: 0.8857421875\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5437463521957397, accuracy: 0.88671875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.4881247282028198, accuracy: 0.889892578125\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5657727718353271, accuracy: 0.88671875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5045305490493774, accuracy: 0.88818359375\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5339217185974121, accuracy: 0.89013671875\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.4853978455066681, accuracy: 0.885986328125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5113803744316101, accuracy: 0.884033203125\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.492373526096344, accuracy: 0.885009765625\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5194486379623413, accuracy: 0.893798828125\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.552988588809967, accuracy: 0.887451171875\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5185965299606323, accuracy: 0.89111328125\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5318096876144409, accuracy: 0.890869140625\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5260375738143921, accuracy: 0.884765625\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5130321979522705, accuracy: 0.89453125\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5551168322563171, accuracy: 0.887451171875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5117310285568237, accuracy: 0.88916015625\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.5660521984100342, accuracy: 0.89501953125\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.48683130741119385, accuracy: 0.890380859375\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5153232216835022, accuracy: 0.88525390625\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5240875482559204, accuracy: 0.89892578125\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.47681328654289246, accuracy: 0.887451171875\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.48924127221107483, accuracy: 0.887939453125\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5140758156776428, accuracy: 0.876220703125\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5225394368171692, accuracy: 0.88427734375\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.4786134362220764, accuracy: 0.888671875\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.511221170425415, accuracy: 0.896728515625\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.49937567114830017, accuracy: 0.891357421875\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.4764064848423004, accuracy: 0.893798828125\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5009236335754395, accuracy: 0.892333984375\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5007293224334717, accuracy: 0.89306640625\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.559971272945404, accuracy: 0.89306640625\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.44733336567878723, accuracy: 0.894287109375\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.4910435676574707, accuracy: 0.89208984375\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5262657999992371, accuracy: 0.888671875\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.5271987318992615, accuracy: 0.890380859375\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.5089123845100403, accuracy: 0.88916015625\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5343918800354004, accuracy: 0.888671875\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.4994731843471527, accuracy: 0.896728515625\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.247147560119629, accuracy: 0.299560546875\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.161179542541504, accuracy: 0.528564453125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.0912764072418213, accuracy: 0.6533203125\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.01448392868042, accuracy: 0.702392578125\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9362212419509888, accuracy: 0.729736328125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8034363985061646, accuracy: 0.74853515625\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.6829389333724976, accuracy: 0.74609375\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5578399896621704, accuracy: 0.764404296875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4389933347702026, accuracy: 0.773681640625\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3499408960342407, accuracy: 0.787841796875\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.252053141593933, accuracy: 0.7939453125\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2084808349609375, accuracy: 0.807373046875\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.121644139289856, accuracy: 0.819091796875\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.055376410484314, accuracy: 0.822265625\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0542633533477783, accuracy: 0.823974609375\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9781851172447205, accuracy: 0.8330078125\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.8874842524528503, accuracy: 0.83544921875\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8852819204330444, accuracy: 0.85009765625\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8393338918685913, accuracy: 0.846923828125\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.8210778832435608, accuracy: 0.851806640625\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.787330687046051, accuracy: 0.8564453125\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7843941450119019, accuracy: 0.854736328125\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7508519887924194, accuracy: 0.854736328125\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7410503625869751, accuracy: 0.855712890625\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7068731784820557, accuracy: 0.860107421875\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.696948230266571, accuracy: 0.85693359375\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.7270660996437073, accuracy: 0.869873046875\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6685324907302856, accuracy: 0.8681640625\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6394814252853394, accuracy: 0.87255859375\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.692452609539032, accuracy: 0.869140625\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6690434813499451, accuracy: 0.8642578125\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6705113649368286, accuracy: 0.873779296875\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6470324397087097, accuracy: 0.875244140625\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.6108996272087097, accuracy: 0.87158203125\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6002273559570312, accuracy: 0.880859375\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6014278531074524, accuracy: 0.8818359375\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6164142489433289, accuracy: 0.87451171875\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.637342631816864, accuracy: 0.88134765625\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.64556884765625, accuracy: 0.883056640625\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.576339602470398, accuracy: 0.87841796875\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.5727213621139526, accuracy: 0.880859375\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5813493728637695, accuracy: 0.881591796875\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.58333820104599, accuracy: 0.88330078125\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.5675462484359741, accuracy: 0.888916015625\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.5285701155662537, accuracy: 0.883544921875\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.5849623680114746, accuracy: 0.89453125\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5778287649154663, accuracy: 0.883544921875\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5687335133552551, accuracy: 0.880615234375\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5528350472450256, accuracy: 0.89306640625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.6222900748252869, accuracy: 0.882080078125\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.6051062941551208, accuracy: 0.887451171875\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.6235262155532837, accuracy: 0.882080078125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5240185856819153, accuracy: 0.88818359375\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.556087076663971, accuracy: 0.888916015625\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5735453367233276, accuracy: 0.894287109375\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5084359645843506, accuracy: 0.8935546875\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5840634107589722, accuracy: 0.888427734375\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5525041818618774, accuracy: 0.8935546875\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.6066206693649292, accuracy: 0.890625\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5698135495185852, accuracy: 0.890380859375\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5768234729766846, accuracy: 0.888671875\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.522273063659668, accuracy: 0.886962890625\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5593276023864746, accuracy: 0.884033203125\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.550679087638855, accuracy: 0.892822265625\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.4915981590747833, accuracy: 0.8837890625\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5279123783111572, accuracy: 0.8857421875\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.552649736404419, accuracy: 0.889404296875\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5403972268104553, accuracy: 0.88330078125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5881252884864807, accuracy: 0.8896484375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5854041576385498, accuracy: 0.89013671875\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5432096719741821, accuracy: 0.891845703125\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5596646070480347, accuracy: 0.890380859375\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5123699307441711, accuracy: 0.8896484375\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5003727674484253, accuracy: 0.888427734375\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5175706148147583, accuracy: 0.8876953125\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5245062708854675, accuracy: 0.891357421875\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5022237300872803, accuracy: 0.88671875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5369886755943298, accuracy: 0.881591796875\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.47755685448646545, accuracy: 0.88427734375\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.532991886138916, accuracy: 0.88427734375\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5157824754714966, accuracy: 0.89501953125\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5499017834663391, accuracy: 0.89208984375\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5562883615493774, accuracy: 0.892578125\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.504857063293457, accuracy: 0.898681640625\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.48394012451171875, accuracy: 0.890380859375\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5372974276542664, accuracy: 0.892822265625\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5079554915428162, accuracy: 0.89306640625\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.4639245867729187, accuracy: 0.8876953125\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.5514435172080994, accuracy: 0.889404296875\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.5046290159225464, accuracy: 0.891845703125\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.4928126037120819, accuracy: 0.89306640625\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5213765501976013, accuracy: 0.895751953125\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.47073617577552795, accuracy: 0.89013671875\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.5168079733848572, accuracy: 0.89306640625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5060599446296692, accuracy: 0.888671875\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5273576974868774, accuracy: 0.882568359375\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.4874769151210785, accuracy: 0.895263671875\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.4933762848377228, accuracy: 0.899169921875\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5523935556411743, accuracy: 0.894287109375\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.4709622263908386, accuracy: 0.893310546875\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.245016098022461, accuracy: 0.322265625\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.176295757293701, accuracy: 0.53076171875\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.1043026447296143, accuracy: 0.65185546875\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.03096866607666, accuracy: 0.6845703125\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.9229017496109009, accuracy: 0.708984375\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8263429403305054, accuracy: 0.7275390625\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7118208408355713, accuracy: 0.73046875\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.6044718027114868, accuracy: 0.755615234375\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4714584350585938, accuracy: 0.77685546875\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3553006649017334, accuracy: 0.788818359375\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.32481050491333, accuracy: 0.7958984375\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2539522647857666, accuracy: 0.8154296875\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.076633334159851, accuracy: 0.81396484375\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0854971408843994, accuracy: 0.822509765625\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0238268375396729, accuracy: 0.826171875\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9858166575431824, accuracy: 0.841064453125\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.9650009870529175, accuracy: 0.84423828125\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8804304003715515, accuracy: 0.84423828125\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8301016092300415, accuracy: 0.847412109375\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.8263480067253113, accuracy: 0.852294921875\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7698333263397217, accuracy: 0.862548828125\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7743695974349976, accuracy: 0.853759765625\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7715240120887756, accuracy: 0.85693359375\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7350574135780334, accuracy: 0.8671875\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.6917718052864075, accuracy: 0.867431640625\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.7312532663345337, accuracy: 0.862548828125\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.6635400056838989, accuracy: 0.863037109375\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.7273219227790833, accuracy: 0.869384765625\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6662333607673645, accuracy: 0.87109375\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6277301907539368, accuracy: 0.87255859375\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6535907983779907, accuracy: 0.872802734375\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6289511919021606, accuracy: 0.872802734375\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6306828856468201, accuracy: 0.871826171875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.657302975654602, accuracy: 0.887451171875\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6060975790023804, accuracy: 0.86669921875\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.6251802444458008, accuracy: 0.882568359375\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6341466903686523, accuracy: 0.87451171875\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.6065576076507568, accuracy: 0.878662109375\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.6162984371185303, accuracy: 0.882080078125\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.6170545816421509, accuracy: 0.8828125\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.5658333897590637, accuracy: 0.875244140625\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5884715914726257, accuracy: 0.872802734375\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5869362950325012, accuracy: 0.890869140625\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.6072026491165161, accuracy: 0.879638671875\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.6097661256790161, accuracy: 0.88134765625\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.6159592866897583, accuracy: 0.883056640625\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5525110960006714, accuracy: 0.88330078125\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.6049640774726868, accuracy: 0.88134765625\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.5524190664291382, accuracy: 0.881103515625\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5561997294425964, accuracy: 0.894287109375\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.599693238735199, accuracy: 0.887939453125\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.5395303964614868, accuracy: 0.887939453125\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5244610905647278, accuracy: 0.89306640625\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5653252601623535, accuracy: 0.885986328125\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5232900977134705, accuracy: 0.8916015625\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5424808263778687, accuracy: 0.890869140625\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.5307361483573914, accuracy: 0.893798828125\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5465424656867981, accuracy: 0.880615234375\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5439066886901855, accuracy: 0.892578125\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.5524160861968994, accuracy: 0.890869140625\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5127527713775635, accuracy: 0.888671875\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.49471333622932434, accuracy: 0.888671875\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.5278223752975464, accuracy: 0.89306640625\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5300960540771484, accuracy: 0.89013671875\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.4890897870063782, accuracy: 0.893310546875\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5866355299949646, accuracy: 0.885986328125\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.5043068528175354, accuracy: 0.884033203125\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.5417601466178894, accuracy: 0.887451171875\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.5328429341316223, accuracy: 0.891845703125\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.49987682700157166, accuracy: 0.89404296875\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5274285078048706, accuracy: 0.89306640625\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5065240263938904, accuracy: 0.89111328125\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5636591911315918, accuracy: 0.882568359375\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5545135736465454, accuracy: 0.89013671875\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5580891370773315, accuracy: 0.88623046875\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5141633152961731, accuracy: 0.889892578125\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.5118700265884399, accuracy: 0.88916015625\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5037611722946167, accuracy: 0.892822265625\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.4974737763404846, accuracy: 0.89306640625\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.524347186088562, accuracy: 0.89013671875\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.5261043906211853, accuracy: 0.889404296875\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.505124032497406, accuracy: 0.895751953125\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5005718469619751, accuracy: 0.892578125\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.4978591501712799, accuracy: 0.899658203125\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5003864169120789, accuracy: 0.895263671875\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5466918349266052, accuracy: 0.89404296875\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5642580389976501, accuracy: 0.892333984375\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.48320135474205017, accuracy: 0.89013671875\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.5514106154441833, accuracy: 0.893310546875\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.46067044138908386, accuracy: 0.88671875\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5297302007675171, accuracy: 0.885986328125\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.5135542154312134, accuracy: 0.892578125\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5284786820411682, accuracy: 0.8935546875\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.5089269876480103, accuracy: 0.892822265625\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.5217735767364502, accuracy: 0.890380859375\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.5152183771133423, accuracy: 0.8935546875\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.45935285091400146, accuracy: 0.8955078125\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.5032205581665039, accuracy: 0.888916015625\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.5602856874465942, accuracy: 0.890380859375\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.5336394309997559, accuracy: 0.888427734375\n",
            "Epoch: 1, learning_rate:[0.01],costo: 2.237895965576172, accuracy: 0.393798828125\n",
            "Epoch: 2, learning_rate:[0.01],costo: 2.169433355331421, accuracy: 0.58251953125\n",
            "Epoch: 3, learning_rate:[0.01],costo: 2.1030499935150146, accuracy: 0.681640625\n",
            "Epoch: 4, learning_rate:[0.01],costo: 2.020024061203003, accuracy: 0.7255859375\n",
            "Epoch: 5, learning_rate:[0.01],costo: 1.927836537361145, accuracy: 0.734619140625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 1.8437063694000244, accuracy: 0.74658203125\n",
            "Epoch: 7, learning_rate:[0.01],costo: 1.7231253385543823, accuracy: 0.74267578125\n",
            "Epoch: 8, learning_rate:[0.01],costo: 1.5870131254196167, accuracy: 0.754638671875\n",
            "Epoch: 9, learning_rate:[0.01],costo: 1.4528661966323853, accuracy: 0.77001953125\n",
            "Epoch: 10, learning_rate:[0.006999999999999999],costo: 1.3358193635940552, accuracy: 0.783203125\n",
            "Epoch: 11, learning_rate:[0.006999999999999999],costo: 1.2725999355316162, accuracy: 0.7978515625\n",
            "Epoch: 12, learning_rate:[0.006999999999999999],costo: 1.2074428796768188, accuracy: 0.8037109375\n",
            "Epoch: 13, learning_rate:[0.006999999999999999],costo: 1.1329734325408936, accuracy: 0.812744140625\n",
            "Epoch: 14, learning_rate:[0.006999999999999999],costo: 1.0835130214691162, accuracy: 0.827880859375\n",
            "Epoch: 15, learning_rate:[0.006999999999999999],costo: 1.0189294815063477, accuracy: 0.82666015625\n",
            "Epoch: 16, learning_rate:[0.006999999999999999],costo: 0.9898688793182373, accuracy: 0.8369140625\n",
            "Epoch: 17, learning_rate:[0.006999999999999999],costo: 0.8702362179756165, accuracy: 0.83740234375\n",
            "Epoch: 18, learning_rate:[0.006999999999999999],costo: 0.8768708109855652, accuracy: 0.84326171875\n",
            "Epoch: 19, learning_rate:[0.006999999999999999],costo: 0.8446299433708191, accuracy: 0.84619140625\n",
            "Epoch: 20, learning_rate:[0.004899999999999999],costo: 0.8131443858146667, accuracy: 0.85107421875\n",
            "Epoch: 21, learning_rate:[0.004899999999999999],costo: 0.7605184316635132, accuracy: 0.85107421875\n",
            "Epoch: 22, learning_rate:[0.004899999999999999],costo: 0.7763209939002991, accuracy: 0.854248046875\n",
            "Epoch: 23, learning_rate:[0.004899999999999999],costo: 0.7164825797080994, accuracy: 0.85888671875\n",
            "Epoch: 24, learning_rate:[0.004899999999999999],costo: 0.7118149399757385, accuracy: 0.860107421875\n",
            "Epoch: 25, learning_rate:[0.004899999999999999],costo: 0.7112769484519958, accuracy: 0.862060546875\n",
            "Epoch: 26, learning_rate:[0.004899999999999999],costo: 0.6871230006217957, accuracy: 0.86279296875\n",
            "Epoch: 27, learning_rate:[0.004899999999999999],costo: 0.7211102843284607, accuracy: 0.8720703125\n",
            "Epoch: 28, learning_rate:[0.004899999999999999],costo: 0.6784917712211609, accuracy: 0.863525390625\n",
            "Epoch: 29, learning_rate:[0.004899999999999999],costo: 0.6533292531967163, accuracy: 0.873046875\n",
            "Epoch: 30, learning_rate:[0.003429999999999999],costo: 0.6328989267349243, accuracy: 0.86767578125\n",
            "Epoch: 31, learning_rate:[0.003429999999999999],costo: 0.6142057180404663, accuracy: 0.8662109375\n",
            "Epoch: 32, learning_rate:[0.003429999999999999],costo: 0.6419240236282349, accuracy: 0.8759765625\n",
            "Epoch: 33, learning_rate:[0.003429999999999999],costo: 0.6630093455314636, accuracy: 0.873779296875\n",
            "Epoch: 34, learning_rate:[0.003429999999999999],costo: 0.6007096171379089, accuracy: 0.87353515625\n",
            "Epoch: 35, learning_rate:[0.003429999999999999],costo: 0.6385440230369568, accuracy: 0.8740234375\n",
            "Epoch: 36, learning_rate:[0.003429999999999999],costo: 0.5729061365127563, accuracy: 0.87451171875\n",
            "Epoch: 37, learning_rate:[0.003429999999999999],costo: 0.6042851805686951, accuracy: 0.872314453125\n",
            "Epoch: 38, learning_rate:[0.003429999999999999],costo: 0.5761178731918335, accuracy: 0.875\n",
            "Epoch: 39, learning_rate:[0.003429999999999999],costo: 0.6170623302459717, accuracy: 0.877197265625\n",
            "Epoch: 40, learning_rate:[0.002400999999999999],costo: 0.631993293762207, accuracy: 0.882080078125\n",
            "Epoch: 41, learning_rate:[0.002400999999999999],costo: 0.6553414463996887, accuracy: 0.8779296875\n",
            "Epoch: 42, learning_rate:[0.002400999999999999],costo: 0.5457412004470825, accuracy: 0.87890625\n",
            "Epoch: 43, learning_rate:[0.002400999999999999],costo: 0.5869982242584229, accuracy: 0.88232421875\n",
            "Epoch: 44, learning_rate:[0.002400999999999999],costo: 0.6224319338798523, accuracy: 0.88427734375\n",
            "Epoch: 45, learning_rate:[0.002400999999999999],costo: 0.591758131980896, accuracy: 0.88037109375\n",
            "Epoch: 46, learning_rate:[0.002400999999999999],costo: 0.591646671295166, accuracy: 0.87939453125\n",
            "Epoch: 47, learning_rate:[0.002400999999999999],costo: 0.5404210090637207, accuracy: 0.8837890625\n",
            "Epoch: 48, learning_rate:[0.002400999999999999],costo: 0.5573228597640991, accuracy: 0.88671875\n",
            "Epoch: 49, learning_rate:[0.002400999999999999],costo: 0.562687873840332, accuracy: 0.889404296875\n",
            "Epoch: 50, learning_rate:[0.0016806999999999992],costo: 0.5584662556648254, accuracy: 0.8837890625\n",
            "Epoch: 51, learning_rate:[0.0016806999999999992],costo: 0.5598780512809753, accuracy: 0.885009765625\n",
            "Epoch: 52, learning_rate:[0.0016806999999999992],costo: 0.591489315032959, accuracy: 0.888427734375\n",
            "Epoch: 53, learning_rate:[0.0016806999999999992],costo: 0.5441805124282837, accuracy: 0.876953125\n",
            "Epoch: 54, learning_rate:[0.0016806999999999992],costo: 0.5404083132743835, accuracy: 0.885986328125\n",
            "Epoch: 55, learning_rate:[0.0016806999999999992],costo: 0.5276144742965698, accuracy: 0.88427734375\n",
            "Epoch: 56, learning_rate:[0.0016806999999999992],costo: 0.5439943075180054, accuracy: 0.894775390625\n",
            "Epoch: 57, learning_rate:[0.0016806999999999992],costo: 0.589876651763916, accuracy: 0.888671875\n",
            "Epoch: 58, learning_rate:[0.0016806999999999992],costo: 0.5769704580307007, accuracy: 0.8837890625\n",
            "Epoch: 59, learning_rate:[0.0016806999999999992],costo: 0.5438639521598816, accuracy: 0.878173828125\n",
            "Epoch: 60, learning_rate:[0.0011764899999999994],costo: 0.45688581466674805, accuracy: 0.89013671875\n",
            "Epoch: 61, learning_rate:[0.0011764899999999994],costo: 0.5315492153167725, accuracy: 0.89208984375\n",
            "Epoch: 62, learning_rate:[0.0011764899999999994],costo: 0.5501988530158997, accuracy: 0.88720703125\n",
            "Epoch: 63, learning_rate:[0.0011764899999999994],costo: 0.556618332862854, accuracy: 0.88623046875\n",
            "Epoch: 64, learning_rate:[0.0011764899999999994],costo: 0.5073775053024292, accuracy: 0.882568359375\n",
            "Epoch: 65, learning_rate:[0.0011764899999999994],costo: 0.5762643814086914, accuracy: 0.88818359375\n",
            "Epoch: 66, learning_rate:[0.0011764899999999994],costo: 0.5262539386749268, accuracy: 0.889892578125\n",
            "Epoch: 67, learning_rate:[0.0011764899999999994],costo: 0.49906468391418457, accuracy: 0.892333984375\n",
            "Epoch: 68, learning_rate:[0.0011764899999999994],costo: 0.4771094024181366, accuracy: 0.8876953125\n",
            "Epoch: 69, learning_rate:[0.0011764899999999994],costo: 0.4834931790828705, accuracy: 0.884521484375\n",
            "Epoch: 70, learning_rate:[0.0008235429999999996],costo: 0.5305956602096558, accuracy: 0.885986328125\n",
            "Epoch: 71, learning_rate:[0.0008235429999999996],costo: 0.5359843969345093, accuracy: 0.89111328125\n",
            "Epoch: 72, learning_rate:[0.0008235429999999996],costo: 0.5238938927650452, accuracy: 0.892333984375\n",
            "Epoch: 73, learning_rate:[0.0008235429999999996],costo: 0.5568001866340637, accuracy: 0.886474609375\n",
            "Epoch: 74, learning_rate:[0.0008235429999999996],costo: 0.5394256114959717, accuracy: 0.888916015625\n",
            "Epoch: 75, learning_rate:[0.0008235429999999996],costo: 0.5452063679695129, accuracy: 0.89697265625\n",
            "Epoch: 76, learning_rate:[0.0008235429999999996],costo: 0.5270963907241821, accuracy: 0.89599609375\n",
            "Epoch: 77, learning_rate:[0.0008235429999999996],costo: 0.48425912857055664, accuracy: 0.891357421875\n",
            "Epoch: 78, learning_rate:[0.0008235429999999996],costo: 0.5196214914321899, accuracy: 0.896484375\n",
            "Epoch: 79, learning_rate:[0.0008235429999999996],costo: 0.4814266562461853, accuracy: 0.89599609375\n",
            "Epoch: 80, learning_rate:[0.0005764800999999997],costo: 0.5025156140327454, accuracy: 0.89208984375\n",
            "Epoch: 81, learning_rate:[0.0005764800999999997],costo: 0.516720712184906, accuracy: 0.885986328125\n",
            "Epoch: 82, learning_rate:[0.0005764800999999997],costo: 0.5162993669509888, accuracy: 0.8876953125\n",
            "Epoch: 83, learning_rate:[0.0005764800999999997],costo: 0.5376077890396118, accuracy: 0.89013671875\n",
            "Epoch: 84, learning_rate:[0.0005764800999999997],costo: 0.5532508492469788, accuracy: 0.894775390625\n",
            "Epoch: 85, learning_rate:[0.0005764800999999997],costo: 0.5111315846443176, accuracy: 0.894775390625\n",
            "Epoch: 86, learning_rate:[0.0005764800999999997],costo: 0.5422688722610474, accuracy: 0.890380859375\n",
            "Epoch: 87, learning_rate:[0.0005764800999999997],costo: 0.5221267342567444, accuracy: 0.890869140625\n",
            "Epoch: 88, learning_rate:[0.0005764800999999997],costo: 0.4996572434902191, accuracy: 0.892578125\n",
            "Epoch: 89, learning_rate:[0.0005764800999999997],costo: 0.5395603775978088, accuracy: 0.89306640625\n",
            "Epoch: 90, learning_rate:[0.00040353606999999974],costo: 0.4872591495513916, accuracy: 0.89599609375\n",
            "Epoch: 91, learning_rate:[0.00040353606999999974],costo: 0.5726909637451172, accuracy: 0.8955078125\n",
            "Epoch: 92, learning_rate:[0.00040353606999999974],costo: 0.4766675531864166, accuracy: 0.894287109375\n",
            "Epoch: 93, learning_rate:[0.00040353606999999974],costo: 0.5064013004302979, accuracy: 0.892333984375\n",
            "Epoch: 94, learning_rate:[0.00040353606999999974],costo: 0.5158709287643433, accuracy: 0.8935546875\n",
            "Epoch: 95, learning_rate:[0.00040353606999999974],costo: 0.4757705628871918, accuracy: 0.88671875\n",
            "Epoch: 96, learning_rate:[0.00040353606999999974],costo: 0.4570152461528778, accuracy: 0.888427734375\n",
            "Epoch: 97, learning_rate:[0.00040353606999999974],costo: 0.49698853492736816, accuracy: 0.89404296875\n",
            "Epoch: 98, learning_rate:[0.00040353606999999974],costo: 0.5660067200660706, accuracy: 0.89404296875\n",
            "Epoch: 99, learning_rate:[0.00040353606999999974],costo: 0.4572530686855316, accuracy: 0.89990234375\n",
            "Epoch: 100, learning_rate:[0.0002824752489999998],costo: 0.5283082723617554, accuracy: 0.892333984375\n"
          ]
        }
      ],
      "source": [
        "\n",
        "resultados['decay'] = {}\n",
        "resultados['decay']['val_acc_list'] = [0] * epochs\n",
        "resultados['decay']['test_acc'] = 0\n",
        "resultados['decay']['cost'] = [0] * epochs\n",
        "resultados['decay']['time'] = 0\n",
        "resultados['decay']['epochs'] = 0\n",
        "\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    decay_acc_list, decay_cost_list, decay_lr_list, decay_time, decay_acc, decay_epochs = Decay()\n",
        "    resultados['decay']['val_acc_list'] = SumList(resultados['decay']['val_acc_list'], decay_acc_list)\n",
        "    resultados['decay']['test_acc'] += decay_acc\n",
        "    resultados['decay']['cost'] = SumList(resultados['decay']['cost'], decay_cost_list)\n",
        "    resultados['decay']['time'] += decay_time\n",
        "    resultados['decay']['epochs'] += decay_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['decay']['name'] = 'Decreciente'\n",
        "resultados['decay']['lr'] = decay_lr_list\n",
        "resultados['decay']['test_acc'] = resultados['decay']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['decay']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['decay']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['decay']['cost'] = DeleteZerosFromList(DivideList(resultados['decay']['cost'], MAX_ITERATIONS))\n",
        "resultados['decay']['time'] = resultados['decay']['time']/ MAX_ITERATIONS\n",
        "resultados['decay']['epochs'] = resultados['decay']['epochs'] / MAX_ITERATIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "print(fixed_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mAWn11Vmc6-"
      },
      "source": [
        "## Tasa de aprendizaje cíclica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNhEa7B6eoVt"
      },
      "source": [
        "Oscila entre una $base\\_ta$ y un $max\\_ta$ cada $n$ epochs en una proporción igual a \n",
        "\n",
        "$$\n",
        "proporción\\_de\\_cambio = \\frac{max\\_ta - base\\_ta}{n}\n",
        "$$\n",
        "\n",
        "Esta implementación facilitada por PyTorch, está basada en la publicación de Tasas de aprendizaje cíclico para la red neuronal de entrenamiento (*Cyclical Learning Rates for Training Neural Networks* o por sus siglas CLR) de Leslie Smith, 2017.\n",
        "\n",
        "$\\alpha: 1x10^{-2}$\n",
        "\n",
        "$beta: 0.9$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3o9wO0qfWfU"
      },
      "source": [
        "![CLR.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XQlDjhUFfGaS"
      },
      "outputs": [],
      "source": [
        "def Cyclic():\n",
        "    modelCyclic = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelCyclic.parameters(), lr=lr)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3,cycle_momentum=False )\n",
        "\n",
        "    start.record()\n",
        "    cyclic_acc_list, cyclic_cost_list, cyclic_lr_list, cyclic_epochs= train(modelCyclic, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    cyclic_time = start.elapsed_time(end)\n",
        "\n",
        "    cyclic_acc = accuracy(modelCyclic, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return cyclic_acc_list, cyclic_cost_list, cyclic_lr_list, cyclic_time, cyclic_acc, cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWp659FGmhDK",
        "outputId": "ff8bbc6c-d3bc-4c21-dad2-353c96980953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.228969097137451, accuracy: 0.3154296875\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9247106313705444, accuracy: 0.72900390625\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.138918399810791, accuracy: 0.822509765625\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.703225314617157, accuracy: 0.80517578125\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5302348136901855, accuracy: 0.884033203125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.46653562784194946, accuracy: 0.88916015625\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.5215521454811096, accuracy: 0.898681640625\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4642823040485382, accuracy: 0.901123046875\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.46070849895477295, accuracy: 0.8974609375\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.3604356348514557, accuracy: 0.90234375\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3433154821395874, accuracy: 0.911376953125\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3575507402420044, accuracy: 0.912109375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.33513307571411133, accuracy: 0.913330078125\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.36317339539527893, accuracy: 0.910400390625\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3164331316947937, accuracy: 0.91943359375\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.3824653923511505, accuracy: 0.916748046875\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.30715063214302063, accuracy: 0.927490234375\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.2897511422634125, accuracy: 0.92529296875\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.30119988322257996, accuracy: 0.925048828125\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.32613834738731384, accuracy: 0.931884765625\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.29170629382133484, accuracy: 0.92919921875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.2932095229625702, accuracy: 0.92919921875\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.30573949217796326, accuracy: 0.933349609375\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.28025057911872864, accuracy: 0.931640625\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.2411288619041443, accuracy: 0.9296875\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.23615306615829468, accuracy: 0.9365234375\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.28131455183029175, accuracy: 0.932861328125\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.2878217101097107, accuracy: 0.935546875\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.28251612186431885, accuracy: 0.934814453125\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.23814010620117188, accuracy: 0.93798828125\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2194799929857254, accuracy: 0.938232421875\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.234277606010437, accuracy: 0.933837890625\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.22213459014892578, accuracy: 0.93994140625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.24415044486522675, accuracy: 0.94091796875\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.24914833903312683, accuracy: 0.940673828125\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.22191353142261505, accuracy: 0.945556640625\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.21420109272003174, accuracy: 0.938720703125\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2067381590604782, accuracy: 0.9453125\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.17788010835647583, accuracy: 0.94482421875\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.20394635200500488, accuracy: 0.94873046875\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.2290402054786682, accuracy: 0.949462890625\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.20140160620212555, accuracy: 0.94775390625\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.20959904789924622, accuracy: 0.949462890625\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.20569249987602234, accuracy: 0.95654296875\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.18887737393379211, accuracy: 0.951904296875\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.19724629819393158, accuracy: 0.955810546875\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.1829526722431183, accuracy: 0.951904296875\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.2222932130098343, accuracy: 0.95166015625\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.22562500834465027, accuracy: 0.95361328125\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.22095169126987457, accuracy: 0.956298828125\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.19068191945552826, accuracy: 0.956787109375\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.19533173739910126, accuracy: 0.953369140625\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.17801885306835175, accuracy: 0.95849609375\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.21226073801517487, accuracy: 0.9560546875\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.16221080720424652, accuracy: 0.954833984375\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.1909008026123047, accuracy: 0.95556640625\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.1704670935869217, accuracy: 0.9619140625\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.15167608857154846, accuracy: 0.95654296875\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.18512436747550964, accuracy: 0.9599609375\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.16339430212974548, accuracy: 0.960205078125\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.18089427053928375, accuracy: 0.956787109375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1875201165676117, accuracy: 0.959228515625\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.20119017362594604, accuracy: 0.95703125\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.1560787558555603, accuracy: 0.958984375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.16091018915176392, accuracy: 0.96142578125\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.18994355201721191, accuracy: 0.955322265625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.19664999842643738, accuracy: 0.9609375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.14987215399742126, accuracy: 0.96142578125\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15197710692882538, accuracy: 0.961181640625\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.14231033623218536, accuracy: 0.965576171875\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.19745507836341858, accuracy: 0.962646484375\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.14369933307170868, accuracy: 0.958251953125\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.14451035857200623, accuracy: 0.960693359375\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.12013638019561768, accuracy: 0.962646484375\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.1414506733417511, accuracy: 0.962646484375\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.16848202049732208, accuracy: 0.9609375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.13015641272068024, accuracy: 0.963134765625\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.13849511742591858, accuracy: 0.964599609375\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.13571199774742126, accuracy: 0.96142578125\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.16190312802791595, accuracy: 0.962646484375\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.13932788372039795, accuracy: 0.96435546875\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.151808500289917, accuracy: 0.96728515625\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.11195936799049377, accuracy: 0.96630859375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.11661738157272339, accuracy: 0.96240234375\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.1739334911108017, accuracy: 0.962890625\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.11567315459251404, accuracy: 0.9638671875\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.1422615349292755, accuracy: 0.964111328125\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.12553229928016663, accuracy: 0.968017578125\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.1432928740978241, accuracy: 0.970703125\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.11908098310232162, accuracy: 0.966796875\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.13232441246509552, accuracy: 0.964599609375\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.15919049084186554, accuracy: 0.969970703125\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.12514762580394745, accuracy: 0.969482421875\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.12204554677009583, accuracy: 0.97119140625\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.1341709941625595, accuracy: 0.96728515625\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.13894401490688324, accuracy: 0.972900390625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.12796756625175476, accuracy: 0.972900390625\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.12183414399623871, accuracy: 0.97216796875\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.15812979638576508, accuracy: 0.969970703125\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.10985049605369568, accuracy: 0.966064453125\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.2533135414123535, accuracy: 0.357177734375\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9500519037246704, accuracy: 0.72021484375\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1748234033584595, accuracy: 0.817138671875\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7276500463485718, accuracy: 0.808837890625\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5260801315307617, accuracy: 0.88134765625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.4589534401893616, accuracy: 0.890869140625\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.47707968950271606, accuracy: 0.895751953125\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4633343815803528, accuracy: 0.899658203125\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.42205867171287537, accuracy: 0.9013671875\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.44163942337036133, accuracy: 0.885986328125\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3759705126285553, accuracy: 0.910888671875\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3785216212272644, accuracy: 0.912353515625\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.3691871464252472, accuracy: 0.91357421875\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.38250917196273804, accuracy: 0.909423828125\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.37905609607696533, accuracy: 0.916259765625\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.3164820671081543, accuracy: 0.923583984375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.2977147102355957, accuracy: 0.918701171875\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.2974826991558075, accuracy: 0.921630859375\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.35966160893440247, accuracy: 0.925048828125\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.3114200532436371, accuracy: 0.928466796875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.303170770406723, accuracy: 0.92236328125\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.33522018790245056, accuracy: 0.926025390625\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.330363929271698, accuracy: 0.9326171875\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.3153854310512543, accuracy: 0.932861328125\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.23479652404785156, accuracy: 0.928466796875\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.26834553480148315, accuracy: 0.931640625\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2727443277835846, accuracy: 0.938232421875\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.220353364944458, accuracy: 0.932373046875\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.23039895296096802, accuracy: 0.933837890625\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.2520485818386078, accuracy: 0.932373046875\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2827282249927521, accuracy: 0.9326171875\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2771432101726532, accuracy: 0.940185546875\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.28150251507759094, accuracy: 0.937255859375\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.2794364392757416, accuracy: 0.936767578125\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.22007466852664948, accuracy: 0.943115234375\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.24645638465881348, accuracy: 0.944580078125\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.2413821816444397, accuracy: 0.94482421875\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2249538004398346, accuracy: 0.947265625\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.20931659638881683, accuracy: 0.939453125\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.21170595288276672, accuracy: 0.946044921875\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.24086244404315948, accuracy: 0.947021484375\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.2049543410539627, accuracy: 0.945556640625\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.20233695209026337, accuracy: 0.95166015625\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.20025290548801422, accuracy: 0.947998046875\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.1924162060022354, accuracy: 0.9521484375\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.18194973468780518, accuracy: 0.953857421875\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.22885414958000183, accuracy: 0.955810546875\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.23710516095161438, accuracy: 0.956298828125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.20485819876194, accuracy: 0.955322265625\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.19009007513523102, accuracy: 0.955322265625\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.1748255044221878, accuracy: 0.947998046875\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.1856205016374588, accuracy: 0.95751953125\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.18225964903831482, accuracy: 0.956787109375\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.1526506543159485, accuracy: 0.9599609375\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.20705673098564148, accuracy: 0.954345703125\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.18195006251335144, accuracy: 0.9541015625\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.166619673371315, accuracy: 0.959716796875\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.19416366517543793, accuracy: 0.955322265625\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.15958340466022491, accuracy: 0.95703125\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.180843323469162, accuracy: 0.95849609375\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.16492369771003723, accuracy: 0.9599609375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.14099478721618652, accuracy: 0.9599609375\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.1380261927843094, accuracy: 0.96142578125\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.18483196198940277, accuracy: 0.960693359375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.15967334806919098, accuracy: 0.962890625\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.14678433537483215, accuracy: 0.9619140625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1818009316921234, accuracy: 0.96240234375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.14019373059272766, accuracy: 0.96337890625\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15729142725467682, accuracy: 0.95849609375\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.14040042459964752, accuracy: 0.96142578125\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.1627245843410492, accuracy: 0.966064453125\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.14670152962207794, accuracy: 0.9619140625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.15594908595085144, accuracy: 0.96337890625\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.14518916606903076, accuracy: 0.963623046875\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.16523659229278564, accuracy: 0.964599609375\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.12870943546295166, accuracy: 0.963623046875\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.1531955897808075, accuracy: 0.96337890625\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.13244137167930603, accuracy: 0.964111328125\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.10355958342552185, accuracy: 0.967041015625\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.16910907626152039, accuracy: 0.9638671875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.13763906061649323, accuracy: 0.96533203125\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.17157353460788727, accuracy: 0.96728515625\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.11104445904493332, accuracy: 0.962890625\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.13850392401218414, accuracy: 0.963623046875\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.15040037035942078, accuracy: 0.96533203125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.14512678980827332, accuracy: 0.969482421875\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.1544066071510315, accuracy: 0.967041015625\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.11302678287029266, accuracy: 0.968505859375\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.11792092770338058, accuracy: 0.970703125\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.13398639857769012, accuracy: 0.964111328125\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.12610328197479248, accuracy: 0.9677734375\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.11995900422334671, accuracy: 0.96435546875\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.11197671294212341, accuracy: 0.966064453125\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.11954844743013382, accuracy: 0.968505859375\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.12241949141025543, accuracy: 0.9677734375\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.1041669249534607, accuracy: 0.970947265625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.09678971022367477, accuracy: 0.97021484375\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.0972265675663948, accuracy: 0.970703125\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.11837475001811981, accuracy: 0.969482421875\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.10623932629823685, accuracy: 0.96826171875\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.243079900741577, accuracy: 0.385009765625\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9410585165023804, accuracy: 0.727783203125\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1908950805664062, accuracy: 0.796875\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.792261004447937, accuracy: 0.7666015625\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.4902200996875763, accuracy: 0.876953125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.4787430167198181, accuracy: 0.885498046875\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.4369959533214569, accuracy: 0.891845703125\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4677606523036957, accuracy: 0.899169921875\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.49971452355384827, accuracy: 0.911376953125\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.4802067279815674, accuracy: 0.88525390625\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3847486078739166, accuracy: 0.909423828125\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3174532353878021, accuracy: 0.91796875\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.3858039379119873, accuracy: 0.914794921875\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.39015573263168335, accuracy: 0.915771484375\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3767479956150055, accuracy: 0.9140625\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.32881423830986023, accuracy: 0.916748046875\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.3227304518222809, accuracy: 0.92431640625\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.3350408375263214, accuracy: 0.922119140625\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3077666759490967, accuracy: 0.920654296875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.27769964933395386, accuracy: 0.920654296875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.2826765477657318, accuracy: 0.921142578125\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.35056206583976746, accuracy: 0.92529296875\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.2843635082244873, accuracy: 0.92578125\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.24737602472305298, accuracy: 0.93408203125\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.25322848558425903, accuracy: 0.927490234375\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.2912176251411438, accuracy: 0.932373046875\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.26411759853363037, accuracy: 0.927978515625\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.25551557540893555, accuracy: 0.93359375\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.25739070773124695, accuracy: 0.937255859375\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.24515900015830994, accuracy: 0.939208984375\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.24035872519016266, accuracy: 0.933349609375\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2473495751619339, accuracy: 0.942626953125\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.26258358359336853, accuracy: 0.936279296875\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.19360318779945374, accuracy: 0.938720703125\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.268681138753891, accuracy: 0.940185546875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.26163411140441895, accuracy: 0.943115234375\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.255390465259552, accuracy: 0.94580078125\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2322351634502411, accuracy: 0.94091796875\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.2618159353733063, accuracy: 0.9453125\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.21314962208271027, accuracy: 0.946533203125\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.21802553534507751, accuracy: 0.95166015625\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.2205149084329605, accuracy: 0.94921875\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.2027440369129181, accuracy: 0.95166015625\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.19222493469715118, accuracy: 0.955078125\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.2142348736524582, accuracy: 0.954345703125\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.23199164867401123, accuracy: 0.953125\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.21939539909362793, accuracy: 0.948974609375\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.19182324409484863, accuracy: 0.9580078125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.19370168447494507, accuracy: 0.949951171875\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.1938486397266388, accuracy: 0.955322265625\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.2160634696483612, accuracy: 0.95361328125\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.21610911190509796, accuracy: 0.954345703125\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.20235760509967804, accuracy: 0.954833984375\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.1766640692949295, accuracy: 0.95556640625\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.22415205836296082, accuracy: 0.95751953125\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.18102143704891205, accuracy: 0.960693359375\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.19981034100055695, accuracy: 0.954833984375\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.17491191625595093, accuracy: 0.953857421875\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.1764826625585556, accuracy: 0.9580078125\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.17925845086574554, accuracy: 0.95849609375\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.16390350461006165, accuracy: 0.96044921875\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1793397217988968, accuracy: 0.953369140625\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.17418301105499268, accuracy: 0.96240234375\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.17260831594467163, accuracy: 0.959228515625\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.13221745193004608, accuracy: 0.961181640625\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.16935661435127258, accuracy: 0.961181640625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1462470293045044, accuracy: 0.96240234375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.16472086310386658, accuracy: 0.962890625\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.18478654325008392, accuracy: 0.96044921875\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.1402270793914795, accuracy: 0.958740234375\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.1674949824810028, accuracy: 0.961181640625\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.17229793965816498, accuracy: 0.963134765625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.1373121440410614, accuracy: 0.96923828125\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.14842920005321503, accuracy: 0.95947265625\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.12243114411830902, accuracy: 0.964111328125\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.15885740518569946, accuracy: 0.965087890625\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.16080327332019806, accuracy: 0.963623046875\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.14838553965091705, accuracy: 0.96728515625\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1452597826719284, accuracy: 0.965576171875\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.12986333668231964, accuracy: 0.963623046875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.14814120531082153, accuracy: 0.967041015625\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.10578694194555283, accuracy: 0.96435546875\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.1296478509902954, accuracy: 0.9677734375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.15443238615989685, accuracy: 0.967529296875\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.12303443998098373, accuracy: 0.965576171875\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.1319570094347, accuracy: 0.964111328125\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.14064109325408936, accuracy: 0.969482421875\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.14235126972198486, accuracy: 0.96630859375\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.13034597039222717, accuracy: 0.96630859375\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.1513882726430893, accuracy: 0.9619140625\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.13282613456249237, accuracy: 0.96826171875\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.12614184617996216, accuracy: 0.967041015625\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.13383719325065613, accuracy: 0.969970703125\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.12561358511447906, accuracy: 0.966064453125\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.10511072725057602, accuracy: 0.969970703125\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.12151670455932617, accuracy: 0.969970703125\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.1097998321056366, accuracy: 0.961669921875\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.1058095172047615, accuracy: 0.966796875\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.10897301882505417, accuracy: 0.970947265625\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.11929433047771454, accuracy: 0.966552734375\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.252941131591797, accuracy: 0.3095703125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9684803485870361, accuracy: 0.751708984375\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.163305640220642, accuracy: 0.80712890625\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7356009483337402, accuracy: 0.797119140625\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5401880741119385, accuracy: 0.884033203125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5121761560440063, accuracy: 0.88671875\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.5097404718399048, accuracy: 0.895263671875\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.46233928203582764, accuracy: 0.897216796875\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.40963882207870483, accuracy: 0.904541015625\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.4292279779911041, accuracy: 0.89013671875\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.4163650870323181, accuracy: 0.91357421875\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.37389007210731506, accuracy: 0.90771484375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.31732869148254395, accuracy: 0.9130859375\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.38979795575141907, accuracy: 0.9072265625\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3597160279750824, accuracy: 0.91748046875\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.30159011483192444, accuracy: 0.9208984375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.2906520366668701, accuracy: 0.920654296875\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.3292325437068939, accuracy: 0.921875\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.29267001152038574, accuracy: 0.921142578125\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.329251766204834, accuracy: 0.919921875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.2608250081539154, accuracy: 0.926513671875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.2755654752254486, accuracy: 0.93017578125\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.24723736941814423, accuracy: 0.932861328125\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.3006358742713928, accuracy: 0.932373046875\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.3050718903541565, accuracy: 0.927490234375\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.30476027727127075, accuracy: 0.935302734375\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2512969970703125, accuracy: 0.938232421875\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.26273131370544434, accuracy: 0.930419921875\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.2852455973625183, accuracy: 0.933349609375\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.27189865708351135, accuracy: 0.9345703125\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2614136338233948, accuracy: 0.9345703125\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2463773488998413, accuracy: 0.940185546875\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.23931103944778442, accuracy: 0.94140625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.24643705785274506, accuracy: 0.93896484375\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.2336319237947464, accuracy: 0.94482421875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.18477463722229004, accuracy: 0.9462890625\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.20319640636444092, accuracy: 0.941650390625\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.20504571497440338, accuracy: 0.939453125\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.2271641045808792, accuracy: 0.9462890625\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2978823184967041, accuracy: 0.942626953125\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.24608227610588074, accuracy: 0.946533203125\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.21728144586086273, accuracy: 0.947998046875\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.22540749609470367, accuracy: 0.94775390625\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.2120896577835083, accuracy: 0.9482421875\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.19718368351459503, accuracy: 0.95166015625\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.19629575312137604, accuracy: 0.94873046875\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.21556226909160614, accuracy: 0.952392578125\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.25180867314338684, accuracy: 0.95556640625\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.1636635959148407, accuracy: 0.956787109375\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.21207541227340698, accuracy: 0.953857421875\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.17585207521915436, accuracy: 0.95751953125\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.18119199573993683, accuracy: 0.958251953125\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.17893263697624207, accuracy: 0.9619140625\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.18173715472221375, accuracy: 0.95361328125\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.20275135338306427, accuracy: 0.95654296875\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.18177953362464905, accuracy: 0.95703125\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.15026932954788208, accuracy: 0.954833984375\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.17353689670562744, accuracy: 0.95556640625\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.17038798332214355, accuracy: 0.958984375\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.1654803603887558, accuracy: 0.956787109375\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.1785932034254074, accuracy: 0.960205078125\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.19554613530635834, accuracy: 0.963134765625\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.17153547704219818, accuracy: 0.95947265625\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.15317372977733612, accuracy: 0.959716796875\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.19626417756080627, accuracy: 0.96044921875\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.17747223377227783, accuracy: 0.963623046875\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1748480498790741, accuracy: 0.964111328125\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.1498343050479889, accuracy: 0.9599609375\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15901614725589752, accuracy: 0.96142578125\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.1362157016992569, accuracy: 0.958251953125\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.1683156043291092, accuracy: 0.96728515625\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.13794690370559692, accuracy: 0.96240234375\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.16054923832416534, accuracy: 0.96240234375\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.15651938319206238, accuracy: 0.96337890625\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.13828951120376587, accuracy: 0.965087890625\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.13613764941692352, accuracy: 0.964599609375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.14597176015377045, accuracy: 0.968017578125\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.1216961145401001, accuracy: 0.9609375\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.12668658792972565, accuracy: 0.96240234375\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.16206538677215576, accuracy: 0.95947265625\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.1473444402217865, accuracy: 0.962890625\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.14737078547477722, accuracy: 0.961669921875\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.17688274383544922, accuracy: 0.9609375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.1192493736743927, accuracy: 0.9638671875\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.13221819698810577, accuracy: 0.96533203125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.13289538025856018, accuracy: 0.9677734375\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.13795556128025055, accuracy: 0.965087890625\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1333402395248413, accuracy: 0.966552734375\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.12590469419956207, accuracy: 0.967529296875\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.15218845009803772, accuracy: 0.96630859375\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.12453462183475494, accuracy: 0.967041015625\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.12529480457305908, accuracy: 0.971435546875\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.14328531920909882, accuracy: 0.97265625\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.12596766650676727, accuracy: 0.963623046875\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.11882369220256805, accuracy: 0.9716796875\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.14799292385578156, accuracy: 0.968994140625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.13285186886787415, accuracy: 0.970947265625\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.13354185223579407, accuracy: 0.97216796875\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.12391246110200882, accuracy: 0.96923828125\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.11068279296159744, accuracy: 0.968017578125\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.2445788383483887, accuracy: 0.35302734375\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9343172311782837, accuracy: 0.7333984375\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1892879009246826, accuracy: 0.801025390625\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7335760593414307, accuracy: 0.799560546875\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5837595462799072, accuracy: 0.875732421875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5108190178871155, accuracy: 0.89501953125\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.48318806290626526, accuracy: 0.895263671875\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.48026010394096375, accuracy: 0.89697265625\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4389263689517975, accuracy: 0.901123046875\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.4767936170101166, accuracy: 0.84619140625\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3847418427467346, accuracy: 0.9130859375\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.4375505745410919, accuracy: 0.91552734375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.36617931723594666, accuracy: 0.9140625\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3472038805484772, accuracy: 0.909423828125\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3345837891101837, accuracy: 0.914794921875\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.37986287474632263, accuracy: 0.923583984375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.3177644610404968, accuracy: 0.920166015625\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.2747044563293457, accuracy: 0.922607421875\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3085196614265442, accuracy: 0.92919921875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.3276614844799042, accuracy: 0.924560546875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.3061433434486389, accuracy: 0.91943359375\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.27156421542167664, accuracy: 0.92626953125\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.2553633451461792, accuracy: 0.92724609375\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.3147861957550049, accuracy: 0.931640625\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.3094521760940552, accuracy: 0.931884765625\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.2844720482826233, accuracy: 0.92822265625\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2618156671524048, accuracy: 0.936279296875\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.2739787995815277, accuracy: 0.9306640625\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.23272626101970673, accuracy: 0.93408203125\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.25910505652427673, accuracy: 0.935302734375\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2456366866827011, accuracy: 0.938720703125\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.23850572109222412, accuracy: 0.939208984375\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2937629222869873, accuracy: 0.94775390625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.24076810479164124, accuracy: 0.941650390625\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.23072044551372528, accuracy: 0.94091796875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.24793680012226105, accuracy: 0.942626953125\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.24110214412212372, accuracy: 0.94482421875\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2105550765991211, accuracy: 0.943603515625\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.1862448751926422, accuracy: 0.9462890625\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2643512189388275, accuracy: 0.946044921875\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.23021796345710754, accuracy: 0.94970703125\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.22461764514446259, accuracy: 0.948974609375\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.20909450948238373, accuracy: 0.952880859375\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.22864438593387604, accuracy: 0.9482421875\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.2192559540271759, accuracy: 0.949462890625\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.19885939359664917, accuracy: 0.951416015625\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.22072158753871918, accuracy: 0.949462890625\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.21036513149738312, accuracy: 0.952392578125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.21274301409721375, accuracy: 0.950439453125\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.16815361380577087, accuracy: 0.958984375\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.1662040799856186, accuracy: 0.959228515625\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.21338453888893127, accuracy: 0.9501953125\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.18950971961021423, accuracy: 0.953369140625\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.2005748599767685, accuracy: 0.958984375\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.1757378727197647, accuracy: 0.95751953125\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.19925345480442047, accuracy: 0.956298828125\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.15948261320590973, accuracy: 0.959716796875\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.2070809006690979, accuracy: 0.955810546875\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.20432282984256744, accuracy: 0.958740234375\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.1772335022687912, accuracy: 0.96142578125\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.20703189074993134, accuracy: 0.9609375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1797451227903366, accuracy: 0.9609375\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.1627635359764099, accuracy: 0.96240234375\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.20722538232803345, accuracy: 0.96484375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.1687307357788086, accuracy: 0.959716796875\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.14681510627269745, accuracy: 0.962158203125\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.14966310560703278, accuracy: 0.963134765625\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.17651697993278503, accuracy: 0.963134765625\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.152304008603096, accuracy: 0.96484375\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.19376111030578613, accuracy: 0.9619140625\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.14120268821716309, accuracy: 0.96337890625\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.17670489847660065, accuracy: 0.9638671875\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.1671721190214157, accuracy: 0.962890625\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.15418033301830292, accuracy: 0.9658203125\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.14084826409816742, accuracy: 0.96337890625\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.15047268569469452, accuracy: 0.96484375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.16773881018161774, accuracy: 0.9638671875\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.17081373929977417, accuracy: 0.96240234375\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.12712137401103973, accuracy: 0.968505859375\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.17092496156692505, accuracy: 0.96826171875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.15398737788200378, accuracy: 0.962646484375\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.11897672712802887, accuracy: 0.965576171875\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.1172548234462738, accuracy: 0.96533203125\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.1339702010154724, accuracy: 0.964599609375\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.12432879954576492, accuracy: 0.967041015625\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.12532301247119904, accuracy: 0.966552734375\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.1617632955312729, accuracy: 0.967041015625\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1701536923646927, accuracy: 0.967529296875\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.11740464717149734, accuracy: 0.965087890625\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.14942783117294312, accuracy: 0.967529296875\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.13176240026950836, accuracy: 0.97021484375\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.12327384203672409, accuracy: 0.966552734375\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.13697412610054016, accuracy: 0.96435546875\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.13882239162921906, accuracy: 0.96630859375\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.11783701181411743, accuracy: 0.969970703125\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.1282309889793396, accuracy: 0.966064453125\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.10807281732559204, accuracy: 0.96923828125\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.13308210670948029, accuracy: 0.96728515625\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.14143633842468262, accuracy: 0.967529296875\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.1035044714808464, accuracy: 0.96826171875\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.2275025844573975, accuracy: 0.39453125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.909224271774292, accuracy: 0.734375\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.142432689666748, accuracy: 0.806884765625\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7735341191291809, accuracy: 0.767822265625\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.547496497631073, accuracy: 0.878173828125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5075797438621521, accuracy: 0.888671875\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.4909040331840515, accuracy: 0.89306640625\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.502479076385498, accuracy: 0.897705078125\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4315985143184662, accuracy: 0.89990234375\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.4598221182823181, accuracy: 0.8916015625\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.373729407787323, accuracy: 0.9091796875\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3615926206111908, accuracy: 0.909912109375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.37456339597702026, accuracy: 0.9130859375\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.4010806977748871, accuracy: 0.913818359375\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.33705195784568787, accuracy: 0.912109375\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.3245337903499603, accuracy: 0.92578125\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.35315680503845215, accuracy: 0.918701171875\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.30318087339401245, accuracy: 0.925048828125\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3628444969654083, accuracy: 0.91259765625\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.31554293632507324, accuracy: 0.92529296875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.31781870126724243, accuracy: 0.926513671875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.26862281560897827, accuracy: 0.923583984375\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.26283830404281616, accuracy: 0.926513671875\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.24433550238609314, accuracy: 0.9326171875\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.249116912484169, accuracy: 0.93505859375\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.30710911750793457, accuracy: 0.92919921875\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2598375678062439, accuracy: 0.93603515625\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.21332010626792908, accuracy: 0.9365234375\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.2670924961566925, accuracy: 0.93994140625\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.28052210807800293, accuracy: 0.932373046875\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.25778865814208984, accuracy: 0.938232421875\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.23928789794445038, accuracy: 0.9404296875\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2838163673877716, accuracy: 0.943359375\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.21674856543540955, accuracy: 0.94189453125\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.21629922091960907, accuracy: 0.94677734375\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.22518739104270935, accuracy: 0.943603515625\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.21457570791244507, accuracy: 0.941650390625\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2471870332956314, accuracy: 0.946044921875\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.22322531044483185, accuracy: 0.942138671875\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.1798553317785263, accuracy: 0.948974609375\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.20163074135780334, accuracy: 0.948974609375\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.2319631427526474, accuracy: 0.94775390625\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.20044371485710144, accuracy: 0.951171875\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.21804660558700562, accuracy: 0.94873046875\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.20878496766090393, accuracy: 0.9521484375\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.21888892352581024, accuracy: 0.95458984375\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.21511226892471313, accuracy: 0.95166015625\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.19776611030101776, accuracy: 0.954345703125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.19763392210006714, accuracy: 0.9560546875\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.20575270056724548, accuracy: 0.949462890625\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.20276649296283722, accuracy: 0.953369140625\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.18858198821544647, accuracy: 0.94921875\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.1785254031419754, accuracy: 0.95458984375\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.16095736622810364, accuracy: 0.95947265625\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.16196684539318085, accuracy: 0.9560546875\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.1909271776676178, accuracy: 0.956298828125\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.16748331487178802, accuracy: 0.961181640625\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.20175710320472717, accuracy: 0.957275390625\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.1749270111322403, accuracy: 0.960693359375\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.18241402506828308, accuracy: 0.960693359375\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.2039555311203003, accuracy: 0.961669921875\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1713901311159134, accuracy: 0.959228515625\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.15217654407024384, accuracy: 0.9658203125\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.1367500275373459, accuracy: 0.970458984375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.14765037596225739, accuracy: 0.96240234375\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.18672649562358856, accuracy: 0.962646484375\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.14106549322605133, accuracy: 0.9609375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.15955980122089386, accuracy: 0.9599609375\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15783308446407318, accuracy: 0.9619140625\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.13114571571350098, accuracy: 0.962890625\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.1272978037595749, accuracy: 0.96435546875\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.15294060111045837, accuracy: 0.965087890625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.146585613489151, accuracy: 0.967529296875\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.12018104642629623, accuracy: 0.962890625\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.15727904438972473, accuracy: 0.963623046875\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.15622085332870483, accuracy: 0.964599609375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.19819465279579163, accuracy: 0.9677734375\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.13689914345741272, accuracy: 0.96435546875\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.14795272052288055, accuracy: 0.962890625\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.1646520346403122, accuracy: 0.965087890625\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.1512291580438614, accuracy: 0.9599609375\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.1263139396905899, accuracy: 0.968505859375\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.15842291712760925, accuracy: 0.964599609375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.13194489479064941, accuracy: 0.965576171875\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.13267873227596283, accuracy: 0.96826171875\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.15534020960330963, accuracy: 0.962158203125\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.11528173834085464, accuracy: 0.97021484375\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.16788403689861298, accuracy: 0.968994140625\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.11724492907524109, accuracy: 0.96875\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.13341766595840454, accuracy: 0.96923828125\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.14706601202487946, accuracy: 0.96337890625\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.1329667866230011, accuracy: 0.969482421875\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.14809651672840118, accuracy: 0.966064453125\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.11474838852882385, accuracy: 0.97216796875\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.10018842667341232, accuracy: 0.973388671875\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.10582785308361053, accuracy: 0.96923828125\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.10934517532587051, accuracy: 0.967041015625\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.10408951342105865, accuracy: 0.972412109375\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.1290014684200287, accuracy: 0.968994140625\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.13466833531856537, accuracy: 0.969970703125\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.2349231243133545, accuracy: 0.28564453125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9510215520858765, accuracy: 0.7177734375\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1697160005569458, accuracy: 0.8017578125\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7043702602386475, accuracy: 0.843505859375\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5440827012062073, accuracy: 0.8779296875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5326962471008301, accuracy: 0.893798828125\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.5276330709457397, accuracy: 0.8896484375\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.46686187386512756, accuracy: 0.894287109375\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4310479760169983, accuracy: 0.90283203125\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.4059511721134186, accuracy: 0.91357421875\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3878925144672394, accuracy: 0.906494140625\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.365424782037735, accuracy: 0.908935546875\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.3352442979812622, accuracy: 0.91357421875\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3399295210838318, accuracy: 0.91259765625\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3483525514602661, accuracy: 0.915283203125\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.3404286801815033, accuracy: 0.922119140625\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.32551702857017517, accuracy: 0.922607421875\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.3268793523311615, accuracy: 0.92138671875\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3520317077636719, accuracy: 0.92578125\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.3960039019584656, accuracy: 0.926025390625\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.3244782090187073, accuracy: 0.922607421875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.3058527708053589, accuracy: 0.933349609375\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.2576815187931061, accuracy: 0.927490234375\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.28724247217178345, accuracy: 0.9296875\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.24483004212379456, accuracy: 0.927001953125\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.2419409304857254, accuracy: 0.932373046875\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2908855378627777, accuracy: 0.931884765625\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.21225135028362274, accuracy: 0.935302734375\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.27112090587615967, accuracy: 0.932373046875\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.3120548725128174, accuracy: 0.935546875\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.27385690808296204, accuracy: 0.937255859375\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2969071567058563, accuracy: 0.93896484375\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.24364307522773743, accuracy: 0.939697265625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.28613048791885376, accuracy: 0.939697265625\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.2211828976869583, accuracy: 0.94140625\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.2144862413406372, accuracy: 0.94091796875\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.2214258313179016, accuracy: 0.943359375\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2904943823814392, accuracy: 0.943603515625\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.21719509363174438, accuracy: 0.9462890625\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.28261351585388184, accuracy: 0.942138671875\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.2481498420238495, accuracy: 0.9462890625\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.20776653289794922, accuracy: 0.94384765625\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.1795785129070282, accuracy: 0.956298828125\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.20077231526374817, accuracy: 0.9521484375\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.23906485736370087, accuracy: 0.950927734375\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.21134653687477112, accuracy: 0.948974609375\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.17213821411132812, accuracy: 0.95654296875\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.2003973126411438, accuracy: 0.958984375\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.19642691314220428, accuracy: 0.954833984375\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.13781090080738068, accuracy: 0.955078125\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.1689019799232483, accuracy: 0.952880859375\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.1870400458574295, accuracy: 0.957275390625\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.21956922113895416, accuracy: 0.9599609375\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.19612209498882294, accuracy: 0.959716796875\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.1556139886379242, accuracy: 0.95556640625\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.17932675778865814, accuracy: 0.954345703125\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.1806156039237976, accuracy: 0.95849609375\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.18049298226833344, accuracy: 0.962890625\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.1663575917482376, accuracy: 0.9521484375\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.16874627768993378, accuracy: 0.959716796875\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.17142470180988312, accuracy: 0.959716796875\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.20047222077846527, accuracy: 0.963134765625\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.2030273973941803, accuracy: 0.95947265625\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.15978975594043732, accuracy: 0.9609375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.1654903143644333, accuracy: 0.962158203125\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.16944418847560883, accuracy: 0.963134765625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.17426571249961853, accuracy: 0.961181640625\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.13908712565898895, accuracy: 0.963134765625\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.19531530141830444, accuracy: 0.963623046875\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.15839099884033203, accuracy: 0.96240234375\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.1672508865594864, accuracy: 0.96240234375\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.11670518666505814, accuracy: 0.961181640625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.15319402515888214, accuracy: 0.962890625\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.1755499541759491, accuracy: 0.961669921875\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.17317885160446167, accuracy: 0.9638671875\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.13289125263690948, accuracy: 0.967041015625\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.13978040218353271, accuracy: 0.965576171875\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.1461893916130066, accuracy: 0.967041015625\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.14246952533721924, accuracy: 0.9697265625\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.1386004239320755, accuracy: 0.96484375\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.14621080458164215, accuracy: 0.964599609375\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.14862872660160065, accuracy: 0.96142578125\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.11914496123790741, accuracy: 0.96533203125\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.1419549435377121, accuracy: 0.961181640625\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.158565491437912, accuracy: 0.964111328125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.12661845982074738, accuracy: 0.96630859375\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.14608195424079895, accuracy: 0.966552734375\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.14455726742744446, accuracy: 0.9658203125\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.11729668825864792, accuracy: 0.96435546875\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.14010564982891083, accuracy: 0.96728515625\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.12200675904750824, accuracy: 0.966552734375\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.15725132822990417, accuracy: 0.9658203125\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.17005452513694763, accuracy: 0.966552734375\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.13811498880386353, accuracy: 0.967529296875\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.10960473120212555, accuracy: 0.968505859375\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.14448697865009308, accuracy: 0.96728515625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.12948980927467346, accuracy: 0.968994140625\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.10603277385234833, accuracy: 0.9677734375\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.11585148423910141, accuracy: 0.9677734375\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.1449207067489624, accuracy: 0.9658203125\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.2254152297973633, accuracy: 0.47119140625\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9334509372711182, accuracy: 0.736328125\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1252787113189697, accuracy: 0.80517578125\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7907367944717407, accuracy: 0.811767578125\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5462028384208679, accuracy: 0.880126953125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5171805620193481, accuracy: 0.89453125\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.4985571801662445, accuracy: 0.90087890625\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4408698081970215, accuracy: 0.892822265625\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.3703252375125885, accuracy: 0.9072265625\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.4220461845397949, accuracy: 0.903076171875\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3717736303806305, accuracy: 0.907470703125\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.37474524974823, accuracy: 0.915771484375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.365581214427948, accuracy: 0.91015625\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.4050934314727783, accuracy: 0.9140625\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3439674973487854, accuracy: 0.92138671875\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.38128384947776794, accuracy: 0.914794921875\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.2912590205669403, accuracy: 0.925537109375\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.32503989338874817, accuracy: 0.921142578125\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3036337196826935, accuracy: 0.922607421875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.32723408937454224, accuracy: 0.927978515625\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.3106347918510437, accuracy: 0.927001953125\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.31139975786209106, accuracy: 0.92626953125\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.3069254755973816, accuracy: 0.92578125\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.25589191913604736, accuracy: 0.93212890625\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.3042243421077728, accuracy: 0.927734375\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.28038182854652405, accuracy: 0.928466796875\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2613532245159149, accuracy: 0.9375\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.231392964720726, accuracy: 0.93359375\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.29926541447639465, accuracy: 0.934326171875\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.24274842441082, accuracy: 0.93603515625\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.22069282829761505, accuracy: 0.93359375\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2479473203420639, accuracy: 0.936279296875\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2623426616191864, accuracy: 0.933837890625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.2529169023036957, accuracy: 0.935791015625\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.24161288142204285, accuracy: 0.94482421875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.22364763915538788, accuracy: 0.943359375\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.20637719333171844, accuracy: 0.940185546875\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2608955204486847, accuracy: 0.944580078125\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.2689715027809143, accuracy: 0.943359375\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.20734140276908875, accuracy: 0.948974609375\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.23254071176052094, accuracy: 0.948974609375\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.20416592061519623, accuracy: 0.94970703125\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.21749158203601837, accuracy: 0.948974609375\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.21177887916564941, accuracy: 0.947509765625\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.19973547756671906, accuracy: 0.948974609375\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.2184513360261917, accuracy: 0.94580078125\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.19886131584644318, accuracy: 0.94970703125\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.22648218274116516, accuracy: 0.95263671875\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.23516811430454254, accuracy: 0.956298828125\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.19900086522102356, accuracy: 0.95068359375\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.18346869945526123, accuracy: 0.950927734375\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.17793558537960052, accuracy: 0.95654296875\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.18122701346874237, accuracy: 0.95654296875\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.1550690084695816, accuracy: 0.957763671875\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.18838685750961304, accuracy: 0.957763671875\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.19126245379447937, accuracy: 0.9580078125\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.20700274407863617, accuracy: 0.95751953125\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.2060539275407791, accuracy: 0.958740234375\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.13376274704933167, accuracy: 0.962890625\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.16560231149196625, accuracy: 0.961181640625\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.14338354766368866, accuracy: 0.9599609375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.14914272725582123, accuracy: 0.95751953125\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.1966588944196701, accuracy: 0.961181640625\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.16086162626743317, accuracy: 0.96044921875\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.16331475973129272, accuracy: 0.957275390625\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.15899260342121124, accuracy: 0.95947265625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1575399935245514, accuracy: 0.9609375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.12182748317718506, accuracy: 0.954345703125\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.12658441066741943, accuracy: 0.96240234375\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.1802331656217575, accuracy: 0.961669921875\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.11268848180770874, accuracy: 0.961669921875\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.13629455864429474, accuracy: 0.96435546875\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.16389647126197815, accuracy: 0.962646484375\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.18982023000717163, accuracy: 0.960205078125\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.16664330661296844, accuracy: 0.96142578125\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.1312820166349411, accuracy: 0.9609375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.15082183480262756, accuracy: 0.966552734375\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.1277083456516266, accuracy: 0.962890625\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1499360054731369, accuracy: 0.9677734375\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.15583130717277527, accuracy: 0.966064453125\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.15602192282676697, accuracy: 0.96875\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.12919281423091888, accuracy: 0.962646484375\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.11849251389503479, accuracy: 0.966552734375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.12098460644483566, accuracy: 0.96435546875\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.13568800687789917, accuracy: 0.970703125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.13832393288612366, accuracy: 0.966552734375\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.12779295444488525, accuracy: 0.969482421875\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.12322725355625153, accuracy: 0.96484375\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.12131847441196442, accuracy: 0.9658203125\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.10210102051496506, accuracy: 0.96630859375\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.11995984613895416, accuracy: 0.964599609375\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.12004636228084564, accuracy: 0.9677734375\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.14279061555862427, accuracy: 0.9658203125\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.13082531094551086, accuracy: 0.968505859375\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.12403184920549393, accuracy: 0.968505859375\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.10408391803503036, accuracy: 0.962158203125\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.12224335223436356, accuracy: 0.967041015625\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.12296082824468613, accuracy: 0.97119140625\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.10876929759979248, accuracy: 0.96826171875\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.13032789528369904, accuracy: 0.968017578125\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.236898422241211, accuracy: 0.3798828125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9562560319900513, accuracy: 0.739013671875\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.2048954963684082, accuracy: 0.7998046875\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.6547136902809143, accuracy: 0.823974609375\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.542349636554718, accuracy: 0.877685546875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.49753686785697937, accuracy: 0.889404296875\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.4730890691280365, accuracy: 0.887939453125\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4968746602535248, accuracy: 0.89697265625\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.41076961159706116, accuracy: 0.89501953125\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.3766040802001953, accuracy: 0.90478515625\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3733522593975067, accuracy: 0.910400390625\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3639993369579315, accuracy: 0.91162109375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.3653918504714966, accuracy: 0.91455078125\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.29400166869163513, accuracy: 0.907958984375\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3469441831111908, accuracy: 0.92236328125\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.3495160639286041, accuracy: 0.912109375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.2918786406517029, accuracy: 0.923583984375\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.3886772394180298, accuracy: 0.92333984375\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.313751220703125, accuracy: 0.921875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.33250096440315247, accuracy: 0.91943359375\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.33107173442840576, accuracy: 0.926513671875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.30586013197898865, accuracy: 0.924072265625\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.288987934589386, accuracy: 0.929931640625\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.26561158895492554, accuracy: 0.930419921875\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.30414092540740967, accuracy: 0.92919921875\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.25097307562828064, accuracy: 0.931396484375\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2774046063423157, accuracy: 0.940185546875\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.27328237891197205, accuracy: 0.92822265625\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.2831548750400543, accuracy: 0.94140625\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.22550858557224274, accuracy: 0.936279296875\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2690092921257019, accuracy: 0.935791015625\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.24632862210273743, accuracy: 0.941650390625\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2528783679008484, accuracy: 0.94091796875\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.1889294981956482, accuracy: 0.939697265625\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.31434836983680725, accuracy: 0.9404296875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.24187004566192627, accuracy: 0.94287109375\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.22231443226337433, accuracy: 0.941162109375\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2795376181602478, accuracy: 0.94140625\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.23978379368782043, accuracy: 0.946044921875\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2337142527103424, accuracy: 0.9453125\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.1865498274564743, accuracy: 0.94775390625\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.21861569583415985, accuracy: 0.948974609375\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.20665375888347626, accuracy: 0.953125\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.19666391611099243, accuracy: 0.94775390625\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.19721804559230804, accuracy: 0.95166015625\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.21801021695137024, accuracy: 0.948486328125\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.2009861022233963, accuracy: 0.9501953125\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.18415702879428864, accuracy: 0.95263671875\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.20224300026893616, accuracy: 0.95361328125\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.24378222227096558, accuracy: 0.951904296875\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.18038126826286316, accuracy: 0.952880859375\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.19166424870491028, accuracy: 0.953125\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.19192565977573395, accuracy: 0.9521484375\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.2222733050584793, accuracy: 0.958984375\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.20940198004245758, accuracy: 0.955322265625\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.1758822351694107, accuracy: 0.9560546875\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.18725594878196716, accuracy: 0.960205078125\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.223683163523674, accuracy: 0.9580078125\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.1834266632795334, accuracy: 0.959716796875\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.175410196185112, accuracy: 0.95654296875\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.17077869176864624, accuracy: 0.960693359375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1273982971906662, accuracy: 0.96142578125\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.17297476530075073, accuracy: 0.962890625\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.16945812106132507, accuracy: 0.958984375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.16234682500362396, accuracy: 0.959716796875\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.1645604819059372, accuracy: 0.963623046875\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1579708456993103, accuracy: 0.959716796875\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.14207887649536133, accuracy: 0.96533203125\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15070287883281708, accuracy: 0.961669921875\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.16816000640392303, accuracy: 0.96044921875\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.11491776257753372, accuracy: 0.958984375\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.1842816174030304, accuracy: 0.963134765625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.16296175122261047, accuracy: 0.95849609375\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.1385127305984497, accuracy: 0.960205078125\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.1510549634695053, accuracy: 0.95947265625\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.15059539675712585, accuracy: 0.962158203125\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.1682320386171341, accuracy: 0.962890625\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.1561288982629776, accuracy: 0.962890625\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1317596733570099, accuracy: 0.960693359375\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.13192690908908844, accuracy: 0.965087890625\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.15000738203525543, accuracy: 0.96435546875\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.16581431031227112, accuracy: 0.968994140625\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.1344033181667328, accuracy: 0.965576171875\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.11315315961837769, accuracy: 0.9658203125\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.1201920434832573, accuracy: 0.966064453125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.17075909674167633, accuracy: 0.96826171875\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.17149388790130615, accuracy: 0.96875\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.12093766778707504, accuracy: 0.969482421875\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.14801612496376038, accuracy: 0.96728515625\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.12289581447839737, accuracy: 0.9677734375\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.13823135197162628, accuracy: 0.96142578125\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.14253146946430206, accuracy: 0.96533203125\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.12119174748659134, accuracy: 0.968994140625\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.11140232533216476, accuracy: 0.96923828125\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.14131002128124237, accuracy: 0.965576171875\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.10182089358568192, accuracy: 0.9677734375\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.12907519936561584, accuracy: 0.969970703125\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.12093591690063477, accuracy: 0.96826171875\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.10131247341632843, accuracy: 0.9697265625\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.09895789623260498, accuracy: 0.972412109375\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.243346929550171, accuracy: 0.409423828125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.935055136680603, accuracy: 0.72216796875\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1885300874710083, accuracy: 0.840576171875\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.65473473072052, accuracy: 0.86669921875\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5116484761238098, accuracy: 0.880126953125\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.537601888179779, accuracy: 0.89208984375\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.478008508682251, accuracy: 0.8955078125\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4700513482093811, accuracy: 0.90283203125\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.44043412804603577, accuracy: 0.899169921875\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.44259801506996155, accuracy: 0.901123046875\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.36056727170944214, accuracy: 0.906494140625\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.35681676864624023, accuracy: 0.919189453125\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.4103603959083557, accuracy: 0.918212890625\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3541118800640106, accuracy: 0.917236328125\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.33163169026374817, accuracy: 0.92333984375\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.34053754806518555, accuracy: 0.917724609375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.333640992641449, accuracy: 0.91748046875\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.31143009662628174, accuracy: 0.9208984375\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3019915521144867, accuracy: 0.9228515625\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.3258347809314728, accuracy: 0.923583984375\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.3309088945388794, accuracy: 0.92431640625\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.31568634510040283, accuracy: 0.927978515625\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.29759618639945984, accuracy: 0.9306640625\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.2722468972206116, accuracy: 0.92431640625\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.2836196720600128, accuracy: 0.935546875\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.31267309188842773, accuracy: 0.92822265625\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.24327844381332397, accuracy: 0.937744140625\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.3025617003440857, accuracy: 0.938232421875\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.26837068796157837, accuracy: 0.93603515625\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.24411609768867493, accuracy: 0.931396484375\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.25767144560813904, accuracy: 0.9345703125\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.23862482607364655, accuracy: 0.9375\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.27579236030578613, accuracy: 0.940185546875\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.2470710724592209, accuracy: 0.940185546875\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.21197038888931274, accuracy: 0.944580078125\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.22832317650318146, accuracy: 0.943603515625\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.24998992681503296, accuracy: 0.938720703125\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.250776469707489, accuracy: 0.943603515625\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.22958028316497803, accuracy: 0.94970703125\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.23152698576450348, accuracy: 0.948486328125\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.18859168887138367, accuracy: 0.94775390625\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.21696482598781586, accuracy: 0.944091796875\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.24786731600761414, accuracy: 0.95166015625\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.19916395843029022, accuracy: 0.952392578125\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.2480461150407791, accuracy: 0.94580078125\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.18724998831748962, accuracy: 0.944580078125\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.16900357604026794, accuracy: 0.95361328125\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.16676929593086243, accuracy: 0.95703125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.19708874821662903, accuracy: 0.956298828125\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.1865549087524414, accuracy: 0.952392578125\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.17517425119876862, accuracy: 0.946533203125\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.18368923664093018, accuracy: 0.956298828125\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.2066967487335205, accuracy: 0.953125\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.16464482247829437, accuracy: 0.958251953125\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.2015780359506607, accuracy: 0.9599609375\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.17020092904567719, accuracy: 0.955810546875\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.2131037414073944, accuracy: 0.9560546875\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.16506905853748322, accuracy: 0.960693359375\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.191643625497818, accuracy: 0.95703125\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.16105249524116516, accuracy: 0.963134765625\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.21102669835090637, accuracy: 0.956298828125\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1734771430492401, accuracy: 0.95458984375\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.18203198909759521, accuracy: 0.9599609375\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.17812711000442505, accuracy: 0.9599609375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.1424860656261444, accuracy: 0.958740234375\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.1538155972957611, accuracy: 0.9619140625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.15045540034770966, accuracy: 0.964599609375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.1510230302810669, accuracy: 0.964599609375\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15158072113990784, accuracy: 0.957763671875\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.15735678374767303, accuracy: 0.9609375\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.225271537899971, accuracy: 0.96044921875\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.15317483246326447, accuracy: 0.96240234375\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.14218704402446747, accuracy: 0.96337890625\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.14217835664749146, accuracy: 0.960205078125\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.14248065650463104, accuracy: 0.9580078125\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.12750567495822906, accuracy: 0.9619140625\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.1467585265636444, accuracy: 0.968994140625\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.14649759232997894, accuracy: 0.963623046875\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.13887731730937958, accuracy: 0.963623046875\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.10591834783554077, accuracy: 0.965087890625\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.12443296611309052, accuracy: 0.963134765625\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.15132291615009308, accuracy: 0.965576171875\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.1388978660106659, accuracy: 0.964599609375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.12152985483407974, accuracy: 0.9658203125\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.11102839559316635, accuracy: 0.96728515625\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.14539647102355957, accuracy: 0.964599609375\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.12200203537940979, accuracy: 0.967529296875\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1541324108839035, accuracy: 0.96337890625\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.13468657433986664, accuracy: 0.965576171875\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.12599067389965057, accuracy: 0.967529296875\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.11786011606454849, accuracy: 0.967529296875\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.13855458796024323, accuracy: 0.965087890625\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.1222924217581749, accuracy: 0.96728515625\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.12154597789049149, accuracy: 0.97119140625\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.12383493036031723, accuracy: 0.962158203125\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.1348017305135727, accuracy: 0.96875\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.10827422887086868, accuracy: 0.971923828125\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.12986890971660614, accuracy: 0.9716796875\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.14632733166217804, accuracy: 0.97216796875\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.11504779756069183, accuracy: 0.97119140625\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.25093936920166, accuracy: 0.35107421875\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9493297338485718, accuracy: 0.73876953125\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.2112219333648682, accuracy: 0.811279296875\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7057846188545227, accuracy: 0.8720703125\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5804024338722229, accuracy: 0.879638671875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5101146101951599, accuracy: 0.89697265625\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.45360705256462097, accuracy: 0.8935546875\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4618871808052063, accuracy: 0.900634765625\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4275222718715668, accuracy: 0.9013671875\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.42950937151908875, accuracy: 0.892333984375\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3868512213230133, accuracy: 0.90771484375\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.35017460584640503, accuracy: 0.91064453125\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.34863388538360596, accuracy: 0.91015625\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3115462064743042, accuracy: 0.90966796875\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.32724830508232117, accuracy: 0.91845703125\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.33458659052848816, accuracy: 0.9130859375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.3237311542034149, accuracy: 0.92626953125\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.2882401645183563, accuracy: 0.9228515625\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.306612491607666, accuracy: 0.921875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.2860340476036072, accuracy: 0.924560546875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.30681121349334717, accuracy: 0.923828125\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.32001182436943054, accuracy: 0.923095703125\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.28092026710510254, accuracy: 0.927490234375\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.29393213987350464, accuracy: 0.933349609375\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.29114434123039246, accuracy: 0.935302734375\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.2623702585697174, accuracy: 0.927978515625\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2828074097633362, accuracy: 0.935302734375\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.25464576482772827, accuracy: 0.931640625\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.2959066927433014, accuracy: 0.93359375\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.23451153934001923, accuracy: 0.93603515625\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.23003080487251282, accuracy: 0.939453125\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.23514394462108612, accuracy: 0.938232421875\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.28920307755470276, accuracy: 0.935791015625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.18406689167022705, accuracy: 0.9423828125\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.2364559918642044, accuracy: 0.946044921875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.23494718968868256, accuracy: 0.9423828125\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.20051833987236023, accuracy: 0.945556640625\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.19606700539588928, accuracy: 0.94921875\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.23599329590797424, accuracy: 0.953125\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2455701231956482, accuracy: 0.949951171875\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.19220367074012756, accuracy: 0.948974609375\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.22943945229053497, accuracy: 0.954345703125\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.23004966974258423, accuracy: 0.94677734375\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.21112973988056183, accuracy: 0.947265625\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.18515045940876007, accuracy: 0.951171875\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.20156461000442505, accuracy: 0.9521484375\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.24651746451854706, accuracy: 0.95166015625\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.1993115246295929, accuracy: 0.95166015625\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.19216959178447723, accuracy: 0.951171875\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.22935223579406738, accuracy: 0.954345703125\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.1741977483034134, accuracy: 0.95263671875\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.19263701140880585, accuracy: 0.947265625\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.21052221953868866, accuracy: 0.956298828125\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.20295993983745575, accuracy: 0.953369140625\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.1868535578250885, accuracy: 0.95458984375\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.19016185402870178, accuracy: 0.953857421875\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.1885806918144226, accuracy: 0.95947265625\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.1773974746465683, accuracy: 0.960205078125\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.17739719152450562, accuracy: 0.957275390625\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.1724950671195984, accuracy: 0.961669921875\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.15415947139263153, accuracy: 0.961669921875\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.17648166418075562, accuracy: 0.96044921875\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.1784311681985855, accuracy: 0.96044921875\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.13365909457206726, accuracy: 0.956787109375\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.14196059107780457, accuracy: 0.9619140625\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.17261114716529846, accuracy: 0.96142578125\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.18038518726825714, accuracy: 0.96484375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.20571571588516235, accuracy: 0.96044921875\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15775202214717865, accuracy: 0.963134765625\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.14608030021190643, accuracy: 0.963134765625\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.15871722996234894, accuracy: 0.961669921875\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.1357942819595337, accuracy: 0.9619140625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.130067378282547, accuracy: 0.958984375\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.17588144540786743, accuracy: 0.96337890625\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.16231484711170197, accuracy: 0.96240234375\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.11977095156908035, accuracy: 0.967041015625\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.14367516338825226, accuracy: 0.965576171875\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.14684845507144928, accuracy: 0.964599609375\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1601007729768753, accuracy: 0.96435546875\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.13144223392009735, accuracy: 0.962646484375\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.13786445558071136, accuracy: 0.96484375\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.12782251834869385, accuracy: 0.965576171875\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.12345218658447266, accuracy: 0.9609375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.14311423897743225, accuracy: 0.966552734375\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.16233837604522705, accuracy: 0.967041015625\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.1422756165266037, accuracy: 0.965087890625\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.12367631494998932, accuracy: 0.96337890625\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1593775898218155, accuracy: 0.96484375\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.13329613208770752, accuracy: 0.968505859375\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.08761407434940338, accuracy: 0.968505859375\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.11318366229534149, accuracy: 0.9716796875\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.1442885547876358, accuracy: 0.96630859375\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.13541974127292633, accuracy: 0.962890625\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.11727657169103622, accuracy: 0.9697265625\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.11238991469144821, accuracy: 0.9697265625\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.1091323047876358, accuracy: 0.971923828125\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.13068629801273346, accuracy: 0.96826171875\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.14255109429359436, accuracy: 0.96630859375\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.13980618119239807, accuracy: 0.96728515625\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.14466838538646698, accuracy: 0.969970703125\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.236309289932251, accuracy: 0.450927734375\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9212300777435303, accuracy: 0.73828125\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.1486340761184692, accuracy: 0.81201171875\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7213844656944275, accuracy: 0.834716796875\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5121102333068848, accuracy: 0.88818359375\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5242827534675598, accuracy: 0.884765625\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.4508478045463562, accuracy: 0.899169921875\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4524528682231903, accuracy: 0.897216796875\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.42702680826187134, accuracy: 0.901123046875\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.7558736801147461, accuracy: 0.82568359375\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3522624373435974, accuracy: 0.9130859375\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.32481104135513306, accuracy: 0.91796875\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.3896027207374573, accuracy: 0.913818359375\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.33581632375717163, accuracy: 0.914306640625\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.33186423778533936, accuracy: 0.916259765625\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.31298011541366577, accuracy: 0.92333984375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.35869941115379333, accuracy: 0.93310546875\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.28526178002357483, accuracy: 0.921630859375\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.33542925119400024, accuracy: 0.921630859375\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.2923664450645447, accuracy: 0.930419921875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.30370384454727173, accuracy: 0.924560546875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.2826332449913025, accuracy: 0.92724609375\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.26734688878059387, accuracy: 0.9267578125\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.3220173418521881, accuracy: 0.931884765625\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.2987421751022339, accuracy: 0.930908203125\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.26463770866394043, accuracy: 0.92919921875\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2613150179386139, accuracy: 0.93115234375\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.25176769495010376, accuracy: 0.93896484375\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.26782310009002686, accuracy: 0.9326171875\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.27964651584625244, accuracy: 0.937744140625\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2828767001628876, accuracy: 0.941650390625\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.26191726326942444, accuracy: 0.942138671875\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2197495996952057, accuracy: 0.938232421875\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.2621757686138153, accuracy: 0.9453125\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.21893301606178284, accuracy: 0.93994140625\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.23070743680000305, accuracy: 0.94482421875\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.22247442603111267, accuracy: 0.94384765625\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.21368570625782013, accuracy: 0.942138671875\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.20986245572566986, accuracy: 0.947265625\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.23850564658641815, accuracy: 0.948486328125\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.21278700232505798, accuracy: 0.949951171875\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.16897085309028625, accuracy: 0.944580078125\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.2104526162147522, accuracy: 0.948486328125\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.24069179594516754, accuracy: 0.948974609375\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.1657639592885971, accuracy: 0.94775390625\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.2409134805202484, accuracy: 0.954833984375\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.21033483743667603, accuracy: 0.953369140625\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.22720269858837128, accuracy: 0.9560546875\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.18704502284526825, accuracy: 0.956298828125\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.20990510284900665, accuracy: 0.954345703125\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.19121114909648895, accuracy: 0.948486328125\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.20147950947284698, accuracy: 0.95263671875\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.18591615557670593, accuracy: 0.95751953125\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.1872377097606659, accuracy: 0.955078125\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.17193415760993958, accuracy: 0.958740234375\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.15919487178325653, accuracy: 0.953857421875\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.20954783260822296, accuracy: 0.958740234375\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.16858051717281342, accuracy: 0.95751953125\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.19053830206394196, accuracy: 0.960205078125\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.18946342170238495, accuracy: 0.958984375\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.19964350759983063, accuracy: 0.958984375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.1576365828514099, accuracy: 0.95947265625\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.1749105453491211, accuracy: 0.956787109375\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.14841720461845398, accuracy: 0.95654296875\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.15807674825191498, accuracy: 0.96240234375\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.17047438025474548, accuracy: 0.961181640625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1566205471754074, accuracy: 0.96240234375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.18363703787326813, accuracy: 0.961669921875\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.17323389649391174, accuracy: 0.96044921875\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.16662806272506714, accuracy: 0.963623046875\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.13742080330848694, accuracy: 0.96240234375\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.11946715414524078, accuracy: 0.964599609375\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.14691884815692902, accuracy: 0.963134765625\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.13029442727565765, accuracy: 0.963623046875\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.17120859026908875, accuracy: 0.964599609375\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.17519652843475342, accuracy: 0.965087890625\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.13121572136878967, accuracy: 0.967041015625\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.15976868569850922, accuracy: 0.9658203125\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1527627855539322, accuracy: 0.96435546875\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.13656675815582275, accuracy: 0.96826171875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.16268400847911835, accuracy: 0.96435546875\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.11962300539016724, accuracy: 0.962890625\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.11084325611591339, accuracy: 0.963623046875\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.13823889195919037, accuracy: 0.971923828125\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.15175768733024597, accuracy: 0.96484375\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.13399970531463623, accuracy: 0.967041015625\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.1206459105014801, accuracy: 0.962890625\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.14634619653224945, accuracy: 0.96435546875\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.12687061727046967, accuracy: 0.96533203125\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.10366510599851608, accuracy: 0.9658203125\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.13541029393672943, accuracy: 0.965576171875\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.12993931770324707, accuracy: 0.96728515625\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.17534129321575165, accuracy: 0.965087890625\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.11878461390733719, accuracy: 0.966796875\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.12863226234912872, accuracy: 0.965576171875\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.15387371182441711, accuracy: 0.967041015625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.1398824006319046, accuracy: 0.966064453125\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.11399558186531067, accuracy: 0.966552734375\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.133292093873024, accuracy: 0.970947265625\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.1407686322927475, accuracy: 0.97265625\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.25217342376709, accuracy: 0.307861328125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9508124589920044, accuracy: 0.703857421875\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.2176016569137573, accuracy: 0.810302734375\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7224166393280029, accuracy: 0.826416015625\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5905870199203491, accuracy: 0.87353515625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5095771551132202, accuracy: 0.88427734375\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.529303252696991, accuracy: 0.894287109375\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4912993609905243, accuracy: 0.892822265625\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4342532157897949, accuracy: 0.89892578125\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.42558926343917847, accuracy: 0.9091796875\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3707873523235321, accuracy: 0.9091796875\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.39216116070747375, accuracy: 0.908203125\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.39355701208114624, accuracy: 0.908935546875\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3761650621891022, accuracy: 0.91064453125\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3763806223869324, accuracy: 0.915283203125\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.3410375118255615, accuracy: 0.9130859375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.32319730520248413, accuracy: 0.918212890625\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.3264210522174835, accuracy: 0.929443359375\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.31782475113868713, accuracy: 0.924560546875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.2964683473110199, accuracy: 0.91943359375\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.326965868473053, accuracy: 0.92138671875\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.3220575451850891, accuracy: 0.925048828125\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.3015866279602051, accuracy: 0.9287109375\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.31220224499702454, accuracy: 0.928955078125\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.26939550042152405, accuracy: 0.935546875\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.2821305990219116, accuracy: 0.9326171875\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2810688614845276, accuracy: 0.937255859375\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.2654600441455841, accuracy: 0.935546875\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.27865520119667053, accuracy: 0.9384765625\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.3064892888069153, accuracy: 0.9345703125\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.2493315488100052, accuracy: 0.936767578125\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2725067436695099, accuracy: 0.938720703125\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.25219446420669556, accuracy: 0.938720703125\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.22750325500965118, accuracy: 0.93603515625\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.2205478549003601, accuracy: 0.93896484375\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.23656794428825378, accuracy: 0.947265625\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.22044223546981812, accuracy: 0.946533203125\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.2668306231498718, accuracy: 0.9443359375\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.21823449432849884, accuracy: 0.941650390625\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2566266655921936, accuracy: 0.942626953125\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.20567965507507324, accuracy: 0.94580078125\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.24408109486103058, accuracy: 0.951416015625\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.21420185267925262, accuracy: 0.94384765625\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.21075095236301422, accuracy: 0.947509765625\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.23378443717956543, accuracy: 0.948486328125\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.2048468142747879, accuracy: 0.9443359375\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.20637227594852448, accuracy: 0.95458984375\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.19736535847187042, accuracy: 0.952392578125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.18960805237293243, accuracy: 0.957275390625\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.19683445990085602, accuracy: 0.950439453125\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.18197864294052124, accuracy: 0.95458984375\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.2152630090713501, accuracy: 0.958740234375\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.19216343760490417, accuracy: 0.9580078125\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.1977207064628601, accuracy: 0.95556640625\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.17421530187129974, accuracy: 0.961181640625\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.1609664112329483, accuracy: 0.95703125\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.20036330819129944, accuracy: 0.95654296875\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.1832984834909439, accuracy: 0.957763671875\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.16027140617370605, accuracy: 0.96142578125\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.16149015724658966, accuracy: 0.95751953125\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.19450819492340088, accuracy: 0.956787109375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.12662632763385773, accuracy: 0.959716796875\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.16021084785461426, accuracy: 0.956787109375\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.19036361575126648, accuracy: 0.961669921875\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.17956428229808807, accuracy: 0.960693359375\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.14608538150787354, accuracy: 0.958740234375\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.15266039967536926, accuracy: 0.96044921875\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.19572009146213531, accuracy: 0.96240234375\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.1532209813594818, accuracy: 0.960693359375\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.1419312208890915, accuracy: 0.96142578125\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.16206106543540955, accuracy: 0.9580078125\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.16848218441009521, accuracy: 0.962890625\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.17187944054603577, accuracy: 0.96044921875\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.1750674545764923, accuracy: 0.962646484375\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.1435755044221878, accuracy: 0.96484375\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.16211405396461487, accuracy: 0.96240234375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.15833847224712372, accuracy: 0.96142578125\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.1304931491613388, accuracy: 0.969482421875\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1442793309688568, accuracy: 0.965087890625\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.14573410153388977, accuracy: 0.965576171875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.14419692754745483, accuracy: 0.966552734375\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.15796741843223572, accuracy: 0.966552734375\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.14792244136333466, accuracy: 0.963134765625\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.14340077340602875, accuracy: 0.967529296875\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.11408108472824097, accuracy: 0.96630859375\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.14765611290931702, accuracy: 0.9619140625\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.1406334638595581, accuracy: 0.96484375\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1231379434466362, accuracy: 0.965087890625\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.11919724196195602, accuracy: 0.963623046875\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.10499364137649536, accuracy: 0.967041015625\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.1649625301361084, accuracy: 0.96728515625\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.1209653839468956, accuracy: 0.965576171875\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.12661868333816528, accuracy: 0.96923828125\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.13821908831596375, accuracy: 0.9697265625\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.14722856879234314, accuracy: 0.971435546875\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.13196448981761932, accuracy: 0.97265625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.13343308866024017, accuracy: 0.9658203125\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.11085616052150726, accuracy: 0.969482421875\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.13750985264778137, accuracy: 0.96923828125\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.12494871765375137, accuracy: 0.970458984375\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.256525993347168, accuracy: 0.26220703125\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9918699264526367, accuracy: 0.722900390625\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.2410976886749268, accuracy: 0.806640625\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.7510435581207275, accuracy: 0.86279296875\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.5542952418327332, accuracy: 0.88623046875\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.4977343678474426, accuracy: 0.892578125\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.4355558753013611, accuracy: 0.899658203125\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.45288729667663574, accuracy: 0.899658203125\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4485875368118286, accuracy: 0.89501953125\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.42460477352142334, accuracy: 0.90185546875\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.3443126678466797, accuracy: 0.906005859375\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3555668592453003, accuracy: 0.907958984375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.37601780891418457, accuracy: 0.91357421875\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3602934181690216, accuracy: 0.908935546875\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.35428744554519653, accuracy: 0.9140625\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.303461492061615, accuracy: 0.91552734375\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.2935769557952881, accuracy: 0.921142578125\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.30155688524246216, accuracy: 0.926025390625\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.3332826495170593, accuracy: 0.9248046875\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.3288029432296753, accuracy: 0.9248046875\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.2558867633342743, accuracy: 0.929443359375\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.2857656478881836, accuracy: 0.929931640625\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.2507456839084625, accuracy: 0.931884765625\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.2823176681995392, accuracy: 0.926513671875\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.3100165128707886, accuracy: 0.92724609375\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.28052303194999695, accuracy: 0.931640625\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2672058939933777, accuracy: 0.932373046875\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.27148663997650146, accuracy: 0.9326171875\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.27187713980674744, accuracy: 0.9345703125\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.2558881342411041, accuracy: 0.935791015625\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.24371609091758728, accuracy: 0.935791015625\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2182895541191101, accuracy: 0.939208984375\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2680734097957611, accuracy: 0.93603515625\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.2179454118013382, accuracy: 0.942138671875\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.2299124151468277, accuracy: 0.94091796875\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.21478261053562164, accuracy: 0.940673828125\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.24847543239593506, accuracy: 0.941650390625\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.23750844597816467, accuracy: 0.94384765625\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.1924331784248352, accuracy: 0.943603515625\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2358742356300354, accuracy: 0.946044921875\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.22008390724658966, accuracy: 0.9423828125\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.21086624264717102, accuracy: 0.945556640625\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.21189239621162415, accuracy: 0.950439453125\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.20437867939472198, accuracy: 0.95166015625\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.21889391541481018, accuracy: 0.950927734375\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.20512279868125916, accuracy: 0.957275390625\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.2564713656902313, accuracy: 0.95458984375\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.16934284567832947, accuracy: 0.953125\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.21064262092113495, accuracy: 0.951171875\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.20872282981872559, accuracy: 0.9599609375\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.19385433197021484, accuracy: 0.95556640625\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.18580101430416107, accuracy: 0.951904296875\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.1687670797109604, accuracy: 0.954345703125\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.19167640805244446, accuracy: 0.9560546875\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.21263588964939117, accuracy: 0.959716796875\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.16427092254161835, accuracy: 0.9599609375\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.17715905606746674, accuracy: 0.96044921875\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.15839742124080658, accuracy: 0.957763671875\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.15307442843914032, accuracy: 0.959228515625\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.14405356347560883, accuracy: 0.958740234375\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.1752563714981079, accuracy: 0.9599609375\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.18626031279563904, accuracy: 0.964111328125\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.13848163187503815, accuracy: 0.955810546875\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.16791285574436188, accuracy: 0.95654296875\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.17500978708267212, accuracy: 0.95947265625\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.1713567078113556, accuracy: 0.963134765625\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.15549017488956451, accuracy: 0.95947265625\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.17120283842086792, accuracy: 0.963134765625\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.18061883747577667, accuracy: 0.95751953125\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.1728295087814331, accuracy: 0.9638671875\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.12260646373033524, accuracy: 0.961181640625\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.1390179693698883, accuracy: 0.964111328125\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.14840713143348694, accuracy: 0.9638671875\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.13648483157157898, accuracy: 0.961181640625\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.17856590449810028, accuracy: 0.961669921875\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.19438351690769196, accuracy: 0.967041015625\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.15962108969688416, accuracy: 0.962158203125\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.1391010582447052, accuracy: 0.96533203125\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.1623050570487976, accuracy: 0.96875\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.16346655786037445, accuracy: 0.965576171875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.11858616024255753, accuracy: 0.968505859375\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.1868123859167099, accuracy: 0.9658203125\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.16520899534225464, accuracy: 0.966552734375\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.11762779951095581, accuracy: 0.962646484375\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.17869620025157928, accuracy: 0.96533203125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.13043281435966492, accuracy: 0.966796875\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.12871766090393066, accuracy: 0.966064453125\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1495668739080429, accuracy: 0.965576171875\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.13915541768074036, accuracy: 0.9638671875\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.14942343533039093, accuracy: 0.969482421875\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.13838474452495575, accuracy: 0.969970703125\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.15031234920024872, accuracy: 0.96533203125\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.12120002508163452, accuracy: 0.96630859375\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.12502573430538177, accuracy: 0.966064453125\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.10494057834148407, accuracy: 0.9658203125\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.11529345065355301, accuracy: 0.96728515625\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.12435055524110794, accuracy: 0.971435546875\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.13316428661346436, accuracy: 0.96728515625\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.11209678649902344, accuracy: 0.966064453125\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.1329670548439026, accuracy: 0.968994140625\n",
            "Epoch: 1, learning_rate:[0.040000000000000015],costo: 2.235628604888916, accuracy: 0.452880859375\n",
            "Epoch: 2, learning_rate:[0.06999999999999999],costo: 1.9423160552978516, accuracy: 0.717041015625\n",
            "Epoch: 3, learning_rate:[0.1],costo: 1.181072473526001, accuracy: 0.7958984375\n",
            "Epoch: 4, learning_rate:[0.07000000000000003],costo: 0.6692993640899658, accuracy: 0.84326171875\n",
            "Epoch: 5, learning_rate:[0.03999999999999998],costo: 0.524814248085022, accuracy: 0.8759765625\n",
            "Epoch: 6, learning_rate:[0.01],costo: 0.5599026679992676, accuracy: 0.891845703125\n",
            "Epoch: 7, learning_rate:[0.040000000000000056],costo: 0.5033193826675415, accuracy: 0.89453125\n",
            "Epoch: 8, learning_rate:[0.06999999999999995],costo: 0.4744108021259308, accuracy: 0.900146484375\n",
            "Epoch: 9, learning_rate:[0.1],costo: 0.4486956000328064, accuracy: 0.903076171875\n",
            "Epoch: 10, learning_rate:[0.06999999999999995],costo: 0.46483129262924194, accuracy: 0.88330078125\n",
            "Epoch: 11, learning_rate:[0.040000000000000056],costo: 0.38283786177635193, accuracy: 0.9091796875\n",
            "Epoch: 12, learning_rate:[0.01],costo: 0.3748280107975006, accuracy: 0.91162109375\n",
            "Epoch: 13, learning_rate:[0.03999999999999998],costo: 0.3931256830692291, accuracy: 0.91162109375\n",
            "Epoch: 14, learning_rate:[0.07000000000000003],costo: 0.3735160827636719, accuracy: 0.911865234375\n",
            "Epoch: 15, learning_rate:[0.1],costo: 0.3815743923187256, accuracy: 0.913818359375\n",
            "Epoch: 16, learning_rate:[0.07000000000000003],costo: 0.33365389704704285, accuracy: 0.91748046875\n",
            "Epoch: 17, learning_rate:[0.03999999999999998],costo: 0.3389493525028229, accuracy: 0.914306640625\n",
            "Epoch: 18, learning_rate:[0.01],costo: 0.29766184091567993, accuracy: 0.925048828125\n",
            "Epoch: 19, learning_rate:[0.0399999999999999],costo: 0.34971174597740173, accuracy: 0.91943359375\n",
            "Epoch: 20, learning_rate:[0.07000000000000012],costo: 0.3028244078159332, accuracy: 0.92236328125\n",
            "Epoch: 21, learning_rate:[0.1],costo: 0.29941654205322266, accuracy: 0.927001953125\n",
            "Epoch: 22, learning_rate:[0.07000000000000012],costo: 0.2823672890663147, accuracy: 0.925048828125\n",
            "Epoch: 23, learning_rate:[0.0399999999999999],costo: 0.2880336046218872, accuracy: 0.9287109375\n",
            "Epoch: 24, learning_rate:[0.01],costo: 0.2709188163280487, accuracy: 0.9306640625\n",
            "Epoch: 25, learning_rate:[0.040000000000000056],costo: 0.2866263687610626, accuracy: 0.9296875\n",
            "Epoch: 26, learning_rate:[0.06999999999999995],costo: 0.2682066559791565, accuracy: 0.9267578125\n",
            "Epoch: 27, learning_rate:[0.1],costo: 0.2840486466884613, accuracy: 0.925048828125\n",
            "Epoch: 28, learning_rate:[0.06999999999999995],costo: 0.25209754705429077, accuracy: 0.931884765625\n",
            "Epoch: 29, learning_rate:[0.040000000000000056],costo: 0.2824653685092926, accuracy: 0.934326171875\n",
            "Epoch: 30, learning_rate:[0.01],costo: 0.25366461277008057, accuracy: 0.93896484375\n",
            "Epoch: 31, learning_rate:[0.040000000000000056],costo: 0.22095824778079987, accuracy: 0.927001953125\n",
            "Epoch: 32, learning_rate:[0.06999999999999995],costo: 0.2173895388841629, accuracy: 0.941162109375\n",
            "Epoch: 33, learning_rate:[0.1],costo: 0.2834126353263855, accuracy: 0.9375\n",
            "Epoch: 34, learning_rate:[0.06999999999999995],costo: 0.2224198579788208, accuracy: 0.93359375\n",
            "Epoch: 35, learning_rate:[0.040000000000000056],costo: 0.26241612434387207, accuracy: 0.9365234375\n",
            "Epoch: 36, learning_rate:[0.01],costo: 0.252407044172287, accuracy: 0.935546875\n",
            "Epoch: 37, learning_rate:[0.040000000000000056],costo: 0.2424544394016266, accuracy: 0.9404296875\n",
            "Epoch: 38, learning_rate:[0.06999999999999995],costo: 0.21825498342514038, accuracy: 0.9453125\n",
            "Epoch: 39, learning_rate:[0.1],costo: 0.2686140239238739, accuracy: 0.9423828125\n",
            "Epoch: 40, learning_rate:[0.06999999999999995],costo: 0.2464611977338791, accuracy: 0.9443359375\n",
            "Epoch: 41, learning_rate:[0.040000000000000056],costo: 0.17224548757076263, accuracy: 0.94482421875\n",
            "Epoch: 42, learning_rate:[0.01],costo: 0.2065240442752838, accuracy: 0.945068359375\n",
            "Epoch: 43, learning_rate:[0.040000000000000216],costo: 0.25508442521095276, accuracy: 0.949951171875\n",
            "Epoch: 44, learning_rate:[0.0699999999999998],costo: 0.20550937950611115, accuracy: 0.949951171875\n",
            "Epoch: 45, learning_rate:[0.1],costo: 0.23396119475364685, accuracy: 0.95361328125\n",
            "Epoch: 46, learning_rate:[0.0699999999999998],costo: 0.24112725257873535, accuracy: 0.954345703125\n",
            "Epoch: 47, learning_rate:[0.040000000000000216],costo: 0.18277187645435333, accuracy: 0.950439453125\n",
            "Epoch: 48, learning_rate:[0.01],costo: 0.20931865274906158, accuracy: 0.9541015625\n",
            "Epoch: 49, learning_rate:[0.0399999999999999],costo: 0.21198928356170654, accuracy: 0.953857421875\n",
            "Epoch: 50, learning_rate:[0.07000000000000012],costo: 0.1987694650888443, accuracy: 0.950927734375\n",
            "Epoch: 51, learning_rate:[0.1],costo: 0.2058921605348587, accuracy: 0.953125\n",
            "Epoch: 52, learning_rate:[0.07000000000000012],costo: 0.19457149505615234, accuracy: 0.951171875\n",
            "Epoch: 53, learning_rate:[0.0399999999999999],costo: 0.18629054725170135, accuracy: 0.953369140625\n",
            "Epoch: 54, learning_rate:[0.01],costo: 0.16634045541286469, accuracy: 0.958984375\n",
            "Epoch: 55, learning_rate:[0.0399999999999999],costo: 0.19057030975818634, accuracy: 0.958984375\n",
            "Epoch: 56, learning_rate:[0.07000000000000012],costo: 0.20634764432907104, accuracy: 0.953857421875\n",
            "Epoch: 57, learning_rate:[0.1],costo: 0.20662105083465576, accuracy: 0.95947265625\n",
            "Epoch: 58, learning_rate:[0.07000000000000012],costo: 0.15285137295722961, accuracy: 0.955322265625\n",
            "Epoch: 59, learning_rate:[0.0399999999999999],costo: 0.20529618859291077, accuracy: 0.95751953125\n",
            "Epoch: 60, learning_rate:[0.01],costo: 0.13955135643482208, accuracy: 0.957763671875\n",
            "Epoch: 61, learning_rate:[0.0399999999999999],costo: 0.190598726272583, accuracy: 0.96044921875\n",
            "Epoch: 62, learning_rate:[0.07000000000000012],costo: 0.14201129972934723, accuracy: 0.958984375\n",
            "Epoch: 63, learning_rate:[0.1],costo: 0.16159965097904205, accuracy: 0.958740234375\n",
            "Epoch: 64, learning_rate:[0.07000000000000012],costo: 0.17340624332427979, accuracy: 0.957275390625\n",
            "Epoch: 65, learning_rate:[0.0399999999999999],costo: 0.13368239998817444, accuracy: 0.9580078125\n",
            "Epoch: 66, learning_rate:[0.01],costo: 0.16282226145267487, accuracy: 0.960693359375\n",
            "Epoch: 67, learning_rate:[0.0399999999999999],costo: 0.1533294916152954, accuracy: 0.964599609375\n",
            "Epoch: 68, learning_rate:[0.07000000000000012],costo: 0.14948496222496033, accuracy: 0.953857421875\n",
            "Epoch: 69, learning_rate:[0.1],costo: 0.15473110973834991, accuracy: 0.961181640625\n",
            "Epoch: 70, learning_rate:[0.07000000000000012],costo: 0.1271476149559021, accuracy: 0.9609375\n",
            "Epoch: 71, learning_rate:[0.0399999999999999],costo: 0.150467649102211, accuracy: 0.96337890625\n",
            "Epoch: 72, learning_rate:[0.01],costo: 0.14317870140075684, accuracy: 0.96484375\n",
            "Epoch: 73, learning_rate:[0.0399999999999999],costo: 0.15531452000141144, accuracy: 0.958984375\n",
            "Epoch: 74, learning_rate:[0.07000000000000012],costo: 0.17633168399333954, accuracy: 0.960693359375\n",
            "Epoch: 75, learning_rate:[0.1],costo: 0.1276611089706421, accuracy: 0.9619140625\n",
            "Epoch: 76, learning_rate:[0.07000000000000012],costo: 0.161123588681221, accuracy: 0.964599609375\n",
            "Epoch: 77, learning_rate:[0.0399999999999999],costo: 0.11144008487462997, accuracy: 0.966552734375\n",
            "Epoch: 78, learning_rate:[0.01],costo: 0.14165431261062622, accuracy: 0.967041015625\n",
            "Epoch: 79, learning_rate:[0.0399999999999999],costo: 0.13263873755931854, accuracy: 0.966064453125\n",
            "Epoch: 80, learning_rate:[0.07000000000000012],costo: 0.12287125736474991, accuracy: 0.96875\n",
            "Epoch: 81, learning_rate:[0.1],costo: 0.14190828800201416, accuracy: 0.965576171875\n",
            "Epoch: 82, learning_rate:[0.07000000000000012],costo: 0.13295812904834747, accuracy: 0.968017578125\n",
            "Epoch: 83, learning_rate:[0.0399999999999999],costo: 0.1636120229959488, accuracy: 0.968994140625\n",
            "Epoch: 84, learning_rate:[0.01],costo: 0.1606084108352661, accuracy: 0.96337890625\n",
            "Epoch: 85, learning_rate:[0.0399999999999999],costo: 0.13950730860233307, accuracy: 0.966064453125\n",
            "Epoch: 86, learning_rate:[0.07000000000000012],costo: 0.12630131840705872, accuracy: 0.966552734375\n",
            "Epoch: 87, learning_rate:[0.1],costo: 0.1275539994239807, accuracy: 0.96728515625\n",
            "Epoch: 88, learning_rate:[0.07000000000000012],costo: 0.1188022792339325, accuracy: 0.969482421875\n",
            "Epoch: 89, learning_rate:[0.0399999999999999],costo: 0.11866337060928345, accuracy: 0.96630859375\n",
            "Epoch: 90, learning_rate:[0.01],costo: 0.12389644235372543, accuracy: 0.965576171875\n",
            "Epoch: 91, learning_rate:[0.03999999999999958],costo: 0.16302765905857086, accuracy: 0.964111328125\n",
            "Epoch: 92, learning_rate:[0.07000000000000044],costo: 0.15987884998321533, accuracy: 0.97314453125\n",
            "Epoch: 93, learning_rate:[0.1],costo: 0.10804902017116547, accuracy: 0.967529296875\n",
            "Epoch: 94, learning_rate:[0.07000000000000044],costo: 0.14328725636005402, accuracy: 0.965087890625\n",
            "Epoch: 95, learning_rate:[0.03999999999999958],costo: 0.1370648592710495, accuracy: 0.9677734375\n",
            "Epoch: 96, learning_rate:[0.01],costo: 0.1324222832918167, accuracy: 0.9677734375\n",
            "Epoch: 97, learning_rate:[0.040000000000000216],costo: 0.13525554537773132, accuracy: 0.96875\n",
            "Epoch: 98, learning_rate:[0.0699999999999998],costo: 0.12980228662490845, accuracy: 0.969970703125\n",
            "Epoch: 99, learning_rate:[0.1],costo: 0.11598248034715652, accuracy: 0.9677734375\n",
            "Epoch: 100, learning_rate:[0.0699999999999998],costo: 0.13153338432312012, accuracy: 0.970703125\n"
          ]
        }
      ],
      "source": [
        "resultados['cyclic'] = {}\n",
        "resultados['cyclic']['val_acc_list'] = [0]* epochs\n",
        "resultados['cyclic']['test_acc'] = 0\n",
        "resultados['cyclic']['cost'] = [0] * epochs\n",
        "resultados['cyclic']['time'] = 0\n",
        "resultados['cyclic']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    cyclic_acc_list, cyclic_cost_list, cyclic_lr_list, cyclic_time, cyclic_acc, cyclic_epochs = Cyclic()\n",
        "    resultados['cyclic']['val_acc_list'] = SumList(resultados['cyclic']['val_acc_list'], cyclic_acc_list)\n",
        "    resultados['cyclic']['test_acc'] += cyclic_acc\n",
        "    resultados['cyclic']['cost'] = SumList(resultados['cyclic']['cost'], cyclic_cost_list)\n",
        "    resultados['cyclic']['time'] += cyclic_time\n",
        "    resultados['cyclic']['epochs'] += cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['cyclic']['name'] = 'Ciclico'\n",
        "resultados['cyclic']['lr'] = cyclic_lr_list\n",
        "resultados['cyclic']['test_acc'] = resultados['cyclic']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['cyclic']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['cyclic']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['cyclic']['cost'] = DeleteZerosFromList(DivideList(resultados['cyclic']['cost'], MAX_ITERATIONS))\n",
        "resultados['cyclic']['time'] = resultados['cyclic']['time']/ MAX_ITERATIONS\n",
        "resultados['cyclic']['epochs'] = resultados['cyclic']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f8ZZZ1Hcg2R"
      },
      "source": [
        "## Tasa de aprendizaje cíclica aleatoria (propuesta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btFiYiGVgWvF"
      },
      "source": [
        "Oscila entre una $base\\_ta$ y un $max\\_ta$ cada $n$ epochs en una proporción aleatoria.\n",
        "\n",
        "$base\\_ta: 1x10^{-2}$\n",
        "\n",
        "$max\\_ta: 1x10^{-1}$\n",
        "\n",
        "$n: 3$ epochs\n",
        "\n",
        "![random.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3AG-ZFJ9fGaW"
      },
      "outputs": [],
      "source": [
        "def CyclicGD():\n",
        "    import random\n",
        "    modelRandomCyclic = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelRandomCyclic.parameters(), lr=lr)\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3, scale_mode='chipichipi')\n",
        "\n",
        "    start.record()\n",
        "    random_cyclic_acc_list, random_cyclic_cost_list, random_cyclic_lr_list, random_cyclic_epochs= train(modelRandomCyclic, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize() \n",
        "    random_cyclic_time = start.elapsed_time(end)\n",
        "\n",
        "    random_cyclic_acc = accuracy(modelRandomCyclic, x_test_tensor,  y_test_tensor, mb_size) \n",
        "\n",
        "    return random_cyclic_acc_list, random_cyclic_cost_list, random_cyclic_lr_list, random_cyclic_time, random_cyclic_acc, random_cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acBgxgGkZdL6",
        "outputId": "258ebbfe-57b4-403d-962f-f4be515a6008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:[0.07608094438540566],costo: 1.990390658378601, accuracy: 0.739990234375\n",
            "Epoch: 2, learning_rate:[0.07611882664870047],costo: 1.173996090888977, accuracy: 0.81591796875\n",
            "Epoch: 3, learning_rate:[0.0786728496997142],costo: 0.7070961594581604, accuracy: 0.8583984375\n",
            "Epoch: 4, learning_rate:[0.05648140500800983],costo: 0.5842505097389221, accuracy: 0.89306640625\n",
            "Epoch: 5, learning_rate:[0.04523140877747463],costo: 0.5178374648094177, accuracy: 0.88037109375\n",
            "Epoch: 6, learning_rate:[0.018872238820907692],costo: 0.48925212025642395, accuracy: 0.897216796875\n",
            "Epoch: 7, learning_rate:[0.08805761764213184],costo: 0.44896379113197327, accuracy: 0.908935546875\n",
            "Epoch: 8, learning_rate:[0.09602193718842472],costo: 0.43718525767326355, accuracy: 0.9091796875\n",
            "Epoch: 9, learning_rate:[0.09903611155224495],costo: 0.499578058719635, accuracy: 0.88427734375\n",
            "Epoch: 10, learning_rate:[0.033232326624053024],costo: 0.35287410020828247, accuracy: 0.90771484375\n",
            "Epoch: 11, learning_rate:[0.020282086216374173],costo: 0.38037487864494324, accuracy: 0.917236328125\n",
            "Epoch: 12, learning_rate:[0.018935431819536067],costo: 0.3752885162830353, accuracy: 0.91455078125\n",
            "Epoch: 13, learning_rate:[0.054112128502257814],costo: 0.307193785905838, accuracy: 0.919677734375\n",
            "Epoch: 14, learning_rate:[0.06132713662795142],costo: 0.2996092140674591, accuracy: 0.922119140625\n",
            "Epoch: 15, learning_rate:[0.08462590076697278],costo: 0.2966236174106598, accuracy: 0.91796875\n",
            "Epoch: 16, learning_rate:[0.048945744895648985],costo: 0.2890607714653015, accuracy: 0.91943359375\n",
            "Epoch: 17, learning_rate:[0.01855300542559475],costo: 0.29943522810935974, accuracy: 0.9287109375\n",
            "Epoch: 18, learning_rate:[0.014305223193494695],costo: 0.3063446283340454, accuracy: 0.92041015625\n",
            "Epoch: 19, learning_rate:[0.09728738992157387],costo: 0.3020614981651306, accuracy: 0.923828125\n",
            "Epoch: 20, learning_rate:[0.09784773354212939],costo: 0.3013608455657959, accuracy: 0.931884765625\n",
            "Epoch: 21, learning_rate:[0.09921172426477119],costo: 0.2791904807090759, accuracy: 0.927001953125\n",
            "Epoch: 22, learning_rate:[0.021357315098284292],costo: 0.2705817222595215, accuracy: 0.936767578125\n",
            "Epoch: 23, learning_rate:[0.012275443571560905],costo: 0.2774766981601715, accuracy: 0.929931640625\n",
            "Epoch: 24, learning_rate:[0.011044692084025462],costo: 0.30060285329818726, accuracy: 0.933349609375\n",
            "Epoch: 25, learning_rate:[0.03747009516379603],costo: 0.29842084646224976, accuracy: 0.932861328125\n",
            "Epoch: 26, learning_rate:[0.07574395941762918],costo: 0.2545251250267029, accuracy: 0.93115234375\n",
            "Epoch: 27, learning_rate:[0.08872589494332596],costo: 0.2463468462228775, accuracy: 0.934814453125\n",
            "Epoch: 28, learning_rate:[0.03138065006529105],costo: 0.2778882086277008, accuracy: 0.929443359375\n",
            "Epoch: 29, learning_rate:[0.013340726587507422],costo: 0.24109555780887604, accuracy: 0.936279296875\n",
            "Epoch: 30, learning_rate:[0.011192566690327928],costo: 0.27267441153526306, accuracy: 0.936279296875\n",
            "Epoch: 31, learning_rate:[0.04541483302372434],costo: 0.26345500349998474, accuracy: 0.93115234375\n",
            "Epoch: 32, learning_rate:[0.06270486203219161],costo: 0.23588180541992188, accuracy: 0.933349609375\n",
            "Epoch: 33, learning_rate:[0.09841340094513887],costo: 0.2581104636192322, accuracy: 0.93701171875\n",
            "Epoch: 34, learning_rate:[0.023857876004796705],costo: 0.24220117926597595, accuracy: 0.93798828125\n",
            "Epoch: 35, learning_rate:[0.023623364081122096],costo: 0.2977704107761383, accuracy: 0.940185546875\n",
            "Epoch: 36, learning_rate:[0.022473127444185295],costo: 0.23757395148277283, accuracy: 0.941162109375\n",
            "Epoch: 37, learning_rate:[0.05024612145463181],costo: 0.2070983499288559, accuracy: 0.94677734375\n",
            "Epoch: 38, learning_rate:[0.05267810494664902],costo: 0.21690592169761658, accuracy: 0.941162109375\n",
            "Epoch: 39, learning_rate:[0.07957275182979216],costo: 0.20863302052021027, accuracy: 0.9404296875\n",
            "Epoch: 40, learning_rate:[0.05118490184909937],costo: 0.21911080181598663, accuracy: 0.943115234375\n",
            "Epoch: 41, learning_rate:[0.03694890255700896],costo: 0.2126566469669342, accuracy: 0.948974609375\n",
            "Epoch: 42, learning_rate:[0.01320636564179532],costo: 0.21658360958099365, accuracy: 0.944580078125\n",
            "Epoch: 43, learning_rate:[0.02968195711915205],costo: 0.23612076044082642, accuracy: 0.950439453125\n",
            "Epoch: 44, learning_rate:[0.07248159992328108],costo: 0.18777373433113098, accuracy: 0.949462890625\n",
            "Epoch: 45, learning_rate:[0.07888214776536252],costo: 0.24379000067710876, accuracy: 0.946533203125\n",
            "Epoch: 46, learning_rate:[0.02007142757861142],costo: 0.22633737325668335, accuracy: 0.947998046875\n",
            "Epoch: 47, learning_rate:[0.016201680830625703],costo: 0.21036279201507568, accuracy: 0.949462890625\n",
            "Epoch: 48, learning_rate:[0.010904631187541654],costo: 0.19824698567390442, accuracy: 0.946044921875\n",
            "Epoch: 49, learning_rate:[0.020500313886769837],costo: 0.20819924771785736, accuracy: 0.951416015625\n",
            "Epoch: 50, learning_rate:[0.021582725559500825],costo: 0.22180825471878052, accuracy: 0.954345703125\n",
            "Epoch: 51, learning_rate:[0.024100828294573787],costo: 0.20484040677547455, accuracy: 0.94970703125\n",
            "Epoch: 52, learning_rate:[0.01992929819148066],costo: 0.2287217378616333, accuracy: 0.947509765625\n",
            "Epoch: 53, learning_rate:[0.012008396150333424],costo: 0.20012962818145752, accuracy: 0.947021484375\n",
            "Epoch: 54, learning_rate:[0.010164728684585933],costo: 0.20459938049316406, accuracy: 0.949951171875\n",
            "Epoch: 55, learning_rate:[0.08644605570878279],costo: 0.17699025571346283, accuracy: 0.947021484375\n",
            "Epoch: 56, learning_rate:[0.09508515930349548],costo: 0.2782440483570099, accuracy: 0.953369140625\n",
            "Epoch: 57, learning_rate:[0.09671720962317139],costo: 0.22672949731349945, accuracy: 0.948974609375\n",
            "Epoch: 58, learning_rate:[0.08079666853730479],costo: 0.1687224805355072, accuracy: 0.955810546875\n",
            "Epoch: 59, learning_rate:[0.05013797302473039],costo: 0.19353903830051422, accuracy: 0.957275390625\n",
            "Epoch: 60, learning_rate:[0.01956849795213156],costo: 0.1947903037071228, accuracy: 0.957763671875\n",
            "Epoch: 61, learning_rate:[0.0250496806672544],costo: 0.16278640925884247, accuracy: 0.956298828125\n",
            "Epoch: 62, learning_rate:[0.09031451408241856],costo: 0.1746378242969513, accuracy: 0.958740234375\n",
            "Epoch: 63, learning_rate:[0.09075053016234275],costo: 0.18453630805015564, accuracy: 0.955078125\n",
            "Epoch: 64, learning_rate:[0.053196540521521625],costo: 0.15566082298755646, accuracy: 0.95703125\n",
            "Epoch: 65, learning_rate:[0.016811042198676275],costo: 0.16653554141521454, accuracy: 0.957763671875\n",
            "Epoch: 66, learning_rate:[0.011110269982142344],costo: 0.18229562044143677, accuracy: 0.96044921875\n",
            "Epoch: 67, learning_rate:[0.09910151671365497],costo: 0.1804930418729782, accuracy: 0.961181640625\n",
            "Epoch: 68, learning_rate:[0.09939993302016663],costo: 0.15399043262004852, accuracy: 0.9580078125\n",
            "Epoch: 69, learning_rate:[0.09946869842263995],costo: 0.1657211184501648, accuracy: 0.9580078125\n",
            "Epoch: 70, learning_rate:[0.026323544341640047],costo: 0.17699339985847473, accuracy: 0.960693359375\n",
            "Epoch: 71, learning_rate:[0.016381314421890742],costo: 0.20541390776634216, accuracy: 0.958984375\n",
            "Epoch: 72, learning_rate:[0.012487548913523303],costo: 0.14076420664787292, accuracy: 0.96142578125\n",
            "Epoch: 73, learning_rate:[0.07829324235453426],costo: 0.18222637474536896, accuracy: 0.957275390625\n",
            "Epoch: 74, learning_rate:[0.09806022378229416],costo: 0.13159702718257904, accuracy: 0.964599609375\n",
            "Epoch: 75, learning_rate:[0.09869232469215888],costo: 0.15676923096179962, accuracy: 0.962646484375\n",
            "Epoch: 76, learning_rate:[0.0483640294194769],costo: 0.1686711609363556, accuracy: 0.959228515625\n",
            "Epoch: 77, learning_rate:[0.021606995283678092],costo: 0.16084599494934082, accuracy: 0.963623046875\n",
            "Epoch: 78, learning_rate:[0.010569900844957555],costo: 0.15427157282829285, accuracy: 0.95947265625\n",
            "Epoch: 79, learning_rate:[0.07732214896645218],costo: 0.13498131930828094, accuracy: 0.96435546875\n",
            "Epoch: 80, learning_rate:[0.09155875654923376],costo: 0.17575089633464813, accuracy: 0.9658203125\n",
            "Epoch: 81, learning_rate:[0.09253335958349086],costo: 0.13650023937225342, accuracy: 0.964599609375\n",
            "Epoch: 82, learning_rate:[0.07528443680350166],costo: 0.16041293740272522, accuracy: 0.964111328125\n",
            "Epoch: 83, learning_rate:[0.06797938850053364],costo: 0.15477006137371063, accuracy: 0.9599609375\n",
            "Epoch: 84, learning_rate:[0.05043469579855488],costo: 0.12001684308052063, accuracy: 0.96826171875\n",
            "Epoch: 85, learning_rate:[0.05790576685830929],costo: 0.10279425978660583, accuracy: 0.96923828125\n",
            "Epoch: 86, learning_rate:[0.06490256558567195],costo: 0.16685383021831512, accuracy: 0.967041015625\n",
            "Epoch: 87, learning_rate:[0.08718237352702961],costo: 0.130981907248497, accuracy: 0.964111328125\n",
            "Epoch: 88, learning_rate:[0.019508537704504426],costo: 0.1543455272912979, accuracy: 0.9658203125\n",
            "Epoch: 89, learning_rate:[0.01682812220845824],costo: 0.137197807431221, accuracy: 0.96728515625\n",
            "Epoch: 90, learning_rate:[0.0144081812590026],costo: 0.17516086995601654, accuracy: 0.966796875\n",
            "Epoch: 91, learning_rate:[0.07473580232008252],costo: 0.1521316021680832, accuracy: 0.968017578125\n",
            "Epoch: 92, learning_rate:[0.07729604315217647],costo: 0.1156688705086708, accuracy: 0.96826171875\n",
            "Epoch: 93, learning_rate:[0.08737767100667054],costo: 0.12737146019935608, accuracy: 0.9658203125\n",
            "Epoch: 94, learning_rate:[0.05445134187251335],costo: 0.10645762830972672, accuracy: 0.9697265625\n",
            "Epoch: 95, learning_rate:[0.04974833200085147],costo: 0.12169496715068817, accuracy: 0.967041015625\n",
            "Epoch: 96, learning_rate:[0.041488211426059116],costo: 0.16388848423957825, accuracy: 0.966064453125\n",
            "Epoch: 97, learning_rate:[0.08293961042188708],costo: 0.1138569563627243, accuracy: 0.966796875\n",
            "Epoch: 98, learning_rate:[0.09959004823794636],costo: 0.11064261943101883, accuracy: 0.9697265625\n",
            "Epoch: 99, learning_rate:[0.09973137802528843],costo: 0.13530376553535461, accuracy: 0.96826171875\n",
            "Epoch: 100, learning_rate:[0.044696826153091215],costo: 0.1409996598958969, accuracy: 0.972412109375\n",
            "Epoch: 1, learning_rate:[0.09756969805260679],costo: 1.9116392135620117, accuracy: 0.736083984375\n",
            "Epoch: 2, learning_rate:[0.09965276110291632],costo: 0.947895884513855, accuracy: 0.822021484375\n",
            "Epoch: 3, learning_rate:[0.09993952865724078],costo: 0.6805471777915955, accuracy: 0.844970703125\n",
            "Epoch: 4, learning_rate:[0.06203466259915399],costo: 0.5797812342643738, accuracy: 0.845703125\n",
            "Epoch: 5, learning_rate:[0.02974689979908276],costo: 0.4409632384777069, accuracy: 0.893798828125\n",
            "Epoch: 6, learning_rate:[0.014195570856449076],costo: 0.4516391456127167, accuracy: 0.9033203125\n",
            "Epoch: 7, learning_rate:[0.07956721146079479],costo: 0.44389599561691284, accuracy: 0.90625\n",
            "Epoch: 8, learning_rate:[0.09818202306189605],costo: 0.4279351830482483, accuracy: 0.911865234375\n",
            "Epoch: 9, learning_rate:[0.09912922601571364],costo: 0.3704298436641693, accuracy: 0.908203125\n",
            "Epoch: 10, learning_rate:[0.08962709220627724],costo: 0.3430382311344147, accuracy: 0.913818359375\n",
            "Epoch: 11, learning_rate:[0.06961942422043747],costo: 0.3507266044616699, accuracy: 0.91845703125\n",
            "Epoch: 12, learning_rate:[0.026863951358907547],costo: 0.33124589920043945, accuracy: 0.916748046875\n",
            "Epoch: 13, learning_rate:[0.051928053291633414],costo: 0.30071353912353516, accuracy: 0.91796875\n",
            "Epoch: 14, learning_rate:[0.07349031896152983],costo: 0.33419471979141235, accuracy: 0.916259765625\n",
            "Epoch: 15, learning_rate:[0.09904428670043436],costo: 0.31853383779525757, accuracy: 0.92431640625\n",
            "Epoch: 16, learning_rate:[0.03342994585650122],costo: 0.29568251967430115, accuracy: 0.927490234375\n",
            "Epoch: 17, learning_rate:[0.018511062601806173],costo: 0.29138442873954773, accuracy: 0.92724609375\n",
            "Epoch: 18, learning_rate:[0.014420354167521444],costo: 0.3178028166294098, accuracy: 0.923828125\n",
            "Epoch: 19, learning_rate:[0.0858136391192586],costo: 0.2762686312198639, accuracy: 0.927734375\n",
            "Epoch: 20, learning_rate:[0.09476403650440164],costo: 0.30448564887046814, accuracy: 0.9296875\n",
            "Epoch: 21, learning_rate:[0.09928988175069892],costo: 0.28037941455841064, accuracy: 0.939697265625\n",
            "Epoch: 22, learning_rate:[0.08167953653125667],costo: 0.27967512607574463, accuracy: 0.930419921875\n",
            "Epoch: 23, learning_rate:[0.07697767233345433],costo: 0.2738235890865326, accuracy: 0.938232421875\n",
            "Epoch: 24, learning_rate:[0.046457690614427484],costo: 0.2808312773704529, accuracy: 0.931396484375\n",
            "Epoch: 25, learning_rate:[0.051715119983731704],costo: 0.2516140043735504, accuracy: 0.937255859375\n",
            "Epoch: 26, learning_rate:[0.08431114161155573],costo: 0.2532927393913269, accuracy: 0.94189453125\n",
            "Epoch: 27, learning_rate:[0.09421415850013341],costo: 0.2813310921192169, accuracy: 0.93896484375\n",
            "Epoch: 28, learning_rate:[0.040152286645673024],costo: 0.24320143461227417, accuracy: 0.945556640625\n",
            "Epoch: 29, learning_rate:[0.017292508837603443],costo: 0.26615071296691895, accuracy: 0.94482421875\n",
            "Epoch: 30, learning_rate:[0.01707063492927722],costo: 0.2416243851184845, accuracy: 0.944091796875\n",
            "Epoch: 31, learning_rate:[0.03315215844781158],costo: 0.225270614027977, accuracy: 0.939697265625\n",
            "Epoch: 32, learning_rate:[0.09710046921225833],costo: 0.2198207974433899, accuracy: 0.942626953125\n",
            "Epoch: 33, learning_rate:[0.09999208308367404],costo: 0.23287782073020935, accuracy: 0.943359375\n",
            "Epoch: 34, learning_rate:[0.037443540106292195],costo: 0.2552638053894043, accuracy: 0.947998046875\n",
            "Epoch: 35, learning_rate:[0.024504570644243807],costo: 0.2344646453857422, accuracy: 0.950439453125\n",
            "Epoch: 36, learning_rate:[0.018473979953362196],costo: 0.20404702425003052, accuracy: 0.946044921875\n",
            "Epoch: 37, learning_rate:[0.05282107587055684],costo: 0.19690090417861938, accuracy: 0.951171875\n",
            "Epoch: 38, learning_rate:[0.06572188404116674],costo: 0.22264507412910461, accuracy: 0.947998046875\n",
            "Epoch: 39, learning_rate:[0.08574693219077135],costo: 0.20246872305870056, accuracy: 0.955810546875\n",
            "Epoch: 40, learning_rate:[0.06735411056823039],costo: 0.1892327219247818, accuracy: 0.95166015625\n",
            "Epoch: 41, learning_rate:[0.03641131575664051],costo: 0.17023718357086182, accuracy: 0.9541015625\n",
            "Epoch: 42, learning_rate:[0.011754422057522952],costo: 0.2104417085647583, accuracy: 0.95263671875\n",
            "Epoch: 43, learning_rate:[0.014159262187123876],costo: 0.20554614067077637, accuracy: 0.952880859375\n",
            "Epoch: 44, learning_rate:[0.04309782283430315],costo: 0.18638451397418976, accuracy: 0.951904296875\n",
            "Epoch: 45, learning_rate:[0.09597549437221947],costo: 0.19602113962173462, accuracy: 0.95361328125\n",
            "Epoch: 46, learning_rate:[0.07870405585838675],costo: 0.18561773002147675, accuracy: 0.95263671875\n",
            "Epoch: 47, learning_rate:[0.05687420667745952],costo: 0.2100180834531784, accuracy: 0.95166015625\n",
            "Epoch: 48, learning_rate:[0.03330315523566155],costo: 0.1992814987897873, accuracy: 0.952392578125\n",
            "Epoch: 49, learning_rate:[0.04585225470354176],costo: 0.17549459636211395, accuracy: 0.95458984375\n",
            "Epoch: 50, learning_rate:[0.09737533984516211],costo: 0.17042671144008636, accuracy: 0.959716796875\n",
            "Epoch: 51, learning_rate:[0.09785612331032575],costo: 0.16622334718704224, accuracy: 0.952880859375\n",
            "Epoch: 52, learning_rate:[0.05953821886164748],costo: 0.17348356544971466, accuracy: 0.95556640625\n",
            "Epoch: 53, learning_rate:[0.050587149562278666],costo: 0.16733065247535706, accuracy: 0.959716796875\n",
            "Epoch: 54, learning_rate:[0.0321312614155505],costo: 0.15659655630588531, accuracy: 0.95849609375\n",
            "Epoch: 55, learning_rate:[0.042429814157995786],costo: 0.15014249086380005, accuracy: 0.9609375\n",
            "Epoch: 56, learning_rate:[0.0625208951480299],costo: 0.17214708030223846, accuracy: 0.96337890625\n",
            "Epoch: 57, learning_rate:[0.08298037897253202],costo: 0.1593511998653412, accuracy: 0.9609375\n",
            "Epoch: 58, learning_rate:[0.05791910227319176],costo: 0.15154984593391418, accuracy: 0.960693359375\n",
            "Epoch: 59, learning_rate:[0.02738280391129503],costo: 0.1499393880367279, accuracy: 0.9609375\n",
            "Epoch: 60, learning_rate:[0.011921064222131862],costo: 0.2130286693572998, accuracy: 0.958740234375\n",
            "Epoch: 61, learning_rate:[0.07786015181320834],costo: 0.17771607637405396, accuracy: 0.96337890625\n",
            "Epoch: 62, learning_rate:[0.0809968143455389],costo: 0.1616627722978592, accuracy: 0.96142578125\n",
            "Epoch: 63, learning_rate:[0.09102133522737751],costo: 0.15903079509735107, accuracy: 0.963134765625\n",
            "Epoch: 64, learning_rate:[0.06484654631784663],costo: 0.14952430129051208, accuracy: 0.964599609375\n",
            "Epoch: 65, learning_rate:[0.023559399749686398],costo: 0.14117924869060516, accuracy: 0.962646484375\n",
            "Epoch: 66, learning_rate:[0.01505685367536776],costo: 0.15603430569171906, accuracy: 0.963623046875\n",
            "Epoch: 67, learning_rate:[0.031195744650482905],costo: 0.14973407983779907, accuracy: 0.962158203125\n",
            "Epoch: 68, learning_rate:[0.04971387761611977],costo: 0.13117802143096924, accuracy: 0.9619140625\n",
            "Epoch: 69, learning_rate:[0.08825733648725476],costo: 0.16208279132843018, accuracy: 0.96533203125\n",
            "Epoch: 70, learning_rate:[0.06334635447368606],costo: 0.1858828365802765, accuracy: 0.965576171875\n",
            "Epoch: 71, learning_rate:[0.054949714253236887],costo: 0.16321566700935364, accuracy: 0.962890625\n",
            "Epoch: 72, learning_rate:[0.036304096454918444],costo: 0.14787590503692627, accuracy: 0.967529296875\n",
            "Epoch: 73, learning_rate:[0.039861038300578445],costo: 0.17749589681625366, accuracy: 0.963623046875\n",
            "Epoch: 74, learning_rate:[0.0819462377740264],costo: 0.14095954596996307, accuracy: 0.96533203125\n",
            "Epoch: 75, learning_rate:[0.08791056781668895],costo: 0.13466770946979523, accuracy: 0.9619140625\n",
            "Epoch: 76, learning_rate:[0.03310365478869293],costo: 0.1543608456850052, accuracy: 0.9658203125\n",
            "Epoch: 77, learning_rate:[0.029073201203421245],costo: 0.14927145838737488, accuracy: 0.961669921875\n",
            "Epoch: 78, learning_rate:[0.011502799911581936],costo: 0.12611962854862213, accuracy: 0.96875\n",
            "Epoch: 79, learning_rate:[0.035783772607998934],costo: 0.1473688930273056, accuracy: 0.96630859375\n",
            "Epoch: 80, learning_rate:[0.04771377735503763],costo: 0.14302849769592285, accuracy: 0.96484375\n",
            "Epoch: 81, learning_rate:[0.09681205538943574],costo: 0.12632334232330322, accuracy: 0.963623046875\n",
            "Epoch: 82, learning_rate:[0.08449396590091013],costo: 0.18188582360744476, accuracy: 0.964111328125\n",
            "Epoch: 83, learning_rate:[0.056047954269014634],costo: 0.09806349873542786, accuracy: 0.96630859375\n",
            "Epoch: 84, learning_rate:[0.02619819206569078],costo: 0.1361485719680786, accuracy: 0.963623046875\n",
            "Epoch: 85, learning_rate:[0.06224759812786376],costo: 0.10884376615285873, accuracy: 0.966796875\n",
            "Epoch: 86, learning_rate:[0.08080458225018694],costo: 0.11497446149587631, accuracy: 0.965087890625\n",
            "Epoch: 87, learning_rate:[0.08918310224867067],costo: 0.12431199848651886, accuracy: 0.966064453125\n",
            "Epoch: 88, learning_rate:[0.07628511695882496],costo: 0.11135360598564148, accuracy: 0.966796875\n",
            "Epoch: 89, learning_rate:[0.07403833305260797],costo: 0.11765726655721664, accuracy: 0.968505859375\n",
            "Epoch: 90, learning_rate:[0.020268185417831486],costo: 0.13146014511585236, accuracy: 0.968505859375\n",
            "Epoch: 91, learning_rate:[0.05618560718251872],costo: 0.15996667742729187, accuracy: 0.96533203125\n",
            "Epoch: 92, learning_rate:[0.07621644880722811],costo: 0.14729927480220795, accuracy: 0.96826171875\n",
            "Epoch: 93, learning_rate:[0.0798210154075057],costo: 0.13510414958000183, accuracy: 0.970703125\n",
            "Epoch: 94, learning_rate:[0.05023474820280176],costo: 0.13128413259983063, accuracy: 0.968017578125\n",
            "Epoch: 95, learning_rate:[0.015662549281668128],costo: 0.11871516704559326, accuracy: 0.96484375\n",
            "Epoch: 96, learning_rate:[0.015151532697413091],costo: 0.11061668395996094, accuracy: 0.970458984375\n",
            "Epoch: 97, learning_rate:[0.06477996059949499],costo: 0.1397300809621811, accuracy: 0.97119140625\n",
            "Epoch: 98, learning_rate:[0.06536862482853138],costo: 0.10491306334733963, accuracy: 0.968017578125\n",
            "Epoch: 99, learning_rate:[0.07275149029237259],costo: 0.11059264093637466, accuracy: 0.9716796875\n",
            "Epoch: 100, learning_rate:[0.017258566835840372],costo: 0.10591750591993332, accuracy: 0.971923828125\n",
            "Epoch: 1, learning_rate:[0.09194604656562042],costo: 1.6252802610397339, accuracy: 0.754150390625\n",
            "Epoch: 2, learning_rate:[0.09935604303152767],costo: 0.809093177318573, accuracy: 0.847412109375\n",
            "Epoch: 3, learning_rate:[0.09953863393146169],costo: 0.7101627588272095, accuracy: 0.796142578125\n",
            "Epoch: 4, learning_rate:[0.041757195301011754],costo: 0.5398222804069519, accuracy: 0.886962890625\n",
            "Epoch: 5, learning_rate:[0.03893934817020572],costo: 0.4450122117996216, accuracy: 0.900146484375\n",
            "Epoch: 6, learning_rate:[0.028040873442140846],costo: 0.4277965724468231, accuracy: 0.905029296875\n",
            "Epoch: 7, learning_rate:[0.05519972091158565],costo: 0.45445767045021057, accuracy: 0.90869140625\n",
            "Epoch: 8, learning_rate:[0.056689557693921054],costo: 0.40491801500320435, accuracy: 0.90869140625\n",
            "Epoch: 9, learning_rate:[0.06061495781174726],costo: 0.37107229232788086, accuracy: 0.908203125\n",
            "Epoch: 10, learning_rate:[0.02091492583639111],costo: 0.3844458758831024, accuracy: 0.91455078125\n",
            "Epoch: 11, learning_rate:[0.01769577759569628],costo: 0.32393112778663635, accuracy: 0.91162109375\n",
            "Epoch: 12, learning_rate:[0.017569676779718095],costo: 0.34532812237739563, accuracy: 0.9130859375\n",
            "Epoch: 13, learning_rate:[0.027404379899153973],costo: 0.3639068901538849, accuracy: 0.9150390625\n",
            "Epoch: 14, learning_rate:[0.08006908197111501],costo: 0.3764089047908783, accuracy: 0.915283203125\n",
            "Epoch: 15, learning_rate:[0.08340697820227498],costo: 0.37127289175987244, accuracy: 0.921142578125\n",
            "Epoch: 16, learning_rate:[0.023007055178911176],costo: 0.311614990234375, accuracy: 0.919189453125\n",
            "Epoch: 17, learning_rate:[0.01865658442334165],costo: 0.3205951154232025, accuracy: 0.92333984375\n",
            "Epoch: 18, learning_rate:[0.013381749998596251],costo: 0.34542784094810486, accuracy: 0.91845703125\n",
            "Epoch: 19, learning_rate:[0.021808737228859686],costo: 0.3214291036128998, accuracy: 0.924560546875\n",
            "Epoch: 20, learning_rate:[0.03899720337868178],costo: 0.30504295229911804, accuracy: 0.92236328125\n",
            "Epoch: 21, learning_rate:[0.08864171622031324],costo: 0.28755706548690796, accuracy: 0.92578125\n",
            "Epoch: 22, learning_rate:[0.03885870248298144],costo: 0.31092795729637146, accuracy: 0.926025390625\n",
            "Epoch: 23, learning_rate:[0.030913008246388353],costo: 0.3237481713294983, accuracy: 0.926025390625\n",
            "Epoch: 24, learning_rate:[0.01977679028731979],costo: 0.226028710603714, accuracy: 0.925537109375\n",
            "Epoch: 25, learning_rate:[0.08866534066310564],costo: 0.28003427386283875, accuracy: 0.9306640625\n",
            "Epoch: 26, learning_rate:[0.09785346970920607],costo: 0.30450597405433655, accuracy: 0.928955078125\n",
            "Epoch: 27, learning_rate:[0.09861437912424992],costo: 0.32578739523887634, accuracy: 0.9375\n",
            "Epoch: 28, learning_rate:[0.02773978427127341],costo: 0.2894596755504608, accuracy: 0.93798828125\n",
            "Epoch: 29, learning_rate:[0.014366555055485349],costo: 0.2657024562358856, accuracy: 0.936279296875\n",
            "Epoch: 30, learning_rate:[0.012308253644522269],costo: 0.27213072776794434, accuracy: 0.9375\n",
            "Epoch: 31, learning_rate:[0.04745875955913266],costo: 0.27930790185928345, accuracy: 0.935791015625\n",
            "Epoch: 32, learning_rate:[0.04923737706038098],costo: 0.23913982510566711, accuracy: 0.939453125\n",
            "Epoch: 33, learning_rate:[0.05620283461580044],costo: 0.2986734211444855, accuracy: 0.93603515625\n",
            "Epoch: 34, learning_rate:[0.020342262884054524],costo: 0.21660029888153076, accuracy: 0.934814453125\n",
            "Epoch: 35, learning_rate:[0.017721353595751044],costo: 0.2905973494052887, accuracy: 0.93212890625\n",
            "Epoch: 36, learning_rate:[0.012198576437535481],costo: 0.22795648872852325, accuracy: 0.933837890625\n",
            "Epoch: 37, learning_rate:[0.027231303044635974],costo: 0.20574502646923065, accuracy: 0.941650390625\n",
            "Epoch: 38, learning_rate:[0.05477098626052754],costo: 0.2622496783733368, accuracy: 0.94287109375\n",
            "Epoch: 39, learning_rate:[0.08731770431542388],costo: 0.26863566040992737, accuracy: 0.9423828125\n",
            "Epoch: 40, learning_rate:[0.028229459452610302],costo: 0.252763032913208, accuracy: 0.93994140625\n",
            "Epoch: 41, learning_rate:[0.024003069511165685],costo: 0.25024551153182983, accuracy: 0.93896484375\n",
            "Epoch: 42, learning_rate:[0.020896704084250345],costo: 0.2569864094257355, accuracy: 0.943603515625\n",
            "Epoch: 43, learning_rate:[0.022719472575510474],costo: 0.2290591299533844, accuracy: 0.94482421875\n",
            "Epoch: 44, learning_rate:[0.03854114428918433],costo: 0.21356730163097382, accuracy: 0.945556640625\n",
            "Epoch: 45, learning_rate:[0.08396522439107656],costo: 0.277668297290802, accuracy: 0.948486328125\n",
            "Epoch: 46, learning_rate:[0.05186853051736354],costo: 0.23096217215061188, accuracy: 0.93994140625\n",
            "Epoch: 47, learning_rate:[0.028630137662454924],costo: 0.24525292217731476, accuracy: 0.947265625\n",
            "Epoch: 48, learning_rate:[0.016263988395293475],costo: 0.19924309849739075, accuracy: 0.95166015625\n",
            "Epoch: 49, learning_rate:[0.04325798484584632],costo: 0.2090454399585724, accuracy: 0.947265625\n",
            "Epoch: 50, learning_rate:[0.05594160435404156],costo: 0.23066012561321259, accuracy: 0.944580078125\n",
            "Epoch: 51, learning_rate:[0.06902357524204054],costo: 0.22449995577335358, accuracy: 0.947998046875\n",
            "Epoch: 52, learning_rate:[0.03132395496719843],costo: 0.1813758760690689, accuracy: 0.950927734375\n",
            "Epoch: 53, learning_rate:[0.030382118070981283],costo: 0.19827350974082947, accuracy: 0.953369140625\n",
            "Epoch: 54, learning_rate:[0.010286900878812703],costo: 0.19395209848880768, accuracy: 0.950927734375\n",
            "Epoch: 55, learning_rate:[0.04857074115534064],costo: 0.2053847759962082, accuracy: 0.950927734375\n",
            "Epoch: 56, learning_rate:[0.05380560570792254],costo: 0.18063248693943024, accuracy: 0.955078125\n",
            "Epoch: 57, learning_rate:[0.09330206621621195],costo: 0.20172563195228577, accuracy: 0.953369140625\n",
            "Epoch: 58, learning_rate:[0.03284083705200714],costo: 0.2441650629043579, accuracy: 0.955322265625\n",
            "Epoch: 59, learning_rate:[0.0317803594766653],costo: 0.21028941869735718, accuracy: 0.9560546875\n",
            "Epoch: 60, learning_rate:[0.02011015162964368],costo: 0.20581242442131042, accuracy: 0.95361328125\n",
            "Epoch: 61, learning_rate:[0.02791931327202336],costo: 0.20084883272647858, accuracy: 0.95703125\n",
            "Epoch: 62, learning_rate:[0.029575811259770782],costo: 0.17624513804912567, accuracy: 0.958251953125\n",
            "Epoch: 63, learning_rate:[0.09259848774479905],costo: 0.20721203088760376, accuracy: 0.955322265625\n",
            "Epoch: 64, learning_rate:[0.023651262077556065],costo: 0.1914825737476349, accuracy: 0.956787109375\n",
            "Epoch: 65, learning_rate:[0.013981420005042725],costo: 0.22956334054470062, accuracy: 0.958251953125\n",
            "Epoch: 66, learning_rate:[0.013121126771062688],costo: 0.21794894337654114, accuracy: 0.95654296875\n",
            "Epoch: 67, learning_rate:[0.0942674383434021],costo: 0.1927979290485382, accuracy: 0.96142578125\n",
            "Epoch: 68, learning_rate:[0.09530751406941046],costo: 0.164532870054245, accuracy: 0.958251953125\n",
            "Epoch: 69, learning_rate:[0.09929956126526975],costo: 0.17245519161224365, accuracy: 0.95361328125\n",
            "Epoch: 70, learning_rate:[0.0349696738281926],costo: 0.19195818901062012, accuracy: 0.960205078125\n",
            "Epoch: 71, learning_rate:[0.02911060363157815],costo: 0.16668067872524261, accuracy: 0.962646484375\n",
            "Epoch: 72, learning_rate:[0.02318727705279591],costo: 0.17662766575813293, accuracy: 0.95849609375\n",
            "Epoch: 73, learning_rate:[0.06333130794137594],costo: 0.18456795811653137, accuracy: 0.9599609375\n",
            "Epoch: 74, learning_rate:[0.06731684685833648],costo: 0.1216253787279129, accuracy: 0.9609375\n",
            "Epoch: 75, learning_rate:[0.08673801361811069],costo: 0.1587948501110077, accuracy: 0.9599609375\n",
            "Epoch: 76, learning_rate:[0.0813214230726095],costo: 0.14496733248233795, accuracy: 0.958984375\n",
            "Epoch: 77, learning_rate:[0.03753865311219585],costo: 0.14910270273685455, accuracy: 0.962158203125\n",
            "Epoch: 78, learning_rate:[0.020388226495792035],costo: 0.1620902270078659, accuracy: 0.958984375\n",
            "Epoch: 79, learning_rate:[0.08266749989507469],costo: 0.16586193442344666, accuracy: 0.96240234375\n",
            "Epoch: 80, learning_rate:[0.09083177515907033],costo: 0.1339934766292572, accuracy: 0.961181640625\n",
            "Epoch: 81, learning_rate:[0.0921118006983279],costo: 0.15283791720867157, accuracy: 0.9638671875\n",
            "Epoch: 82, learning_rate:[0.061512166949769236],costo: 0.17873458564281464, accuracy: 0.963134765625\n",
            "Epoch: 83, learning_rate:[0.05447057055134702],costo: 0.1598861962556839, accuracy: 0.962158203125\n",
            "Epoch: 84, learning_rate:[0.012306037781572491],costo: 0.1864536702632904, accuracy: 0.963623046875\n",
            "Epoch: 85, learning_rate:[0.06738710158794022],costo: 0.169320747256279, accuracy: 0.962158203125\n",
            "Epoch: 86, learning_rate:[0.08833763046822163],costo: 0.13894647359848022, accuracy: 0.960205078125\n",
            "Epoch: 87, learning_rate:[0.09300828450364343],costo: 0.1361113041639328, accuracy: 0.96630859375\n",
            "Epoch: 88, learning_rate:[0.010460455941863074],costo: 0.15368472039699554, accuracy: 0.967529296875\n",
            "Epoch: 89, learning_rate:[0.010421121427864869],costo: 0.18430779874324799, accuracy: 0.9599609375\n",
            "Epoch: 90, learning_rate:[0.010148588551413696],costo: 0.18761052191257477, accuracy: 0.96875\n",
            "Epoch: 91, learning_rate:[0.05699339950093128],costo: 0.15355294942855835, accuracy: 0.965576171875\n",
            "Epoch: 92, learning_rate:[0.08176370844917304],costo: 0.1405932605266571, accuracy: 0.9619140625\n",
            "Epoch: 93, learning_rate:[0.09596753143958463],costo: 0.11031465977430344, accuracy: 0.96484375\n",
            "Epoch: 94, learning_rate:[0.012225630779287311],costo: 0.14795292913913727, accuracy: 0.96923828125\n",
            "Epoch: 95, learning_rate:[0.01164982556777622],costo: 0.14083443582057953, accuracy: 0.963623046875\n",
            "Epoch: 96, learning_rate:[0.011312868875681708],costo: 0.1500803679227829, accuracy: 0.968505859375\n",
            "Epoch: 97, learning_rate:[0.027130141709949044],costo: 0.13482677936553955, accuracy: 0.96630859375\n",
            "Epoch: 98, learning_rate:[0.09194371141218907],costo: 0.15164825320243835, accuracy: 0.968017578125\n",
            "Epoch: 99, learning_rate:[0.09474077854274973],costo: 0.13995473086833954, accuracy: 0.9677734375\n",
            "Epoch: 100, learning_rate:[0.07168470703068605],costo: 0.1573849767446518, accuracy: 0.965576171875\n",
            "Epoch: 1, learning_rate:[0.0455721501101064],costo: 2.1635241508483887, accuracy: 0.59423828125\n",
            "Epoch: 2, learning_rate:[0.05540287125163328],costo: 1.7731080055236816, accuracy: 0.7744140625\n",
            "Epoch: 3, learning_rate:[0.08754118497839258],costo: 1.1519485712051392, accuracy: 0.81787109375\n",
            "Epoch: 4, learning_rate:[0.037014134938704375],costo: 0.6912000179290771, accuracy: 0.860595703125\n",
            "Epoch: 5, learning_rate:[0.017462804792643],costo: 0.5931336283683777, accuracy: 0.8779296875\n",
            "Epoch: 6, learning_rate:[0.014487364433665717],costo: 0.5387255549430847, accuracy: 0.884033203125\n",
            "Epoch: 7, learning_rate:[0.048937456265980166],costo: 0.6128953099250793, accuracy: 0.891845703125\n",
            "Epoch: 8, learning_rate:[0.09437004801742696],costo: 0.5296006798744202, accuracy: 0.89892578125\n",
            "Epoch: 9, learning_rate:[0.09856516560045647],costo: 0.49100595712661743, accuracy: 0.883056640625\n",
            "Epoch: 10, learning_rate:[0.053212447247599916],costo: 0.4117265045642853, accuracy: 0.90283203125\n",
            "Epoch: 11, learning_rate:[0.03546910289826608],costo: 0.4143625795841217, accuracy: 0.90673828125\n",
            "Epoch: 12, learning_rate:[0.03162324634593589],costo: 0.377574622631073, accuracy: 0.910888671875\n",
            "Epoch: 13, learning_rate:[0.08236709202630121],costo: 0.37529048323631287, accuracy: 0.91357421875\n",
            "Epoch: 14, learning_rate:[0.09766309942842132],costo: 0.30048710107803345, accuracy: 0.917724609375\n",
            "Epoch: 15, learning_rate:[0.09855320697281378],costo: 0.34813520312309265, accuracy: 0.922607421875\n",
            "Epoch: 16, learning_rate:[0.050654244389443076],costo: 0.32071420550346375, accuracy: 0.91650390625\n",
            "Epoch: 17, learning_rate:[0.0476913670534599],costo: 0.2896754741668701, accuracy: 0.923095703125\n",
            "Epoch: 18, learning_rate:[0.03849628463929183],costo: 0.2821459174156189, accuracy: 0.927978515625\n",
            "Epoch: 19, learning_rate:[0.04611076372235839],costo: 0.2658080756664276, accuracy: 0.92431640625\n",
            "Epoch: 20, learning_rate:[0.06518394201985679],costo: 0.31102243065834045, accuracy: 0.92529296875\n",
            "Epoch: 21, learning_rate:[0.0903970364691475],costo: 0.2981868088245392, accuracy: 0.928466796875\n",
            "Epoch: 22, learning_rate:[0.027339812493124865],costo: 0.310589998960495, accuracy: 0.9287109375\n",
            "Epoch: 23, learning_rate:[0.01630524711281636],costo: 0.27512165904045105, accuracy: 0.935791015625\n",
            "Epoch: 24, learning_rate:[0.010985444602219441],costo: 0.2657260298728943, accuracy: 0.929443359375\n",
            "Epoch: 25, learning_rate:[0.08205092621545997],costo: 0.27423080801963806, accuracy: 0.9365234375\n",
            "Epoch: 26, learning_rate:[0.08901202678130653],costo: 0.27765798568725586, accuracy: 0.93603515625\n",
            "Epoch: 27, learning_rate:[0.09164883719294036],costo: 0.29554301500320435, accuracy: 0.934814453125\n",
            "Epoch: 28, learning_rate:[0.0850076274360388],costo: 0.2558101713657379, accuracy: 0.9326171875\n",
            "Epoch: 29, learning_rate:[0.022772551110319266],costo: 0.29289329051971436, accuracy: 0.93798828125\n",
            "Epoch: 30, learning_rate:[0.012164688056368538],costo: 0.243025541305542, accuracy: 0.941650390625\n",
            "Epoch: 31, learning_rate:[0.042908453182224575],costo: 0.28198185563087463, accuracy: 0.937255859375\n",
            "Epoch: 32, learning_rate:[0.06973559315019426],costo: 0.21302330493927002, accuracy: 0.940673828125\n",
            "Epoch: 33, learning_rate:[0.09643124971473968],costo: 0.28102755546569824, accuracy: 0.939697265625\n",
            "Epoch: 34, learning_rate:[0.061084823001362566],costo: 0.29190486669540405, accuracy: 0.9462890625\n",
            "Epoch: 35, learning_rate:[0.0242490546448033],costo: 0.189469575881958, accuracy: 0.942138671875\n",
            "Epoch: 36, learning_rate:[0.01710959315422443],costo: 0.23739303648471832, accuracy: 0.939697265625\n",
            "Epoch: 37, learning_rate:[0.07459305189086665],costo: 0.2806023955345154, accuracy: 0.943115234375\n",
            "Epoch: 38, learning_rate:[0.07889933621606589],costo: 0.2203277200460434, accuracy: 0.947265625\n",
            "Epoch: 39, learning_rate:[0.09259648876024343],costo: 0.19946326315402985, accuracy: 0.948974609375\n",
            "Epoch: 40, learning_rate:[0.011602344042267421],costo: 0.19681069254875183, accuracy: 0.94189453125\n",
            "Epoch: 41, learning_rate:[0.010741187055408937],costo: 0.23174932599067688, accuracy: 0.94677734375\n",
            "Epoch: 42, learning_rate:[0.010025412804232445],costo: 0.23808403313159943, accuracy: 0.948486328125\n",
            "Epoch: 43, learning_rate:[0.025055062811824368],costo: 0.22730420529842377, accuracy: 0.95068359375\n",
            "Epoch: 44, learning_rate:[0.047612582992323495],costo: 0.2843780815601349, accuracy: 0.94580078125\n",
            "Epoch: 45, learning_rate:[0.05725201220546926],costo: 0.2041245698928833, accuracy: 0.952392578125\n",
            "Epoch: 46, learning_rate:[0.010378220745125405],costo: 0.20761877298355103, accuracy: 0.951171875\n",
            "Epoch: 47, learning_rate:[0.010027186481592907],costo: 0.19891789555549622, accuracy: 0.95263671875\n",
            "Epoch: 48, learning_rate:[0.010024105177837184],costo: 0.20523419976234436, accuracy: 0.952880859375\n",
            "Epoch: 49, learning_rate:[0.04664700933160455],costo: 0.20107954740524292, accuracy: 0.953857421875\n",
            "Epoch: 50, learning_rate:[0.05774368616085515],costo: 0.2047823816537857, accuracy: 0.95361328125\n",
            "Epoch: 51, learning_rate:[0.0948502604011785],costo: 0.20857898890972137, accuracy: 0.950439453125\n",
            "Epoch: 52, learning_rate:[0.05942234964232959],costo: 0.16935928165912628, accuracy: 0.952880859375\n",
            "Epoch: 53, learning_rate:[0.04958616681530957],costo: 0.1924208402633667, accuracy: 0.9521484375\n",
            "Epoch: 54, learning_rate:[0.04145107755210292],costo: 0.2006186544895172, accuracy: 0.95849609375\n",
            "Epoch: 55, learning_rate:[0.06852794344271614],costo: 0.2067776918411255, accuracy: 0.952880859375\n",
            "Epoch: 56, learning_rate:[0.084196400725953],costo: 0.20049728453159332, accuracy: 0.958984375\n",
            "Epoch: 57, learning_rate:[0.08502646316342478],costo: 0.18154673278331757, accuracy: 0.9580078125\n",
            "Epoch: 58, learning_rate:[0.07317096034385644],costo: 0.2125868946313858, accuracy: 0.95263671875\n",
            "Epoch: 59, learning_rate:[0.011504449608617101],costo: 0.1768970638513565, accuracy: 0.957275390625\n",
            "Epoch: 60, learning_rate:[0.011064164329352635],costo: 0.1863182783126831, accuracy: 0.959228515625\n",
            "Epoch: 61, learning_rate:[0.08969896061722203],costo: 0.22073695063591003, accuracy: 0.96044921875\n",
            "Epoch: 62, learning_rate:[0.09161364140259409],costo: 0.1816563904285431, accuracy: 0.956787109375\n",
            "Epoch: 63, learning_rate:[0.0975384913436116],costo: 0.14854872226715088, accuracy: 0.955810546875\n",
            "Epoch: 64, learning_rate:[0.04526479992418896],costo: 0.23305459320545197, accuracy: 0.958740234375\n",
            "Epoch: 65, learning_rate:[0.03572275054854394],costo: 0.1751447468996048, accuracy: 0.959716796875\n",
            "Epoch: 66, learning_rate:[0.01994546267343439],costo: 0.1876560002565384, accuracy: 0.9599609375\n",
            "Epoch: 67, learning_rate:[0.061237360028687494],costo: 0.16703937947750092, accuracy: 0.9599609375\n",
            "Epoch: 68, learning_rate:[0.09548099642539917],costo: 0.17644824087619781, accuracy: 0.962158203125\n",
            "Epoch: 69, learning_rate:[0.09737292920867874],costo: 0.1723598688840866, accuracy: 0.9619140625\n",
            "Epoch: 70, learning_rate:[0.04926251095572448],costo: 0.14876724779605865, accuracy: 0.961669921875\n",
            "Epoch: 71, learning_rate:[0.034981894389410156],costo: 0.1574406772851944, accuracy: 0.962890625\n",
            "Epoch: 72, learning_rate:[0.02760288025164396],costo: 0.1439821869134903, accuracy: 0.9619140625\n",
            "Epoch: 73, learning_rate:[0.06828793126846895],costo: 0.14901305735111237, accuracy: 0.962158203125\n",
            "Epoch: 74, learning_rate:[0.08800352346601562],costo: 0.14703220129013062, accuracy: 0.956298828125\n",
            "Epoch: 75, learning_rate:[0.08801621244216712],costo: 0.1484805792570114, accuracy: 0.963623046875\n",
            "Epoch: 76, learning_rate:[0.07727360569446491],costo: 0.14982740581035614, accuracy: 0.965576171875\n",
            "Epoch: 77, learning_rate:[0.05591176760348914],costo: 0.13107232749462128, accuracy: 0.96484375\n",
            "Epoch: 78, learning_rate:[0.049869522092117945],costo: 0.1521524339914322, accuracy: 0.962890625\n",
            "Epoch: 79, learning_rate:[0.0760892809578458],costo: 0.12774799764156342, accuracy: 0.96533203125\n",
            "Epoch: 80, learning_rate:[0.09612714144869403],costo: 0.10676149278879166, accuracy: 0.962646484375\n",
            "Epoch: 81, learning_rate:[0.09662446748000274],costo: 0.1559232920408249, accuracy: 0.962646484375\n",
            "Epoch: 82, learning_rate:[0.09449317349452366],costo: 0.17459207773208618, accuracy: 0.967529296875\n",
            "Epoch: 83, learning_rate:[0.06915812990324342],costo: 0.1379491090774536, accuracy: 0.968505859375\n",
            "Epoch: 84, learning_rate:[0.029021982991870074],costo: 0.12391410768032074, accuracy: 0.966064453125\n",
            "Epoch: 85, learning_rate:[0.029872331699720877],costo: 0.1272311806678772, accuracy: 0.968017578125\n",
            "Epoch: 86, learning_rate:[0.05401376244600194],costo: 0.12434955686330795, accuracy: 0.967041015625\n",
            "Epoch: 87, learning_rate:[0.09705172068216894],costo: 0.11054983735084534, accuracy: 0.96435546875\n",
            "Epoch: 88, learning_rate:[0.09034347933603493],costo: 0.16451968252658844, accuracy: 0.963623046875\n",
            "Epoch: 89, learning_rate:[0.018990813638697118],costo: 0.15433405339717865, accuracy: 0.96728515625\n",
            "Epoch: 90, learning_rate:[0.018401025815410758],costo: 0.10898729413747787, accuracy: 0.966796875\n",
            "Epoch: 91, learning_rate:[0.05803600943736602],costo: 0.1115061566233635, accuracy: 0.970458984375\n",
            "Epoch: 92, learning_rate:[0.0907144785422695],costo: 0.1037590280175209, accuracy: 0.966796875\n",
            "Epoch: 93, learning_rate:[0.09248047400850076],costo: 0.12670302391052246, accuracy: 0.969970703125\n",
            "Epoch: 94, learning_rate:[0.09172757388108549],costo: 0.1369076520204544, accuracy: 0.96923828125\n",
            "Epoch: 95, learning_rate:[0.021680639831227946],costo: 0.10668918490409851, accuracy: 0.963623046875\n",
            "Epoch: 96, learning_rate:[0.018178196717781345],costo: 0.12697690725326538, accuracy: 0.96630859375\n",
            "Epoch: 97, learning_rate:[0.07608124273915697],costo: 0.1340806484222412, accuracy: 0.97314453125\n",
            "Epoch: 98, learning_rate:[0.09283626076972373],costo: 0.14529700577259064, accuracy: 0.9697265625\n",
            "Epoch: 99, learning_rate:[0.09616800389873376],costo: 0.11731311678886414, accuracy: 0.969482421875\n",
            "Epoch: 100, learning_rate:[0.021416943324697922],costo: 0.12611639499664307, accuracy: 0.96533203125\n",
            "Epoch: 1, learning_rate:[0.09498840320971536],costo: 1.6319468021392822, accuracy: 0.776123046875\n",
            "Epoch: 2, learning_rate:[0.0998105631088634],costo: 0.793848991394043, accuracy: 0.854248046875\n",
            "Epoch: 3, learning_rate:[0.09992859161142492],costo: 0.6091873645782471, accuracy: 0.835205078125\n",
            "Epoch: 4, learning_rate:[0.022839119492423003],costo: 0.4400073289871216, accuracy: 0.899169921875\n",
            "Epoch: 5, learning_rate:[0.02253639809971611],costo: 0.45070046186447144, accuracy: 0.900390625\n",
            "Epoch: 6, learning_rate:[0.014455312524168769],costo: 0.43733736872673035, accuracy: 0.90576171875\n",
            "Epoch: 7, learning_rate:[0.06881306862132397],costo: 0.4551987051963806, accuracy: 0.90625\n",
            "Epoch: 8, learning_rate:[0.086176087560517],costo: 0.4243689775466919, accuracy: 0.90234375\n",
            "Epoch: 9, learning_rate:[0.09066623896171011],costo: 0.38494768738746643, accuracy: 0.91455078125\n",
            "Epoch: 10, learning_rate:[0.013752859006455617],costo: 0.37077873945236206, accuracy: 0.900146484375\n",
            "Epoch: 11, learning_rate:[0.01052278789442608],costo: 0.3524414300918579, accuracy: 0.911376953125\n",
            "Epoch: 12, learning_rate:[0.010171799355734493],costo: 0.37858495116233826, accuracy: 0.915283203125\n",
            "Epoch: 13, learning_rate:[0.01648025357067019],costo: 0.4074188768863678, accuracy: 0.91357421875\n",
            "Epoch: 14, learning_rate:[0.0733047689869223],costo: 0.35028165578842163, accuracy: 0.912109375\n",
            "Epoch: 15, learning_rate:[0.08488092190016314],costo: 0.33594775199890137, accuracy: 0.911376953125\n",
            "Epoch: 16, learning_rate:[0.07874032052675718],costo: 0.3455769419670105, accuracy: 0.924560546875\n",
            "Epoch: 17, learning_rate:[0.02388857686230271],costo: 0.3298809230327606, accuracy: 0.92431640625\n",
            "Epoch: 18, learning_rate:[0.02050159795565866],costo: 0.3212919533252716, accuracy: 0.921630859375\n",
            "Epoch: 19, learning_rate:[0.052524200817286336],costo: 0.3264089524745941, accuracy: 0.92236328125\n",
            "Epoch: 20, learning_rate:[0.07757067599490097],costo: 0.30329543352127075, accuracy: 0.92822265625\n",
            "Epoch: 21, learning_rate:[0.09615251647076753],costo: 0.2932421863079071, accuracy: 0.926025390625\n",
            "Epoch: 22, learning_rate:[0.08615961362370148],costo: 0.3163633644580841, accuracy: 0.926025390625\n",
            "Epoch: 23, learning_rate:[0.030806012086483085],costo: 0.3061155676841736, accuracy: 0.931884765625\n",
            "Epoch: 24, learning_rate:[0.019840232458497337],costo: 0.27205953001976013, accuracy: 0.930908203125\n",
            "Epoch: 25, learning_rate:[0.061678810483742366],costo: 0.2563019394874573, accuracy: 0.929931640625\n",
            "Epoch: 26, learning_rate:[0.08046576790468692],costo: 0.28854429721832275, accuracy: 0.934814453125\n",
            "Epoch: 27, learning_rate:[0.09535100122532307],costo: 0.2623727321624756, accuracy: 0.93701171875\n",
            "Epoch: 28, learning_rate:[0.08459293405869858],costo: 0.24134021997451782, accuracy: 0.937744140625\n",
            "Epoch: 29, learning_rate:[0.010741088851302141],costo: 0.23836059868335724, accuracy: 0.938720703125\n",
            "Epoch: 30, learning_rate:[0.010583880915979536],costo: 0.21558240056037903, accuracy: 0.93701171875\n",
            "Epoch: 31, learning_rate:[0.025625184266826806],costo: 0.2286483496427536, accuracy: 0.937255859375\n",
            "Epoch: 32, learning_rate:[0.08716364709335345],costo: 0.2775852084159851, accuracy: 0.9443359375\n",
            "Epoch: 33, learning_rate:[0.09505233753344251],costo: 0.21182972192764282, accuracy: 0.93701171875\n",
            "Epoch: 34, learning_rate:[0.08502784610995588],costo: 0.2670835256576538, accuracy: 0.9443359375\n",
            "Epoch: 35, learning_rate:[0.025580221751810406],costo: 0.23640087246894836, accuracy: 0.94189453125\n",
            "Epoch: 36, learning_rate:[0.02408334550960133],costo: 0.26047807931900024, accuracy: 0.94287109375\n",
            "Epoch: 37, learning_rate:[0.040402489717909176],costo: 0.261760413646698, accuracy: 0.9443359375\n",
            "Epoch: 38, learning_rate:[0.048655145634492206],costo: 0.22090891003608704, accuracy: 0.94287109375\n",
            "Epoch: 39, learning_rate:[0.0501357682930427],costo: 0.2634544372558594, accuracy: 0.942626953125\n",
            "Epoch: 40, learning_rate:[0.021620206687253764],costo: 0.18428732454776764, accuracy: 0.94921875\n",
            "Epoch: 41, learning_rate:[0.01889274989011694],costo: 0.22249272465705872, accuracy: 0.95361328125\n",
            "Epoch: 42, learning_rate:[0.010777651798441236],costo: 0.21246032416820526, accuracy: 0.947265625\n",
            "Epoch: 43, learning_rate:[0.07303263746703251],costo: 0.20902498066425323, accuracy: 0.94775390625\n",
            "Epoch: 44, learning_rate:[0.08268805413067791],costo: 0.19178557395935059, accuracy: 0.943603515625\n",
            "Epoch: 45, learning_rate:[0.09647280011316399],costo: 0.22680316865444183, accuracy: 0.95263671875\n",
            "Epoch: 46, learning_rate:[0.062044957338656205],costo: 0.18590165674686432, accuracy: 0.94873046875\n",
            "Epoch: 47, learning_rate:[0.014358347537665465],costo: 0.20579500496387482, accuracy: 0.95361328125\n",
            "Epoch: 48, learning_rate:[0.012979561821240625],costo: 0.1958736777305603, accuracy: 0.951416015625\n",
            "Epoch: 49, learning_rate:[0.08247855654534192],costo: 0.19154822826385498, accuracy: 0.953857421875\n",
            "Epoch: 50, learning_rate:[0.09774350631311887],costo: 0.2067192792892456, accuracy: 0.95751953125\n",
            "Epoch: 51, learning_rate:[0.09801233985730626],costo: 0.1761472523212433, accuracy: 0.95263671875\n",
            "Epoch: 52, learning_rate:[0.040726656217000896],costo: 0.17467349767684937, accuracy: 0.955810546875\n",
            "Epoch: 53, learning_rate:[0.015225631226439856],costo: 0.19960369169712067, accuracy: 0.95703125\n",
            "Epoch: 54, learning_rate:[0.012727627004143607],costo: 0.17403544485569, accuracy: 0.95458984375\n",
            "Epoch: 55, learning_rate:[0.06712002262322977],costo: 0.1539900302886963, accuracy: 0.956298828125\n",
            "Epoch: 56, learning_rate:[0.08306327652572608],costo: 0.1887243688106537, accuracy: 0.950927734375\n",
            "Epoch: 57, learning_rate:[0.08825538019322932],costo: 0.18228711187839508, accuracy: 0.95849609375\n",
            "Epoch: 58, learning_rate:[0.04573202161191123],costo: 0.18268179893493652, accuracy: 0.955078125\n",
            "Epoch: 59, learning_rate:[0.0355510553774697],costo: 0.20382675528526306, accuracy: 0.958984375\n",
            "Epoch: 60, learning_rate:[0.013491945641572252],costo: 0.17408134043216705, accuracy: 0.9541015625\n",
            "Epoch: 61, learning_rate:[0.015505726896973266],costo: 0.17182427644729614, accuracy: 0.956787109375\n",
            "Epoch: 62, learning_rate:[0.018657397535898592],costo: 0.18006263673305511, accuracy: 0.958740234375\n",
            "Epoch: 63, learning_rate:[0.09727794825408081],costo: 0.19175340235233307, accuracy: 0.962158203125\n",
            "Epoch: 64, learning_rate:[0.09304570218819058],costo: 0.15373697876930237, accuracy: 0.9560546875\n",
            "Epoch: 65, learning_rate:[0.01821852802982552],costo: 0.17673048377037048, accuracy: 0.953369140625\n",
            "Epoch: 66, learning_rate:[0.010090715022855794],costo: 0.1737631857395172, accuracy: 0.95849609375\n",
            "Epoch: 67, learning_rate:[0.06404873019263921],costo: 0.16797924041748047, accuracy: 0.95654296875\n",
            "Epoch: 68, learning_rate:[0.0759176895862132],costo: 0.14908385276794434, accuracy: 0.953369140625\n",
            "Epoch: 69, learning_rate:[0.09744220603543649],costo: 0.18167658150196075, accuracy: 0.959228515625\n",
            "Epoch: 70, learning_rate:[0.07699598047525685],costo: 0.15841853618621826, accuracy: 0.960693359375\n",
            "Epoch: 71, learning_rate:[0.0455233827968402],costo: 0.1308189034461975, accuracy: 0.958251953125\n",
            "Epoch: 72, learning_rate:[0.01914833900006888],costo: 0.15228135883808136, accuracy: 0.960205078125\n",
            "Epoch: 73, learning_rate:[0.07990409490350787],costo: 0.17488634586334229, accuracy: 0.95751953125\n",
            "Epoch: 74, learning_rate:[0.09749848307277448],costo: 0.16462136805057526, accuracy: 0.961669921875\n",
            "Epoch: 75, learning_rate:[0.09850502491418542],costo: 0.15345732867717743, accuracy: 0.963623046875\n",
            "Epoch: 76, learning_rate:[0.07772844737106337],costo: 0.13913482427597046, accuracy: 0.963623046875\n",
            "Epoch: 77, learning_rate:[0.06034468512217946],costo: 0.13590563833713531, accuracy: 0.962158203125\n",
            "Epoch: 78, learning_rate:[0.02268371749379398],costo: 0.15407751500606537, accuracy: 0.963623046875\n",
            "Epoch: 79, learning_rate:[0.05551727734466087],costo: 0.13911579549312592, accuracy: 0.96044921875\n",
            "Epoch: 80, learning_rate:[0.05748757321457273],costo: 0.1563764065504074, accuracy: 0.962890625\n",
            "Epoch: 81, learning_rate:[0.08156957049389728],costo: 0.13055144250392914, accuracy: 0.965576171875\n",
            "Epoch: 82, learning_rate:[0.03815794372285926],costo: 0.15039606392383575, accuracy: 0.967041015625\n",
            "Epoch: 83, learning_rate:[0.03599851690392161],costo: 0.141058087348938, accuracy: 0.964599609375\n",
            "Epoch: 84, learning_rate:[0.010537799080176633],costo: 0.14912119507789612, accuracy: 0.9599609375\n",
            "Epoch: 85, learning_rate:[0.04626802208444493],costo: 0.16710463166236877, accuracy: 0.96337890625\n",
            "Epoch: 86, learning_rate:[0.09215390975417764],costo: 0.14950869977474213, accuracy: 0.9638671875\n",
            "Epoch: 87, learning_rate:[0.0983551324479338],costo: 0.13676276803016663, accuracy: 0.962646484375\n",
            "Epoch: 88, learning_rate:[0.04633130471872359],costo: 0.1315452605485916, accuracy: 0.963623046875\n",
            "Epoch: 89, learning_rate:[0.03671335919558971],costo: 0.11024115234613419, accuracy: 0.967041015625\n",
            "Epoch: 90, learning_rate:[0.02202877776968256],costo: 0.13652923703193665, accuracy: 0.964599609375\n",
            "Epoch: 91, learning_rate:[0.0862713926281764],costo: 0.1563635766506195, accuracy: 0.967529296875\n",
            "Epoch: 92, learning_rate:[0.09531351338719012],costo: 0.1432967334985733, accuracy: 0.96484375\n",
            "Epoch: 93, learning_rate:[0.09684132713051037],costo: 0.13722862303256989, accuracy: 0.9619140625\n",
            "Epoch: 94, learning_rate:[0.059588270373663904],costo: 0.1554187387228012, accuracy: 0.9638671875\n",
            "Epoch: 95, learning_rate:[0.058550675608323215],costo: 0.11726842820644379, accuracy: 0.96435546875\n",
            "Epoch: 96, learning_rate:[0.04625898960502213],costo: 0.1350870430469513, accuracy: 0.964599609375\n",
            "Epoch: 97, learning_rate:[0.08525281454784858],costo: 0.16355225443840027, accuracy: 0.968505859375\n",
            "Epoch: 98, learning_rate:[0.08757501882215302],costo: 0.1092442199587822, accuracy: 0.965576171875\n",
            "Epoch: 99, learning_rate:[0.08960175394846244],costo: 0.13192833960056305, accuracy: 0.970703125\n",
            "Epoch: 100, learning_rate:[0.06095257991123904],costo: 0.12584134936332703, accuracy: 0.967041015625\n",
            "Epoch: 1, learning_rate:[0.09771731409555014],costo: 1.551952600479126, accuracy: 0.781005859375\n",
            "Epoch: 2, learning_rate:[0.09833625681817493],costo: 0.7630211710929871, accuracy: 0.863037109375\n",
            "Epoch: 3, learning_rate:[0.09907964451574847],costo: 0.6833978891372681, accuracy: 0.795654296875\n",
            "Epoch: 4, learning_rate:[0.06574298840584411],costo: 0.5045496225357056, accuracy: 0.88818359375\n",
            "Epoch: 5, learning_rate:[0.03692906632117135],costo: 0.5061100125312805, accuracy: 0.899169921875\n",
            "Epoch: 6, learning_rate:[0.015937210836135182],costo: 0.3965149521827698, accuracy: 0.902587890625\n",
            "Epoch: 7, learning_rate:[0.055328544387153726],costo: 0.3975267708301544, accuracy: 0.898681640625\n",
            "Epoch: 8, learning_rate:[0.06115728014540844],costo: 0.43144887685775757, accuracy: 0.908203125\n",
            "Epoch: 9, learning_rate:[0.08435540600219812],costo: 0.38018742203712463, accuracy: 0.90771484375\n",
            "Epoch: 10, learning_rate:[0.051082286474299854],costo: 0.3653438091278076, accuracy: 0.910400390625\n",
            "Epoch: 11, learning_rate:[0.02718904770055504],costo: 0.37024858593940735, accuracy: 0.9228515625\n",
            "Epoch: 12, learning_rate:[0.010416914751949951],costo: 0.3486545979976654, accuracy: 0.92236328125\n",
            "Epoch: 13, learning_rate:[0.0814973735520835],costo: 0.3419329822063446, accuracy: 0.912353515625\n",
            "Epoch: 14, learning_rate:[0.09267941004442347],costo: 0.3241282105445862, accuracy: 0.91943359375\n",
            "Epoch: 15, learning_rate:[0.09621744907439413],costo: 0.32259610295295715, accuracy: 0.9228515625\n",
            "Epoch: 16, learning_rate:[0.013082466841134583],costo: 0.29310229420661926, accuracy: 0.921875\n",
            "Epoch: 17, learning_rate:[0.012947615281367062],costo: 0.3205568194389343, accuracy: 0.9248046875\n",
            "Epoch: 18, learning_rate:[0.01255317537645491],costo: 0.31543707847595215, accuracy: 0.923095703125\n",
            "Epoch: 19, learning_rate:[0.06167860552881439],costo: 0.29612618684768677, accuracy: 0.932861328125\n",
            "Epoch: 20, learning_rate:[0.07291221166529648],costo: 0.26700153946876526, accuracy: 0.92822265625\n",
            "Epoch: 21, learning_rate:[0.09902927941929644],costo: 0.2851105332374573, accuracy: 0.92919921875\n",
            "Epoch: 22, learning_rate:[0.07528126783180493],costo: 0.29136720299720764, accuracy: 0.92724609375\n",
            "Epoch: 23, learning_rate:[0.06728828689822876],costo: 0.29242125153541565, accuracy: 0.93017578125\n",
            "Epoch: 24, learning_rate:[0.03726782707228201],costo: 0.2766546308994293, accuracy: 0.93505859375\n",
            "Epoch: 25, learning_rate:[0.04931077887999006],costo: 0.21132691204547882, accuracy: 0.930419921875\n",
            "Epoch: 26, learning_rate:[0.09242296641056824],costo: 0.2209068089723587, accuracy: 0.9375\n",
            "Epoch: 27, learning_rate:[0.093831969315071],costo: 0.2661714553833008, accuracy: 0.939208984375\n",
            "Epoch: 28, learning_rate:[0.04809826716304526],costo: 0.21940334141254425, accuracy: 0.9404296875\n",
            "Epoch: 29, learning_rate:[0.04355934122613336],costo: 0.20128673315048218, accuracy: 0.942138671875\n",
            "Epoch: 30, learning_rate:[0.033091931798149246],costo: 0.2526445984840393, accuracy: 0.942138671875\n",
            "Epoch: 31, learning_rate:[0.03822821658730505],costo: 0.2261800915002823, accuracy: 0.942138671875\n",
            "Epoch: 32, learning_rate:[0.062434389841396376],costo: 0.20231769979000092, accuracy: 0.944580078125\n",
            "Epoch: 33, learning_rate:[0.09966945424884589],costo: 0.2615242302417755, accuracy: 0.94189453125\n",
            "Epoch: 34, learning_rate:[0.026922838315417467],costo: 0.19415821135044098, accuracy: 0.93896484375\n",
            "Epoch: 35, learning_rate:[0.018864802965031693],costo: 0.20465122163295746, accuracy: 0.947021484375\n",
            "Epoch: 36, learning_rate:[0.010891724315677191],costo: 0.2327125072479248, accuracy: 0.948486328125\n",
            "Epoch: 37, learning_rate:[0.09075775616885032],costo: 0.21883781254291534, accuracy: 0.942138671875\n",
            "Epoch: 38, learning_rate:[0.09194963930213906],costo: 0.2406025230884552, accuracy: 0.951171875\n",
            "Epoch: 39, learning_rate:[0.098411472777208],costo: 0.20789651572704315, accuracy: 0.9482421875\n",
            "Epoch: 40, learning_rate:[0.050247771798648],costo: 0.21854481101036072, accuracy: 0.945068359375\n",
            "Epoch: 41, learning_rate:[0.04033108145023846],costo: 0.1928965151309967, accuracy: 0.95263671875\n",
            "Epoch: 42, learning_rate:[0.029757618188737088],costo: 0.19733630120754242, accuracy: 0.95263671875\n",
            "Epoch: 43, learning_rate:[0.07422878466900436],costo: 0.2130035012960434, accuracy: 0.956298828125\n",
            "Epoch: 44, learning_rate:[0.0770808218121729],costo: 0.1866195946931839, accuracy: 0.949951171875\n",
            "Epoch: 45, learning_rate:[0.07882951222085115],costo: 0.22805353999137878, accuracy: 0.94873046875\n",
            "Epoch: 46, learning_rate:[0.07727156016701413],costo: 0.18754297494888306, accuracy: 0.95458984375\n",
            "Epoch: 47, learning_rate:[0.051680027966022585],costo: 0.19643078744411469, accuracy: 0.954833984375\n",
            "Epoch: 48, learning_rate:[0.023043513981472776],costo: 0.20163178443908691, accuracy: 0.95556640625\n",
            "Epoch: 49, learning_rate:[0.051187653650601614],costo: 0.16521327197551727, accuracy: 0.951171875\n",
            "Epoch: 50, learning_rate:[0.09255318464357065],costo: 0.1820550560951233, accuracy: 0.955078125\n",
            "Epoch: 51, learning_rate:[0.0945868464708357],costo: 0.19398419559001923, accuracy: 0.956298828125\n",
            "Epoch: 52, learning_rate:[0.02950910493298914],costo: 0.1863187551498413, accuracy: 0.9580078125\n",
            "Epoch: 53, learning_rate:[0.010512672919967861],costo: 0.19678223133087158, accuracy: 0.958984375\n",
            "Epoch: 54, learning_rate:[0.010455704869015205],costo: 0.20263974368572235, accuracy: 0.959716796875\n",
            "Epoch: 55, learning_rate:[0.012314070770362574],costo: 0.1758347749710083, accuracy: 0.95654296875\n",
            "Epoch: 56, learning_rate:[0.07555400842796559],costo: 0.16137094795703888, accuracy: 0.960693359375\n",
            "Epoch: 57, learning_rate:[0.08300053791403678],costo: 0.20356446504592896, accuracy: 0.95849609375\n",
            "Epoch: 58, learning_rate:[0.044375677686283845],costo: 0.1579635590314865, accuracy: 0.962890625\n",
            "Epoch: 59, learning_rate:[0.02376073507802929],costo: 0.1872420608997345, accuracy: 0.963134765625\n",
            "Epoch: 60, learning_rate:[0.018754082145052312],costo: 0.18011213839054108, accuracy: 0.95849609375\n",
            "Epoch: 61, learning_rate:[0.07546231432020575],costo: 0.17720404267311096, accuracy: 0.958251953125\n",
            "Epoch: 62, learning_rate:[0.08721487805951779],costo: 0.17207694053649902, accuracy: 0.962646484375\n",
            "Epoch: 63, learning_rate:[0.09263795621921903],costo: 0.155462384223938, accuracy: 0.965087890625\n",
            "Epoch: 64, learning_rate:[0.051592702404641276],costo: 0.16234351694583893, accuracy: 0.958251953125\n",
            "Epoch: 65, learning_rate:[0.013182686759947534],costo: 0.17098461091518402, accuracy: 0.96337890625\n",
            "Epoch: 66, learning_rate:[0.013002396403038765],costo: 0.12654344737529755, accuracy: 0.95947265625\n",
            "Epoch: 67, learning_rate:[0.025096761125426463],costo: 0.14052210748195648, accuracy: 0.95947265625\n",
            "Epoch: 68, learning_rate:[0.050909353885626354],costo: 0.1410837173461914, accuracy: 0.9619140625\n",
            "Epoch: 69, learning_rate:[0.09839575501220638],costo: 0.13710534572601318, accuracy: 0.9658203125\n",
            "Epoch: 70, learning_rate:[0.060783576655124946],costo: 0.1562163531780243, accuracy: 0.962890625\n",
            "Epoch: 71, learning_rate:[0.016363992311754234],costo: 0.1377546489238739, accuracy: 0.962646484375\n",
            "Epoch: 72, learning_rate:[0.014795914975367665],costo: 0.15539538860321045, accuracy: 0.962158203125\n",
            "Epoch: 73, learning_rate:[0.09547153484266745],costo: 0.16091707348823547, accuracy: 0.959228515625\n",
            "Epoch: 74, learning_rate:[0.0962957122152956],costo: 0.1604888141155243, accuracy: 0.967041015625\n",
            "Epoch: 75, learning_rate:[0.09891174118920615],costo: 0.12835125625133514, accuracy: 0.96337890625\n",
            "Epoch: 76, learning_rate:[0.04352616531138509],costo: 0.14031367003917694, accuracy: 0.966796875\n",
            "Epoch: 77, learning_rate:[0.02970370750278503],costo: 0.14830033481121063, accuracy: 0.9638671875\n",
            "Epoch: 78, learning_rate:[0.013059542783406115],costo: 0.14718842506408691, accuracy: 0.966064453125\n",
            "Epoch: 79, learning_rate:[0.07659966092011844],costo: 0.1522776335477829, accuracy: 0.96533203125\n",
            "Epoch: 80, learning_rate:[0.08696257132151905],costo: 0.13020308315753937, accuracy: 0.96533203125\n",
            "Epoch: 81, learning_rate:[0.09025181715068292],costo: 0.14771024882793427, accuracy: 0.96630859375\n",
            "Epoch: 82, learning_rate:[0.08914123463486022],costo: 0.1339162439107895, accuracy: 0.96826171875\n",
            "Epoch: 83, learning_rate:[0.015348913795376562],costo: 0.12123938649892807, accuracy: 0.967041015625\n",
            "Epoch: 84, learning_rate:[0.014788463644900919],costo: 0.16144615411758423, accuracy: 0.9658203125\n",
            "Epoch: 85, learning_rate:[0.023413565271055953],costo: 0.12769277393817902, accuracy: 0.964111328125\n",
            "Epoch: 86, learning_rate:[0.09405422778245294],costo: 0.1463993340730667, accuracy: 0.96728515625\n",
            "Epoch: 87, learning_rate:[0.09484185123995903],costo: 0.139781191945076, accuracy: 0.963623046875\n",
            "Epoch: 88, learning_rate:[0.0695859141990752],costo: 0.15757927298545837, accuracy: 0.967041015625\n",
            "Epoch: 89, learning_rate:[0.024621569786063224],costo: 0.13640227913856506, accuracy: 0.972412109375\n",
            "Epoch: 90, learning_rate:[0.01353813898689345],costo: 0.15680775046348572, accuracy: 0.965087890625\n",
            "Epoch: 91, learning_rate:[0.0201083971791834],costo: 0.14152085781097412, accuracy: 0.9677734375\n",
            "Epoch: 92, learning_rate:[0.07409517848533065],costo: 0.10103714466094971, accuracy: 0.96728515625\n",
            "Epoch: 93, learning_rate:[0.09307889794520781],costo: 0.11525844037532806, accuracy: 0.965576171875\n",
            "Epoch: 94, learning_rate:[0.06984219476946668],costo: 0.1073075532913208, accuracy: 0.971923828125\n",
            "Epoch: 95, learning_rate:[0.06640199233128513],costo: 0.09885548055171967, accuracy: 0.968994140625\n",
            "Epoch: 96, learning_rate:[0.06493275438382679],costo: 0.11118456721305847, accuracy: 0.96923828125\n",
            "Epoch: 97, learning_rate:[0.0810315000234752],costo: 0.11561749130487442, accuracy: 0.963623046875\n",
            "Epoch: 98, learning_rate:[0.0827564557740784],costo: 0.10779419541358948, accuracy: 0.96728515625\n",
            "Epoch: 99, learning_rate:[0.09540055418194553],costo: 0.10825303196907043, accuracy: 0.968017578125\n",
            "Epoch: 100, learning_rate:[0.01867223329939133],costo: 0.13549770414829254, accuracy: 0.970458984375\n",
            "Epoch: 1, learning_rate:[0.06772472272529234],costo: 1.8924264907836914, accuracy: 0.721923828125\n",
            "Epoch: 2, learning_rate:[0.07791104265573734],costo: 1.1179856061935425, accuracy: 0.8037109375\n",
            "Epoch: 3, learning_rate:[0.07885256328699841],costo: 0.6870592832565308, accuracy: 0.848876953125\n",
            "Epoch: 4, learning_rate:[0.010491695896855138],costo: 0.5657945275306702, accuracy: 0.870361328125\n",
            "Epoch: 5, learning_rate:[0.010130674349394783],costo: 0.5767464637756348, accuracy: 0.885986328125\n",
            "Epoch: 6, learning_rate:[0.010064718815714753],costo: 0.5439236760139465, accuracy: 0.88720703125\n",
            "Epoch: 7, learning_rate:[0.04013519514951232],costo: 0.5001441836357117, accuracy: 0.88525390625\n",
            "Epoch: 8, learning_rate:[0.07718536360752126],costo: 0.49855440855026245, accuracy: 0.894775390625\n",
            "Epoch: 9, learning_rate:[0.09932249746642145],costo: 0.4203716218471527, accuracy: 0.88525390625\n",
            "Epoch: 10, learning_rate:[0.031683004258757926],costo: 0.4242396056652069, accuracy: 0.905029296875\n",
            "Epoch: 11, learning_rate:[0.01195048211615063],costo: 0.3852674067020416, accuracy: 0.90869140625\n",
            "Epoch: 12, learning_rate:[0.011294766829370107],costo: 0.37652599811553955, accuracy: 0.908935546875\n",
            "Epoch: 13, learning_rate:[0.02807090954857816],costo: 0.4150957763195038, accuracy: 0.90673828125\n",
            "Epoch: 14, learning_rate:[0.03128793899944884],costo: 0.3519653081893921, accuracy: 0.9072265625\n",
            "Epoch: 15, learning_rate:[0.06775835404745836],costo: 0.39567339420318604, accuracy: 0.9130859375\n",
            "Epoch: 16, learning_rate:[0.02360944481124249],costo: 0.36762338876724243, accuracy: 0.9111328125\n",
            "Epoch: 17, learning_rate:[0.020208357601577506],costo: 0.3411079943180084, accuracy: 0.9189453125\n",
            "Epoch: 18, learning_rate:[0.01080728085629916],costo: 0.38822776079177856, accuracy: 0.916259765625\n",
            "Epoch: 19, learning_rate:[0.019060831254711114],costo: 0.3770087659358978, accuracy: 0.91748046875\n",
            "Epoch: 20, learning_rate:[0.06314254614717718],costo: 0.39256370067596436, accuracy: 0.91162109375\n",
            "Epoch: 21, learning_rate:[0.07655098857494239],costo: 0.331535667181015, accuracy: 0.919189453125\n",
            "Epoch: 22, learning_rate:[0.014925783550928596],costo: 0.3066003918647766, accuracy: 0.9189453125\n",
            "Epoch: 23, learning_rate:[0.014007931301027196],costo: 0.3437595069408417, accuracy: 0.921142578125\n",
            "Epoch: 24, learning_rate:[0.012492848670357446],costo: 0.27525773644447327, accuracy: 0.9248046875\n",
            "Epoch: 25, learning_rate:[0.027664485738303914],costo: 0.32654228806495667, accuracy: 0.918701171875\n",
            "Epoch: 26, learning_rate:[0.06925903320739596],costo: 0.31874415278434753, accuracy: 0.92578125\n",
            "Epoch: 27, learning_rate:[0.09508851303292175],costo: 0.35252150893211365, accuracy: 0.922119140625\n",
            "Epoch: 28, learning_rate:[0.07062161940677847],costo: 0.34713688492774963, accuracy: 0.926025390625\n",
            "Epoch: 29, learning_rate:[0.03025933740055719],costo: 0.28277653455734253, accuracy: 0.93115234375\n",
            "Epoch: 30, learning_rate:[0.027000955405907218],costo: 0.2946004569530487, accuracy: 0.934326171875\n",
            "Epoch: 31, learning_rate:[0.03312265267945359],costo: 0.2756641209125519, accuracy: 0.930419921875\n",
            "Epoch: 32, learning_rate:[0.09404274502927462],costo: 0.3131118714809418, accuracy: 0.931396484375\n",
            "Epoch: 33, learning_rate:[0.09444055244891952],costo: 0.2596728205680847, accuracy: 0.932861328125\n",
            "Epoch: 34, learning_rate:[0.02988347167391712],costo: 0.27975067496299744, accuracy: 0.93603515625\n",
            "Epoch: 35, learning_rate:[0.015452856119393659],costo: 0.2460256814956665, accuracy: 0.93603515625\n",
            "Epoch: 36, learning_rate:[0.010154392202719218],costo: 0.27407822012901306, accuracy: 0.938720703125\n",
            "Epoch: 37, learning_rate:[0.022813469016829888],costo: 0.2610553503036499, accuracy: 0.933837890625\n",
            "Epoch: 38, learning_rate:[0.07885142441306633],costo: 0.29591381549835205, accuracy: 0.93115234375\n",
            "Epoch: 39, learning_rate:[0.08237795827168497],costo: 0.2881917953491211, accuracy: 0.933837890625\n",
            "Epoch: 40, learning_rate:[0.060869916688973666],costo: 0.3106713891029358, accuracy: 0.939208984375\n",
            "Epoch: 41, learning_rate:[0.013234822262087097],costo: 0.22193840146064758, accuracy: 0.93896484375\n",
            "Epoch: 42, learning_rate:[0.011493864116647642],costo: 0.25009864568710327, accuracy: 0.93701171875\n",
            "Epoch: 43, learning_rate:[0.08636369958561327],costo: 0.2786710560321808, accuracy: 0.9375\n",
            "Epoch: 44, learning_rate:[0.08761952527765865],costo: 0.21888302266597748, accuracy: 0.940185546875\n",
            "Epoch: 45, learning_rate:[0.0896430883629404],costo: 0.22835122048854828, accuracy: 0.9404296875\n",
            "Epoch: 46, learning_rate:[0.04972450788376548],costo: 0.2227781116962433, accuracy: 0.9443359375\n",
            "Epoch: 47, learning_rate:[0.04153700142221117],costo: 0.2388753741979599, accuracy: 0.947265625\n",
            "Epoch: 48, learning_rate:[0.03396918642173494],costo: 0.21260036528110504, accuracy: 0.9453125\n",
            "Epoch: 49, learning_rate:[0.042779115824174624],costo: 0.23552477359771729, accuracy: 0.94287109375\n",
            "Epoch: 50, learning_rate:[0.07727870515739507],costo: 0.2367764115333557, accuracy: 0.94970703125\n",
            "Epoch: 51, learning_rate:[0.09495532254037015],costo: 0.24976956844329834, accuracy: 0.94921875\n",
            "Epoch: 52, learning_rate:[0.0629953477050014],costo: 0.20340877771377563, accuracy: 0.94970703125\n",
            "Epoch: 53, learning_rate:[0.024994191572883205],costo: 0.21915414929389954, accuracy: 0.950927734375\n",
            "Epoch: 54, learning_rate:[0.011601346607074499],costo: 0.2112576961517334, accuracy: 0.950927734375\n",
            "Epoch: 55, learning_rate:[0.03200914555272143],costo: 0.1840164065361023, accuracy: 0.954345703125\n",
            "Epoch: 56, learning_rate:[0.06634508146640918],costo: 0.2156078964471817, accuracy: 0.947509765625\n",
            "Epoch: 57, learning_rate:[0.07677179470898601],costo: 0.2388421893119812, accuracy: 0.955078125\n",
            "Epoch: 58, learning_rate:[0.011299497976869816],costo: 0.1954420804977417, accuracy: 0.948974609375\n",
            "Epoch: 59, learning_rate:[0.010586087006605446],costo: 0.205344557762146, accuracy: 0.952880859375\n",
            "Epoch: 60, learning_rate:[0.010210184024251247],costo: 0.20414401590824127, accuracy: 0.953125\n",
            "Epoch: 61, learning_rate:[0.06048134616329452],costo: 0.18717461824417114, accuracy: 0.954833984375\n",
            "Epoch: 62, learning_rate:[0.06693093694668241],costo: 0.16282989084720612, accuracy: 0.9580078125\n",
            "Epoch: 63, learning_rate:[0.09303348361742095],costo: 0.22701126337051392, accuracy: 0.9560546875\n",
            "Epoch: 64, learning_rate:[0.06480291235385034],costo: 0.17700523138046265, accuracy: 0.958740234375\n",
            "Epoch: 65, learning_rate:[0.0514700881220283],costo: 0.14636848866939545, accuracy: 0.95166015625\n",
            "Epoch: 66, learning_rate:[0.022304579550992534],costo: 0.20482906699180603, accuracy: 0.9580078125\n",
            "Epoch: 67, learning_rate:[0.06869003154858452],costo: 0.15180052816867828, accuracy: 0.95361328125\n",
            "Epoch: 68, learning_rate:[0.09548179970424067],costo: 0.17263822257518768, accuracy: 0.959228515625\n",
            "Epoch: 69, learning_rate:[0.09835525396711348],costo: 0.1704902946949005, accuracy: 0.956787109375\n",
            "Epoch: 70, learning_rate:[0.08989617022616027],costo: 0.20860843360424042, accuracy: 0.962646484375\n",
            "Epoch: 71, learning_rate:[0.027013383758762846],costo: 0.1642327904701233, accuracy: 0.95849609375\n",
            "Epoch: 72, learning_rate:[0.024656412301891053],costo: 0.17690476775169373, accuracy: 0.9638671875\n",
            "Epoch: 73, learning_rate:[0.05435511073204773],costo: 0.18542452156543732, accuracy: 0.960693359375\n",
            "Epoch: 74, learning_rate:[0.059659056119174686],costo: 0.1642247885465622, accuracy: 0.958984375\n",
            "Epoch: 75, learning_rate:[0.06193405792859614],costo: 0.17326483130455017, accuracy: 0.958251953125\n",
            "Epoch: 76, learning_rate:[0.017969725094518923],costo: 0.16420267522335052, accuracy: 0.958984375\n",
            "Epoch: 77, learning_rate:[0.015406967760089561],costo: 0.1560812145471573, accuracy: 0.95751953125\n",
            "Epoch: 78, learning_rate:[0.013865010444299044],costo: 0.15432283282279968, accuracy: 0.96533203125\n",
            "Epoch: 79, learning_rate:[0.08709629571538686],costo: 0.16386575996875763, accuracy: 0.96044921875\n",
            "Epoch: 80, learning_rate:[0.09051626828878462],costo: 0.14814157783985138, accuracy: 0.96728515625\n",
            "Epoch: 81, learning_rate:[0.09057943977400126],costo: 0.16257469356060028, accuracy: 0.958740234375\n",
            "Epoch: 82, learning_rate:[0.08422372375048934],costo: 0.1560744345188141, accuracy: 0.95849609375\n",
            "Epoch: 83, learning_rate:[0.029787371076083306],costo: 0.16169007122516632, accuracy: 0.96240234375\n",
            "Epoch: 84, learning_rate:[0.02803205631738439],costo: 0.12962767481803894, accuracy: 0.963623046875\n",
            "Epoch: 85, learning_rate:[0.07702059643889667],costo: 0.16479064524173737, accuracy: 0.9609375\n",
            "Epoch: 86, learning_rate:[0.08063849476057443],costo: 0.15225550532341003, accuracy: 0.962890625\n",
            "Epoch: 87, learning_rate:[0.0833361728619644],costo: 0.1553741991519928, accuracy: 0.964599609375\n",
            "Epoch: 88, learning_rate:[0.08209576417155501],costo: 0.14024753868579865, accuracy: 0.966796875\n",
            "Epoch: 89, learning_rate:[0.05870867938098495],costo: 0.12275990843772888, accuracy: 0.966552734375\n",
            "Epoch: 90, learning_rate:[0.055421166691900836],costo: 0.13277922570705414, accuracy: 0.96435546875\n",
            "Epoch: 91, learning_rate:[0.05564298420058742],costo: 0.17161007225513458, accuracy: 0.965576171875\n",
            "Epoch: 92, learning_rate:[0.08588452361573604],costo: 0.1372366100549698, accuracy: 0.967529296875\n",
            "Epoch: 93, learning_rate:[0.09220152944302196],costo: 0.11057928204536438, accuracy: 0.96630859375\n",
            "Epoch: 94, learning_rate:[0.08281441229322645],costo: 0.1347534954547882, accuracy: 0.96533203125\n",
            "Epoch: 95, learning_rate:[0.040143990286746575],costo: 0.14271914958953857, accuracy: 0.96923828125\n",
            "Epoch: 96, learning_rate:[0.02351203753702967],costo: 0.14255090057849884, accuracy: 0.967041015625\n",
            "Epoch: 97, learning_rate:[0.06334523449764909],costo: 0.16271062195301056, accuracy: 0.966064453125\n",
            "Epoch: 98, learning_rate:[0.09307898601824668],costo: 0.13935033977031708, accuracy: 0.96630859375\n",
            "Epoch: 99, learning_rate:[0.09342223618022553],costo: 0.12420202046632767, accuracy: 0.96630859375\n",
            "Epoch: 100, learning_rate:[0.07713007592540118],costo: 0.11024868488311768, accuracy: 0.9619140625\n",
            "Epoch: 1, learning_rate:[0.037882089268005154],costo: 2.105259418487549, accuracy: 0.680908203125\n",
            "Epoch: 2, learning_rate:[0.07578713461947814],costo: 1.753780484199524, accuracy: 0.768310546875\n",
            "Epoch: 3, learning_rate:[0.08468089142415972],costo: 0.9870730042457581, accuracy: 0.847412109375\n",
            "Epoch: 4, learning_rate:[0.057195226981825095],costo: 0.7047067284584045, accuracy: 0.85791015625\n",
            "Epoch: 5, learning_rate:[0.0240416826284945],costo: 0.521060049533844, accuracy: 0.889404296875\n",
            "Epoch: 6, learning_rate:[0.012743172754232278],costo: 0.4790763258934021, accuracy: 0.890380859375\n",
            "Epoch: 7, learning_rate:[0.09121019377012374],costo: 0.5184665322303772, accuracy: 0.898193359375\n",
            "Epoch: 8, learning_rate:[0.0984347473061842],costo: 0.47614040970802307, accuracy: 0.884765625\n",
            "Epoch: 9, learning_rate:[0.0997756935031228],costo: 0.3903808295726776, accuracy: 0.89990234375\n",
            "Epoch: 10, learning_rate:[0.028940224993110657],costo: 0.38047879934310913, accuracy: 0.912353515625\n",
            "Epoch: 11, learning_rate:[0.015393410930524192],costo: 0.40309956669807434, accuracy: 0.915283203125\n",
            "Epoch: 12, learning_rate:[0.01265817784057168],costo: 0.3665272295475006, accuracy: 0.912353515625\n",
            "Epoch: 13, learning_rate:[0.01464553387684181],costo: 0.3374805748462677, accuracy: 0.921142578125\n",
            "Epoch: 14, learning_rate:[0.025279361105774736],costo: 0.37376007437705994, accuracy: 0.91748046875\n",
            "Epoch: 15, learning_rate:[0.04275451064651941],costo: 0.37610140442848206, accuracy: 0.912109375\n",
            "Epoch: 16, learning_rate:[0.03467552883872056],costo: 0.2788401246070862, accuracy: 0.91748046875\n",
            "Epoch: 17, learning_rate:[0.030769236589291163],costo: 0.3840961754322052, accuracy: 0.91552734375\n",
            "Epoch: 18, learning_rate:[0.022475897901819124],costo: 0.30175507068634033, accuracy: 0.917724609375\n",
            "Epoch: 19, learning_rate:[0.09486963485853368],costo: 0.30775314569473267, accuracy: 0.92138671875\n",
            "Epoch: 20, learning_rate:[0.09974069769492873],costo: 0.27424636483192444, accuracy: 0.921142578125\n",
            "Epoch: 21, learning_rate:[0.0999640905398393],costo: 0.28479576110839844, accuracy: 0.925537109375\n",
            "Epoch: 22, learning_rate:[0.09406545772665871],costo: 0.2816404402256012, accuracy: 0.9189453125\n",
            "Epoch: 23, learning_rate:[0.06639354118039784],costo: 0.306430459022522, accuracy: 0.9296875\n",
            "Epoch: 24, learning_rate:[0.06282644318444468],costo: 0.26403534412384033, accuracy: 0.931396484375\n",
            "Epoch: 25, learning_rate:[0.06435079310697041],costo: 0.2712607979774475, accuracy: 0.931396484375\n",
            "Epoch: 26, learning_rate:[0.06513962807510565],costo: 0.2524675726890564, accuracy: 0.933349609375\n",
            "Epoch: 27, learning_rate:[0.07762131250117989],costo: 0.2810731530189514, accuracy: 0.931396484375\n",
            "Epoch: 28, learning_rate:[0.07587471003779192],costo: 0.3124053180217743, accuracy: 0.93505859375\n",
            "Epoch: 29, learning_rate:[0.015047189177438618],costo: 0.23112189769744873, accuracy: 0.93359375\n",
            "Epoch: 30, learning_rate:[0.011748368578776465],costo: 0.27614614367485046, accuracy: 0.93701171875\n",
            "Epoch: 31, learning_rate:[0.09273809594075794],costo: 0.2824777662754059, accuracy: 0.9384765625\n",
            "Epoch: 32, learning_rate:[0.09604095911211526],costo: 0.25537583231925964, accuracy: 0.9462890625\n",
            "Epoch: 33, learning_rate:[0.09743768533579823],costo: 0.28634119033813477, accuracy: 0.941162109375\n",
            "Epoch: 34, learning_rate:[0.03037727159120191],costo: 0.22517837584018707, accuracy: 0.9443359375\n",
            "Epoch: 35, learning_rate:[0.014211220398132829],costo: 0.22268402576446533, accuracy: 0.943115234375\n",
            "Epoch: 36, learning_rate:[0.012080231770423795],costo: 0.2481575310230255, accuracy: 0.94482421875\n",
            "Epoch: 37, learning_rate:[0.01755598864328007],costo: 0.251336932182312, accuracy: 0.94189453125\n",
            "Epoch: 38, learning_rate:[0.09389485243623144],costo: 0.22097431123256683, accuracy: 0.947265625\n",
            "Epoch: 39, learning_rate:[0.09927948992611242],costo: 0.1913059651851654, accuracy: 0.9443359375\n",
            "Epoch: 40, learning_rate:[0.05242669755660802],costo: 0.2075130194425583, accuracy: 0.950439453125\n",
            "Epoch: 41, learning_rate:[0.019147784506738395],costo: 0.2701493501663208, accuracy: 0.946533203125\n",
            "Epoch: 42, learning_rate:[0.015484397474328677],costo: 0.2240820825099945, accuracy: 0.95166015625\n",
            "Epoch: 43, learning_rate:[0.07593564305872172],costo: 0.2535223960876465, accuracy: 0.94970703125\n",
            "Epoch: 44, learning_rate:[0.09679319118269919],costo: 0.21771077811717987, accuracy: 0.955078125\n",
            "Epoch: 45, learning_rate:[0.09937553078087336],costo: 0.19577309489250183, accuracy: 0.947021484375\n",
            "Epoch: 46, learning_rate:[0.012113212203185189],costo: 0.22457993030548096, accuracy: 0.948486328125\n",
            "Epoch: 47, learning_rate:[0.011750888991980917],costo: 0.20164400339126587, accuracy: 0.953369140625\n",
            "Epoch: 48, learning_rate:[0.010794656799232118],costo: 0.18395693600177765, accuracy: 0.9541015625\n",
            "Epoch: 49, learning_rate:[0.09853844028450215],costo: 0.2163992077112198, accuracy: 0.953369140625\n",
            "Epoch: 50, learning_rate:[0.09956723886428613],costo: 0.1701112538576126, accuracy: 0.951416015625\n",
            "Epoch: 51, learning_rate:[0.09969080817852981],costo: 0.17896106839179993, accuracy: 0.952880859375\n",
            "Epoch: 52, learning_rate:[0.03331670289727505],costo: 0.20908336341381073, accuracy: 0.954345703125\n",
            "Epoch: 53, learning_rate:[0.029764959286234932],costo: 0.18105217814445496, accuracy: 0.96044921875\n",
            "Epoch: 54, learning_rate:[0.022496096350335868],costo: 0.19758963584899902, accuracy: 0.960205078125\n",
            "Epoch: 55, learning_rate:[0.07962924472672296],costo: 0.19602340459823608, accuracy: 0.957275390625\n",
            "Epoch: 56, learning_rate:[0.08447110899159754],costo: 0.20091907680034637, accuracy: 0.95654296875\n",
            "Epoch: 57, learning_rate:[0.08766139105813653],costo: 0.17960527539253235, accuracy: 0.9560546875\n",
            "Epoch: 58, learning_rate:[0.08371719138228546],costo: 0.16642093658447266, accuracy: 0.9609375\n",
            "Epoch: 59, learning_rate:[0.036711277574527565],costo: 0.19199831783771515, accuracy: 0.960205078125\n",
            "Epoch: 60, learning_rate:[0.023520335108685515],costo: 0.18522296845912933, accuracy: 0.959228515625\n",
            "Epoch: 61, learning_rate:[0.04409464811678186],costo: 0.2056635320186615, accuracy: 0.958740234375\n",
            "Epoch: 62, learning_rate:[0.0936787196896754],costo: 0.21895219385623932, accuracy: 0.961669921875\n",
            "Epoch: 63, learning_rate:[0.09611412781102052],costo: 0.16016939282417297, accuracy: 0.9609375\n",
            "Epoch: 64, learning_rate:[0.02346649447445953],costo: 0.1534011960029602, accuracy: 0.959716796875\n",
            "Epoch: 65, learning_rate:[0.011904243279075171],costo: 0.16044068336486816, accuracy: 0.9619140625\n",
            "Epoch: 66, learning_rate:[0.011837869976356385],costo: 0.14847996830940247, accuracy: 0.9609375\n",
            "Epoch: 67, learning_rate:[0.07195141770515565],costo: 0.13584329187870026, accuracy: 0.967041015625\n",
            "Epoch: 68, learning_rate:[0.09516619860452466],costo: 0.2105409801006317, accuracy: 0.963623046875\n",
            "Epoch: 69, learning_rate:[0.09540617624232793],costo: 0.18587374687194824, accuracy: 0.962890625\n",
            "Epoch: 70, learning_rate:[0.059352908466903005],costo: 0.1345735341310501, accuracy: 0.960205078125\n",
            "Epoch: 71, learning_rate:[0.04859895422741028],costo: 0.12926337122917175, accuracy: 0.96142578125\n",
            "Epoch: 72, learning_rate:[0.033771444342263784],costo: 0.17972442507743835, accuracy: 0.966552734375\n",
            "Epoch: 73, learning_rate:[0.07743551875848106],costo: 0.1443844884634018, accuracy: 0.96728515625\n",
            "Epoch: 74, learning_rate:[0.08435263335342072],costo: 0.1335901916027069, accuracy: 0.96875\n",
            "Epoch: 75, learning_rate:[0.08983417669234761],costo: 0.12738312780857086, accuracy: 0.968017578125\n",
            "Epoch: 76, learning_rate:[0.02304700879108402],costo: 0.19013676047325134, accuracy: 0.96337890625\n",
            "Epoch: 77, learning_rate:[0.01049317629831386],costo: 0.12370728701353073, accuracy: 0.968017578125\n",
            "Epoch: 78, learning_rate:[0.010358227447954664],costo: 0.1464557945728302, accuracy: 0.966552734375\n",
            "Epoch: 79, learning_rate:[0.023172338305543334],costo: 0.16810469329357147, accuracy: 0.963134765625\n",
            "Epoch: 80, learning_rate:[0.0926032758186845],costo: 0.13831360638141632, accuracy: 0.962646484375\n",
            "Epoch: 81, learning_rate:[0.09402771323487018],costo: 0.1540316939353943, accuracy: 0.967529296875\n",
            "Epoch: 82, learning_rate:[0.057867222674498675],costo: 0.1521565169095993, accuracy: 0.968017578125\n",
            "Epoch: 83, learning_rate:[0.0130601569025334],costo: 0.1255766898393631, accuracy: 0.96533203125\n",
            "Epoch: 84, learning_rate:[0.011394439765570571],costo: 0.14988648891448975, accuracy: 0.96337890625\n",
            "Epoch: 85, learning_rate:[0.07132624652650493],costo: 0.1588701754808426, accuracy: 0.96484375\n",
            "Epoch: 86, learning_rate:[0.07800163108507795],costo: 0.13995563983917236, accuracy: 0.9638671875\n",
            "Epoch: 87, learning_rate:[0.0950007972961466],costo: 0.1408466249704361, accuracy: 0.96630859375\n",
            "Epoch: 88, learning_rate:[0.02151688675065657],costo: 0.14048562943935394, accuracy: 0.966796875\n",
            "Epoch: 89, learning_rate:[0.020937133448735126],costo: 0.11530883610248566, accuracy: 0.970703125\n",
            "Epoch: 90, learning_rate:[0.014437194568078748],costo: 0.11650865525007248, accuracy: 0.967529296875\n",
            "Epoch: 91, learning_rate:[0.04754054597155377],costo: 0.11160993576049805, accuracy: 0.965087890625\n",
            "Epoch: 92, learning_rate:[0.09201662157327217],costo: 0.14332172274589539, accuracy: 0.96630859375\n",
            "Epoch: 93, learning_rate:[0.09856283110287768],costo: 0.11357653141021729, accuracy: 0.970458984375\n",
            "Epoch: 94, learning_rate:[0.0597537598346086],costo: 0.14976899325847626, accuracy: 0.9658203125\n",
            "Epoch: 95, learning_rate:[0.04197066678630987],costo: 0.11948888003826141, accuracy: 0.97216796875\n",
            "Epoch: 96, learning_rate:[0.040733446567927774],costo: 0.11090691387653351, accuracy: 0.968994140625\n",
            "Epoch: 97, learning_rate:[0.07506951289897104],costo: 0.12194381654262543, accuracy: 0.97119140625\n",
            "Epoch: 98, learning_rate:[0.08794286289405442],costo: 0.14260686933994293, accuracy: 0.968017578125\n",
            "Epoch: 99, learning_rate:[0.09593525256674712],costo: 0.10103540867567062, accuracy: 0.968994140625\n",
            "Epoch: 100, learning_rate:[0.08371780066420242],costo: 0.12027769535779953, accuracy: 0.96826171875\n",
            "Epoch: 1, learning_rate:[0.08855174506958219],costo: 1.951829195022583, accuracy: 0.727783203125\n",
            "Epoch: 2, learning_rate:[0.08997438739296534],costo: 1.0432177782058716, accuracy: 0.82080078125\n",
            "Epoch: 3, learning_rate:[0.09857638241708858],costo: 0.6570917367935181, accuracy: 0.849365234375\n",
            "Epoch: 4, learning_rate:[0.09506705634386546],costo: 0.5375710725784302, accuracy: 0.864501953125\n",
            "Epoch: 5, learning_rate:[0.01838819452673586],costo: 0.4375157654285431, accuracy: 0.895263671875\n",
            "Epoch: 6, learning_rate:[0.010516195221439236],costo: 0.43628448247909546, accuracy: 0.901123046875\n",
            "Epoch: 7, learning_rate:[0.07157229953689534],costo: 0.46761956810951233, accuracy: 0.90087890625\n",
            "Epoch: 8, learning_rate:[0.08825221787504506],costo: 0.40093451738357544, accuracy: 0.901611328125\n",
            "Epoch: 9, learning_rate:[0.09965437964330542],costo: 0.37406274676322937, accuracy: 0.910400390625\n",
            "Epoch: 10, learning_rate:[0.09186243529299774],costo: 0.29552972316741943, accuracy: 0.9130859375\n",
            "Epoch: 11, learning_rate:[0.010669793494027743],costo: 0.34654200077056885, accuracy: 0.9130859375\n",
            "Epoch: 12, learning_rate:[0.010525922565937621],costo: 0.3408636748790741, accuracy: 0.918212890625\n",
            "Epoch: 13, learning_rate:[0.09132652886220957],costo: 0.3379534184932709, accuracy: 0.918212890625\n",
            "Epoch: 14, learning_rate:[0.09213316613579325],costo: 0.3331716060638428, accuracy: 0.917236328125\n",
            "Epoch: 15, learning_rate:[0.09919843447851795],costo: 0.30693918466567993, accuracy: 0.921630859375\n",
            "Epoch: 16, learning_rate:[0.05294337767011969],costo: 0.2910815477371216, accuracy: 0.922607421875\n",
            "Epoch: 17, learning_rate:[0.05146301958016586],costo: 0.31853625178337097, accuracy: 0.9248046875\n",
            "Epoch: 18, learning_rate:[0.034533762910725734],costo: 0.2824166417121887, accuracy: 0.9296875\n",
            "Epoch: 19, learning_rate:[0.0912123099305082],costo: 0.2678232491016388, accuracy: 0.92724609375\n",
            "Epoch: 20, learning_rate:[0.09500496369154587],costo: 0.28480544686317444, accuracy: 0.927490234375\n",
            "Epoch: 21, learning_rate:[0.09582181188971593],costo: 0.28138917684555054, accuracy: 0.929931640625\n",
            "Epoch: 22, learning_rate:[0.05307217752311412],costo: 0.3235786259174347, accuracy: 0.933349609375\n",
            "Epoch: 23, learning_rate:[0.0517447646477891],costo: 0.2706223130226135, accuracy: 0.935302734375\n",
            "Epoch: 24, learning_rate:[0.023371354972408866],costo: 0.23020751774311066, accuracy: 0.935791015625\n",
            "Epoch: 25, learning_rate:[0.09321121089344322],costo: 0.24739307165145874, accuracy: 0.937744140625\n",
            "Epoch: 26, learning_rate:[0.09926650149230318],costo: 0.27744928002357483, accuracy: 0.93798828125\n",
            "Epoch: 27, learning_rate:[0.09986147006286392],costo: 0.2640450894832611, accuracy: 0.941650390625\n",
            "Epoch: 28, learning_rate:[0.08716519133810044],costo: 0.22215086221694946, accuracy: 0.942626953125\n",
            "Epoch: 29, learning_rate:[0.05702221873199344],costo: 0.20212142169475555, accuracy: 0.937744140625\n",
            "Epoch: 30, learning_rate:[0.031060187565479694],costo: 0.24957135319709778, accuracy: 0.947021484375\n",
            "Epoch: 31, learning_rate:[0.049521142735276864],costo: 0.1990094780921936, accuracy: 0.947998046875\n",
            "Epoch: 32, learning_rate:[0.06380501856391756],costo: 0.24231107532978058, accuracy: 0.950439453125\n",
            "Epoch: 33, learning_rate:[0.08763507034404325],costo: 0.18322040140628815, accuracy: 0.93994140625\n",
            "Epoch: 34, learning_rate:[0.03153895387955117],costo: 0.2533370554447174, accuracy: 0.948486328125\n",
            "Epoch: 35, learning_rate:[0.017936453380384264],costo: 0.19445140659809113, accuracy: 0.94921875\n",
            "Epoch: 36, learning_rate:[0.015796880677485466],costo: 0.20489171147346497, accuracy: 0.947998046875\n",
            "Epoch: 37, learning_rate:[0.023142451658408635],costo: 0.17070920765399933, accuracy: 0.947509765625\n",
            "Epoch: 38, learning_rate:[0.04486975239657006],costo: 0.2094561755657196, accuracy: 0.954345703125\n",
            "Epoch: 39, learning_rate:[0.07327581454577893],costo: 0.18531018495559692, accuracy: 0.9521484375\n",
            "Epoch: 40, learning_rate:[0.04320179590060495],costo: 0.212197944521904, accuracy: 0.949951171875\n",
            "Epoch: 41, learning_rate:[0.03963394087394258],costo: 0.1894419640302658, accuracy: 0.949951171875\n",
            "Epoch: 42, learning_rate:[0.029848648027093493],costo: 0.21126124262809753, accuracy: 0.95166015625\n",
            "Epoch: 43, learning_rate:[0.06593594469943581],costo: 0.19761033356189728, accuracy: 0.956298828125\n",
            "Epoch: 44, learning_rate:[0.06811184908998939],costo: 0.2032763808965683, accuracy: 0.951904296875\n",
            "Epoch: 45, learning_rate:[0.07695652887620931],costo: 0.20342254638671875, accuracy: 0.955322265625\n",
            "Epoch: 46, learning_rate:[0.03155044091035245],costo: 0.23066312074661255, accuracy: 0.955078125\n",
            "Epoch: 47, learning_rate:[0.027155564251009998],costo: 0.19604891538619995, accuracy: 0.95556640625\n",
            "Epoch: 48, learning_rate:[0.024493514493374308],costo: 0.15921607613563538, accuracy: 0.95556640625\n",
            "Epoch: 49, learning_rate:[0.07286971509218944],costo: 0.17983344197273254, accuracy: 0.953125\n",
            "Epoch: 50, learning_rate:[0.08461353390371536],costo: 0.21486282348632812, accuracy: 0.95703125\n",
            "Epoch: 51, learning_rate:[0.08849894041742593],costo: 0.18379344046115875, accuracy: 0.95703125\n",
            "Epoch: 52, learning_rate:[0.012158604078775639],costo: 0.17099961638450623, accuracy: 0.957763671875\n",
            "Epoch: 53, learning_rate:[0.010047677781340773],costo: 0.19230221211910248, accuracy: 0.95947265625\n",
            "Epoch: 54, learning_rate:[0.010011040697670415],costo: 0.16278116405010223, accuracy: 0.959228515625\n",
            "Epoch: 55, learning_rate:[0.08919628708547567],costo: 0.18788713216781616, accuracy: 0.959228515625\n",
            "Epoch: 56, learning_rate:[0.0960172293661629],costo: 0.18750089406967163, accuracy: 0.961669921875\n",
            "Epoch: 57, learning_rate:[0.0993209078417112],costo: 0.1617516279220581, accuracy: 0.960693359375\n",
            "Epoch: 58, learning_rate:[0.0911396679250856],costo: 0.16220006346702576, accuracy: 0.962158203125\n",
            "Epoch: 59, learning_rate:[0.06596363828048882],costo: 0.15448835492134094, accuracy: 0.959716796875\n",
            "Epoch: 60, learning_rate:[0.0467567665856485],costo: 0.16770556569099426, accuracy: 0.961181640625\n",
            "Epoch: 61, learning_rate:[0.08879087580097554],costo: 0.16425897181034088, accuracy: 0.95947265625\n",
            "Epoch: 62, learning_rate:[0.09653743688879404],costo: 0.17738895118236542, accuracy: 0.96337890625\n",
            "Epoch: 63, learning_rate:[0.09924110205623296],costo: 0.16409710049629211, accuracy: 0.962890625\n",
            "Epoch: 64, learning_rate:[0.07818611304615945],costo: 0.14657993614673615, accuracy: 0.962890625\n",
            "Epoch: 65, learning_rate:[0.022640876148946845],costo: 0.15310446918010712, accuracy: 0.964111328125\n",
            "Epoch: 66, learning_rate:[0.014835105099162443],costo: 0.14555884897708893, accuracy: 0.963623046875\n",
            "Epoch: 67, learning_rate:[0.09027130915407613],costo: 0.1577705591917038, accuracy: 0.96435546875\n",
            "Epoch: 68, learning_rate:[0.09913735522659134],costo: 0.16434888541698456, accuracy: 0.966796875\n",
            "Epoch: 69, learning_rate:[0.099553297286257],costo: 0.17186617851257324, accuracy: 0.968994140625\n",
            "Epoch: 70, learning_rate:[0.09429520904717478],costo: 0.13330812752246857, accuracy: 0.96728515625\n",
            "Epoch: 71, learning_rate:[0.043919760804415786],costo: 0.12753474712371826, accuracy: 0.969482421875\n",
            "Epoch: 72, learning_rate:[0.02557772472213534],costo: 0.16731654107570648, accuracy: 0.966064453125\n",
            "Epoch: 73, learning_rate:[0.026984771592757608],costo: 0.15226447582244873, accuracy: 0.96630859375\n",
            "Epoch: 74, learning_rate:[0.07624906192078215],costo: 0.1373651772737503, accuracy: 0.96484375\n",
            "Epoch: 75, learning_rate:[0.07899475683993429],costo: 0.14672650396823883, accuracy: 0.967041015625\n",
            "Epoch: 76, learning_rate:[0.042066858970468954],costo: 0.11894773691892624, accuracy: 0.9658203125\n",
            "Epoch: 77, learning_rate:[0.04199281649129719],costo: 0.16333840787410736, accuracy: 0.9697265625\n",
            "Epoch: 78, learning_rate:[0.03165502971132589],costo: 0.1298075020313263, accuracy: 0.9658203125\n",
            "Epoch: 79, learning_rate:[0.03462433282176327],costo: 0.12708492577075958, accuracy: 0.970458984375\n",
            "Epoch: 80, learning_rate:[0.04950496645702142],costo: 0.1429997980594635, accuracy: 0.96630859375\n",
            "Epoch: 81, learning_rate:[0.07387535426637894],costo: 0.1332867443561554, accuracy: 0.968017578125\n",
            "Epoch: 82, learning_rate:[0.03345519555632134],costo: 0.13011877238750458, accuracy: 0.966796875\n",
            "Epoch: 83, learning_rate:[0.021871834221026898],costo: 0.15184800326824188, accuracy: 0.966552734375\n",
            "Epoch: 84, learning_rate:[0.018120792621799376],costo: 0.13392482697963715, accuracy: 0.969482421875\n",
            "Epoch: 85, learning_rate:[0.02747322327277025],costo: 0.13043786585330963, accuracy: 0.969482421875\n",
            "Epoch: 86, learning_rate:[0.05224191806708542],costo: 0.1315256804227829, accuracy: 0.967041015625\n",
            "Epoch: 87, learning_rate:[0.09703201461843525],costo: 0.1316765546798706, accuracy: 0.970703125\n",
            "Epoch: 88, learning_rate:[0.042025004454172205],costo: 0.15060639381408691, accuracy: 0.967529296875\n",
            "Epoch: 89, learning_rate:[0.020175550819739096],costo: 0.11450675874948502, accuracy: 0.966552734375\n",
            "Epoch: 90, learning_rate:[0.015520561556390946],costo: 0.11099175363779068, accuracy: 0.9697265625\n",
            "Epoch: 91, learning_rate:[0.08965743047341634],costo: 0.12093819677829742, accuracy: 0.96923828125\n",
            "Epoch: 92, learning_rate:[0.09536735213638377],costo: 0.1210286021232605, accuracy: 0.968994140625\n",
            "Epoch: 93, learning_rate:[0.09846084710818696],costo: 0.0951680988073349, accuracy: 0.97021484375\n",
            "Epoch: 94, learning_rate:[0.07239953693068059],costo: 0.14222364127635956, accuracy: 0.96826171875\n",
            "Epoch: 95, learning_rate:[0.032049770731055686],costo: 0.1382579654455185, accuracy: 0.9697265625\n",
            "Epoch: 96, learning_rate:[0.015645705524491786],costo: 0.12204879522323608, accuracy: 0.970947265625\n",
            "Epoch: 97, learning_rate:[0.06304319028257467],costo: 0.11808493733406067, accuracy: 0.9697265625\n",
            "Epoch: 98, learning_rate:[0.09504375976723406],costo: 0.12424158304929733, accuracy: 0.973388671875\n",
            "Epoch: 99, learning_rate:[0.09671561403290194],costo: 0.10531727224588394, accuracy: 0.968017578125\n",
            "Epoch: 100, learning_rate:[0.051753588215145765],costo: 0.1081765741109848, accuracy: 0.968994140625\n",
            "Epoch: 1, learning_rate:[0.07790276381663531],costo: 1.7892134189605713, accuracy: 0.773193359375\n",
            "Epoch: 2, learning_rate:[0.08243807279609947],costo: 0.9512859582901001, accuracy: 0.85205078125\n",
            "Epoch: 3, learning_rate:[0.09356024844922663],costo: 0.6541242003440857, accuracy: 0.876220703125\n",
            "Epoch: 4, learning_rate:[0.07979071636627923],costo: 0.5839476585388184, accuracy: 0.880615234375\n",
            "Epoch: 5, learning_rate:[0.05498791929982483],costo: 0.4125773310661316, accuracy: 0.903564453125\n",
            "Epoch: 6, learning_rate:[0.01244674126541291],costo: 0.39389804005622864, accuracy: 0.90234375\n",
            "Epoch: 7, learning_rate:[0.022111954841567777],costo: 0.36653244495391846, accuracy: 0.900634765625\n",
            "Epoch: 8, learning_rate:[0.027156576785209618],costo: 0.41459813714027405, accuracy: 0.908935546875\n",
            "Epoch: 9, learning_rate:[0.08962202783518032],costo: 0.41323933005332947, accuracy: 0.91064453125\n",
            "Epoch: 10, learning_rate:[0.08769158589971635],costo: 0.4185223877429962, accuracy: 0.904052734375\n",
            "Epoch: 11, learning_rate:[0.08216138785366976],costo: 0.3405816853046417, accuracy: 0.9130859375\n",
            "Epoch: 12, learning_rate:[0.05454376785044719],costo: 0.3551672101020813, accuracy: 0.92041015625\n",
            "Epoch: 13, learning_rate:[0.09352351367552242],costo: 0.34329289197921753, accuracy: 0.919677734375\n",
            "Epoch: 14, learning_rate:[0.09915572407426884],costo: 0.30418530106544495, accuracy: 0.92236328125\n",
            "Epoch: 15, learning_rate:[0.09977939106216212],costo: 0.3002956807613373, accuracy: 0.91845703125\n",
            "Epoch: 16, learning_rate:[0.03615181249085481],costo: 0.31906160712242126, accuracy: 0.9228515625\n",
            "Epoch: 17, learning_rate:[0.03439751560692707],costo: 0.2760351002216339, accuracy: 0.9228515625\n",
            "Epoch: 18, learning_rate:[0.012145758180687406],costo: 0.3064602315425873, accuracy: 0.928466796875\n",
            "Epoch: 19, learning_rate:[0.07344370402350285],costo: 0.3157808780670166, accuracy: 0.93115234375\n",
            "Epoch: 20, learning_rate:[0.09045194092228877],costo: 0.3073374927043915, accuracy: 0.93017578125\n",
            "Epoch: 21, learning_rate:[0.09559130629962678],costo: 0.2695983350276947, accuracy: 0.932373046875\n",
            "Epoch: 22, learning_rate:[0.024306130412882352],costo: 0.31187891960144043, accuracy: 0.931884765625\n",
            "Epoch: 23, learning_rate:[0.018050490191940063],costo: 0.2389403134584427, accuracy: 0.937255859375\n",
            "Epoch: 24, learning_rate:[0.011605565844366672],costo: 0.3005165755748749, accuracy: 0.9345703125\n",
            "Epoch: 25, learning_rate:[0.08559566782870622],costo: 0.25707006454467773, accuracy: 0.931396484375\n",
            "Epoch: 26, learning_rate:[0.09573064035149839],costo: 0.26059025526046753, accuracy: 0.929931640625\n",
            "Epoch: 27, learning_rate:[0.09608408313317976],costo: 0.21341374516487122, accuracy: 0.94091796875\n",
            "Epoch: 28, learning_rate:[0.09112126188220977],costo: 0.26084113121032715, accuracy: 0.940673828125\n",
            "Epoch: 29, learning_rate:[0.06049410397178684],costo: 0.25086137652397156, accuracy: 0.939697265625\n",
            "Epoch: 30, learning_rate:[0.05669715733570975],costo: 0.2425515204668045, accuracy: 0.946533203125\n",
            "Epoch: 31, learning_rate:[0.07618070832366226],costo: 0.29298070073127747, accuracy: 0.948974609375\n",
            "Epoch: 32, learning_rate:[0.09403181720575479],costo: 0.2151660919189453, accuracy: 0.9404296875\n",
            "Epoch: 33, learning_rate:[0.09866723835137284],costo: 0.21864888072013855, accuracy: 0.94580078125\n",
            "Epoch: 34, learning_rate:[0.01566814583597104],costo: 0.20653145015239716, accuracy: 0.944580078125\n",
            "Epoch: 35, learning_rate:[0.010218191279272011],costo: 0.2514261305332184, accuracy: 0.945556640625\n",
            "Epoch: 36, learning_rate:[0.010099156342064635],costo: 0.2122679352760315, accuracy: 0.946044921875\n",
            "Epoch: 37, learning_rate:[0.013006782985317964],costo: 0.24073736369609833, accuracy: 0.94921875\n",
            "Epoch: 38, learning_rate:[0.054165190235861305],costo: 0.24622182548046112, accuracy: 0.94921875\n",
            "Epoch: 39, learning_rate:[0.07054047843296082],costo: 0.23776166141033173, accuracy: 0.953369140625\n",
            "Epoch: 40, learning_rate:[0.07008806614718424],costo: 0.23332476615905762, accuracy: 0.9501953125\n",
            "Epoch: 41, learning_rate:[0.06453054560966105],costo: 0.17960546910762787, accuracy: 0.951416015625\n",
            "Epoch: 42, learning_rate:[0.04947131251599244],costo: 0.19340474903583527, accuracy: 0.9521484375\n",
            "Epoch: 43, learning_rate:[0.06066378235661703],costo: 0.1533820480108261, accuracy: 0.95458984375\n",
            "Epoch: 44, learning_rate:[0.09993369094291622],costo: 0.16049082577228546, accuracy: 0.955810546875\n",
            "Epoch: 45, learning_rate:[0.09998781762751684],costo: 0.20928232371807098, accuracy: 0.95458984375\n",
            "Epoch: 46, learning_rate:[0.07354347137513034],costo: 0.2034190446138382, accuracy: 0.955322265625\n",
            "Epoch: 47, learning_rate:[0.029832820454031843],costo: 0.15786676108837128, accuracy: 0.954833984375\n",
            "Epoch: 48, learning_rate:[0.019873569958191225],costo: 0.20075015723705292, accuracy: 0.95654296875\n",
            "Epoch: 49, learning_rate:[0.08829549881142888],costo: 0.1932576447725296, accuracy: 0.958740234375\n",
            "Epoch: 50, learning_rate:[0.09875961689733377],costo: 0.16766589879989624, accuracy: 0.958740234375\n",
            "Epoch: 51, learning_rate:[0.09907884202387121],costo: 0.17524708807468414, accuracy: 0.955322265625\n",
            "Epoch: 52, learning_rate:[0.042978073451280185],costo: 0.16917240619659424, accuracy: 0.960693359375\n",
            "Epoch: 53, learning_rate:[0.025395517118660817],costo: 0.18494775891304016, accuracy: 0.958251953125\n",
            "Epoch: 54, learning_rate:[0.02335734736505856],costo: 0.19295252859592438, accuracy: 0.956787109375\n",
            "Epoch: 55, learning_rate:[0.07333207612665205],costo: 0.17485451698303223, accuracy: 0.958740234375\n",
            "Epoch: 56, learning_rate:[0.08966940379461188],costo: 0.1928052008152008, accuracy: 0.9609375\n",
            "Epoch: 57, learning_rate:[0.0960595439834063],costo: 0.15666751563549042, accuracy: 0.9638671875\n",
            "Epoch: 58, learning_rate:[0.05529122573197756],costo: 0.1482202708721161, accuracy: 0.963623046875\n",
            "Epoch: 59, learning_rate:[0.0430208833739039],costo: 0.19057968258857727, accuracy: 0.96533203125\n",
            "Epoch: 60, learning_rate:[0.04228408483417691],costo: 0.15185591578483582, accuracy: 0.96337890625\n",
            "Epoch: 61, learning_rate:[0.05818792369122163],costo: 0.20919181406497955, accuracy: 0.9638671875\n",
            "Epoch: 62, learning_rate:[0.08786934532961697],costo: 0.15494415163993835, accuracy: 0.962158203125\n",
            "Epoch: 63, learning_rate:[0.09014805128128384],costo: 0.2053842544555664, accuracy: 0.95849609375\n",
            "Epoch: 64, learning_rate:[0.07883111803824004],costo: 0.14181002974510193, accuracy: 0.96630859375\n",
            "Epoch: 65, learning_rate:[0.015694922158934067],costo: 0.14599864184856415, accuracy: 0.96630859375\n",
            "Epoch: 66, learning_rate:[0.012807240664281377],costo: 0.12800127267837524, accuracy: 0.96484375\n",
            "Epoch: 67, learning_rate:[0.09978759381120267],costo: 0.17122477293014526, accuracy: 0.96435546875\n",
            "Epoch: 68, learning_rate:[0.09993297731310204],costo: 0.12196432054042816, accuracy: 0.964111328125\n",
            "Epoch: 69, learning_rate:[0.09998952504373358],costo: 0.12760064005851746, accuracy: 0.963623046875\n",
            "Epoch: 70, learning_rate:[0.04888995628056172],costo: 0.13150335848331451, accuracy: 0.96630859375\n",
            "Epoch: 71, learning_rate:[0.035914783793596375],costo: 0.14035986363887787, accuracy: 0.962890625\n",
            "Epoch: 72, learning_rate:[0.01680782315435953],costo: 0.16424362361431122, accuracy: 0.967041015625\n",
            "Epoch: 73, learning_rate:[0.07502489314762736],costo: 0.13969986140727997, accuracy: 0.9697265625\n",
            "Epoch: 74, learning_rate:[0.07886308672391192],costo: 0.12983405590057373, accuracy: 0.965576171875\n",
            "Epoch: 75, learning_rate:[0.09837395217287061],costo: 0.12972591817378998, accuracy: 0.96630859375\n",
            "Epoch: 76, learning_rate:[0.06444672156564198],costo: 0.12013427168130875, accuracy: 0.96630859375\n",
            "Epoch: 77, learning_rate:[0.016009117789111522],costo: 0.10502365231513977, accuracy: 0.962890625\n",
            "Epoch: 78, learning_rate:[0.012406389114188036],costo: 0.12492911517620087, accuracy: 0.96728515625\n",
            "Epoch: 79, learning_rate:[0.03378488371628347],costo: 0.14886675775051117, accuracy: 0.96728515625\n",
            "Epoch: 80, learning_rate:[0.07551162228599467],costo: 0.13352136313915253, accuracy: 0.969482421875\n",
            "Epoch: 81, learning_rate:[0.08145869265502534],costo: 0.12466756999492645, accuracy: 0.968505859375\n",
            "Epoch: 82, learning_rate:[0.012888231618556777],costo: 0.14111676812171936, accuracy: 0.967041015625\n",
            "Epoch: 83, learning_rate:[0.010341057432095607],costo: 0.16090014576911926, accuracy: 0.9697265625\n",
            "Epoch: 84, learning_rate:[0.010046949120482464],costo: 0.14630454778671265, accuracy: 0.966552734375\n",
            "Epoch: 85, learning_rate:[0.09853189721550432],costo: 0.15914855897426605, accuracy: 0.964599609375\n",
            "Epoch: 86, learning_rate:[0.09934100843392064],costo: 0.11829137802124023, accuracy: 0.968505859375\n",
            "Epoch: 87, learning_rate:[0.09947286772599671],costo: 0.1677413284778595, accuracy: 0.970947265625\n",
            "Epoch: 88, learning_rate:[0.036053599733832646],costo: 0.12427785247564316, accuracy: 0.969970703125\n",
            "Epoch: 89, learning_rate:[0.03577107650201549],costo: 0.12380062788724899, accuracy: 0.966064453125\n",
            "Epoch: 90, learning_rate:[0.012937069111150253],costo: 0.140205517411232, accuracy: 0.96923828125\n",
            "Epoch: 91, learning_rate:[0.024195031025051453],costo: 0.12551777064800262, accuracy: 0.97021484375\n",
            "Epoch: 92, learning_rate:[0.02584732172438943],costo: 0.13273568451404572, accuracy: 0.96923828125\n",
            "Epoch: 93, learning_rate:[0.07674818019819732],costo: 0.12787947058677673, accuracy: 0.96923828125\n",
            "Epoch: 94, learning_rate:[0.06924830458580772],costo: 0.12601259350776672, accuracy: 0.972412109375\n",
            "Epoch: 95, learning_rate:[0.015009486414060216],costo: 0.1224588006734848, accuracy: 0.968994140625\n",
            "Epoch: 96, learning_rate:[0.011226988170366645],costo: 0.11075970530509949, accuracy: 0.9697265625\n",
            "Epoch: 97, learning_rate:[0.01759199006050222],costo: 0.10573966801166534, accuracy: 0.97021484375\n",
            "Epoch: 98, learning_rate:[0.06038389805405028],costo: 0.08607824891805649, accuracy: 0.971435546875\n",
            "Epoch: 99, learning_rate:[0.08804171330005502],costo: 0.08915116637945175, accuracy: 0.97119140625\n",
            "Epoch: 100, learning_rate:[0.06715708953065809],costo: 0.12156246602535248, accuracy: 0.970703125\n",
            "Epoch: 1, learning_rate:[0.08612532438511852],costo: 2.1619367599487305, accuracy: 0.631591796875\n",
            "Epoch: 2, learning_rate:[0.09969217260597504],costo: 1.3339730501174927, accuracy: 0.804443359375\n",
            "Epoch: 3, learning_rate:[0.0997579103077485],costo: 0.7262313365936279, accuracy: 0.823486328125\n",
            "Epoch: 4, learning_rate:[0.08603638601123345],costo: 0.540057361125946, accuracy: 0.86083984375\n",
            "Epoch: 5, learning_rate:[0.02520138246894947],costo: 0.45178449153900146, accuracy: 0.89501953125\n",
            "Epoch: 6, learning_rate:[0.01735977996524944],costo: 0.4530697166919708, accuracy: 0.9013671875\n",
            "Epoch: 7, learning_rate:[0.075515533947211],costo: 0.43903085589408875, accuracy: 0.90234375\n",
            "Epoch: 8, learning_rate:[0.07862956060219524],costo: 0.4507920742034912, accuracy: 0.896484375\n",
            "Epoch: 9, learning_rate:[0.09032280596612229],costo: 0.41524165868759155, accuracy: 0.906494140625\n",
            "Epoch: 10, learning_rate:[0.06744167879027343],costo: 0.3485211730003357, accuracy: 0.908447265625\n",
            "Epoch: 11, learning_rate:[0.02685064696975347],costo: 0.3652487099170685, accuracy: 0.917724609375\n",
            "Epoch: 12, learning_rate:[0.023609432565382366],costo: 0.37840762734413147, accuracy: 0.91650390625\n",
            "Epoch: 13, learning_rate:[0.08748024556761844],costo: 0.3276609480381012, accuracy: 0.91552734375\n",
            "Epoch: 14, learning_rate:[0.08904361127387553],costo: 0.3335043787956238, accuracy: 0.91748046875\n",
            "Epoch: 15, learning_rate:[0.09312723433351411],costo: 0.27498751878738403, accuracy: 0.923828125\n",
            "Epoch: 16, learning_rate:[0.02869450553415162],costo: 0.33147937059402466, accuracy: 0.92138671875\n",
            "Epoch: 17, learning_rate:[0.012105566858657378],costo: 0.307081401348114, accuracy: 0.928955078125\n",
            "Epoch: 18, learning_rate:[0.010870859869575825],costo: 0.27391284704208374, accuracy: 0.932861328125\n",
            "Epoch: 19, learning_rate:[0.05534080699448184],costo: 0.2933845818042755, accuracy: 0.92822265625\n",
            "Epoch: 20, learning_rate:[0.06946148858731772],costo: 0.31231051683425903, accuracy: 0.9267578125\n",
            "Epoch: 21, learning_rate:[0.07961920490147023],costo: 0.3132651746273041, accuracy: 0.9208984375\n",
            "Epoch: 22, learning_rate:[0.07318130631151021],costo: 0.30331629514694214, accuracy: 0.928466796875\n",
            "Epoch: 23, learning_rate:[0.0605625366444938],costo: 0.25119882822036743, accuracy: 0.934814453125\n",
            "Epoch: 24, learning_rate:[0.01401878773437581],costo: 0.2917751371860504, accuracy: 0.933349609375\n",
            "Epoch: 25, learning_rate:[0.06327410257032398],costo: 0.290886253118515, accuracy: 0.930908203125\n",
            "Epoch: 26, learning_rate:[0.09627356307635704],costo: 0.2500215768814087, accuracy: 0.93896484375\n",
            "Epoch: 27, learning_rate:[0.09755011099561411],costo: 0.2463582456111908, accuracy: 0.93798828125\n",
            "Epoch: 28, learning_rate:[0.06923458303223413],costo: 0.2403411716222763, accuracy: 0.942138671875\n",
            "Epoch: 29, learning_rate:[0.02343082649122865],costo: 0.24376331269741058, accuracy: 0.937255859375\n",
            "Epoch: 30, learning_rate:[0.019899991294451136],costo: 0.2534986138343811, accuracy: 0.939208984375\n",
            "Epoch: 31, learning_rate:[0.02632160044396976],costo: 0.25840315222740173, accuracy: 0.94189453125\n",
            "Epoch: 32, learning_rate:[0.05449439671534721],costo: 0.24536196887493134, accuracy: 0.9423828125\n",
            "Epoch: 33, learning_rate:[0.09625867855053868],costo: 0.23674409091472626, accuracy: 0.935791015625\n",
            "Epoch: 34, learning_rate:[0.09157385836536105],costo: 0.2359764724969864, accuracy: 0.942138671875\n",
            "Epoch: 35, learning_rate:[0.06354128701191533],costo: 0.22780153155326843, accuracy: 0.943115234375\n",
            "Epoch: 36, learning_rate:[0.05437361541364886],costo: 0.2699204087257385, accuracy: 0.94677734375\n",
            "Epoch: 37, learning_rate:[0.0979406257046781],costo: 0.2216930389404297, accuracy: 0.952392578125\n",
            "Epoch: 38, learning_rate:[0.09900584569344789],costo: 0.22197221219539642, accuracy: 0.9521484375\n",
            "Epoch: 39, learning_rate:[0.0997210587709286],costo: 0.24237996339797974, accuracy: 0.94775390625\n",
            "Epoch: 40, learning_rate:[0.05940553215379311],costo: 0.19782215356826782, accuracy: 0.957275390625\n",
            "Epoch: 41, learning_rate:[0.04168988148991812],costo: 0.19555900990962982, accuracy: 0.954345703125\n",
            "Epoch: 42, learning_rate:[0.029553623115939447],costo: 0.17544913291931152, accuracy: 0.9521484375\n",
            "Epoch: 43, learning_rate:[0.04410746341812353],costo: 0.2068222016096115, accuracy: 0.9560546875\n",
            "Epoch: 44, learning_rate:[0.06101032485913489],costo: 0.18479783833026886, accuracy: 0.957275390625\n",
            "Epoch: 45, learning_rate:[0.08553469937932562],costo: 0.1620177924633026, accuracy: 0.956298828125\n",
            "Epoch: 46, learning_rate:[0.07575839563529972],costo: 0.1962655633687973, accuracy: 0.95654296875\n",
            "Epoch: 47, learning_rate:[0.015321232228268106],costo: 0.18228884041309357, accuracy: 0.95849609375\n",
            "Epoch: 48, learning_rate:[0.01241018262570045],costo: 0.17759789526462555, accuracy: 0.95751953125\n",
            "Epoch: 49, learning_rate:[0.06014887228477303],costo: 0.1903374195098877, accuracy: 0.9599609375\n",
            "Epoch: 50, learning_rate:[0.07567861324338146],costo: 0.17056973278522491, accuracy: 0.95361328125\n",
            "Epoch: 51, learning_rate:[0.07814697700701437],costo: 0.17036592960357666, accuracy: 0.957763671875\n",
            "Epoch: 52, learning_rate:[0.03638909080617705],costo: 0.17740339040756226, accuracy: 0.948974609375\n",
            "Epoch: 53, learning_rate:[0.01916733161069315],costo: 0.1764221340417862, accuracy: 0.95751953125\n",
            "Epoch: 54, learning_rate:[0.019100684999202373],costo: 0.18560445308685303, accuracy: 0.95703125\n",
            "Epoch: 55, learning_rate:[0.09396248940102755],costo: 0.1507064700126648, accuracy: 0.95703125\n",
            "Epoch: 56, learning_rate:[0.0976670822353357],costo: 0.15991395711898804, accuracy: 0.96240234375\n",
            "Epoch: 57, learning_rate:[0.0983121464014174],costo: 0.18757164478302002, accuracy: 0.96142578125\n",
            "Epoch: 58, learning_rate:[0.09133390003441737],costo: 0.1417604684829712, accuracy: 0.959228515625\n",
            "Epoch: 59, learning_rate:[0.05671119428680217],costo: 0.15996219217777252, accuracy: 0.96240234375\n",
            "Epoch: 60, learning_rate:[0.04408098771172207],costo: 0.17047831416130066, accuracy: 0.962158203125\n",
            "Epoch: 61, learning_rate:[0.0652759397917795],costo: 0.16049326956272125, accuracy: 0.960693359375\n",
            "Epoch: 62, learning_rate:[0.09347598159098607],costo: 0.13654451072216034, accuracy: 0.96533203125\n",
            "Epoch: 63, learning_rate:[0.09632053586756703],costo: 0.14518700540065765, accuracy: 0.964599609375\n",
            "Epoch: 64, learning_rate:[0.024104159335926675],costo: 0.13173401355743408, accuracy: 0.9638671875\n",
            "Epoch: 65, learning_rate:[0.022570238909378343],costo: 0.13434725999832153, accuracy: 0.964111328125\n",
            "Epoch: 66, learning_rate:[0.022210475105483227],costo: 0.17563650012016296, accuracy: 0.962158203125\n",
            "Epoch: 67, learning_rate:[0.04185841162972148],costo: 0.16978603601455688, accuracy: 0.9619140625\n",
            "Epoch: 68, learning_rate:[0.053399442187598026],costo: 0.16592809557914734, accuracy: 0.96337890625\n",
            "Epoch: 69, learning_rate:[0.069205273634295],costo: 0.15618836879730225, accuracy: 0.964111328125\n",
            "Epoch: 70, learning_rate:[0.04221068373736248],costo: 0.15417048335075378, accuracy: 0.968017578125\n",
            "Epoch: 71, learning_rate:[0.024069212503819847],costo: 0.1644989401102066, accuracy: 0.9658203125\n",
            "Epoch: 72, learning_rate:[0.012253876215222028],costo: 0.18499648571014404, accuracy: 0.966064453125\n",
            "Epoch: 73, learning_rate:[0.03400124241175748],costo: 0.11733322590589523, accuracy: 0.96337890625\n",
            "Epoch: 74, learning_rate:[0.05728771360973467],costo: 0.14299990236759186, accuracy: 0.965087890625\n",
            "Epoch: 75, learning_rate:[0.06566775047074733],costo: 0.11814528703689575, accuracy: 0.9677734375\n",
            "Epoch: 76, learning_rate:[0.056478328777323186],costo: 0.12738651037216187, accuracy: 0.96826171875\n",
            "Epoch: 77, learning_rate:[0.05582276542683759],costo: 0.13702404499053955, accuracy: 0.96826171875\n",
            "Epoch: 78, learning_rate:[0.03489247694380302],costo: 0.12604396045207977, accuracy: 0.966064453125\n",
            "Epoch: 79, learning_rate:[0.09488601205805305],costo: 0.1332542598247528, accuracy: 0.965087890625\n",
            "Epoch: 80, learning_rate:[0.09640251320228033],costo: 0.11667454987764359, accuracy: 0.96923828125\n",
            "Epoch: 81, learning_rate:[0.09690787277779292],costo: 0.1531318873167038, accuracy: 0.96484375\n",
            "Epoch: 82, learning_rate:[0.054512428611805774],costo: 0.12529096007347107, accuracy: 0.968994140625\n",
            "Epoch: 83, learning_rate:[0.01953647859165323],costo: 0.1554974466562271, accuracy: 0.9677734375\n",
            "Epoch: 84, learning_rate:[0.014137275058427733],costo: 0.10166364908218384, accuracy: 0.968017578125\n",
            "Epoch: 85, learning_rate:[0.017089334500188808],costo: 0.11241734772920609, accuracy: 0.967041015625\n",
            "Epoch: 86, learning_rate:[0.07091875616594445],costo: 0.09522506594657898, accuracy: 0.9658203125\n",
            "Epoch: 87, learning_rate:[0.09523499821068301],costo: 0.1416388601064682, accuracy: 0.970703125\n",
            "Epoch: 88, learning_rate:[0.01827254935962807],costo: 0.12106110900640488, accuracy: 0.96923828125\n",
            "Epoch: 89, learning_rate:[0.018133104225751418],costo: 0.10690220445394516, accuracy: 0.967529296875\n",
            "Epoch: 90, learning_rate:[0.012173503280413436],costo: 0.12435282766819, accuracy: 0.969482421875\n",
            "Epoch: 91, learning_rate:[0.06713701470210005],costo: 0.1079489216208458, accuracy: 0.966064453125\n",
            "Epoch: 92, learning_rate:[0.09813095826177717],costo: 0.13181637227535248, accuracy: 0.966796875\n",
            "Epoch: 93, learning_rate:[0.09900210363481568],costo: 0.1234700009226799, accuracy: 0.9716796875\n",
            "Epoch: 94, learning_rate:[0.07180490892532683],costo: 0.12221232056617737, accuracy: 0.9677734375\n",
            "Epoch: 95, learning_rate:[0.05853163272674368],costo: 0.11980339139699936, accuracy: 0.966796875\n",
            "Epoch: 96, learning_rate:[0.02789704763571759],costo: 0.1405596286058426, accuracy: 0.969482421875\n",
            "Epoch: 97, learning_rate:[0.05580365325477584],costo: 0.13495351374149323, accuracy: 0.97021484375\n",
            "Epoch: 98, learning_rate:[0.0706871611315707],costo: 0.10555266588926315, accuracy: 0.96875\n",
            "Epoch: 99, learning_rate:[0.09947094749246624],costo: 0.09134215116500854, accuracy: 0.970947265625\n",
            "Epoch: 100, learning_rate:[0.08205434305075919],costo: 0.15858682990074158, accuracy: 0.967041015625\n",
            "Epoch: 1, learning_rate:[0.06532002873768428],costo: 1.8807553052902222, accuracy: 0.71142578125\n",
            "Epoch: 2, learning_rate:[0.07174408283763978],costo: 1.154374122619629, accuracy: 0.8154296875\n",
            "Epoch: 3, learning_rate:[0.09768109427385749],costo: 0.6997673511505127, accuracy: 0.86083984375\n",
            "Epoch: 4, learning_rate:[0.0416213370511395],costo: 0.5963146090507507, accuracy: 0.843017578125\n",
            "Epoch: 5, learning_rate:[0.0359752309614701],costo: 0.49759191274642944, accuracy: 0.89501953125\n",
            "Epoch: 6, learning_rate:[0.02742121242049171],costo: 0.4808366894721985, accuracy: 0.894287109375\n",
            "Epoch: 7, learning_rate:[0.08352082130948599],costo: 0.4361514449119568, accuracy: 0.89990234375\n",
            "Epoch: 8, learning_rate:[0.09995472037374317],costo: 0.3823951780796051, accuracy: 0.904541015625\n",
            "Epoch: 9, learning_rate:[0.09997116302442309],costo: 0.5008612871170044, accuracy: 0.85791015625\n",
            "Epoch: 10, learning_rate:[0.04214128049898572],costo: 0.3840877115726471, accuracy: 0.91796875\n",
            "Epoch: 11, learning_rate:[0.01099556189030519],costo: 0.3590805232524872, accuracy: 0.91162109375\n",
            "Epoch: 12, learning_rate:[0.010550847445652102],costo: 0.36400580406188965, accuracy: 0.91796875\n",
            "Epoch: 13, learning_rate:[0.04676544051449865],costo: 0.3357091248035431, accuracy: 0.917724609375\n",
            "Epoch: 14, learning_rate:[0.051825263358385436],costo: 0.37052392959594727, accuracy: 0.919189453125\n",
            "Epoch: 15, learning_rate:[0.09704793708792268],costo: 0.34859344363212585, accuracy: 0.921630859375\n",
            "Epoch: 16, learning_rate:[0.03722895203154836],costo: 0.37641623616218567, accuracy: 0.91796875\n",
            "Epoch: 17, learning_rate:[0.021479327184552196],costo: 0.33568239212036133, accuracy: 0.922607421875\n",
            "Epoch: 18, learning_rate:[0.02142602036915197],costo: 0.32118430733680725, accuracy: 0.924560546875\n",
            "Epoch: 19, learning_rate:[0.06434885763879311],costo: 0.26708585023880005, accuracy: 0.924560546875\n",
            "Epoch: 20, learning_rate:[0.07405555380827004],costo: 0.29489418864250183, accuracy: 0.921630859375\n",
            "Epoch: 21, learning_rate:[0.09108240572273939],costo: 0.3517390787601471, accuracy: 0.9267578125\n",
            "Epoch: 22, learning_rate:[0.08611100534609717],costo: 0.2883315086364746, accuracy: 0.9296875\n",
            "Epoch: 23, learning_rate:[0.07001382163630877],costo: 0.34930482506752014, accuracy: 0.9248046875\n",
            "Epoch: 24, learning_rate:[0.022953947520705936],costo: 0.2450214922428131, accuracy: 0.933349609375\n",
            "Epoch: 25, learning_rate:[0.0253213836801232],costo: 0.2816859483718872, accuracy: 0.93798828125\n",
            "Epoch: 26, learning_rate:[0.03473084652275102],costo: 0.2629586160182953, accuracy: 0.936767578125\n",
            "Epoch: 27, learning_rate:[0.08597398312861411],costo: 0.23160846531391144, accuracy: 0.932373046875\n",
            "Epoch: 28, learning_rate:[0.07948674928875521],costo: 0.2810091972351074, accuracy: 0.93408203125\n",
            "Epoch: 29, learning_rate:[0.05552980462133966],costo: 0.25800275802612305, accuracy: 0.937255859375\n",
            "Epoch: 30, learning_rate:[0.027858512449465966],costo: 0.2538684010505676, accuracy: 0.937744140625\n",
            "Epoch: 31, learning_rate:[0.08620416109435358],costo: 0.2530145049095154, accuracy: 0.938720703125\n",
            "Epoch: 32, learning_rate:[0.09397335301596413],costo: 0.29311537742614746, accuracy: 0.939453125\n",
            "Epoch: 33, learning_rate:[0.09780998059589424],costo: 0.27403101325035095, accuracy: 0.937744140625\n",
            "Epoch: 34, learning_rate:[0.09258471751292566],costo: 0.24584481120109558, accuracy: 0.941650390625\n",
            "Epoch: 35, learning_rate:[0.054888615847227915],costo: 0.24357537925243378, accuracy: 0.947509765625\n",
            "Epoch: 36, learning_rate:[0.021374173899929457],costo: 0.19612304866313934, accuracy: 0.94482421875\n",
            "Epoch: 37, learning_rate:[0.04716095348686128],costo: 0.22960975766181946, accuracy: 0.942138671875\n",
            "Epoch: 38, learning_rate:[0.07361745312951024],costo: 0.22896169126033783, accuracy: 0.9501953125\n",
            "Epoch: 39, learning_rate:[0.08171633785979576],costo: 0.2591170072555542, accuracy: 0.950439453125\n",
            "Epoch: 40, learning_rate:[0.03665065049582605],costo: 0.20842693746089935, accuracy: 0.948486328125\n",
            "Epoch: 41, learning_rate:[0.03299933505809741],costo: 0.21424730122089386, accuracy: 0.949462890625\n",
            "Epoch: 42, learning_rate:[0.01730965751913156],costo: 0.20877912640571594, accuracy: 0.953369140625\n",
            "Epoch: 43, learning_rate:[0.02222463669854318],costo: 0.1901904195547104, accuracy: 0.95068359375\n",
            "Epoch: 44, learning_rate:[0.0704919614422497],costo: 0.20877626538276672, accuracy: 0.951904296875\n",
            "Epoch: 45, learning_rate:[0.09969625851278074],costo: 0.20851367712020874, accuracy: 0.94873046875\n",
            "Epoch: 46, learning_rate:[0.039434153147576215],costo: 0.1752142757177353, accuracy: 0.951171875\n",
            "Epoch: 47, learning_rate:[0.01725536204685642],costo: 0.18101510405540466, accuracy: 0.957763671875\n",
            "Epoch: 48, learning_rate:[0.015899379464955118],costo: 0.18602922558784485, accuracy: 0.95654296875\n",
            "Epoch: 49, learning_rate:[0.06748721468103443],costo: 0.15887926518917084, accuracy: 0.953125\n",
            "Epoch: 50, learning_rate:[0.0867917272514247],costo: 0.18192851543426514, accuracy: 0.949462890625\n",
            "Epoch: 51, learning_rate:[0.09313045947407876],costo: 0.18508946895599365, accuracy: 0.955078125\n",
            "Epoch: 52, learning_rate:[0.021200133560787635],costo: 0.18915115296840668, accuracy: 0.957763671875\n",
            "Epoch: 53, learning_rate:[0.017743033177900925],costo: 0.2201003134250641, accuracy: 0.952392578125\n",
            "Epoch: 54, learning_rate:[0.010494899032825165],costo: 0.14790894091129303, accuracy: 0.952392578125\n",
            "Epoch: 55, learning_rate:[0.06201608929196778],costo: 0.157553568482399, accuracy: 0.96044921875\n",
            "Epoch: 56, learning_rate:[0.08355619710752396],costo: 0.17346209287643433, accuracy: 0.961181640625\n",
            "Epoch: 57, learning_rate:[0.08415851950123175],costo: 0.20837314426898956, accuracy: 0.95703125\n",
            "Epoch: 58, learning_rate:[0.028364257422225495],costo: 0.15612627565860748, accuracy: 0.958251953125\n",
            "Epoch: 59, learning_rate:[0.010425780850457542],costo: 0.21225349605083466, accuracy: 0.956787109375\n",
            "Epoch: 60, learning_rate:[0.010320752506820643],costo: 0.1782914102077484, accuracy: 0.9580078125\n",
            "Epoch: 61, learning_rate:[0.04733905968227168],costo: 0.16378985345363617, accuracy: 0.95654296875\n",
            "Epoch: 62, learning_rate:[0.05603543944834434],costo: 0.18189817667007446, accuracy: 0.959716796875\n",
            "Epoch: 63, learning_rate:[0.08101257829855324],costo: 0.17172934114933014, accuracy: 0.9580078125\n",
            "Epoch: 64, learning_rate:[0.028773873391145406],costo: 0.15242315828800201, accuracy: 0.960693359375\n",
            "Epoch: 65, learning_rate:[0.023739040137534258],costo: 0.18503190577030182, accuracy: 0.956787109375\n",
            "Epoch: 66, learning_rate:[0.022718320427449132],costo: 0.14636197686195374, accuracy: 0.961669921875\n",
            "Epoch: 67, learning_rate:[0.054121019833763016],costo: 0.19500522315502167, accuracy: 0.9599609375\n",
            "Epoch: 68, learning_rate:[0.09749346444283166],costo: 0.17050836980342865, accuracy: 0.963623046875\n",
            "Epoch: 69, learning_rate:[0.09934419378238576],costo: 0.1600167602300644, accuracy: 0.96142578125\n",
            "Epoch: 70, learning_rate:[0.07003083498628118],costo: 0.14253728091716766, accuracy: 0.95703125\n",
            "Epoch: 71, learning_rate:[0.029924471939786576],costo: 0.14093375205993652, accuracy: 0.9599609375\n",
            "Epoch: 72, learning_rate:[0.014269592734419205],costo: 0.16429650783538818, accuracy: 0.96484375\n",
            "Epoch: 73, learning_rate:[0.015128386882452284],costo: 0.12156294286251068, accuracy: 0.96044921875\n",
            "Epoch: 74, learning_rate:[0.07620695048809327],costo: 0.1325000822544098, accuracy: 0.9609375\n",
            "Epoch: 75, learning_rate:[0.07681615704471528],costo: 0.14057286083698273, accuracy: 0.961181640625\n",
            "Epoch: 76, learning_rate:[0.06880943103344699],costo: 0.17406423389911652, accuracy: 0.965576171875\n",
            "Epoch: 77, learning_rate:[0.037084180658351444],costo: 0.14039964973926544, accuracy: 0.9638671875\n",
            "Epoch: 78, learning_rate:[0.01892411231077007],costo: 0.14985735714435577, accuracy: 0.96435546875\n",
            "Epoch: 79, learning_rate:[0.053881962516635594],costo: 0.14490707218647003, accuracy: 0.9619140625\n",
            "Epoch: 80, learning_rate:[0.07913277028921105],costo: 0.12074721604585648, accuracy: 0.96337890625\n",
            "Epoch: 81, learning_rate:[0.09991742922406736],costo: 0.15332536399364471, accuracy: 0.9658203125\n",
            "Epoch: 82, learning_rate:[0.04665067375918058],costo: 0.17690859735012054, accuracy: 0.965576171875\n",
            "Epoch: 83, learning_rate:[0.030472205709280435],costo: 0.1347339153289795, accuracy: 0.96533203125\n",
            "Epoch: 84, learning_rate:[0.02812646560306712],costo: 0.1404157131910324, accuracy: 0.9638671875\n",
            "Epoch: 85, learning_rate:[0.028220229031113493],costo: 0.11619038879871368, accuracy: 0.96435546875\n",
            "Epoch: 86, learning_rate:[0.06310377991406424],costo: 0.14078976213932037, accuracy: 0.96630859375\n",
            "Epoch: 87, learning_rate:[0.07774238593148378],costo: 0.16259323060512543, accuracy: 0.968505859375\n",
            "Epoch: 88, learning_rate:[0.06844325025699685],costo: 0.19044017791748047, accuracy: 0.96630859375\n",
            "Epoch: 89, learning_rate:[0.03263851175384757],costo: 0.1387578845024109, accuracy: 0.962158203125\n",
            "Epoch: 90, learning_rate:[0.025491620443150512],costo: 0.14677481353282928, accuracy: 0.96337890625\n",
            "Epoch: 91, learning_rate:[0.07237200350855189],costo: 0.12107639759778976, accuracy: 0.968994140625\n",
            "Epoch: 92, learning_rate:[0.08133409921814072],costo: 0.126242995262146, accuracy: 0.965087890625\n",
            "Epoch: 93, learning_rate:[0.09824014218739684],costo: 0.12992875277996063, accuracy: 0.96484375\n",
            "Epoch: 94, learning_rate:[0.09622348541964658],costo: 0.14681822061538696, accuracy: 0.966064453125\n",
            "Epoch: 95, learning_rate:[0.08613719201781775],costo: 0.13358370959758759, accuracy: 0.96875\n",
            "Epoch: 96, learning_rate:[0.04903095561622273],costo: 0.14454814791679382, accuracy: 0.968994140625\n",
            "Epoch: 97, learning_rate:[0.05658862458429037],costo: 0.11920661479234695, accuracy: 0.962158203125\n",
            "Epoch: 98, learning_rate:[0.05836194792444837],costo: 0.1353248804807663, accuracy: 0.968505859375\n",
            "Epoch: 99, learning_rate:[0.0924867086144002],costo: 0.1236160472035408, accuracy: 0.96923828125\n",
            "Epoch: 100, learning_rate:[0.034507694102513704],costo: 0.1054658517241478, accuracy: 0.96533203125\n",
            "Epoch: 1, learning_rate:[0.08680846933953394],costo: 1.856278657913208, accuracy: 0.732666015625\n",
            "Epoch: 2, learning_rate:[0.08947386652195716],costo: 0.9529168009757996, accuracy: 0.848388671875\n",
            "Epoch: 3, learning_rate:[0.09456259053927127],costo: 0.6487683057785034, accuracy: 0.83837890625\n",
            "Epoch: 4, learning_rate:[0.08445207022582917],costo: 0.5568501949310303, accuracy: 0.88720703125\n",
            "Epoch: 5, learning_rate:[0.08320101030165897],costo: 0.42688965797424316, accuracy: 0.883056640625\n",
            "Epoch: 6, learning_rate:[0.0581969191691188],costo: 0.39819130301475525, accuracy: 0.903564453125\n",
            "Epoch: 7, learning_rate:[0.09811058961071453],costo: 0.405516654253006, accuracy: 0.902099609375\n",
            "Epoch: 8, learning_rate:[0.09912613179132117],costo: 0.38515084981918335, accuracy: 0.907470703125\n",
            "Epoch: 9, learning_rate:[0.09987132499263038],costo: 0.38913342356681824, accuracy: 0.912841796875\n",
            "Epoch: 10, learning_rate:[0.09678414450627884],costo: 0.33323854207992554, accuracy: 0.9208984375\n",
            "Epoch: 11, learning_rate:[0.047332261885108605],costo: 0.35382312536239624, accuracy: 0.921875\n",
            "Epoch: 12, learning_rate:[0.013264212797581929],costo: 0.25709354877471924, accuracy: 0.92333984375\n",
            "Epoch: 13, learning_rate:[0.037473254535257766],costo: 0.31844350695610046, accuracy: 0.92626953125\n",
            "Epoch: 14, learning_rate:[0.055775500161519984],costo: 0.31140169501304626, accuracy: 0.931640625\n",
            "Epoch: 15, learning_rate:[0.09840742851286827],costo: 0.33228600025177, accuracy: 0.923583984375\n",
            "Epoch: 16, learning_rate:[0.09617456901294172],costo: 0.3139888048171997, accuracy: 0.927734375\n",
            "Epoch: 17, learning_rate:[0.08603467586362096],costo: 0.2744879126548767, accuracy: 0.9326171875\n",
            "Epoch: 18, learning_rate:[0.04681372601169426],costo: 0.30748897790908813, accuracy: 0.928955078125\n",
            "Epoch: 19, learning_rate:[0.07870211053974828],costo: 0.23639953136444092, accuracy: 0.936767578125\n",
            "Epoch: 20, learning_rate:[0.0998434556634533],costo: 0.25361523032188416, accuracy: 0.93505859375\n",
            "Epoch: 21, learning_rate:[0.09984640381114984],costo: 0.24811314046382904, accuracy: 0.93310546875\n",
            "Epoch: 22, learning_rate:[0.09072656155492625],costo: 0.2666269540786743, accuracy: 0.934814453125\n",
            "Epoch: 23, learning_rate:[0.04603345744356637],costo: 0.2827228903770447, accuracy: 0.940673828125\n",
            "Epoch: 24, learning_rate:[0.03780163946795825],costo: 0.21947236359119415, accuracy: 0.93994140625\n",
            "Epoch: 25, learning_rate:[0.04016428804884984],costo: 0.23332399129867554, accuracy: 0.938232421875\n",
            "Epoch: 26, learning_rate:[0.05064497271464791],costo: 0.22966842353343964, accuracy: 0.944580078125\n",
            "Epoch: 27, learning_rate:[0.06537651404860742],costo: 0.25297218561172485, accuracy: 0.944580078125\n",
            "Epoch: 28, learning_rate:[0.023215609298726018],costo: 0.19999589025974274, accuracy: 0.93798828125\n",
            "Epoch: 29, learning_rate:[0.01827225842162355],costo: 0.2634705901145935, accuracy: 0.94384765625\n",
            "Epoch: 30, learning_rate:[0.012946471320747721],costo: 0.2538101375102997, accuracy: 0.94775390625\n",
            "Epoch: 31, learning_rate:[0.04049956796292112],costo: 0.23078884184360504, accuracy: 0.94873046875\n",
            "Epoch: 32, learning_rate:[0.08963587170593391],costo: 0.23883742094039917, accuracy: 0.942626953125\n",
            "Epoch: 33, learning_rate:[0.09799116916498864],costo: 0.21529293060302734, accuracy: 0.9443359375\n",
            "Epoch: 34, learning_rate:[0.025066404868531456],costo: 0.22448375821113586, accuracy: 0.95068359375\n",
            "Epoch: 35, learning_rate:[0.01226568266841393],costo: 0.21573536098003387, accuracy: 0.945068359375\n",
            "Epoch: 36, learning_rate:[0.01121432086194855],costo: 0.22152599692344666, accuracy: 0.95263671875\n",
            "Epoch: 37, learning_rate:[0.03883778134919593],costo: 0.21926705539226532, accuracy: 0.95361328125\n",
            "Epoch: 38, learning_rate:[0.03952917048644121],costo: 0.20429687201976776, accuracy: 0.950927734375\n",
            "Epoch: 39, learning_rate:[0.0798330200189582],costo: 0.22719718515872955, accuracy: 0.953369140625\n",
            "Epoch: 40, learning_rate:[0.06112105125156788],costo: 0.18206362426280975, accuracy: 0.953369140625\n",
            "Epoch: 41, learning_rate:[0.06101712898661111],costo: 0.24182626605033875, accuracy: 0.953125\n",
            "Epoch: 42, learning_rate:[0.038717711881256466],costo: 0.18747423589229584, accuracy: 0.95361328125\n",
            "Epoch: 43, learning_rate:[0.04676527013718159],costo: 0.17631202936172485, accuracy: 0.953125\n",
            "Epoch: 44, learning_rate:[0.0592665144756684],costo: 0.1760442852973938, accuracy: 0.954345703125\n",
            "Epoch: 45, learning_rate:[0.09342562603793558],costo: 0.21512086689472198, accuracy: 0.9580078125\n",
            "Epoch: 46, learning_rate:[0.08397730041925458],costo: 0.1890634298324585, accuracy: 0.9560546875\n",
            "Epoch: 47, learning_rate:[0.0129477388386792],costo: 0.18358033895492554, accuracy: 0.958251953125\n",
            "Epoch: 48, learning_rate:[0.01165515975236246],costo: 0.20374755561351776, accuracy: 0.956787109375\n",
            "Epoch: 49, learning_rate:[0.06847460549995235],costo: 0.18498845398426056, accuracy: 0.951171875\n",
            "Epoch: 50, learning_rate:[0.08320989253028703],costo: 0.19516511261463165, accuracy: 0.96044921875\n",
            "Epoch: 51, learning_rate:[0.08935223926252094],costo: 0.1760711669921875, accuracy: 0.954345703125\n",
            "Epoch: 52, learning_rate:[0.03805574449383495],costo: 0.16710273921489716, accuracy: 0.9580078125\n",
            "Epoch: 53, learning_rate:[0.023259786119370393],costo: 0.14448237419128418, accuracy: 0.9619140625\n",
            "Epoch: 54, learning_rate:[0.011123316915522648],costo: 0.17900919914245605, accuracy: 0.957763671875\n",
            "Epoch: 55, learning_rate:[0.0941105948686589],costo: 0.150689959526062, accuracy: 0.95751953125\n",
            "Epoch: 56, learning_rate:[0.09470103775533735],costo: 0.18599918484687805, accuracy: 0.9599609375\n",
            "Epoch: 57, learning_rate:[0.09551762976453994],costo: 0.16021262109279633, accuracy: 0.959716796875\n",
            "Epoch: 58, learning_rate:[0.05833148560801833],costo: 0.21052207052707672, accuracy: 0.957275390625\n",
            "Epoch: 59, learning_rate:[0.026568764805326515],costo: 0.1661141812801361, accuracy: 0.9638671875\n",
            "Epoch: 60, learning_rate:[0.026060649060725492],costo: 0.16896115243434906, accuracy: 0.963134765625\n",
            "Epoch: 61, learning_rate:[0.09996143268922753],costo: 0.163209468126297, accuracy: 0.959716796875\n",
            "Epoch: 62, learning_rate:[0.09999912910014543],costo: 0.16318006813526154, accuracy: 0.9658203125\n",
            "Epoch: 63, learning_rate:[0.09999991618203954],costo: 0.15195997059345245, accuracy: 0.967529296875\n",
            "Epoch: 64, learning_rate:[0.05351007353378994],costo: 0.14879019558429718, accuracy: 0.9599609375\n",
            "Epoch: 65, learning_rate:[0.025562312074378795],costo: 0.15683385729789734, accuracy: 0.96337890625\n",
            "Epoch: 66, learning_rate:[0.015581560560787223],costo: 0.2042112648487091, accuracy: 0.96728515625\n",
            "Epoch: 67, learning_rate:[0.06581130407041999],costo: 0.20214323699474335, accuracy: 0.96337890625\n",
            "Epoch: 68, learning_rate:[0.08352906225095752],costo: 0.17980024218559265, accuracy: 0.961669921875\n",
            "Epoch: 69, learning_rate:[0.08897908095621027],costo: 0.1507013887166977, accuracy: 0.966552734375\n",
            "Epoch: 70, learning_rate:[0.05654935353338174],costo: 0.1589168906211853, accuracy: 0.96142578125\n",
            "Epoch: 71, learning_rate:[0.026018023583419515],costo: 0.14560596644878387, accuracy: 0.964111328125\n",
            "Epoch: 72, learning_rate:[0.01572190627164173],costo: 0.0979827418923378, accuracy: 0.966796875\n",
            "Epoch: 73, learning_rate:[0.0745983404340328],costo: 0.15078096091747284, accuracy: 0.965087890625\n",
            "Epoch: 74, learning_rate:[0.08880100328696178],costo: 0.1687585413455963, accuracy: 0.966552734375\n",
            "Epoch: 75, learning_rate:[0.097618588232211],costo: 0.14819729328155518, accuracy: 0.964599609375\n",
            "Epoch: 76, learning_rate:[0.03258035238431767],costo: 0.15326127409934998, accuracy: 0.96728515625\n",
            "Epoch: 77, learning_rate:[0.02278993500323498],costo: 0.11956857144832611, accuracy: 0.967041015625\n",
            "Epoch: 78, learning_rate:[0.020701048325905677],costo: 0.19198714196681976, accuracy: 0.966796875\n",
            "Epoch: 79, learning_rate:[0.07980790854527113],costo: 0.17005382478237152, accuracy: 0.96923828125\n",
            "Epoch: 80, learning_rate:[0.09133333669902025],costo: 0.15218831598758698, accuracy: 0.967529296875\n",
            "Epoch: 81, learning_rate:[0.09891887721394985],costo: 0.11714667081832886, accuracy: 0.969482421875\n",
            "Epoch: 82, learning_rate:[0.08622884338097941],costo: 0.14725595712661743, accuracy: 0.9638671875\n",
            "Epoch: 83, learning_rate:[0.08076534040506311],costo: 0.13255749642848969, accuracy: 0.970703125\n",
            "Epoch: 84, learning_rate:[0.032916297501405435],costo: 0.11726587265729904, accuracy: 0.968505859375\n",
            "Epoch: 85, learning_rate:[0.09743224510868906],costo: 0.127365842461586, accuracy: 0.967041015625\n",
            "Epoch: 86, learning_rate:[0.09904706870902195],costo: 0.13817860186100006, accuracy: 0.966796875\n",
            "Epoch: 87, learning_rate:[0.09930879527978602],costo: 0.10965696722269058, accuracy: 0.96923828125\n",
            "Epoch: 88, learning_rate:[0.049885303737133166],costo: 0.12409744411706924, accuracy: 0.96923828125\n",
            "Epoch: 89, learning_rate:[0.027589009076352297],costo: 0.09380998462438583, accuracy: 0.970458984375\n",
            "Epoch: 90, learning_rate:[0.018399867546330155],costo: 0.08984792232513428, accuracy: 0.9736328125\n",
            "Epoch: 91, learning_rate:[0.04919038982461993],costo: 0.11009535938501358, accuracy: 0.968505859375\n",
            "Epoch: 92, learning_rate:[0.05071273144009147],costo: 0.12328754365444183, accuracy: 0.968505859375\n",
            "Epoch: 93, learning_rate:[0.06937129215433302],costo: 0.11238237470388412, accuracy: 0.968505859375\n",
            "Epoch: 94, learning_rate:[0.04550308258212284],costo: 0.08044493943452835, accuracy: 0.97705078125\n",
            "Epoch: 95, learning_rate:[0.035504021516450913],costo: 0.10994750261306763, accuracy: 0.973876953125\n",
            "Epoch: 96, learning_rate:[0.023698329033321808],costo: 0.11853625625371933, accuracy: 0.96923828125\n",
            "Epoch: 97, learning_rate:[0.03058204891550855],costo: 0.10782147198915482, accuracy: 0.973388671875\n",
            "Epoch: 98, learning_rate:[0.08411829300794957],costo: 0.10764976590871811, accuracy: 0.96728515625\n",
            "Epoch: 99, learning_rate:[0.09437561375210221],costo: 0.1002306193113327, accuracy: 0.9716796875\n",
            "Epoch: 100, learning_rate:[0.038413795784351196],costo: 0.11511430144309998, accuracy: 0.9697265625\n",
            "Epoch: 1, learning_rate:[0.0943473292442042],costo: 1.5871537923812866, accuracy: 0.7626953125\n",
            "Epoch: 2, learning_rate:[0.09618783579085159],costo: 0.7664044499397278, accuracy: 0.84814453125\n",
            "Epoch: 3, learning_rate:[0.09914048037071864],costo: 0.5850011706352234, accuracy: 0.842529296875\n",
            "Epoch: 4, learning_rate:[0.09787220673245008],costo: 0.5518777370452881, accuracy: 0.869873046875\n",
            "Epoch: 5, learning_rate:[0.07750026905478823],costo: 0.42469558119773865, accuracy: 0.902099609375\n",
            "Epoch: 6, learning_rate:[0.05825636532079988],costo: 0.39888137578964233, accuracy: 0.907958984375\n",
            "Epoch: 7, learning_rate:[0.06664858711458232],costo: 0.39212411642074585, accuracy: 0.901123046875\n",
            "Epoch: 8, learning_rate:[0.09161299512879767],costo: 0.36676764488220215, accuracy: 0.911376953125\n",
            "Epoch: 9, learning_rate:[0.0982167193378857],costo: 0.34225964546203613, accuracy: 0.91015625\n",
            "Epoch: 10, learning_rate:[0.042116145534054496],costo: 0.3438106179237366, accuracy: 0.918212890625\n",
            "Epoch: 11, learning_rate:[0.030849438031859015],costo: 0.3180346190929413, accuracy: 0.921142578125\n",
            "Epoch: 12, learning_rate:[0.03018550778559543],costo: 0.31516700983047485, accuracy: 0.9228515625\n",
            "Epoch: 13, learning_rate:[0.0327899356740962],costo: 0.3219975531101227, accuracy: 0.919921875\n",
            "Epoch: 14, learning_rate:[0.0855489599770487],costo: 0.3648040294647217, accuracy: 0.92333984375\n",
            "Epoch: 15, learning_rate:[0.08762724512931035],costo: 0.3118817210197449, accuracy: 0.92236328125\n",
            "Epoch: 16, learning_rate:[0.02277616386441441],costo: 0.2978391945362091, accuracy: 0.925537109375\n",
            "Epoch: 17, learning_rate:[0.015357670434738336],costo: 0.3013618290424347, accuracy: 0.925537109375\n",
            "Epoch: 18, learning_rate:[0.011269798516996013],costo: 0.3094714283943176, accuracy: 0.9287109375\n",
            "Epoch: 19, learning_rate:[0.024480941695191098],costo: 0.2366175800561905, accuracy: 0.925537109375\n",
            "Epoch: 20, learning_rate:[0.09889688194007099],costo: 0.2927674353122711, accuracy: 0.922119140625\n",
            "Epoch: 21, learning_rate:[0.09983673222840495],costo: 0.26608479022979736, accuracy: 0.930419921875\n",
            "Epoch: 22, learning_rate:[0.0852194177648334],costo: 0.28414347767829895, accuracy: 0.931396484375\n",
            "Epoch: 23, learning_rate:[0.01399420548958425],costo: 0.2327398657798767, accuracy: 0.931396484375\n",
            "Epoch: 24, learning_rate:[0.011879608868313386],costo: 0.24978548288345337, accuracy: 0.931640625\n",
            "Epoch: 25, learning_rate:[0.09649628026536808],costo: 0.24153976142406464, accuracy: 0.93505859375\n",
            "Epoch: 26, learning_rate:[0.09737930814199555],costo: 0.26202839612960815, accuracy: 0.934814453125\n",
            "Epoch: 27, learning_rate:[0.09956286045630312],costo: 0.2936691641807556, accuracy: 0.93896484375\n",
            "Epoch: 28, learning_rate:[0.01731507598984687],costo: 0.22459156811237335, accuracy: 0.9423828125\n",
            "Epoch: 29, learning_rate:[0.010078364422722832],costo: 0.23408763110637665, accuracy: 0.9375\n",
            "Epoch: 30, learning_rate:[0.010035718623094313],costo: 0.24422140419483185, accuracy: 0.942626953125\n",
            "Epoch: 31, learning_rate:[0.043450191448692395],costo: 0.33340805768966675, accuracy: 0.94189453125\n",
            "Epoch: 32, learning_rate:[0.0563647590752191],costo: 0.31156471371650696, accuracy: 0.939697265625\n",
            "Epoch: 33, learning_rate:[0.07600634734092837],costo: 0.21547895669937134, accuracy: 0.947998046875\n",
            "Epoch: 34, learning_rate:[0.07279574869499668],costo: 0.23206131160259247, accuracy: 0.937255859375\n",
            "Epoch: 35, learning_rate:[0.06133728308510121],costo: 0.21723313629627228, accuracy: 0.93896484375\n",
            "Epoch: 36, learning_rate:[0.010571519156878647],costo: 0.23460553586483002, accuracy: 0.9462890625\n",
            "Epoch: 37, learning_rate:[0.05589726104417342],costo: 0.21897083520889282, accuracy: 0.947998046875\n",
            "Epoch: 38, learning_rate:[0.056982756950081995],costo: 0.20285898447036743, accuracy: 0.94970703125\n",
            "Epoch: 39, learning_rate:[0.061312659204533264],costo: 0.20759744942188263, accuracy: 0.94970703125\n",
            "Epoch: 40, learning_rate:[0.03621308807414621],costo: 0.2049712985754013, accuracy: 0.95068359375\n",
            "Epoch: 41, learning_rate:[0.020040723204871127],costo: 0.22021746635437012, accuracy: 0.947509765625\n",
            "Epoch: 42, learning_rate:[0.0145145435117367],costo: 0.2047077715396881, accuracy: 0.94580078125\n",
            "Epoch: 43, learning_rate:[0.053398621981948745],costo: 0.21084879338741302, accuracy: 0.955078125\n",
            "Epoch: 44, learning_rate:[0.05993199116635278],costo: 0.20402581989765167, accuracy: 0.951416015625\n",
            "Epoch: 45, learning_rate:[0.06862513020341932],costo: 0.21772617101669312, accuracy: 0.955322265625\n",
            "Epoch: 46, learning_rate:[0.016156451972177452],costo: 0.1769111156463623, accuracy: 0.95703125\n",
            "Epoch: 47, learning_rate:[0.015262296241846832],costo: 0.20092695951461792, accuracy: 0.950439453125\n",
            "Epoch: 48, learning_rate:[0.010579279173317852],costo: 0.2074376791715622, accuracy: 0.95361328125\n",
            "Epoch: 49, learning_rate:[0.033529337956407196],costo: 0.18698354065418243, accuracy: 0.950439453125\n",
            "Epoch: 50, learning_rate:[0.04618596947268863],costo: 0.18166545033454895, accuracy: 0.95556640625\n",
            "Epoch: 51, learning_rate:[0.06544943047311957],costo: 0.17282968759536743, accuracy: 0.9521484375\n",
            "Epoch: 52, learning_rate:[0.04865546247304138],costo: 0.1640186607837677, accuracy: 0.958251953125\n",
            "Epoch: 53, learning_rate:[0.037949261823071685],costo: 0.1971345990896225, accuracy: 0.951416015625\n",
            "Epoch: 54, learning_rate:[0.03792680689771557],costo: 0.16822054982185364, accuracy: 0.955810546875\n",
            "Epoch: 55, learning_rate:[0.08238794906665545],costo: 0.1756303757429123, accuracy: 0.957275390625\n",
            "Epoch: 56, learning_rate:[0.09810135729725444],costo: 0.20426976680755615, accuracy: 0.954345703125\n",
            "Epoch: 57, learning_rate:[0.09839030347767436],costo: 0.178954616189003, accuracy: 0.95703125\n",
            "Epoch: 58, learning_rate:[0.08208067687770743],costo: 0.15328598022460938, accuracy: 0.95849609375\n",
            "Epoch: 59, learning_rate:[0.03464564558604607],costo: 0.16334481537342072, accuracy: 0.956787109375\n",
            "Epoch: 60, learning_rate:[0.030450920832355587],costo: 0.18423521518707275, accuracy: 0.95458984375\n",
            "Epoch: 61, learning_rate:[0.07233668552344644],costo: 0.19884264469146729, accuracy: 0.9560546875\n",
            "Epoch: 62, learning_rate:[0.0967703644799463],costo: 0.1468898504972458, accuracy: 0.959228515625\n",
            "Epoch: 63, learning_rate:[0.09784274336248223],costo: 0.168707013130188, accuracy: 0.96435546875\n",
            "Epoch: 64, learning_rate:[0.040391830537758036],costo: 0.17991171777248383, accuracy: 0.960205078125\n",
            "Epoch: 65, learning_rate:[0.013953498071603069],costo: 0.1395864635705948, accuracy: 0.95849609375\n",
            "Epoch: 66, learning_rate:[0.010857429230144645],costo: 0.17323839664459229, accuracy: 0.96240234375\n",
            "Epoch: 67, learning_rate:[0.057258667106296776],costo: 0.13053971529006958, accuracy: 0.96044921875\n",
            "Epoch: 68, learning_rate:[0.06939982465657955],costo: 0.16512489318847656, accuracy: 0.962646484375\n",
            "Epoch: 69, learning_rate:[0.0785277881634803],costo: 0.17485004663467407, accuracy: 0.964599609375\n",
            "Epoch: 70, learning_rate:[0.0685485521830935],costo: 0.14032651484012604, accuracy: 0.9609375\n",
            "Epoch: 71, learning_rate:[0.044129368649376534],costo: 0.15595367550849915, accuracy: 0.959228515625\n",
            "Epoch: 72, learning_rate:[0.041850377490248156],costo: 0.16816258430480957, accuracy: 0.963134765625\n",
            "Epoch: 73, learning_rate:[0.09112386194122067],costo: 0.1451902538537979, accuracy: 0.964111328125\n",
            "Epoch: 74, learning_rate:[0.09566788079787009],costo: 0.1607581079006195, accuracy: 0.9658203125\n",
            "Epoch: 75, learning_rate:[0.09908535019819449],costo: 0.14654287695884705, accuracy: 0.966064453125\n",
            "Epoch: 76, learning_rate:[0.04121815457352474],costo: 0.14846041798591614, accuracy: 0.959228515625\n",
            "Epoch: 77, learning_rate:[0.013555951805793557],costo: 0.10465863347053528, accuracy: 0.961669921875\n",
            "Epoch: 78, learning_rate:[0.012167359171151934],costo: 0.13570015132427216, accuracy: 0.966064453125\n",
            "Epoch: 79, learning_rate:[0.016362094199667932],costo: 0.12010440230369568, accuracy: 0.963623046875\n",
            "Epoch: 80, learning_rate:[0.053869300206949675],costo: 0.1510668843984604, accuracy: 0.9619140625\n",
            "Epoch: 81, learning_rate:[0.05621525096546148],costo: 0.15070976316928864, accuracy: 0.963134765625\n",
            "Epoch: 82, learning_rate:[0.02198434596371905],costo: 0.14290623366832733, accuracy: 0.96142578125\n",
            "Epoch: 83, learning_rate:[0.021522334454699386],costo: 0.1284359246492386, accuracy: 0.965087890625\n",
            "Epoch: 84, learning_rate:[0.019837296847710725],costo: 0.13106916844844818, accuracy: 0.965576171875\n",
            "Epoch: 85, learning_rate:[0.08940432938005587],costo: 0.16254423558712006, accuracy: 0.966552734375\n",
            "Epoch: 86, learning_rate:[0.09286966548726294],costo: 0.12360766530036926, accuracy: 0.966796875\n",
            "Epoch: 87, learning_rate:[0.0929796772106539],costo: 0.12853050231933594, accuracy: 0.966064453125\n",
            "Epoch: 88, learning_rate:[0.05772116130416599],costo: 0.13080614805221558, accuracy: 0.962890625\n",
            "Epoch: 89, learning_rate:[0.051006613606200464],costo: 0.1282733827829361, accuracy: 0.9638671875\n",
            "Epoch: 90, learning_rate:[0.039250976027923504],costo: 0.1405952274799347, accuracy: 0.968505859375\n",
            "Epoch: 91, learning_rate:[0.06728773542818171],costo: 0.137057825922966, accuracy: 0.970947265625\n",
            "Epoch: 92, learning_rate:[0.07884141494537875],costo: 0.12931297719478607, accuracy: 0.97314453125\n",
            "Epoch: 93, learning_rate:[0.08516675309309049],costo: 0.1290828436613083, accuracy: 0.966796875\n",
            "Epoch: 94, learning_rate:[0.0327614479875171],costo: 0.12629194557666779, accuracy: 0.970458984375\n",
            "Epoch: 95, learning_rate:[0.010127060332826588],costo: 0.14494304358959198, accuracy: 0.97021484375\n",
            "Epoch: 96, learning_rate:[0.01008811695488392],costo: 0.10988162457942963, accuracy: 0.962890625\n",
            "Epoch: 97, learning_rate:[0.08272688120811336],costo: 0.11907946318387985, accuracy: 0.96728515625\n",
            "Epoch: 98, learning_rate:[0.09689831668229316],costo: 0.106087327003479, accuracy: 0.968017578125\n",
            "Epoch: 99, learning_rate:[0.09958925734774889],costo: 0.10792277753353119, accuracy: 0.96728515625\n",
            "Epoch: 100, learning_rate:[0.07422084125050496],costo: 0.1829715073108673, accuracy: 0.96875\n",
            "Epoch: 1, learning_rate:[0.06535118038795736],costo: 2.0757668018341064, accuracy: 0.67138671875\n",
            "Epoch: 2, learning_rate:[0.07576448370203961],costo: 1.4099230766296387, accuracy: 0.785888671875\n",
            "Epoch: 3, learning_rate:[0.09359895909947832],costo: 0.7880027890205383, accuracy: 0.86376953125\n",
            "Epoch: 4, learning_rate:[0.05809535734693404],costo: 0.594431459903717, accuracy: 0.8232421875\n",
            "Epoch: 5, learning_rate:[0.03803155234969063],costo: 0.4930585026741028, accuracy: 0.893310546875\n",
            "Epoch: 6, learning_rate:[0.019896910954887416],costo: 0.462985098361969, accuracy: 0.897216796875\n",
            "Epoch: 7, learning_rate:[0.02240395756408924],costo: 0.47196048498153687, accuracy: 0.89697265625\n",
            "Epoch: 8, learning_rate:[0.061961682071454124],costo: 0.4304724335670471, accuracy: 0.90771484375\n",
            "Epoch: 9, learning_rate:[0.0814980310893675],costo: 0.4232952296733856, accuracy: 0.910888671875\n",
            "Epoch: 10, learning_rate:[0.06447963237641341],costo: 0.4337593913078308, accuracy: 0.900146484375\n",
            "Epoch: 11, learning_rate:[0.04539122728371413],costo: 0.3819717764854431, accuracy: 0.90283203125\n",
            "Epoch: 12, learning_rate:[0.015003175965106072],costo: 0.39087316393852234, accuracy: 0.91650390625\n",
            "Epoch: 13, learning_rate:[0.09414799001957458],costo: 0.3692149817943573, accuracy: 0.9228515625\n",
            "Epoch: 14, learning_rate:[0.09553779845423072],costo: 0.35371747612953186, accuracy: 0.9091796875\n",
            "Epoch: 15, learning_rate:[0.09879244111637486],costo: 0.3085312843322754, accuracy: 0.921875\n",
            "Epoch: 16, learning_rate:[0.024392984426798277],costo: 0.308838814496994, accuracy: 0.923583984375\n",
            "Epoch: 17, learning_rate:[0.022219364516100557],costo: 0.3422565758228302, accuracy: 0.92236328125\n",
            "Epoch: 18, learning_rate:[0.021088268000560018],costo: 0.31633225083351135, accuracy: 0.924072265625\n",
            "Epoch: 19, learning_rate:[0.07172402653654093],costo: 0.3121601641178131, accuracy: 0.927734375\n",
            "Epoch: 20, learning_rate:[0.07291559713049404],costo: 0.30754902958869934, accuracy: 0.930908203125\n",
            "Epoch: 21, learning_rate:[0.0999943136527498],costo: 0.31157174706459045, accuracy: 0.928955078125\n",
            "Epoch: 22, learning_rate:[0.09586848728906465],costo: 0.3052893579006195, accuracy: 0.926025390625\n",
            "Epoch: 23, learning_rate:[0.07861583858106153],costo: 0.2877390384674072, accuracy: 0.93017578125\n",
            "Epoch: 24, learning_rate:[0.0543014936742556],costo: 0.2905789911746979, accuracy: 0.9287109375\n",
            "Epoch: 25, learning_rate:[0.06488886167197536],costo: 0.28008103370666504, accuracy: 0.938720703125\n",
            "Epoch: 26, learning_rate:[0.07791023203990502],costo: 0.30157530307769775, accuracy: 0.9326171875\n",
            "Epoch: 27, learning_rate:[0.0975423593430794],costo: 0.27567368745803833, accuracy: 0.937744140625\n",
            "Epoch: 28, learning_rate:[0.05857058714061638],costo: 0.2283513993024826, accuracy: 0.940185546875\n",
            "Epoch: 29, learning_rate:[0.022267551641306792],costo: 0.2286263257265091, accuracy: 0.944580078125\n",
            "Epoch: 30, learning_rate:[0.011573961447475163],costo: 0.25536447763442993, accuracy: 0.941650390625\n",
            "Epoch: 31, learning_rate:[0.02103996588417456],costo: 0.22045962512493134, accuracy: 0.938720703125\n",
            "Epoch: 32, learning_rate:[0.0879497575849683],costo: 0.23010003566741943, accuracy: 0.940673828125\n",
            "Epoch: 33, learning_rate:[0.0993698880155936],costo: 0.21260207891464233, accuracy: 0.94091796875\n",
            "Epoch: 34, learning_rate:[0.014128086094706973],costo: 0.22655975818634033, accuracy: 0.93798828125\n",
            "Epoch: 35, learning_rate:[0.012626233403890123],costo: 0.24463967978954315, accuracy: 0.94287109375\n",
            "Epoch: 36, learning_rate:[0.012071655942226417],costo: 0.2742727994918823, accuracy: 0.9462890625\n",
            "Epoch: 37, learning_rate:[0.07990281155264652],costo: 0.22899645566940308, accuracy: 0.946533203125\n",
            "Epoch: 38, learning_rate:[0.08186542703808881],costo: 0.20485663414001465, accuracy: 0.946044921875\n",
            "Epoch: 39, learning_rate:[0.09387462212487865],costo: 0.1922161728143692, accuracy: 0.948486328125\n",
            "Epoch: 40, learning_rate:[0.056574604822031145],costo: 0.24036946892738342, accuracy: 0.947021484375\n",
            "Epoch: 41, learning_rate:[0.043953166781177264],costo: 0.2275482714176178, accuracy: 0.949951171875\n",
            "Epoch: 42, learning_rate:[0.021940866787464687],costo: 0.18510781228542328, accuracy: 0.94921875\n",
            "Epoch: 43, learning_rate:[0.07182948682447673],costo: 0.1844334453344345, accuracy: 0.946533203125\n",
            "Epoch: 44, learning_rate:[0.07542315618605014],costo: 0.22997255623340607, accuracy: 0.94775390625\n",
            "Epoch: 45, learning_rate:[0.09605653379658258],costo: 0.23816724121570587, accuracy: 0.9462890625\n",
            "Epoch: 46, learning_rate:[0.029714606334400408],costo: 0.20969215035438538, accuracy: 0.955810546875\n",
            "Epoch: 47, learning_rate:[0.023006555061988697],costo: 0.20958958566188812, accuracy: 0.955078125\n",
            "Epoch: 48, learning_rate:[0.01944835339199908],costo: 0.21744690835475922, accuracy: 0.952392578125\n",
            "Epoch: 49, learning_rate:[0.09939853021186298],costo: 0.22707751393318176, accuracy: 0.954833984375\n",
            "Epoch: 50, learning_rate:[0.09981750762121452],costo: 0.19341155886650085, accuracy: 0.955322265625\n",
            "Epoch: 51, learning_rate:[0.09984687530500437],costo: 0.18179789185523987, accuracy: 0.9560546875\n",
            "Epoch: 52, learning_rate:[0.04322275628966573],costo: 0.1793050467967987, accuracy: 0.955078125\n",
            "Epoch: 53, learning_rate:[0.031558976753059055],costo: 0.16781418025493622, accuracy: 0.955078125\n",
            "Epoch: 54, learning_rate:[0.01846066390766444],costo: 0.1845695972442627, accuracy: 0.959228515625\n",
            "Epoch: 55, learning_rate:[0.05828430713107008],costo: 0.2032005935907364, accuracy: 0.962890625\n",
            "Epoch: 56, learning_rate:[0.09744109290577183],costo: 0.20089727640151978, accuracy: 0.955322265625\n",
            "Epoch: 57, learning_rate:[0.09861991012215614],costo: 0.204212948679924, accuracy: 0.95947265625\n",
            "Epoch: 58, learning_rate:[0.05121217631260585],costo: 0.17270506918430328, accuracy: 0.957275390625\n",
            "Epoch: 59, learning_rate:[0.01869214665489443],costo: 0.16269226372241974, accuracy: 0.957275390625\n",
            "Epoch: 60, learning_rate:[0.013997128281813969],costo: 0.16692033410072327, accuracy: 0.96142578125\n",
            "Epoch: 61, learning_rate:[0.046389523017213594],costo: 0.23561596870422363, accuracy: 0.96240234375\n",
            "Epoch: 62, learning_rate:[0.09565772831348279],costo: 0.16606365144252777, accuracy: 0.958740234375\n",
            "Epoch: 63, learning_rate:[0.09702554592206346],costo: 0.1580452173948288, accuracy: 0.9599609375\n",
            "Epoch: 64, learning_rate:[0.08402023896531238],costo: 0.17421123385429382, accuracy: 0.96337890625\n",
            "Epoch: 65, learning_rate:[0.05595039263549513],costo: 0.18032565712928772, accuracy: 0.96240234375\n",
            "Epoch: 66, learning_rate:[0.04867846914094176],costo: 0.16606487333774567, accuracy: 0.963623046875\n",
            "Epoch: 67, learning_rate:[0.06353301108266515],costo: 0.1430887132883072, accuracy: 0.962646484375\n",
            "Epoch: 68, learning_rate:[0.0915892733712457],costo: 0.1541845202445984, accuracy: 0.96142578125\n",
            "Epoch: 69, learning_rate:[0.09362996611585611],costo: 0.13259673118591309, accuracy: 0.966064453125\n",
            "Epoch: 70, learning_rate:[0.030771282262447845],costo: 0.13341090083122253, accuracy: 0.966796875\n",
            "Epoch: 71, learning_rate:[0.02439008788098581],costo: 0.12313763797283173, accuracy: 0.9677734375\n",
            "Epoch: 72, learning_rate:[0.018478311278699755],costo: 0.12172594666481018, accuracy: 0.96533203125\n",
            "Epoch: 73, learning_rate:[0.05143594412377958],costo: 0.1319456696510315, accuracy: 0.960693359375\n",
            "Epoch: 74, learning_rate:[0.05524113733941624],costo: 0.1583334356546402, accuracy: 0.9697265625\n",
            "Epoch: 75, learning_rate:[0.07062236262563099],costo: 0.1410408318042755, accuracy: 0.96484375\n",
            "Epoch: 76, learning_rate:[0.0428787195645583],costo: 0.15834808349609375, accuracy: 0.962646484375\n",
            "Epoch: 77, learning_rate:[0.03404858405463511],costo: 0.1621442437171936, accuracy: 0.96630859375\n",
            "Epoch: 78, learning_rate:[0.028424695418300755],costo: 0.15805180370807648, accuracy: 0.966796875\n",
            "Epoch: 79, learning_rate:[0.028800532314841386],costo: 0.12356555461883545, accuracy: 0.96923828125\n",
            "Epoch: 80, learning_rate:[0.06691975989526847],costo: 0.13182902336120605, accuracy: 0.9658203125\n",
            "Epoch: 81, learning_rate:[0.0784758030557794],costo: 0.16076643764972687, accuracy: 0.965087890625\n",
            "Epoch: 82, learning_rate:[0.0648250580648898],costo: 0.15001940727233887, accuracy: 0.96435546875\n",
            "Epoch: 83, learning_rate:[0.030428247329550198],costo: 0.14055220782756805, accuracy: 0.96435546875\n",
            "Epoch: 84, learning_rate:[0.02806041718118399],costo: 0.14896160364151, accuracy: 0.9658203125\n",
            "Epoch: 85, learning_rate:[0.04034041259516137],costo: 0.13137681782245636, accuracy: 0.96337890625\n",
            "Epoch: 86, learning_rate:[0.08028669718061975],costo: 0.12357350438833237, accuracy: 0.9677734375\n",
            "Epoch: 87, learning_rate:[0.08087055045718529],costo: 0.13701292872428894, accuracy: 0.967041015625\n",
            "Epoch: 88, learning_rate:[0.08013602869319861],costo: 0.13074424862861633, accuracy: 0.967529296875\n",
            "Epoch: 89, learning_rate:[0.07022527278005734],costo: 0.10940895974636078, accuracy: 0.968017578125\n",
            "Epoch: 90, learning_rate:[0.03774429503952419],costo: 0.13699382543563843, accuracy: 0.9677734375\n",
            "Epoch: 91, learning_rate:[0.05494082577954179],costo: 0.1359805315732956, accuracy: 0.966796875\n",
            "Epoch: 92, learning_rate:[0.06458157838323852],costo: 0.10671684890985489, accuracy: 0.965087890625\n",
            "Epoch: 93, learning_rate:[0.08890351355776825],costo: 0.1371622383594513, accuracy: 0.9697265625\n",
            "Epoch: 94, learning_rate:[0.057503691268267786],costo: 0.13651034235954285, accuracy: 0.968505859375\n",
            "Epoch: 95, learning_rate:[0.019687642946730533],costo: 0.15362444519996643, accuracy: 0.966796875\n",
            "Epoch: 96, learning_rate:[0.0189351569492004],costo: 0.1069713905453682, accuracy: 0.96923828125\n",
            "Epoch: 97, learning_rate:[0.04840338463497744],costo: 0.12048715353012085, accuracy: 0.97021484375\n",
            "Epoch: 98, learning_rate:[0.07376378684526776],costo: 0.13051486015319824, accuracy: 0.969970703125\n",
            "Epoch: 99, learning_rate:[0.0836267714576344],costo: 0.10598959028720856, accuracy: 0.96923828125\n",
            "Epoch: 100, learning_rate:[0.05978853955473416],costo: 0.10910763591527939, accuracy: 0.970458984375\n"
          ]
        }
      ],
      "source": [
        "resultados['random_cyclic'] = {}\n",
        "resultados['random_cyclic']['val_acc_list'] = [0] * epochs\n",
        "resultados['random_cyclic']['test_acc'] = 0\n",
        "resultados['random_cyclic']['cost'] = [0] * epochs\n",
        "resultados['random_cyclic']['time'] = 0\n",
        "resultados['random_cyclic']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    random_cyclic_acc_list, random_cyclic_cost_list, random_cyclic_lr_list, random_cyclic_time, random_cyclic_acc, random_cyclic_epochs = CyclicGD()\n",
        "    a = SumList(resultados['random_cyclic']['val_acc_list'], random_cyclic_acc_list)\n",
        "    resultados['random_cyclic']['val_acc_list'] = SumList(resultados['random_cyclic']['val_acc_list'], random_cyclic_acc_list)\n",
        "    resultados['random_cyclic']['test_acc'] += random_cyclic_acc\n",
        "    resultados['random_cyclic']['cost'] = SumList(resultados['random_cyclic']['cost'], random_cyclic_cost_list)\n",
        "    resultados['random_cyclic']['time'] += random_cyclic_time\n",
        "    resultados['random_cyclic']['epochs'] += random_cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['random_cyclic']['name'] = 'Random Ciclico'\n",
        "resultados['random_cyclic']['lr'] = random_cyclic_lr_list\n",
        "resultados['random_cyclic']['test_acc'] = resultados['random_cyclic']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['random_cyclic']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['random_cyclic']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic']['cost'] = DeleteZerosFromList(DivideList(resultados['random_cyclic']['cost'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic']['time'] = resultados['random_cyclic']['time']/ MAX_ITERATIONS\n",
        "resultados['random_cyclic']['epochs'] = resultados['random_cyclic']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dD4C1mSZidw"
      },
      "source": [
        "## Tasa de aprendizaje decreciente (Propuesta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyV63d-ng_GM"
      },
      "source": [
        "Inicia con una tasa de aprendizaje $\\alpha$ inicial y posee una disminución de 0.001 cada $p$ epochs.\n",
        "\n",
        "$\\alpha: 1x10^{-2}$\n",
        "\n",
        "$p: 1$ epochs\n",
        "\n",
        "![decreciente.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAbcAAAFMCAYAAABIwvIxAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAACxMAAAsTAQCanBgAADgJSURBVHhe7d0JmFTlmT3wN2ERZJVVAiaogzoqCthCBCWtRGBkBkUJIBFBIQyLQSEiCHFDBIEkAkEZZG3BP7sxBBQ1CGGRaRdQQJyAGgig7Ivs+/+cW/emL2VVU910VVfVPb/nOU/fququ7q6urre+7373vSYiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiLJ5r+QmaHNlHAW+bfQZtrIRLaGNh2fI7zuQryNdAxtXrBNyM9DmwkzAJkQ2kwKK5C6oc2EOoRcEdrMVar9H4skxDrkhtDm9/Cfy8sZ5Kjv8i+RRAtCcUs2hVHcCkpNhM+Zos6l/GHhWBjadDyLnET4P7Af+QC5BSlsuf0fi88P3Y+S/qYjXUOb31Pal38i/Ef3Lr+OBNGFvFAGSbo8Tt2QqaHNf+Eoif8DlZHlyBvID5BwRdyPiZDb/7H4qLill8sQ/gPuQvYgYxDPEqRFaDNm9ZGVCN+5fovw/oojxH/yl5CdyHfIWuR6hPh9ViO8fgvCd8G56Yvw/r9BHuYVPhchv0NYdHcg/4OURCK5Enkf4e++G2FhLo94ODp5ElmP7EMmIyUQ8kZW/ZDtCG/j/0d/5CuE9zkLqYCQN1rgtCB/Nn6/gYiHP+MUhN+H3+9mxM8/UuLj642UDyO8X97/Jch8hH9P3g+3ayAe/k27hDYdfOy+QPi57yA/QaLpgGxG+Hv5f26K5ffujPD35uNNuX3v65D3kL0I/4acjiQ+L6aFNh0/RThC4uPxGeKftuXv+jzCqcODyLtIJYSWuh+9x9EbYcX6ePA5fQfyN+fS93EEl4VcilRE+Hcdi7yF8O91O/LvCH9G/gyccm6JePj5fN7yMeDPzu/j/1n8MxXlkNcQ/s359/kt4n+dzs//sUhK47tHviCw4JRC+KJ9K+LhixP/ico6l6Lzv+jehPAFh+/O+aLGF4rHEGqGfIKweLDQ8Z+7GkJ8UaqN8J+SUyh8QbsHiaQ5wttZGPlz/z/E/8/O32cewp+/DPIXZCgSCb/mToQFke+2+aI3EvHwd+O0Dt8E8P74QjkYIf7Mp5BhCL+exelR5H8RFhReNw7hO2fyXuTHI/zcG5HjCB8HehFZhvD78Pvx+/qnJaNNAw5B+HMXQ/hCeh9yMcLffTbyJuLxF7e7kS8Rfn/+vfiiyEIRybUIi0BjhL/XHxD+7t7PE8vvzRdg/r34u+f2vflz843LbxA+J3m5AUL+4lYdYSG9C+Hzhn9HXubfkfi7sthehfB78jIfY/J+Jv8oMi+PB4svi5Sf/2fjYzACYTEnFqsDSCOEPyt/J34vFm2vULKIXY0QP5+Xvcd7FMKRoMf/fOfj+meE98nfawPCNxKeWP+PRdIG363y3Z7/H9yPL5b8p/ixcym6aC+6xML2p9Cm8w/MfzwWP/87y0hYYFikIpmEeC9SxBcv75+dRZMvOhyRefh7/iO0eV4sqBxBevi7cfrJwxdSvmASi9sJxBvJEYt5k9Cmg8Wb7+L5GHsvqP6R1IdIu9CmfY2wcHs4lXS+4tYW4fXeC3q4OghHIR5/cePiEv+LIP8mR5BIo5WnkRmhTQeLFH937+eJ5ff2L4DI7Xvfj/j/Bn7+AsIRc/i0IEdb3oIZ/q4sUJ4eiLePLFJxy8vjwSLF0boffzY+JhyJcXaCI1S+2SMWKxYhz20Iv97/f8A3A7wP4uf7H29OdZ5G+KaHvOc736Dye/LNh+e/Ef7unlj/jwPvfC9Kkjr4j8JpDL4Dj4TvBIn/rLFioeFUGP9xOcXIUYU3FcR/dk5Tvozwn/9VxHs3yXfmixEWW77DZUHxvi7cjxBOXXr4O3j4Is9RC0eI/LkZvqBFe/GvivBFZBvCn5cvnOHfN/x78ft7+PMeC206+ELIYu59b77o80WJ38fjf1HkiydfuCi33ysSrtLj49kK4c9B/N05auLX8vfhiI4j5Uj7ePizckTg/aycAuSbA46IwoX/bHwDwVGSJ5bf2//1uX1vPi+9NxC54X38AvHug+HMgzcbQNEe60jy8njwDYP3/+HH6Vg+3lUQvpnj89Dj//29x5OLsTz8m/m/l//zOWrmz+N/7hGfqyxe/udK+P3k5/84kFTc0gf/efhuLtrIjdMzHBXwRTJW3K/wf0gthIWL0y58gfCMRvhulu80WQi574w4tcipRL6wcR8C9zf4v86PU1beO1jyvyPlfiyu3OS0EV9kGN5ftBc1Fl++q+WUKH/eB5Dw7xv+vbifz8Ov9eNj+h+I970ZjuxYPM8nt98rHF88Od3YE/GPcjiVx6ktvlng78NpLYr0WPJn5bt8/8/K6btIU3HhPxuLKKdAPbH83v7HKrfvzdtiWebOz+PIzX8fHFH6R/XRhP/dKC+PB6cUoxW+aPzfk88hPp7+11P+vf2Pl//x5vOX04v+5x7x+c4RMguzJ/x+8vN/HEgqbumDU2J80eKLgbfPjdMtnp8hnKrJC75L5D8R32leg3RHPFwgwRddvtPkO3+OeLx3rvw6vjPldVyU0h6Jhu+OOyEskHyRfQbx8P64T4tTmiwAxBcg7u+LhN+XPytHi/w8r9j6sYBwKpEvLlxIkdtxQyzKLyDeiw1HjNyXEwv+Xly8wkUh/H6/RiLhm5E5CEeZ/Bo//j4s7nyXzp/X/9iE48/K78c3AsQ3ARwJRcLv958IR0bcRzQI8b8W5PX3zu17c+TP0RentLm/ib+Tt8/Nj78/V+nyb8uRKZ+/nCr2T/tGw5Eunyv+IpqXx4NTgX9F+D+SH9kIR5JPIPx/4M/N38U/FckpcO/x5sIY7tNkAfbj6JjPAT72fJz4+PdBvKlbys//sUjK47s8jgA4xcR3gRxZebiakYsezse/L4gjBY7cWDCWIXwR9HaEc5/MGoS3eSsTvRFVa4TTKdyJzhc3Trf5/0HDcWUep5y81ZJ8V+ztYOeLHEdk3IfFQsspsl5IJHwh49QRf6ZPEY58wvdzeaslWTC4Ao4FlfiCFH4cGl/w+eLyd4S/C6fX+LNQpP08/n1gvF/ul+H34fdjoY20z827H75B4M/thX9LTlvxPnmZ+zc5EvF/T//3I66A5N+ZjxNfOLk/MxpvlSefKyzy/r97Xn9vyu17c7HQIoTTf/w78+9N/n1uxKLHlYR8Y8SCtQDxRrzhvyvfEPkXZfC5ya/h4839wJSXx4MrEP1FI/xn8+M+NG8hkofPPf7sfGPFvzenlz38fBZbrpbk35LTy5cjHv/znW+G+H35u/Bn5v5R/xuPWP+PRQKB7yLDRwVB5H8BTwd8kXwwtCkFgKtn49GhJFIxzA/9H4tIROlU3Dgy5EiQK/UkuRVUcZM80D43kdTD/Y+c3uM0mH9qTkREREQkf3gQK3dKc6mttxPZjwsWViE8NouLEPy4w3ujG3/ncy49505V3icXTHjLormajDts+fn8yB2zIiISQNGOPSoIXM7LFV5so8N9Ax8h7FbAlUQerrzi8TuPIzwuikuUiYXqYyQD4UoiroBjUeNqKy5552o5Lr9lbzcWOK5yGo5wlRWXwrOQsrix60FUzZo1O7twob8RuIiIJNoPwN0sMPHc58bjmzi64hJuHkfCYz7Cj5XhDn4uJ/cf2U881sVrtMqCxm2OAnm8DIshjxFh0eNSa69nIe+bS7uJH6P1MvyX3bu5gl1ERNJNPIsbD6L1H6TI0VusHQCifS3jP1bIf59sDcSDmIk72/2tgvzY44+jwo937fK6HImISDpJ19WSHNUxkbAHIqc7MypXjtaiUEREUlk8ixv7ofn7qbGNTiw9+Sja1zL+djz+++RpU7wmq/zIZr4iIhJA8SxuXEDChrtsM8N+ajwVCBeNxIKnumiKcFEIw21ex2lHttJhex3ugGR3Bp77iHjf3qpKfvSuFxGRgIlncePy/kcQFiX2A2TbGJ6hlj3gvLPUsvku95uxoSlP7cHbiQtJ2FyUBZLh1/A64nmcJiBcrMKed14/OK6S5MpMHgrALhSxdBMXEZE0FM9DAZLeTTfddPbjj7m2RERECkuqHQogIiJSKFTc8uH111+3mjVr2g9/+EPnIy+LiEjyUHHLIxayrl272ubNm+3s2bPOR15WgRMRSR7a55bHfW4cqbGghfvJT35imzax4YqIiOSF9rklgX/+kycv/r5o14uISOKpuOXRj3/snfX+XFWq8BRbIiKSDFTc8uiFF16wiy/mSZBzcES9Y8cOe/HFF+3MmfAe0CIikmgqbnn0y1/+0l599VVnHxuLGj+OHz/e2rZta08++aTdfffdtnevd7y5iIgUBi0oKaCDuLly8pVXXrHevXtb9erVbfbs2ZaRwf7MIiKSGy0oSWL82/Ts2dOWL1/uTE02atTIxo4d6xQ9ERFJLBW3Ala/fn1btWqVNWnSxHr06GEPPPCAHTp0yL1VREQSQcUtDipWrGjz58+3wYMH24wZM5yC98UXX6iziYhIgmifW5wbJy9atMjuv/9+O3DggHP5xIkTzkfiqksuTuEiFRGRoIrHPjcVtwScFWDbtm125ZVX2vHjx91rcqiziYgEnRaUpCiunvSP2PzU2UREpOCpuCVItM4m0a4XEZH8U3FLkEidTejGG2+0U6d40nIRESkoKm4JEt7Z5LLLLrPMzEybN2+eNW3a1LZv3+5+poiIXCgtKEnAgpLcZGVlWffu3a18+fLOYQONGzd2bxERCQYtKElDHTt2tOzsbCtdurTdcccdNmLECHU1ERG5QCpuSaB27drGEWSrVq3siSeecD7u37/fvVVERPJKxS1JlC1b1mbNmmWjRo2yBQsWWL169Zw2XiIikncqbkmE0869evWypUuX2smTJ61hw4bWpUsXZxGKWnaJiMROC0oKeUFJNLt377bbb7/d1q1b514TopZdIpJutKAkQCpVqmTfffedeynHkSNHbODAge4lERGJRMUtiW3ZssXdOpdadomI5E7FLYlFa83Fwwai9aoUEREVt6QWqWVX0aJF7eDBg87B3hrBiYhEpuKWxMJbdvHjlClTbM6cObZ+/XqrW7euLVy40P1sERHxaLVkkq6WPJ+NGzda69atbe3atfbb3/7WnnnmGStSpIh7q4hI6tBqSfmXWrVq2cqVK61Tp072/PPPW7NmzWznzp3urSIiwabilsK4P27SpEk2ceJEW7FihTNNyY8iIkGn4pYGHn74YWcUV7JkSfvZz35mv//9751OJuxoos4mIhJE2ueWovvcIjlw4IBT6N544w1n/9vp06fdW9TZRESSVzz2uam4pVFxI54up2LFirZv3z73mhxcbblp0yb3kohIctCCEjkvPkeinS5Hx8WJSFCouKWhaJ1NatSo4W6JiKQ3Fbc0FKmzCXHKcsOGDe4lEZH0peKWhiJ1Nunbt69zRoGMjAynw4mISDrTgpI0W1CSG+5za9OmjWVnZ9tjjz1mw4YNs+LFi7u3iogUDi0okQvCfXE8yzfP9j1y5EjLzMy0rVu3ureKiKQPFbeA4Uht1KhRNnPmTKcvJbuavPvuu+6tIiLpId7FrTnyd+RLpD+vCHMRMhPh7dlITYQ4VzYZWYt8hmQinrbIGuRzZBivcHVCdiGfuumCSBScnuSUbNWqVa158+b23HPP2dSpU9XVRETkPNii/ivkCoTFikXqWsSvB/I/oU1rh7DQUU+ExY2qIJ8gLMQVER6sVRmhLKRJaNMpbmNCm7HhPregO3To0NkOHTqcxcNxFkXN+ejl4osvPjtt2jT3M0VE4gOvNwUuniO3+ghHZF8jPG30DORuxI+XWaCIS/hYqLhjkUXwfYTY6p5HJWcgLJQbEY7Q6K/IfaFNyY9SpUpZVlaWVahQwc6cOeNeG8LVlQMHDnQviYikjngWt+rIltCmgysXeJ2f/3NOIQcQjs44ymuJFEUuR25CLkNYLK9GOH3J2+5BeL2HhY5TliyU/uv9uiJcIvnxrl1ejQw2LlSK1K6L1NVERFJRsi4omYSwGLIIjUQ+QNgFmK/A3RFOXy5D2CjR6w78F4RF7wbkPcQbEYZ7FeEoMKNyZW92U9TVRETSSTyL2zbEP3riqySv8/N/Dkdi5ZA9CEdxvZE6CKcuyyNeaw0WsQbILQgXq3jX8+uOhzZtAsLRnsQoWleTEydOOKsqRURSSTyL20dILYTTilxQwgUj8xA/Xu4Y2rTWCPezceciX2VLIXQnwmK33rkUWmBClyBckMJCRtXcj8QpzS9CmxKLSF1NnnrqKWflZIMGDZz9ciIiqSLeHUruQjityJWTnGp8ARmEcLqRha0EMhWpi+xFWAC5AIXTi+8gXOHA0V1nZDNC05EbQ5vOfXGhCg1FWNRYCHlfnL78PySqoHUoyY/t27db+/btbfHixdalSxcbPXq0c1JUEZGCEo8OJWq/peJ2XqdOnbJnnnnGhgwZYnXq1HF6U1555ZXurSIiFyYexS1ZF5RIEilatKizT27+/Pm2efNmvimwN998071VRCT5qLhJzFq0aGGrVq2yq666ylq1auWcaeDkyZPurSIiyUPFTfKEbbmWLVtmPXv2tN/97nd2/fXXO4cLqGWXiCQTFTfJs4suusjGjBljPXr0cE5+um3bNudEqJyy7Nq1qwqciBQ6FTfJtwULFrhbOdSyS0SSgYqb5Fu01lxq2SUihU3FTfItWssu7n/78MMP3UsiIomn4ib5FqllV4kSJax8+fJ26623Ovvl4nQ2CxGRXKm4Sb5Fatk1YcIEZ5FJs2bN7Ne//rXT3eTgwYPuV4iIJIY6lKhDSVzw3HDDhw93FpfUqlXL5s6da9ddd517q4hIDnUokZTB/W79+/e3RYsW2f79+61+/fo2bdo091YRkfhScZO4yszMtNWrV1tGRoZ16NDBunXrZseOHXNvFRGJDxU3ibtq1ao5I7h+/frZuHHjrFGjRjZy5Eino4k6m4hIPGifm/a5JdS8efOsXbt2dvToUfeaEK665OIULlIRkWCJxz43FTcVt4SrXr26ffPNN+6lHFxtuWnTJveSiASFFpRIWvj222/drXOps4mIFBQVN0m4aJ1NqlSp4m6JiFwYFTdJuEidTTgrsWPHDhs6dKhzjJyIyIVQcZOEi9TZZPz48da2bVsbMGCAtWzZ0vbu3et+tohI3mlBiRaUJA32oXz55ZetT58+zqKT2bNnO8fHiUh604ISSWt8fj/yyCPOmb45Ncnj4caOHavmyyKSZypuknQaNGhgq1atsiZNmjhn+2Znk0OHDrm3ioicn4qbJKWKFSva/PnzbfDgwTZ9+nSnN+WIESPU1UREYqJ9btrnlvTYuqtVq1bfO3WOupqIpAftc5NA4vRk2bJl3Us5jhw54pxSR0QknIqbpIRI7bpIXU1EJBIVN0kJ0bqaVKpUyd0SEcmh4iYpIVpXk127djlTk6dOnXKvFRFRcZMUEamrycSJE+1Xv/qVDRkyxJo2bWrbt293P1tEgi7WFSo/QWohf0VKIkWRc5eupSCtlkwPWVlZ1r17dytfvrzNmDHDGjdu7N4iIqmgsFZL/gqZg4xzLpnVQN4MbYoUvo4dO1p2draVLl3a7rjjDhs+fLi6mogEXCzFrSfSCPnOuWS2EdG5SSSp1K5d2zgKv/fee61fv352zz332P79+91bRSRoYilux5EToU0HpyT1tliSDo+Fmzlzpo0aNcreeustq1evntPGS0SCJ5bi9jdkAMJ9bXcis5G/ICJJh1P3vXr1sqVLl9rJkyetYcOG1rlzZ2cBitp2iQRHLDvxWAA7I00Rfv47yAQk5UdvWlCS3nbv3m233367rVu3zr0mRG27RJJLPBaUFPgdphIVt/THEVukLia8ftOmTe4lESlMiV4tOcv9uBZZE5bPkMXI3YhI0tqyZYu7dS617RJJb7lVy2rItwiPcYuEfY+48+Ia51IK0sgt/XEf2+bNm91LOcqUKeNMWxYvXty9RkQKS6JHbixsxFeGSPkE0U4LSWqR2nYVLVrUOX0OD/bWCE4kPcWyWvKnyEcIT4XMQwJOI94xbyxwIkkrUtuuKVOm2Jw5c2z9+vVWt25dW7hwofvZIpIuYhkKct6uHcJDADKQB5GrkCeRlKZpyWDbuHGjtW7d2tauXes0X3722WetSJEi7q0ikiiJnpb0+xLhfz1HbZOR5ohISqtVq5atXLnSOnXqZIMHD7ZmzZrZzp073VtFJJXFUtyOINzr/ikyHOmNxFoURZIa98dNmjTJOcPAihUrnGnK5cuXu7eKSKqKpUh1QPh5jyCHkcuQ+5BYcIT3d4Qjv/68IsxFyEyEt2cjNRFiMeUIkYch8LCDTMTTFuHhCJ8jw3iFK9p9iZzXww8/7IziSpYsaZmZmda+fXt1NRFJYbEUN54/pBjCRSTPIX2QWJb/cxrzZeQ/kGuR+92Pfux8sg/5N+QlxCtWPBMB1UbY8uv3CH/WisgIpAlyHXKpu03R7kskJnXq1LFPPvnEGb1Nnz7dWUnJswvwUIKuXbuqwImkkFiK2x+RZci/O5dCBrkfc1Mf4Sjqa4SrLGcg4Qd983JWaNM5rQ4LFXcssgi+jxB3grC9OxezXIHwrAS7EOL55bxRZLT7EolZuXLlIu53O3LkiLPoRERSQyzF7R/IwwgLxi94BcRSNKoj/vYQWxFe5+f/nFPIAYSjM05FtkR4BoLLkZsQToeyWF6NcMqRt92D8HqKdl/huiJcIvnxrl1ejRTJoa4mIqkvluLGBsk8b8jPEBaG3yHxXi89CWExZBEaiXyAcKUmpx27I9y3xtEkmwPy+rx4FeEoMKNy5crOFSJ+P/7xj92tc3HxCUdwIpL8YiluXqeS3UgzhMXuel5xHtsQb1RFPIM3r/Pzfw5HYuWQPQhHXlyVWQfhdGN5ZANCPN1OA+QWhItVvOuj3ZdInkTqalKsWDE7fPiw/fSnP7UNG7ynnIgkq1iKWwv3I51B+iKxfB27mtRCOK3I1Y88EHwe4sfLHUOb1hrhfjYWT76ylEKIC0pY7NY7l3LOAn4J0gPh6Xco2n2J5EmkriaTJ0+2t99+27Zt22YZGRlOhxMRSV657TvjdOBjCEdKkYoE94mdz10I74fTmJxqfAHhYhRON7IYlUCmInWRvQgLIBegcJ8azxvHYsoRGVdCsp8lTUduDG0698WFKhTtvqJShxLJK+53a9OmjWVnZ9tjjz1mw4YNU/NlkQsUjw4lud0hF3GwdyT3tUXCM3SnNBU3yY8TJ05Y3759bfTo0XbLLbfYrFmzrEYNzrqLSH4kurilPRU3uRAsap07d7YSJUo4x8A1bcqT1YtIXsWjuOW27yzSSUr9EQk0Tk/yzVHVqlWtefPm9txzz9nUqVOdjibqbCJSuHKrlt5JSnu6H7k/ix5AuA8uUjutlKKRmxQErqLs3r27U9hY1M6c4a7iEK665OIULlIRkcgKa1pyNcJFGn487q1eaDN1qbhJQWGbrkqVKtnevVzLdC6utty0iYdkikgkiZ6W9PCbNgptOhoisXydSGDwf3PfPvYY+D51NhFJvFiKFJfhv4LwrSeX43Ob7bhExCdaZxOtpBRJvFiKGw8H4HFlzA0Iu4ZwWlJEfCJ1NiEeOsCzfYtI4sRS3HietPYIF5Y8ijztRkR8InU2eeqpp5xFJg0aNLCsLO+kFSISb7HsxFuIsMM+R3D+JsU8x1pK04ISSYQdO3bY/fffb4sXL7YuXbo4B3/zpKgiEhKPBSWx3OE6JJZGySlHxU0S5fTp0/bMM884U5c8KSp7U1555ZXurSLBFo/iFsu0JE83wzNii0g+FSlSxAYPHmzz5893zuxdr149+9Of/uTeKiIFLZbidivCKUmeXoadSbzOJSKSRy1atLDVq1fb1Vdfbffee689/vjj9tprr6mriUgBi2Uo6HUqCed16U9ZmpaUwnL8+HH7zW9+Yy+//LK6mkjgFdY+N+Lojedmm4zw9NWlkX8gKU3FTQobzwa/ezfPA3wudTWRICmsfW7PIP2QJ51LZsWQaaFNEbkQe/ZEPlm8upqIXJhYilsrhCcmPexcMvsGKRPaFJELEa2rSfXq1d0tEcmPWIrbCYRnAfDOxl3K/SgiFyhaV5MjR444Z/sWkfyJpbjNQsYh5ZFfIX9FxiMicoEidTUZNGiQlS1b1m677TYbM2aMc8YBEcmb8+3E4+3s+noNwtMM8/I7yHtIytOCEklWPHVOx44dnePi2rZta+PHj7cyZbQ3QNJTYa2W5HFtaXkQt4qbJDMeHjB8+HAbOHCg1apVy+bOnWvXXXede6tI+iis1ZI8A8DNoU0RSRQe/9a/f39btGiR7d+/3+rXr++c7VtEzi+W4tYA+V/kK0QdSkQSLDMz0+lqkpGRYQ8++KB169bNjh075t4qIpHEUtyaIVcgdyD/hfyn+1FEEqRatWrOCK5fv342btw4a9Sokb300ktq2yUSRazznPUQdinhsq0VSFqcrFT73CQVzZs3z9q1a2dHjx51rwlR2y5JVYW1z40nJuVZFisilRC24PotIiKFoGXLlnbJJZe4l3Lw2DguPhGR2EZuPBvAjYg3yc+zLH6KXO1cSmEauUmq4lRkpOPf+AbY34RZJBUU1siN7bZKhDYdFyHbQpsiUhiite2qUqWKuyUSbLEUtwPI58gUhFOSPDP3fmS0GxFJsEhtu/jmd8eOHTZ06FCN3iTwYiluPF3wAGQxsgThpP6fEZ7AlBGRBIvUtotdTNjNZMCAAc5+OXY5EQmqAp/nTCXa5ybphvvheALUPn36OGcWmD17tnN8nEgyK6x9bjxJ6RxkPfK1LyKSZPga8cgjj9iyZcucqUkeDzd27Fg1X5bAiaW4cT/bWOQUcjvyGqKTlYoksQYNGtiqVausSZMm1qNHD+vQoYMdOnTIvVUk/cVS3Lj0fxHCYeNm5FmkBSIiSaxixYrOWQUGDx5s06dPd3pTjhgxQl1NJBBimef8AGF3Ek5Nvo/wMIAXER3nJpIi2LqrVatWdvDgQfeaEHU1kWQQj31usdwhzwjwBcKTlT6PlEVGIGymnNJU3CRIatSoYdu2ff8QVa603LRpk3tJJPEKq7ilLRU3CRJ1NZFkFY/iFss+NxFJA9G6mlSqxJaxIulFxU0kIKJ1Ndm1a5fTcPnUKS6IFkkPKm4iARGpq8nEiROtS5cuNmTIEGvatKnTvkskHcQyz3kVwuPcqiLXIzcgLZHBSErTPjeRkClTplj37t2dU+nMmDHDGjdu7N4iEn+Ftc9tPPIkctK5ZLYGaRfaFJF00KlTJ8vOzrbSpUvbHXfc4RwPp64mkspiKW6cpP8wtPkvmpwXSTM33HCDcSaDx8M98cQTzsf9+3kCEJHUE0tx241ciXhv41oj34Y2z6s5wpOdfon05xVheG64mQhvz0ZqIlQcYduvtchnSCbiuR/h9RxBLkS8pV7snMKDeHgiVeYuRETyoGzZsjZr1iwbOXKkLViwwOrVq+e08WInE3U2kVQSyzznFcirSENkH/IP5AHkfEd9FkE2IHciW5GPEBYmNmD29EC4D68bwqnOVkhbpCfCVuYPITz74tsIDyZnMebJU69FWHSHI0cQFjaGzfN+h8RE+9xEolu5cqW1adPGvv32WytSpIidOHHCvUWdTaRgFdY+N54B4OdIZeQahK24YmlnUB/hiIxfz/+KGcjdiB8vZ4U2nfZeTRD+kixebPVFOxHOjbDY8TamlPuR3VJY7ESkgN1yyy3OqK1YsWLnFDY6cuSIc/iASLLKrbj1Cct/I7/yXT6f6siW0KaDozde5+f/HO7H41m/KyKciuSKzKLI5chNyGUIF7V0Rzgt6Y3gJiKeRxBOV05CLuEVEXRFOFz7mMf3iEh0lStXtuPHj7uXzvXPf/7T3RJJPrkVtzJuOGJiQWEhYjiFWA+JJxYnFkMWoZEImzefRooh/FnqIj9CWMi4kpN4uAL3DdZBuE/w90gknGLl75TBf1wRyV20zibRrhdJBrkVt+fc1EBYzH7jhqOoWJ7VXNzB0ZaH9xPetdX/ORyllUP2IBzF9UZYqDh1yabN3H/Hy/QVwgUusxDuCyQefcoCyCZ5PHyB06IicoEidTaha6655nvTlSLJIpZ9bjx42/8M5javOx8uIOFZvDmtyNWPXDAyD/Hj5Y6hTWcVJvezsWjxP4n71YgLUljsuBCFxZBTkd6Qi7fxjAVUzf1IXJiyLrQpIhcivLMJR2zNmze3d955xznYW9OTkoxiWaHCvcZtkD85l8zuQbh8f6hzKXdcjs9pRa6c5FTjC8gghNONLGwlkKkIpxn3IiyAXIDCQwLeQTgKY0HrjPBEqcRp0UcR7n/jdZ0QjvZ4PxzZsThywQv3EeZ6yIJWS4rk35w5c+zhhx92Fpzw0AAWPJH8iMdqyVjvkNOSt4U2bSmyOrSZ2lTcRC7Mhg0brHXr1rZu3Tp76qmn7Omnn3YOGxDJi8IsbmlJxU3kwvGwgJ49ezr9KX/+8587o7gqVXh4qkhs4lHcYtnnJiISFRebTJ482TnDwPLly52uJitWrHBvFSkcKm4iUiC4/41dTUqUKGGZmZnOQhQuQlHLLikMmpbUtKRIgTpw4IAzPRn+v6WWXRJNYU1L/hThsn72beRhADyW7DtEROR7ypUrZzt3smveudSySxIpluI2BmHD441ISaQL8jIiIhLRli3+zns5dEycJEqs+9zYAJnrezlq46lodECLiEQVrTUXpyY5ghOJt1iKG5+J7DDCc6TxFDNsi6WFKCISVaSWXTzY+/Dhw87ZBjZu5ESQSPzEUqQ6IPw8dtw/jLAX5H2IiEhE4S27+JGHC7z99tu2detWLuayuXPnup8tUvDyukKFp5FhcWM3/pSn1ZIiicf9bjwJanZ2tvXu3duGDRvmjOokuAprteQShCcFrYCsQthx/w+IiEiecX/c0qVLrVevXvbSSy85x8RxNCdSkGIpbjwNDZf+34u8hjRAeGZuEZF8KV68uI0aNcpmzpxpa9assbp169p7773n3ipy4WIpbjzPGk8nwzMDzOcVIiIFgdOT3DVQtWpVa9asmd13333qaiIFIpbixlPU8PQzPByAB3NfgWipk4gUiKuvvtrZ/9awYUN74403nH1yZ8+etc2bN1vXrl1V4CRf1H5LC0pEkgJHbJEO8ub1mzbxFI2SruKxoCSWO+QJRXmy0Ovcbc/D7seUpeImkjw4FckRWzi+7p05w/MWS7oqrNWSPMP1pUgz5G9IDeQgIiJSYKJ1NSlZsqR9953a2Ure5FbcuJCE/g15CuEB3FlIC4QrJkVECky0riZHjx61m2++2dauXeteK3J+uRW3D92PJ92P+5HrER4aoNPsikiBitbVZMmSJc7IrUGDBpaVxffXIueX2zwnD9iuh/AsAOyTUxuZgpRGOJIbh6Q07XMTSQ3bt2+39u3b2+LFi61Lly72xz/+0TkpqqSHRO9z4+isD8LuJA8hGQhPdTMMKYWIiCTEpZdeau+++64NGDDAJkyY4DRf/uqrr9xbRb4vt+LGU9xwlFbGF172IiKSMEWLFnX2y82fP985Bo7Nl9988033VpFzxTItmbY0LSmSmnjc2y9+8Qunu8njjz9utWvXtqeffto5To6rLlkEuQ9PUkM8piVzu8PVSN3QZnpScRNJXcePH7c+ffrYK6+84hwj5z8WjqsuuThFBS41JLq48SwAe0Ob6UnFTST1Va5c2Xbv3u1eyqHOJqkjHsUtt31uaV3YRCQ97Nmzx906V6RWXhIcuRU3EZGkF62zSfXq1d0tCSIVNxFJaZE6m9CRI0fsww+9XhQSNCpuIpLSInU2GTRokJUpU8ZuvfVWe/nllyM2ZJb0VuA78VKJFpSIpK+9e/fagw8+aAsWLLB27do5BZAFT5JPoheUiIikrAoVKti8efNs6NChNmvWLKtfv759/vnn7q2S7lTcRCRt8fi3/v3726JFi2zfvn1OgZs2bZp7q6QzFTcRSXuZmZm2evVqy8jIsA4dOli3bt3s2LFj7q2SjlTcRCQQqlWr5ozg+vXrZ+PGjbNrrrnGOVyAo7uaNWva66+/7n6mpAMVNxEJDDZffvHFF522XWy+/M033zgrKbndtWtXFbg0ouImIoEzdy5PUXkuHhc3cOBA95KkOhU3EQmcaK251LIrfai4iUjgRGvZxcOtlixZ4l6SVKbiJiKBE6llV4kSJaxKlSrWpEkT59g4/yl0JPWouIlI4ERq2TVhwgTbsGGDcxLUAQMGWMuWLZ0uJ5Ka1H5L7bdExIerJ3kC1N69e9uPfvQjmzNnjnN8nMSP2m+JiMQZX2d79uxpy5cvdwpdo0aNbOzYsWq+nGJU3EREImCrrlWrVjn74Hr06GEPPPCAHTp0yL1Vkl28i1tz5O/Il0h/XhHmImQmwtuzkZoIFUcmI2uRz5BMxHM/wuvXIAuRSghVQN5DNrofL0FERPKtYsWKNn/+fBs8eLDNmDHDKXgjRoxwOpqos0lyi+c+tyLIBuROZCvyEcLCtB7x9EBuQLoh7ZBWSFukJ8JJ7oeQKsjbyM0Ii/E3yLXIbmQ4cgR51t3m3t8XERZSFrd+SFTa5yYisWLrrlatWtnBgwfda0K46pKLU7hIRfIn1fa51Uc4IvsaOYHMQO5G/Hg5K7Rpc5AmCH9JFq/3EdqJ7EdY7HgbU8r9WBZhsSP/ffHjPaFNEZELx+nJsmX5knMudTZJTvEsbtWRLaFNB0dvvM7P/zmnkANIRYRTkS2RosjlyE3IZchJpDvCaUlvBDcRoarIt6FN247wciRdEQ7XPt61a5dzhYhILNiLMhJ1Nkk+ybqgZBLCYsgiNBL5ADmNFENY3OoiP0K43+1JJByXNUVb2vQqwlFgRuXKlZ0rRERiEa2zSaVK3q5/SRbxLG7bEI62PDUQXufn/xyO0sohexCO4nojdRBON5ZHuP+Ol+krhMVrFtKQV8AOpFpo0/nI6UwRkQITqbMJdxdxFohTk6dO8aVLkkE8ixsXkNRCOK3I1Y9cMDIP8ePljqFNa41wPxuLFp893K9GXJDCZwwXorAYcirSG3Lxti9Cm+fcFz/+ObQpIlIwInU2mThxonXp0sWGDBliTZs2te3buVdECluBr1AJcxfCaUWunORU4wvIIITTjSxGJZCpCKcZudKRBZALUHhIwDsIm7uxoHVGNiPElZWPItz/xus6IRztcV8dR3KcN+D1bZBce+dotaSIFJSsrCzr3r27lS9f3jlsoHHjxu4tcj7xWC0Z7+KW1FTcRKQgrV271u677z77+uuvnZFc3759nRGe5C4exS1ZF5SIiKSc2rVrG98w83i4fv362T333GP79/NIJkk0FTcRkQLEY+FmzZplo0aNsrfeesvq1avnLERRV5PE0rSkpiVFJE5WrlxpLVq0sH379rnXhKirybk0LSkikkJuueUWK1XKW/idQ11N4k/FTUQkjrZtCz+8N0RdTeJLxU1EJI6idTXhGQckflTcRETiKFJXEy4s2b17tz366KN24gT7yktBU3ETEYmjSF1NJk+ebL1797bRo0c7B3trirLgabWkVkuKSCGZO3euPfTQQ1asWDHn8IDmzXl+5+DRakkRkTTCbiaffPKJ1ahRw+666y57+umn7fRpngBFLpSKm4hIIapVq5ZzPFynTp3s+eeft2bNmtnOnTqpyYVScRMRKWRccDJp0iTnDAMrVqxwuprwI6cq1dkkf7TPTfvcRCSJfPrpp9a6dWun+XLRokXt5EmeACUkXTubxGOfm4qbipuIJJkDBw5YtWrV7OjRo+41ObjactOmTe6l9KAFJSIiAVCuXDk7duyYe+lcOmwgNipuIiJJKFpnk2jXy7lU3EREklCkzibEaUk2XpbcqbiJiCSh8M4mHLHx5KfLli1zzjawceNG9zMlEi0o0YISEUkhCxcudAofV1GyjRcPBE91WlAiIhJwbNG1evVqu/baa51DBvr06XPO4QISouImIpJiOEW5dOlS69Wrl7300kuWmZlpW7dudW8VUnETEUlBxYsXt1GjRtnMmTNtzZo1VrduXXvvvffcW0XFTUQkhbVp08a4dqBq1apOX0rug+MilKC37NKCEi0oEZE0cPjwYae4sSelXyq07NKCEhERiahUqVK2ZcsW91IOHhM3cOBA91JwqLiJiKSJSMWNgtiyS8VNRCRNRGvNVbJkSfvuu+/cS8Gg4iYikiYitewqVqyYc3aBjIwMW7t2rXtt+lNxExFJE+Etu/iRXUyWLFliBw8etAYNGlhWVpb72elNqyW1WlJEAmD79u3Wvn17W7x4sXXp0sVGjx7tTFcmA62WFBGRfLn00kvt3XfftQEDBtiECROsYcOG9tVXX7m3ph8VNxGRgChatKizX27+/Pm2efNmzl7Zm2++6d6aXlTcREQCpkWLFrZq1SqrVauWtWrVyvr27Wuvvfaa09EkXTqbaJ+b9rmJSEAdP37cOavAK6+84hS1M2fOuLcktrNJPPa5qbipuIlIwFWuXNl2797tXsrB1ZabNm1yL8WPFpSIiEiB27Nnj7t1rlTubKLiJiIScNE6m1SvXt3dSj0qbiIiARepswmx6XJ2drZ7KbWouImIBFykziaDBg2yMmXK2G233WZjxoyxs2fPup+dGrSgRAtKREQi2rt3rz344IO2YMECa9u2rY0fP94peAVNC0pERCRhKlSoYPPmzbOhQ4fa7Nmz7eabb7bPP//cvTW5qbiJiEhUPP6tf//+tmjRItu/f7/Vr1/fpk6d6t6avOJd3Jojf0e+RPrzijAXITMR3s69ljURKo5MRnh+hs+QTIQ4Hv7UFx6YMRKhTsguxLutCyIiIgUgMzPTVq9e7Zw6h1OV3bp1sylTpqRVV5NYFUHYlfMKhMWKRepaxK8H8j+hTWuHsNBRT4TFjaognyCRCjGvbxzadIrbmNBmbLjPTUREYnfy5Mmz/fr14+qSsz/4wQ+cj14uvvjis9OmTXM/M3b42gIXz5FbfYQjsq+RE8gM5G7Ej5e9kwvNQZog3LHIIvg+QjuR/UiGcynHVQgL3zLnkoiIxB2bL7/44otOV5PwusRDBwYOHOheKlzxLG48+m9LaNOxFQk/ItD/OaeQA0hFhKO8lkhR5HLkJuQyxM8b6fkf3fuQNQgLZfjne7oiXCL58a5dnMUUEZG8itSui5Klq0myLiiZhLAYsghxn9oHyGnEj8VtemjT8ReE++xuQN5Dop1u9lWEo8AMvvMQEZG8i9bVJNr1iRbP4rYN8Y+eaiC8zs//ORyllUPY5IyjuN5IHYRTl+WRDYjnRoSfz31uHn7d8dCmTUA42hMRkTiI1NWEl3l9MohncfsIqYVwWpELSjjSmof48XLH0Ka1RrifjdOMfMRKIXQnwmK33rkUcj/iH7VRNfcjcUrzi9CmiIgUtEhdTRJ1ipxYxLtDyV0IpxW5cpJTjSzpgxBON7KwlUB4wERdZC/CAsgFKJxefAfhyYU4uuuMbEY8/Bze9/85l0KGIixqLIS8r+6I//bvUYcSEZHCF48OJWq/peImIlKo4lHcknVBiYiISL6puImISNpRcRMRkbSj4iYiImlHxU1ERNKOipuIiKQdFTcREUk7gT7ODdg52Ts4vBISuRNo8OixyKHH4lx6PHLoschxoY8Fv5bn/5Q40NHcOfRY5NBjcS49Hjn0WORIusdC05IiIpJ2VNxERCTtsKGx5PCfQifo9Fjk0GNxLj0eOfRY5NBjISIiIiIiIiIiIhJsPLbi78iXSH9eEXCbkLXIp0jQljrzhLo7kXXOpZAKyHvIRvfjJUgQRHosnkV48mA+NxieMDgILkMWI+uRz5FHEQricyPaYxHU50bS4oKar5ArkOLIZ8i1SJCxuPGAzCBqjNRD/C/owxHvTQ8/Dgttpr1IjwVfwB4PbQZKNYSPBZVBNiB8nQjicyPaY5F0z42gHwpQH+GI7WvkBDIDuRuRYFqK7A1t/gufD1mhTefjPaHNtBfpsQiqb5FVoU07iHyBVEeC+NyI9lgknaAXN/5RtoQ2HVuRpPxDJdBZ5F2Ey3q78oqAq4rwH5q2I7wcZI8gaxBOWwZlitavJlIXyUaC/tzwPxaUVM8NHcQt4W5FOO3wH0hPhNNTEsLCzwTVWORKpA7CF/XfI0FSGpmLPIZ8xyt8gvbcCH8sku65EfTixh2g3EHqqYHwuiDzfn8uJvgTwqnbINuBcD8D8SMfl6DiY3EaOYOMR4L03CiG8MX8deQNXgFBfW5EeyyS6rkR9OL2EVILuRzhgpJ2yDwkqEoh3ElM3G6K+BcUBBGfDx1Dm87HP4c2A8l7IadWSFCeGzx7ykSE+5f+wCtcQXxuRHssgvrcSGpcssoVP1w1OZBXBBhXjXLFKMNlvkF7PKYjnFI5iXD/a2ekIrII4XLvvyJc/h0EkR6LqQgPE+F+Fb6w+1/Q0hmn6jnlyN/bv9Q9iM+NaI9FUJ8bIiIiIiIiIiIiIiIiIiIiIiIiIiIiEghDkdsR9iF8kldEEN5hnSmPFJQpSOvQpkh6UvstkcRqgPwv8jOEzYmjeQlhKyMv+xERiZGKm0hijEB4gOvNyEqkC8J+fE8jseqEsAvGEoQHDj+DePog7ArBsN+f50GE35cH5vNAWw97hn6A8IwY3iiOB96y4HKkyPu5DREREckVC9sfEfbmW8ErogifluTJIYnFjV1D2BmjJMIClIHchLA7BFumsaEtu8uwW/t1CLvveOfn8zpocFpyNsI3tzwXF0/7RL9BvK40PNeh14pNJOVo5CaSODzbAkdQ1yDszZcb/7Qk99F5eMbnPchRhE1r2Q6JYZPrw8ghhNdz1HUHwiK2GyH/+dneRNjklmdU9k7Vwl6rDyEsrrURnq9LJCWpuInEHwsUR2AvIDxb8QKkmXsdR2B5EX5alfyeZuW4+5HYDJc4JcnpSo4aObrjlKZISlJxE4k/FjEWOO+U/O8jLG68jiOwvLgT4fQiiyJXXHJ6c5m7fTHCqUl2Zed1/D6/QDiNSedr7PsThKcu4SlLJiAcaYqkJBU3kcSojOxDOBXIaUlOB+amN+Ltc2N41mP6EOG5tLhIhB8/Rnjaf460eBvPiszCtBrhvjeOFv+GcDrUf4qSSDIRfh6/ti0yChEREYkrLigZE9oUkdxo5CYiIiIiIiIiIiIiIiIiIiIiIiIiIiIikkLM/j/3wagwcMuIHwAAAABJRU5ErkJggg==)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-104rC6UfGaX"
      },
      "outputs": [],
      "source": [
        "def Our_Decay():\n",
        "    modelOurDecay = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelOurDecay.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.0001, max_lr=0.1, step_size_up=1,scale_mode='decrecimiento')\n",
        "\n",
        "    start.record()\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_epochs = train(modelOurDecay,optimizer, scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    our_decay_time = start.elapsed_time(end)\n",
        "\n",
        "    our_decay_acc = accuracy(modelOurDecay, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1gWBYUD-F8g",
        "outputId": "3f364305-afff-415e-b44c-bdcf7b3dec7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4706470966339111, accuracy: 0.771484375\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7205039858818054, accuracy: 0.845703125\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.586100697517395, accuracy: 0.838134765625\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4945555627346039, accuracy: 0.8896484375\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.4494311511516571, accuracy: 0.906005859375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.39120447635650635, accuracy: 0.9033203125\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.34409213066101074, accuracy: 0.907958984375\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3616147041320801, accuracy: 0.918212890625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3533439636230469, accuracy: 0.919921875\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.2510848641395569, accuracy: 0.927490234375\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.32339030504226685, accuracy: 0.928466796875\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.3520966172218323, accuracy: 0.931640625\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.23823398351669312, accuracy: 0.934326171875\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.25237342715263367, accuracy: 0.927734375\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.30606701970100403, accuracy: 0.93896484375\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.30956926941871643, accuracy: 0.934814453125\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2720664143562317, accuracy: 0.943115234375\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.24495747685432434, accuracy: 0.9375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.25410234928131104, accuracy: 0.939697265625\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.22637437283992767, accuracy: 0.939453125\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.2261652797460556, accuracy: 0.942626953125\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.25714609026908875, accuracy: 0.94189453125\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.2078150063753128, accuracy: 0.9453125\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.2033196985721588, accuracy: 0.94921875\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.1871694028377533, accuracy: 0.947509765625\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.21045692265033722, accuracy: 0.952880859375\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.20102770626544952, accuracy: 0.95703125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.19031795859336853, accuracy: 0.954345703125\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.20424190163612366, accuracy: 0.95556640625\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.20605285465717316, accuracy: 0.95166015625\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.21342505514621735, accuracy: 0.95654296875\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.17351552844047546, accuracy: 0.96240234375\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.1618722379207611, accuracy: 0.96337890625\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.19211988151073456, accuracy: 0.961181640625\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.16452078521251678, accuracy: 0.961181640625\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.20638108253479004, accuracy: 0.957275390625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.19725842773914337, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.1476370394229889, accuracy: 0.95947265625\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.1581723392009735, accuracy: 0.956787109375\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.1890868842601776, accuracy: 0.963134765625\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.15829870104789734, accuracy: 0.9697265625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.13199418783187866, accuracy: 0.960205078125\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.1256980150938034, accuracy: 0.966552734375\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.12680619955062866, accuracy: 0.960205078125\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.130612313747406, accuracy: 0.96240234375\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.13996301591396332, accuracy: 0.966064453125\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.11234340816736221, accuracy: 0.964599609375\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.13789677619934082, accuracy: 0.9638671875\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12285563349723816, accuracy: 0.967529296875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.11006919294595718, accuracy: 0.97021484375\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.16612598299980164, accuracy: 0.968505859375\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.1429414451122284, accuracy: 0.9697265625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.15523380041122437, accuracy: 0.96826171875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.14394979178905487, accuracy: 0.96875\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.1407088041305542, accuracy: 0.96826171875\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.1418762505054474, accuracy: 0.9658203125\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.10101210325956345, accuracy: 0.96826171875\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.10334314405918121, accuracy: 0.969482421875\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.10780350118875504, accuracy: 0.9697265625\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.1397925615310669, accuracy: 0.971923828125\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.10826606303453445, accuracy: 0.968505859375\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.10959519445896149, accuracy: 0.969970703125\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.0966232493519783, accuracy: 0.970458984375\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.09813686460256577, accuracy: 0.9736328125\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.11554767191410065, accuracy: 0.970947265625\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.11606625467538834, accuracy: 0.9697265625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.08104509115219116, accuracy: 0.974365234375\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.08911687880754471, accuracy: 0.97412109375\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.10718975961208344, accuracy: 0.968994140625\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.12798991799354553, accuracy: 0.9736328125\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.07052575051784515, accuracy: 0.9697265625\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.09144510328769684, accuracy: 0.971923828125\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.1108175590634346, accuracy: 0.97119140625\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.0952974408864975, accuracy: 0.972412109375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.1078910231590271, accuracy: 0.971923828125\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.07687831670045853, accuracy: 0.97509765625\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.10197746753692627, accuracy: 0.9736328125\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.09961167722940445, accuracy: 0.976318359375\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.07908762991428375, accuracy: 0.970458984375\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.09275254607200623, accuracy: 0.972412109375\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.08845676481723785, accuracy: 0.97607421875\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.09557893127202988, accuracy: 0.976806640625\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.0960615873336792, accuracy: 0.972412109375\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.08065740764141083, accuracy: 0.974609375\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.11175139993429184, accuracy: 0.9736328125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.11007287353277206, accuracy: 0.9775390625\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.10908146947622299, accuracy: 0.975341796875\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.05718153715133667, accuracy: 0.974609375\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.1000463142991066, accuracy: 0.97900390625\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.06811382621526718, accuracy: 0.97314453125\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.07090122997760773, accuracy: 0.971923828125\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.06567905098199844, accuracy: 0.9755859375\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.08705996721982956, accuracy: 0.97607421875\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.09253763407468796, accuracy: 0.977783203125\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.09288569539785385, accuracy: 0.9736328125\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.08605530858039856, accuracy: 0.97412109375\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.09428431838750839, accuracy: 0.97412109375\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.09861338138580322, accuracy: 0.9765625\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.0734466090798378, accuracy: 0.974853515625\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.0626479983329773, accuracy: 0.97509765625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.508862018585205, accuracy: 0.75927734375\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7366037964820862, accuracy: 0.85107421875\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5975498557090759, accuracy: 0.85546875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4665015935897827, accuracy: 0.8935546875\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.44367557764053345, accuracy: 0.886474609375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.3791859745979309, accuracy: 0.904541015625\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.39525580406188965, accuracy: 0.906005859375\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3496529161930084, accuracy: 0.91455078125\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3437183201313019, accuracy: 0.916259765625\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.27766016125679016, accuracy: 0.92578125\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.3190276324748993, accuracy: 0.9248046875\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.31461450457572937, accuracy: 0.930419921875\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.24891921877861023, accuracy: 0.92578125\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.33360400795936584, accuracy: 0.931396484375\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.30297303199768066, accuracy: 0.936279296875\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.270963579416275, accuracy: 0.93798828125\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2550712525844574, accuracy: 0.934326171875\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.2509569525718689, accuracy: 0.94287109375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.24223625659942627, accuracy: 0.941650390625\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.1977137327194214, accuracy: 0.94189453125\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.24141825735569, accuracy: 0.9482421875\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.24003104865550995, accuracy: 0.94189453125\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.23677174746990204, accuracy: 0.94873046875\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.2465459704399109, accuracy: 0.948486328125\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.20428919792175293, accuracy: 0.948974609375\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.19561825692653656, accuracy: 0.94921875\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.20098747313022614, accuracy: 0.952392578125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.21299460530281067, accuracy: 0.948974609375\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.17141176760196686, accuracy: 0.95068359375\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.17533782124519348, accuracy: 0.958740234375\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.20463234186172485, accuracy: 0.95654296875\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.17175309360027313, accuracy: 0.95849609375\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.18830496072769165, accuracy: 0.95703125\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.1809179186820984, accuracy: 0.9580078125\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.15752965211868286, accuracy: 0.961181640625\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.16642668843269348, accuracy: 0.95556640625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.14168989658355713, accuracy: 0.958984375\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.17991964519023895, accuracy: 0.96044921875\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.15383489429950714, accuracy: 0.962890625\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.1374465674161911, accuracy: 0.96142578125\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.1455289125442505, accuracy: 0.9619140625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.18360885977745056, accuracy: 0.963134765625\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.14991922676563263, accuracy: 0.963134765625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.16816867887973785, accuracy: 0.96435546875\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.1409185826778412, accuracy: 0.9658203125\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.13346554338932037, accuracy: 0.964111328125\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.14447492361068726, accuracy: 0.965087890625\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.1683996617794037, accuracy: 0.96533203125\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12423878908157349, accuracy: 0.96728515625\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.15070749819278717, accuracy: 0.9638671875\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.16302675008773804, accuracy: 0.96923828125\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.15531720221042633, accuracy: 0.96875\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.14465971291065216, accuracy: 0.966552734375\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.1219656839966774, accuracy: 0.968017578125\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.13057908415794373, accuracy: 0.966796875\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.09759904444217682, accuracy: 0.966796875\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.13161610066890717, accuracy: 0.9658203125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.13697783648967743, accuracy: 0.967041015625\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.10446128249168396, accuracy: 0.968505859375\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.14232836663722992, accuracy: 0.970458984375\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.09714406728744507, accuracy: 0.969482421875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.11823754757642746, accuracy: 0.9716796875\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.1461167335510254, accuracy: 0.970947265625\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.12364000827074051, accuracy: 0.97021484375\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.10019365698099136, accuracy: 0.972412109375\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.0981762558221817, accuracy: 0.970947265625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11424203962087631, accuracy: 0.96875\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.11639074236154556, accuracy: 0.970703125\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.10684669017791748, accuracy: 0.9697265625\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.09477158635854721, accuracy: 0.972412109375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.1271631419658661, accuracy: 0.972412109375\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.08455602824687958, accuracy: 0.967529296875\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.10218413174152374, accuracy: 0.967041015625\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.0931602492928505, accuracy: 0.970458984375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.11950522661209106, accuracy: 0.9716796875\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.08750717341899872, accuracy: 0.9697265625\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.0849931389093399, accuracy: 0.97021484375\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.08121919631958008, accuracy: 0.97216796875\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.10780294239521027, accuracy: 0.96826171875\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.10560702532529831, accuracy: 0.97216796875\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.09153436869382858, accuracy: 0.971923828125\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.07271993160247803, accuracy: 0.974365234375\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.11649484187364578, accuracy: 0.97216796875\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.10159557312726974, accuracy: 0.972412109375\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.08763831853866577, accuracy: 0.975830078125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.07511593401432037, accuracy: 0.971923828125\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.09492593258619308, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.09477759897708893, accuracy: 0.977294921875\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.07652906328439713, accuracy: 0.973876953125\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.058726586401462555, accuracy: 0.974609375\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.10363196581602097, accuracy: 0.97021484375\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.07009795308113098, accuracy: 0.971923828125\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.07978270202875137, accuracy: 0.973388671875\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.07249115407466888, accuracy: 0.97509765625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.07440117746591568, accuracy: 0.974853515625\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.07488928735256195, accuracy: 0.974365234375\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.08790968358516693, accuracy: 0.972900390625\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07596120983362198, accuracy: 0.9755859375\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.0593598410487175, accuracy: 0.97412109375\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.09118367731571198, accuracy: 0.970947265625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4985496997833252, accuracy: 0.789794921875\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7454813122749329, accuracy: 0.857177734375\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5413398146629333, accuracy: 0.854736328125\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.48659899830818176, accuracy: 0.88720703125\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.425767183303833, accuracy: 0.9091796875\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.36802569031715393, accuracy: 0.905517578125\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.3709387183189392, accuracy: 0.912841796875\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3686618506908417, accuracy: 0.91748046875\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3134773075580597, accuracy: 0.9208984375\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.2959357798099518, accuracy: 0.924072265625\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.28310340642929077, accuracy: 0.92626953125\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.3126961588859558, accuracy: 0.92041015625\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.3008323013782501, accuracy: 0.929931640625\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.2933378517627716, accuracy: 0.930908203125\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.24707967042922974, accuracy: 0.93701171875\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.2839524745941162, accuracy: 0.931640625\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2419445514678955, accuracy: 0.941650390625\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.26547861099243164, accuracy: 0.93896484375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.22043845057487488, accuracy: 0.943359375\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.17879025638103485, accuracy: 0.9462890625\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.23586544394493103, accuracy: 0.9384765625\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.20686602592468262, accuracy: 0.9443359375\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.22640244662761688, accuracy: 0.948974609375\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.1782311648130417, accuracy: 0.949462890625\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.22242222726345062, accuracy: 0.953125\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.15972015261650085, accuracy: 0.9501953125\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.22137486934661865, accuracy: 0.953125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.1944894939661026, accuracy: 0.9501953125\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.17638692259788513, accuracy: 0.95654296875\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.1869371235370636, accuracy: 0.956787109375\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.1843498945236206, accuracy: 0.959228515625\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.20013001561164856, accuracy: 0.956787109375\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.14630655944347382, accuracy: 0.958251953125\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.1755208671092987, accuracy: 0.958740234375\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.1681346744298935, accuracy: 0.957763671875\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.14537593722343445, accuracy: 0.96044921875\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1747751086950302, accuracy: 0.963134765625\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.12636642158031464, accuracy: 0.960693359375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.1476639211177826, accuracy: 0.965087890625\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.14218217134475708, accuracy: 0.9599609375\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.17031140625476837, accuracy: 0.96044921875\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.15192121267318726, accuracy: 0.9638671875\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.118162140250206, accuracy: 0.967529296875\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.13250663876533508, accuracy: 0.96533203125\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.1595468372106552, accuracy: 0.9638671875\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.13877545297145844, accuracy: 0.966796875\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.14643824100494385, accuracy: 0.9638671875\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.13777293264865875, accuracy: 0.966796875\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.14376512169837952, accuracy: 0.96826171875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.1134885922074318, accuracy: 0.964599609375\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.13095392286777496, accuracy: 0.968505859375\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.11799551546573639, accuracy: 0.9697265625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.16075308620929718, accuracy: 0.967529296875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.12398641556501389, accuracy: 0.96484375\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.12505917251110077, accuracy: 0.96923828125\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.11660303920507431, accuracy: 0.966796875\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.11492305248975754, accuracy: 0.968017578125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.12923508882522583, accuracy: 0.966552734375\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.12390005588531494, accuracy: 0.965087890625\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.1372472047805786, accuracy: 0.971435546875\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.12246382981538773, accuracy: 0.966796875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.10670240223407745, accuracy: 0.97021484375\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.10986869782209396, accuracy: 0.968994140625\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.12176850438117981, accuracy: 0.97119140625\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.10721232742071152, accuracy: 0.970458984375\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.10518059879541397, accuracy: 0.972900390625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.095486581325531, accuracy: 0.9716796875\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.11740031093358994, accuracy: 0.96923828125\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.1394204944372177, accuracy: 0.968505859375\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.11660009622573853, accuracy: 0.97265625\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.10715378820896149, accuracy: 0.969482421875\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.08360403031110764, accuracy: 0.97412109375\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.10237487405538559, accuracy: 0.97216796875\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.08798092603683472, accuracy: 0.97021484375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.08222141861915588, accuracy: 0.969970703125\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.0931180864572525, accuracy: 0.97314453125\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.11843610554933548, accuracy: 0.970947265625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.11029652506113052, accuracy: 0.97119140625\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.0977729856967926, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.10533390194177628, accuracy: 0.970947265625\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.10588572174310684, accuracy: 0.975341796875\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.1332460343837738, accuracy: 0.974853515625\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.09771300107240677, accuracy: 0.97802734375\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.08380203694105148, accuracy: 0.971923828125\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.09309949725866318, accuracy: 0.975830078125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.0999341756105423, accuracy: 0.974853515625\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.0776384249329567, accuracy: 0.97607421875\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.10492952913045883, accuracy: 0.97119140625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.06740543246269226, accuracy: 0.97314453125\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.10257991403341293, accuracy: 0.970947265625\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.07040692120790482, accuracy: 0.974609375\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.09221387654542923, accuracy: 0.977294921875\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.09855052083730698, accuracy: 0.97607421875\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.06954000890254974, accuracy: 0.97607421875\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.07652390003204346, accuracy: 0.977783203125\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.08414597809314728, accuracy: 0.972412109375\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.06337492167949677, accuracy: 0.973388671875\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07909955829381943, accuracy: 0.97509765625\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.07938050478696823, accuracy: 0.974853515625\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.06163925677537918, accuracy: 0.9765625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.498189926147461, accuracy: 0.774658203125\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7338263392448425, accuracy: 0.857666015625\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5927552580833435, accuracy: 0.87939453125\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.5576151013374329, accuracy: 0.87255859375\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.39520391821861267, accuracy: 0.89990234375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.4032133221626282, accuracy: 0.9111328125\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.4295838475227356, accuracy: 0.909912109375\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3507246673107147, accuracy: 0.916015625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3915543556213379, accuracy: 0.912109375\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.3819047808647156, accuracy: 0.92724609375\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.30272936820983887, accuracy: 0.929931640625\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.3321937918663025, accuracy: 0.93017578125\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.2945764362812042, accuracy: 0.932373046875\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.26613980531692505, accuracy: 0.9375\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.25525012612342834, accuracy: 0.932861328125\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.23762281239032745, accuracy: 0.93359375\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2755771279335022, accuracy: 0.94140625\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.26009899377822876, accuracy: 0.939208984375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.19998504221439362, accuracy: 0.940185546875\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.21932056546211243, accuracy: 0.94775390625\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.2553935945034027, accuracy: 0.94677734375\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.20213839411735535, accuracy: 0.94921875\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.2089063674211502, accuracy: 0.9482421875\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.21725980937480927, accuracy: 0.949462890625\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.2225627601146698, accuracy: 0.953369140625\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.19112743437290192, accuracy: 0.95068359375\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.18491274118423462, accuracy: 0.955810546875\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.1859360784292221, accuracy: 0.954345703125\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.21290425956249237, accuracy: 0.953369140625\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.19890499114990234, accuracy: 0.95654296875\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.16765013337135315, accuracy: 0.960205078125\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.14753864705562592, accuracy: 0.9560546875\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.1767016351222992, accuracy: 0.96044921875\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.17358893156051636, accuracy: 0.962158203125\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.1564818024635315, accuracy: 0.955322265625\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.1810608059167862, accuracy: 0.958740234375\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.17477920651435852, accuracy: 0.959716796875\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.15160644054412842, accuracy: 0.964599609375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.1339607536792755, accuracy: 0.95654296875\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.12324940413236618, accuracy: 0.961181640625\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.16027449071407318, accuracy: 0.96337890625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.14198586344718933, accuracy: 0.96435546875\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.13189391791820526, accuracy: 0.963623046875\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.15070955455303192, accuracy: 0.960693359375\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.16218440234661102, accuracy: 0.96728515625\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.1470230221748352, accuracy: 0.965087890625\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.12879836559295654, accuracy: 0.964111328125\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.14073485136032104, accuracy: 0.965087890625\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.13437706232070923, accuracy: 0.965087890625\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.15739117562770844, accuracy: 0.965576171875\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.12414398789405823, accuracy: 0.967041015625\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.10133253037929535, accuracy: 0.966552734375\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.12930287420749664, accuracy: 0.96533203125\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.12595981359481812, accuracy: 0.969970703125\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.15250864624977112, accuracy: 0.969482421875\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12498526275157928, accuracy: 0.96923828125\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.10371152311563492, accuracy: 0.9697265625\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.1144702360033989, accuracy: 0.97119140625\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.13031797111034393, accuracy: 0.969970703125\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.1261492818593979, accuracy: 0.97021484375\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.10685130953788757, accuracy: 0.971923828125\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.11812442541122437, accuracy: 0.97216796875\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.0986786037683487, accuracy: 0.97216796875\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.10260426253080368, accuracy: 0.97119140625\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.12235979735851288, accuracy: 0.968505859375\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.1398329734802246, accuracy: 0.971435546875\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.12654735147953033, accuracy: 0.970947265625\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.10761729627847672, accuracy: 0.96875\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.11076509952545166, accuracy: 0.970458984375\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.07008381932973862, accuracy: 0.97412109375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.1014421209692955, accuracy: 0.970458984375\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.11473238468170166, accuracy: 0.968505859375\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.0903744250535965, accuracy: 0.9697265625\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.0767286941409111, accuracy: 0.97021484375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.12093932926654816, accuracy: 0.970703125\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.10105357319116592, accuracy: 0.970703125\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.08991078287363052, accuracy: 0.971923828125\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.09895440191030502, accuracy: 0.97314453125\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.08369824290275574, accuracy: 0.97119140625\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.0955679640173912, accuracy: 0.972900390625\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.11413397639989853, accuracy: 0.9755859375\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.11141300946474075, accuracy: 0.97607421875\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.08036201447248459, accuracy: 0.976806640625\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.0836271345615387, accuracy: 0.972900390625\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.08847445249557495, accuracy: 0.97509765625\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.10457246750593185, accuracy: 0.9736328125\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.06499970704317093, accuracy: 0.97607421875\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.11140789091587067, accuracy: 0.97265625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.10161294788122177, accuracy: 0.978515625\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.07052390277385712, accuracy: 0.972412109375\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.10236752778291702, accuracy: 0.972900390625\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.06203288584947586, accuracy: 0.97607421875\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.09178479760885239, accuracy: 0.9755859375\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.07471717894077301, accuracy: 0.976806640625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.059218671172857285, accuracy: 0.979736328125\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.07531826198101044, accuracy: 0.977294921875\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.07671082019805908, accuracy: 0.976318359375\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.08541760593652725, accuracy: 0.97705078125\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.09327897429466248, accuracy: 0.974609375\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.07803235203027725, accuracy: 0.977783203125\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4380626678466797, accuracy: 0.79638671875\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.8065834641456604, accuracy: 0.8095703125\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5689844489097595, accuracy: 0.865966796875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.5001385807991028, accuracy: 0.86865234375\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.41661638021469116, accuracy: 0.904052734375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.372715026140213, accuracy: 0.906494140625\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.4158124029636383, accuracy: 0.91650390625\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3341010808944702, accuracy: 0.921875\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.32467374205589294, accuracy: 0.9189453125\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.34682488441467285, accuracy: 0.9189453125\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.3293865919113159, accuracy: 0.921875\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.24356433749198914, accuracy: 0.927734375\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.28978466987609863, accuracy: 0.925537109375\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.28885236382484436, accuracy: 0.928955078125\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.27183467149734497, accuracy: 0.9345703125\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.20572863519191742, accuracy: 0.93603515625\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2845439612865448, accuracy: 0.942626953125\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.24375051259994507, accuracy: 0.93701171875\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.23994024097919464, accuracy: 0.939453125\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.23255380988121033, accuracy: 0.943359375\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.22239673137664795, accuracy: 0.946044921875\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.19259078800678253, accuracy: 0.946533203125\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.20158226788043976, accuracy: 0.94775390625\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.20102129876613617, accuracy: 0.951904296875\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.17419670522212982, accuracy: 0.951416015625\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.2668595314025879, accuracy: 0.9462890625\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.25002849102020264, accuracy: 0.94970703125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.16410715878009796, accuracy: 0.949951171875\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.16816791892051697, accuracy: 0.960205078125\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.1995818167924881, accuracy: 0.95361328125\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.17988604307174683, accuracy: 0.954833984375\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.1627173274755478, accuracy: 0.952392578125\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.16815195977687836, accuracy: 0.957275390625\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.16652347147464752, accuracy: 0.961181640625\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.17802377045154572, accuracy: 0.9599609375\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.14595164358615875, accuracy: 0.95947265625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1653430163860321, accuracy: 0.9599609375\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.17014706134796143, accuracy: 0.962646484375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.18241479992866516, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.17324970662593842, accuracy: 0.963134765625\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.15455202758312225, accuracy: 0.965576171875\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.18776081502437592, accuracy: 0.962890625\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.12723490595817566, accuracy: 0.96337890625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.1423797756433487, accuracy: 0.963134765625\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.10483784228563309, accuracy: 0.964111328125\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.11788848787546158, accuracy: 0.9638671875\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.11618500202894211, accuracy: 0.965576171875\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.12305455654859543, accuracy: 0.96875\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.10798600316047668, accuracy: 0.965576171875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.13215187191963196, accuracy: 0.962158203125\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.14932306110858917, accuracy: 0.96875\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.15963970124721527, accuracy: 0.963134765625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.13309228420257568, accuracy: 0.967041015625\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.13426530361175537, accuracy: 0.96875\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.11297255754470825, accuracy: 0.970947265625\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12784557044506073, accuracy: 0.967529296875\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.13505984842777252, accuracy: 0.967041015625\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.11683293431997299, accuracy: 0.971435546875\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.13514560461044312, accuracy: 0.970703125\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.13160452246665955, accuracy: 0.97119140625\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.11300740391016006, accuracy: 0.967529296875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.09744199365377426, accuracy: 0.970947265625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.10765435546636581, accuracy: 0.97412109375\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.10517706722021103, accuracy: 0.97265625\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.07854512333869934, accuracy: 0.97216796875\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.09360765665769577, accuracy: 0.972900390625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.1165941059589386, accuracy: 0.972412109375\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.11624569445848465, accuracy: 0.970947265625\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.11643759906291962, accuracy: 0.96923828125\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.11239954829216003, accuracy: 0.97216796875\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.09337732195854187, accuracy: 0.9716796875\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.08323021978139877, accuracy: 0.97314453125\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.08544743061065674, accuracy: 0.973876953125\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.11380842328071594, accuracy: 0.9697265625\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.1075400710105896, accuracy: 0.972900390625\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.11748995631933212, accuracy: 0.9755859375\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.10206639021635056, accuracy: 0.97265625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.08267221599817276, accuracy: 0.970703125\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.09307712316513062, accuracy: 0.975830078125\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.10252021998167038, accuracy: 0.974853515625\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.09165380895137787, accuracy: 0.9736328125\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.060284074395895004, accuracy: 0.971923828125\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.09923107922077179, accuracy: 0.973388671875\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.10408852994441986, accuracy: 0.975830078125\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.0741577297449112, accuracy: 0.97216796875\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.10841429978609085, accuracy: 0.97314453125\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.06533533334732056, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.067256860435009, accuracy: 0.975341796875\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08831348270177841, accuracy: 0.974609375\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.060681041330099106, accuracy: 0.97509765625\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.07354453206062317, accuracy: 0.972900390625\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.07723323255777359, accuracy: 0.971435546875\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.08373354375362396, accuracy: 0.97509765625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.0668460950255394, accuracy: 0.9775390625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.07489463686943054, accuracy: 0.975341796875\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.07018883526325226, accuracy: 0.9736328125\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.06942504644393921, accuracy: 0.973876953125\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07576864957809448, accuracy: 0.975341796875\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.09416896104812622, accuracy: 0.975830078125\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.0774519070982933, accuracy: 0.9765625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4639476537704468, accuracy: 0.79052734375\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7369762659072876, accuracy: 0.811279296875\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5869202613830566, accuracy: 0.8525390625\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4658621549606323, accuracy: 0.89794921875\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.44187626242637634, accuracy: 0.8935546875\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.39542827010154724, accuracy: 0.903076171875\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.43134549260139465, accuracy: 0.915283203125\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3182564973831177, accuracy: 0.916259765625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3512198030948639, accuracy: 0.91796875\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.33127349615097046, accuracy: 0.923583984375\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.27445563673973083, accuracy: 0.929931640625\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.2918141484260559, accuracy: 0.924560546875\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.314798504114151, accuracy: 0.930908203125\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.2899951934814453, accuracy: 0.936767578125\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.29633966088294983, accuracy: 0.9384765625\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.2687252461910248, accuracy: 0.936279296875\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2469628006219864, accuracy: 0.938232421875\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.23065876960754395, accuracy: 0.938720703125\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.25611263513565063, accuracy: 0.94384765625\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.2648748457431793, accuracy: 0.94189453125\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.21083521842956543, accuracy: 0.94384765625\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.23659361898899078, accuracy: 0.94580078125\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.23374693095684052, accuracy: 0.94482421875\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.17044787108898163, accuracy: 0.948974609375\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.18859651684761047, accuracy: 0.951904296875\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.18448570370674133, accuracy: 0.94970703125\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.20994964241981506, accuracy: 0.95166015625\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.18504664301872253, accuracy: 0.95263671875\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.18464380502700806, accuracy: 0.955810546875\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.18171659111976624, accuracy: 0.953369140625\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.17581288516521454, accuracy: 0.957275390625\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.14257657527923584, accuracy: 0.95458984375\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.1623470038175583, accuracy: 0.95947265625\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.1504550725221634, accuracy: 0.958251953125\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.2156379520893097, accuracy: 0.9580078125\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.17889292538166046, accuracy: 0.960693359375\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1666879653930664, accuracy: 0.960205078125\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.1399029940366745, accuracy: 0.963623046875\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.13598184287548065, accuracy: 0.96142578125\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.1702776849269867, accuracy: 0.963623046875\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.1733437180519104, accuracy: 0.965087890625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.1436430960893631, accuracy: 0.962646484375\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.13222560286521912, accuracy: 0.96337890625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.15002843737602234, accuracy: 0.968017578125\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.20273882150650024, accuracy: 0.965576171875\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.15818321704864502, accuracy: 0.96630859375\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.1543707400560379, accuracy: 0.96630859375\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.13746237754821777, accuracy: 0.964599609375\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12418414652347565, accuracy: 0.9658203125\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.13790729641914368, accuracy: 0.96826171875\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.145916149020195, accuracy: 0.96728515625\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.13812915980815887, accuracy: 0.963134765625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.12150590121746063, accuracy: 0.96875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.12110479921102524, accuracy: 0.967529296875\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.1253071427345276, accuracy: 0.967529296875\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12562215328216553, accuracy: 0.96826171875\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.13821333646774292, accuracy: 0.96533203125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.11601345241069794, accuracy: 0.968505859375\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.11331836879253387, accuracy: 0.9697265625\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.10997773706912994, accuracy: 0.968994140625\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.09843041747808456, accuracy: 0.96923828125\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.08966602385044098, accuracy: 0.968994140625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.10891550779342651, accuracy: 0.97021484375\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.08411175012588501, accuracy: 0.97216796875\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.12999390065670013, accuracy: 0.972900390625\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.10976938158273697, accuracy: 0.9697265625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.1000983789563179, accuracy: 0.96923828125\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.08993813395500183, accuracy: 0.970703125\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.12039761245250702, accuracy: 0.97119140625\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.07280047237873077, accuracy: 0.96630859375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.07479735463857651, accuracy: 0.97021484375\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.12119314074516296, accuracy: 0.97314453125\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.09054671227931976, accuracy: 0.973388671875\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.09073413908481598, accuracy: 0.969970703125\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.13532547652721405, accuracy: 0.97216796875\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.0849493071436882, accuracy: 0.971435546875\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.12447148561477661, accuracy: 0.9736328125\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.11038868129253387, accuracy: 0.972900390625\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.11727549880743027, accuracy: 0.973876953125\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.06612630188465118, accuracy: 0.973876953125\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.08203902095556259, accuracy: 0.97509765625\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.11142092943191528, accuracy: 0.974853515625\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.08302739262580872, accuracy: 0.975830078125\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.09279952943325043, accuracy: 0.97314453125\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.07806140184402466, accuracy: 0.97412109375\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.07432332634925842, accuracy: 0.9755859375\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.09380080550909042, accuracy: 0.9755859375\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.06718458980321884, accuracy: 0.97314453125\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.091411292552948, accuracy: 0.97265625\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.09392362833023071, accuracy: 0.978271484375\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.05778646096587181, accuracy: 0.970947265625\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.06735777854919434, accuracy: 0.97607421875\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.07310660928487778, accuracy: 0.9775390625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.06927070766687393, accuracy: 0.973388671875\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.10605289041996002, accuracy: 0.975830078125\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.05546833947300911, accuracy: 0.972412109375\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.06990154832601547, accuracy: 0.974365234375\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07457029819488525, accuracy: 0.9775390625\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.07106576859951019, accuracy: 0.97412109375\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.06199806556105614, accuracy: 0.974609375\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.5277725458145142, accuracy: 0.7861328125\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7435640096664429, accuracy: 0.810302734375\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.6004943251609802, accuracy: 0.843505859375\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4794553220272064, accuracy: 0.88037109375\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.428466260433197, accuracy: 0.88525390625\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.4110247492790222, accuracy: 0.900390625\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.33276644349098206, accuracy: 0.911376953125\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3755127489566803, accuracy: 0.9140625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.27170002460479736, accuracy: 0.917236328125\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.3157075047492981, accuracy: 0.917236328125\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.2963038682937622, accuracy: 0.921630859375\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.2609083950519562, accuracy: 0.922607421875\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.2998697757720947, accuracy: 0.926513671875\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.3337738811969757, accuracy: 0.931396484375\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.2633635997772217, accuracy: 0.935791015625\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.2179020345211029, accuracy: 0.935302734375\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.26069679856300354, accuracy: 0.937744140625\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.24500350654125214, accuracy: 0.9404296875\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.2274133712053299, accuracy: 0.937255859375\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.22814950346946716, accuracy: 0.942138671875\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.18931226432323456, accuracy: 0.939453125\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.2324976772069931, accuracy: 0.95068359375\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.2615838944911957, accuracy: 0.950439453125\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.20640963315963745, accuracy: 0.951416015625\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.247952401638031, accuracy: 0.952880859375\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.20676890015602112, accuracy: 0.94921875\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.19379401206970215, accuracy: 0.956298828125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.17043128609657288, accuracy: 0.952880859375\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.19223421812057495, accuracy: 0.955322265625\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.19343262910842896, accuracy: 0.956298828125\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.15799036622047424, accuracy: 0.95068359375\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.17724134027957916, accuracy: 0.95654296875\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.14532367885112762, accuracy: 0.956787109375\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.19792844355106354, accuracy: 0.961181640625\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.1830742508172989, accuracy: 0.956787109375\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.1370195746421814, accuracy: 0.959228515625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.18701425194740295, accuracy: 0.956298828125\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.15752056241035461, accuracy: 0.961669921875\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.16409917175769806, accuracy: 0.95751953125\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.16659407317638397, accuracy: 0.96142578125\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.1553860455751419, accuracy: 0.96484375\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.139897882938385, accuracy: 0.968017578125\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.1658415049314499, accuracy: 0.96484375\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.15631018579006195, accuracy: 0.960205078125\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.17273156344890594, accuracy: 0.9677734375\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.17234404385089874, accuracy: 0.965576171875\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.1323266625404358, accuracy: 0.964111328125\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.16245557367801666, accuracy: 0.965576171875\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.1462792158126831, accuracy: 0.96826171875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.12203305959701538, accuracy: 0.96923828125\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.1353975236415863, accuracy: 0.966064453125\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.12043288350105286, accuracy: 0.966064453125\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.10067635029554367, accuracy: 0.96728515625\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.12528182566165924, accuracy: 0.97119140625\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.13911835849285126, accuracy: 0.971435546875\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12286589294672012, accuracy: 0.97314453125\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.12992410361766815, accuracy: 0.968017578125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.12264177948236465, accuracy: 0.968017578125\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.09313071519136429, accuracy: 0.968505859375\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.10851716995239258, accuracy: 0.969970703125\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.12519586086273193, accuracy: 0.97216796875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.11040690541267395, accuracy: 0.9697265625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.09171059727668762, accuracy: 0.972900390625\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.1043638288974762, accuracy: 0.97265625\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.1418989598751068, accuracy: 0.97119140625\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.09368811547756195, accuracy: 0.974609375\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.09378316253423691, accuracy: 0.9716796875\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.10765103250741959, accuracy: 0.97412109375\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.10371365398168564, accuracy: 0.974609375\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.11690203845500946, accuracy: 0.97265625\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.10067424178123474, accuracy: 0.972900390625\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.07924124598503113, accuracy: 0.972900390625\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.10004159063100815, accuracy: 0.97607421875\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.07928375154733658, accuracy: 0.97216796875\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.10109874606132507, accuracy: 0.97265625\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.0956602469086647, accuracy: 0.97265625\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.08423115313053131, accuracy: 0.974853515625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.08090244978666306, accuracy: 0.9736328125\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.10042280703783035, accuracy: 0.974365234375\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.0915960893034935, accuracy: 0.97412109375\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.1047489270567894, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.0886867418885231, accuracy: 0.97216796875\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.09951774775981903, accuracy: 0.973876953125\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.09279228746891022, accuracy: 0.97412109375\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.11025533080101013, accuracy: 0.97314453125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.08390700072050095, accuracy: 0.97509765625\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.08799859136343002, accuracy: 0.972412109375\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.10264340788125992, accuracy: 0.97265625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08727401494979858, accuracy: 0.974365234375\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.09366988390684128, accuracy: 0.975341796875\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.08026447892189026, accuracy: 0.97509765625\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.07132977992296219, accuracy: 0.977783203125\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.07532091438770294, accuracy: 0.972900390625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.08556455373764038, accuracy: 0.97802734375\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.062272556126117706, accuracy: 0.972412109375\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.07488745450973511, accuracy: 0.973876953125\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.059665948152542114, accuracy: 0.972412109375\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07828114926815033, accuracy: 0.977294921875\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.057979173958301544, accuracy: 0.9775390625\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.07499372959136963, accuracy: 0.974365234375\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.462944507598877, accuracy: 0.7509765625\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7654841542243958, accuracy: 0.8017578125\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5852528214454651, accuracy: 0.861572265625\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4901515245437622, accuracy: 0.89453125\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.4249100685119629, accuracy: 0.892822265625\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.3987236022949219, accuracy: 0.901123046875\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.36098477244377136, accuracy: 0.912109375\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.35554641485214233, accuracy: 0.917724609375\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3350798189640045, accuracy: 0.924072265625\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.28340381383895874, accuracy: 0.92529296875\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.32744404673576355, accuracy: 0.920166015625\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.3028760552406311, accuracy: 0.923828125\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.24493084847927094, accuracy: 0.931396484375\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.3391382098197937, accuracy: 0.930419921875\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.2557545006275177, accuracy: 0.93212890625\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.3047572076320648, accuracy: 0.93701171875\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2389673888683319, accuracy: 0.938720703125\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.24974994361400604, accuracy: 0.93896484375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.22946697473526, accuracy: 0.943115234375\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.2701937258243561, accuracy: 0.935791015625\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.23796583712100983, accuracy: 0.941162109375\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.19152452051639557, accuracy: 0.944091796875\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.2238340526819229, accuracy: 0.948486328125\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.21411417424678802, accuracy: 0.951171875\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.21664507687091827, accuracy: 0.952392578125\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.21570584177970886, accuracy: 0.955810546875\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.17361398041248322, accuracy: 0.95361328125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.15854698419570923, accuracy: 0.94921875\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.21148474514484406, accuracy: 0.952880859375\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.2071647346019745, accuracy: 0.9599609375\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.1724323034286499, accuracy: 0.95751953125\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.19138216972351074, accuracy: 0.95654296875\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.17512470483779907, accuracy: 0.962890625\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.19688037037849426, accuracy: 0.95947265625\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.15439707040786743, accuracy: 0.958251953125\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.14551815390586853, accuracy: 0.9609375\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1598673015832901, accuracy: 0.96240234375\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.10234341770410538, accuracy: 0.96142578125\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.18312464654445648, accuracy: 0.9599609375\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.15688183903694153, accuracy: 0.96240234375\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.17051436007022858, accuracy: 0.966552734375\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.13595658540725708, accuracy: 0.962646484375\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.1314208060503006, accuracy: 0.966796875\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.16119667887687683, accuracy: 0.963134765625\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.1386597901582718, accuracy: 0.9638671875\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.1454867571592331, accuracy: 0.964599609375\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.10559432208538055, accuracy: 0.97021484375\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.16305842995643616, accuracy: 0.963623046875\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.13254337012767792, accuracy: 0.96875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.11620312929153442, accuracy: 0.969482421875\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.13351398706436157, accuracy: 0.967041015625\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.13302111625671387, accuracy: 0.964599609375\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.11785311996936798, accuracy: 0.966796875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.1240469440817833, accuracy: 0.97216796875\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.14116869866847992, accuracy: 0.97265625\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.14438584446907043, accuracy: 0.966796875\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.12413056194782257, accuracy: 0.96728515625\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.12211224436759949, accuracy: 0.9716796875\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.18376773595809937, accuracy: 0.96630859375\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.08706177771091461, accuracy: 0.970458984375\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.1121768206357956, accuracy: 0.968994140625\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.10185524821281433, accuracy: 0.972900390625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.11492792516946793, accuracy: 0.974365234375\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.09606511890888214, accuracy: 0.97216796875\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.09884778410196304, accuracy: 0.97119140625\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.07885045558214188, accuracy: 0.973876953125\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.12135040760040283, accuracy: 0.974853515625\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.08225393295288086, accuracy: 0.971923828125\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.11131463944911957, accuracy: 0.97119140625\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.08501877635717392, accuracy: 0.9755859375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.10705099254846573, accuracy: 0.973388671875\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.07504791021347046, accuracy: 0.971923828125\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.11589548736810684, accuracy: 0.96826171875\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.1016862615942955, accuracy: 0.97412109375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.09025442600250244, accuracy: 0.972900390625\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.07947859913110733, accuracy: 0.970703125\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.09068212658166885, accuracy: 0.970947265625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.07713321596384048, accuracy: 0.97509765625\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.11434302479028702, accuracy: 0.972412109375\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.10429386794567108, accuracy: 0.97509765625\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.09267459809780121, accuracy: 0.97265625\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.08407612890005112, accuracy: 0.974365234375\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.10891450196504593, accuracy: 0.97607421875\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.08270065486431122, accuracy: 0.974365234375\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.0825919508934021, accuracy: 0.971923828125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.11508755385875702, accuracy: 0.974365234375\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.06500357389450073, accuracy: 0.977783203125\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.07246909290552139, accuracy: 0.976806640625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08118315786123276, accuracy: 0.9736328125\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.07098569720983505, accuracy: 0.97412109375\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.07302229106426239, accuracy: 0.975341796875\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.07507769763469696, accuracy: 0.97607421875\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.06321076303720474, accuracy: 0.977294921875\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.06787809729576111, accuracy: 0.97900390625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.05161184072494507, accuracy: 0.9736328125\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.06987833231687546, accuracy: 0.976806640625\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.07071901857852936, accuracy: 0.9755859375\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.05499737709760666, accuracy: 0.9736328125\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.05915006250143051, accuracy: 0.9765625\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.058947980403900146, accuracy: 0.97900390625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4838095903396606, accuracy: 0.78662109375\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7413750290870667, accuracy: 0.8310546875\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.64569091796875, accuracy: 0.8046875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4753788411617279, accuracy: 0.85791015625\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.4355076253414154, accuracy: 0.8818359375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.4124751091003418, accuracy: 0.9111328125\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.35457634925842285, accuracy: 0.9111328125\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3552878797054291, accuracy: 0.9150390625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3375999927520752, accuracy: 0.9208984375\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.3380836546421051, accuracy: 0.919921875\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.2947984039783478, accuracy: 0.92626953125\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.2899269461631775, accuracy: 0.92724609375\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.3124161958694458, accuracy: 0.92822265625\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.27931445837020874, accuracy: 0.9306640625\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.2491878867149353, accuracy: 0.927978515625\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.22785967588424683, accuracy: 0.934326171875\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2539703845977783, accuracy: 0.94091796875\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.2823657691478729, accuracy: 0.935546875\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.22853070497512817, accuracy: 0.940673828125\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.24668210744857788, accuracy: 0.93896484375\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.23707477748394012, accuracy: 0.94140625\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.22693385183811188, accuracy: 0.9404296875\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.24263736605644226, accuracy: 0.940673828125\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.2158358246088028, accuracy: 0.953857421875\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.23739390075206757, accuracy: 0.955322265625\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.20693720877170563, accuracy: 0.9541015625\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.1663525551557541, accuracy: 0.951171875\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.20563186705112457, accuracy: 0.95068359375\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.1932213008403778, accuracy: 0.957763671875\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.20584236085414886, accuracy: 0.9560546875\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.200120747089386, accuracy: 0.95654296875\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.13892433047294617, accuracy: 0.95849609375\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.13671863079071045, accuracy: 0.957763671875\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.1671605259180069, accuracy: 0.9599609375\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.15983331203460693, accuracy: 0.957763671875\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.16960899531841278, accuracy: 0.962158203125\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1293611228466034, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.1715518832206726, accuracy: 0.958740234375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.1685977429151535, accuracy: 0.960693359375\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.16756300628185272, accuracy: 0.96337890625\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.15318548679351807, accuracy: 0.966796875\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.15019869804382324, accuracy: 0.964111328125\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.12683488428592682, accuracy: 0.961181640625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.13736851513385773, accuracy: 0.959228515625\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.16023489832878113, accuracy: 0.964599609375\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.14557845890522003, accuracy: 0.960693359375\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.16755613684654236, accuracy: 0.96337890625\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.1618201732635498, accuracy: 0.96484375\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.1331295669078827, accuracy: 0.966552734375\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.15304173529148102, accuracy: 0.966796875\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.10176952183246613, accuracy: 0.966064453125\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.11899660527706146, accuracy: 0.968994140625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.1293506920337677, accuracy: 0.96728515625\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.13208329677581787, accuracy: 0.966796875\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.11898709833621979, accuracy: 0.96728515625\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12744870781898499, accuracy: 0.97021484375\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.11365505307912827, accuracy: 0.969970703125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.11745594441890717, accuracy: 0.970703125\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.12167908251285553, accuracy: 0.9697265625\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.12512630224227905, accuracy: 0.970458984375\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.17092326283454895, accuracy: 0.969482421875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.10806047916412354, accuracy: 0.972412109375\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.11395741999149323, accuracy: 0.971435546875\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.10329581052064896, accuracy: 0.9716796875\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.10789445787668228, accuracy: 0.971435546875\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.11633659899234772, accuracy: 0.969970703125\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.0950184017419815, accuracy: 0.9736328125\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.12774384021759033, accuracy: 0.971435546875\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.10460659861564636, accuracy: 0.972900390625\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.0991443395614624, accuracy: 0.969970703125\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.08363285660743713, accuracy: 0.975830078125\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.09634233266115189, accuracy: 0.974365234375\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.09419753402471542, accuracy: 0.971923828125\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.10160470753908157, accuracy: 0.9736328125\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.09131903201341629, accuracy: 0.972412109375\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.09017430245876312, accuracy: 0.970458984375\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.12093076854944229, accuracy: 0.970947265625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.09294947236776352, accuracy: 0.970947265625\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.10527347773313522, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.09706257283687592, accuracy: 0.971923828125\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.09501681476831436, accuracy: 0.974853515625\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.09070869535207748, accuracy: 0.971923828125\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.1115524172782898, accuracy: 0.973876953125\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.07887758314609528, accuracy: 0.970703125\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.08299568295478821, accuracy: 0.972900390625\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.07322455197572708, accuracy: 0.9736328125\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.06626854091882706, accuracy: 0.972412109375\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.09045916795730591, accuracy: 0.973388671875\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08199596405029297, accuracy: 0.978515625\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.0738326907157898, accuracy: 0.9716796875\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.08857119083404541, accuracy: 0.978271484375\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.0640164166688919, accuracy: 0.97412109375\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.08435001969337463, accuracy: 0.972900390625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.06949120759963989, accuracy: 0.97509765625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.06796054542064667, accuracy: 0.97412109375\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.08578421920537949, accuracy: 0.97509765625\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.06353247910737991, accuracy: 0.97900390625\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07389982789754868, accuracy: 0.97802734375\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.072524793446064, accuracy: 0.977294921875\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.064334936439991, accuracy: 0.975830078125\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4826719760894775, accuracy: 0.787841796875\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.701668381690979, accuracy: 0.847412109375\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.6342231035232544, accuracy: 0.86279296875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.5102254152297974, accuracy: 0.8857421875\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.4547192454338074, accuracy: 0.908935546875\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.38534149527549744, accuracy: 0.90234375\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.32903799414634705, accuracy: 0.911376953125\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.38253164291381836, accuracy: 0.916015625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3227557837963104, accuracy: 0.916748046875\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.2869250774383545, accuracy: 0.92431640625\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.2807105779647827, accuracy: 0.921142578125\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.2815495729446411, accuracy: 0.929443359375\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.31489405035972595, accuracy: 0.93310546875\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.3055712580680847, accuracy: 0.934814453125\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.24811246991157532, accuracy: 0.938232421875\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.26201432943344116, accuracy: 0.93505859375\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2528873383998871, accuracy: 0.939208984375\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.2540055811405182, accuracy: 0.9365234375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.25286799669265747, accuracy: 0.9365234375\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.21996885538101196, accuracy: 0.94189453125\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.1995781809091568, accuracy: 0.943115234375\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.21787917613983154, accuracy: 0.941650390625\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.23282669484615326, accuracy: 0.94482421875\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.2141999900341034, accuracy: 0.951416015625\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.1988515555858612, accuracy: 0.949462890625\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.18922527134418488, accuracy: 0.94970703125\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.2117374688386917, accuracy: 0.952880859375\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.1813531219959259, accuracy: 0.953857421875\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.17895734310150146, accuracy: 0.9580078125\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.1774061918258667, accuracy: 0.957763671875\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.17582060396671295, accuracy: 0.960693359375\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.17570987343788147, accuracy: 0.95751953125\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.1576818972826004, accuracy: 0.954833984375\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.15308260917663574, accuracy: 0.959716796875\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.17502011358737946, accuracy: 0.9619140625\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.15869298577308655, accuracy: 0.963134765625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.13707268238067627, accuracy: 0.960693359375\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.1532968133687973, accuracy: 0.966552734375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.17130862176418304, accuracy: 0.96240234375\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.15263082087039948, accuracy: 0.962158203125\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.1747191697359085, accuracy: 0.965087890625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.11275573074817657, accuracy: 0.96435546875\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.16780985891819, accuracy: 0.967041015625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.1440480798482895, accuracy: 0.96484375\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.13252708315849304, accuracy: 0.964599609375\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.10474451631307602, accuracy: 0.9658203125\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.1336655616760254, accuracy: 0.965576171875\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.1513921469449997, accuracy: 0.96728515625\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.11685275286436081, accuracy: 0.968994140625\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.11561770737171173, accuracy: 0.968505859375\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.15122129023075104, accuracy: 0.966796875\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.12330396473407745, accuracy: 0.969970703125\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.1548687368631363, accuracy: 0.968505859375\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.14846965670585632, accuracy: 0.9677734375\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.10690998286008835, accuracy: 0.970458984375\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12159894406795502, accuracy: 0.9677734375\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.10525360703468323, accuracy: 0.965087890625\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.1078127771615982, accuracy: 0.972412109375\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.1526147425174713, accuracy: 0.97021484375\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.11488719284534454, accuracy: 0.97265625\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.1482343077659607, accuracy: 0.96875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.09245534241199493, accuracy: 0.97216796875\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.110780268907547, accuracy: 0.972900390625\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.11891297250986099, accuracy: 0.96923828125\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.09023631364107132, accuracy: 0.969482421875\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.13265009224414825, accuracy: 0.968994140625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11941056698560715, accuracy: 0.97021484375\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.11177916824817657, accuracy: 0.97412109375\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.10389219224452972, accuracy: 0.97021484375\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.11570890992879868, accuracy: 0.968505859375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.11809240281581879, accuracy: 0.97216796875\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.12269602715969086, accuracy: 0.974609375\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.10737183690071106, accuracy: 0.978759765625\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.11069006472826004, accuracy: 0.972412109375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.08653800934553146, accuracy: 0.97607421875\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.07949947565793991, accuracy: 0.973388671875\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.08262084424495697, accuracy: 0.9755859375\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.11172641813755035, accuracy: 0.973388671875\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.0991162359714508, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.08682451397180557, accuracy: 0.974609375\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.06883765012025833, accuracy: 0.972412109375\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.08053227514028549, accuracy: 0.971923828125\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.10066042095422745, accuracy: 0.973388671875\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.09397586435079575, accuracy: 0.97509765625\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.06698063015937805, accuracy: 0.975341796875\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.06980080157518387, accuracy: 0.978759765625\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.09510673582553864, accuracy: 0.973876953125\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.07318338751792908, accuracy: 0.974609375\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08857762813568115, accuracy: 0.971923828125\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.07080021500587463, accuracy: 0.9775390625\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.08562882244586945, accuracy: 0.976806640625\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.06234796717762947, accuracy: 0.973388671875\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.0761016458272934, accuracy: 0.97705078125\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.07026433944702148, accuracy: 0.977294921875\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.10338795185089111, accuracy: 0.973388671875\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.07910572737455368, accuracy: 0.97314453125\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.07372839748859406, accuracy: 0.978759765625\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.08671582490205765, accuracy: 0.975341796875\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.06142430752515793, accuracy: 0.97607421875\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.06259799003601074, accuracy: 0.973388671875\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4179044961929321, accuracy: 0.782958984375\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7492808103561401, accuracy: 0.843505859375\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5989220142364502, accuracy: 0.829833984375\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4555377662181854, accuracy: 0.8994140625\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.37757280468940735, accuracy: 0.90380859375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.39065808057785034, accuracy: 0.911376953125\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.3655196726322174, accuracy: 0.916259765625\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.354333758354187, accuracy: 0.919677734375\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3161744773387909, accuracy: 0.92138671875\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.2923205494880676, accuracy: 0.924560546875\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.30775153636932373, accuracy: 0.92236328125\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.3554175794124603, accuracy: 0.92822265625\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.3215911388397217, accuracy: 0.927978515625\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.2880765199661255, accuracy: 0.928955078125\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.2750535309314728, accuracy: 0.93408203125\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.2791654169559479, accuracy: 0.935791015625\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.23524989187717438, accuracy: 0.939453125\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.23642654716968536, accuracy: 0.9375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.2475024312734604, accuracy: 0.93896484375\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.25391432642936707, accuracy: 0.94580078125\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.24053315818309784, accuracy: 0.943603515625\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.20793378353118896, accuracy: 0.947509765625\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.2555255889892578, accuracy: 0.951904296875\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.20876263082027435, accuracy: 0.950439453125\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.23377618193626404, accuracy: 0.94580078125\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.2278653085231781, accuracy: 0.95458984375\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.17595022916793823, accuracy: 0.950439453125\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.2055855095386505, accuracy: 0.95361328125\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.18228502571582794, accuracy: 0.95166015625\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.19311323761940002, accuracy: 0.95458984375\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.17821136116981506, accuracy: 0.954833984375\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.19627916812896729, accuracy: 0.955810546875\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.21381448209285736, accuracy: 0.9560546875\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.16915573179721832, accuracy: 0.953125\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.1691705882549286, accuracy: 0.960205078125\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.1569012552499771, accuracy: 0.95751953125\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.19198714196681976, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.1629709154367447, accuracy: 0.958740234375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.13006338477134705, accuracy: 0.963623046875\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.1252269446849823, accuracy: 0.960693359375\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.15992309153079987, accuracy: 0.961669921875\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.1567637175321579, accuracy: 0.9609375\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.1538960188627243, accuracy: 0.965087890625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.1558426171541214, accuracy: 0.96142578125\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.12517142295837402, accuracy: 0.96728515625\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.13606731593608856, accuracy: 0.964599609375\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.12778903543949127, accuracy: 0.965087890625\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.11368004232645035, accuracy: 0.966552734375\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.1153925433754921, accuracy: 0.962646484375\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.11089233309030533, accuracy: 0.9677734375\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.10327702760696411, accuracy: 0.96728515625\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.1326921284198761, accuracy: 0.967041015625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.15347249805927277, accuracy: 0.963623046875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.16259902715682983, accuracy: 0.96337890625\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.14628759026527405, accuracy: 0.9677734375\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.10370495915412903, accuracy: 0.968994140625\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.09993328154087067, accuracy: 0.970703125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.1241280809044838, accuracy: 0.966796875\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.1251009851694107, accuracy: 0.964111328125\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.09617284685373306, accuracy: 0.9677734375\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.10243429988622665, accuracy: 0.971435546875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.104969821870327, accuracy: 0.969970703125\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.11369775980710983, accuracy: 0.9736328125\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.14228036999702454, accuracy: 0.970703125\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.12437540292739868, accuracy: 0.9677734375\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.10214143991470337, accuracy: 0.9716796875\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11155086755752563, accuracy: 0.971435546875\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.11739875376224518, accuracy: 0.97119140625\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.10073041915893555, accuracy: 0.97216796875\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.1220044195652008, accuracy: 0.97119140625\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.11240101605653763, accuracy: 0.974853515625\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.09786362200975418, accuracy: 0.967041015625\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.0835144892334938, accuracy: 0.9755859375\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.08722932636737823, accuracy: 0.970458984375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.08530056476593018, accuracy: 0.970703125\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.09076286852359772, accuracy: 0.97265625\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.09076882153749466, accuracy: 0.97509765625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.09874292463064194, accuracy: 0.97412109375\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.10579845309257507, accuracy: 0.9716796875\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.08036719262599945, accuracy: 0.976806640625\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.10081421583890915, accuracy: 0.973388671875\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.08822129666805267, accuracy: 0.9716796875\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.07964996993541718, accuracy: 0.974853515625\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.08332867175340652, accuracy: 0.973388671875\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.08804047107696533, accuracy: 0.978515625\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.09904617816209793, accuracy: 0.975341796875\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.07970389723777771, accuracy: 0.9765625\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.08639908581972122, accuracy: 0.977294921875\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.10137289017438889, accuracy: 0.974609375\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.07651817798614502, accuracy: 0.97509765625\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.07973979413509369, accuracy: 0.96923828125\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.09446702897548676, accuracy: 0.97314453125\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.11219047009944916, accuracy: 0.9775390625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.10309064388275146, accuracy: 0.974365234375\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.08429180085659027, accuracy: 0.9775390625\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.07049407809972763, accuracy: 0.97119140625\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.08602651208639145, accuracy: 0.974853515625\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.06840194016695023, accuracy: 0.974365234375\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.0877201035618782, accuracy: 0.9794921875\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.061973728239536285, accuracy: 0.97412109375\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.5146974325180054, accuracy: 0.78955078125\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.6892543435096741, accuracy: 0.8125\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.6113424301147461, accuracy: 0.854248046875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.5092345476150513, accuracy: 0.885498046875\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.4339296817779541, accuracy: 0.897216796875\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.34113678336143494, accuracy: 0.904296875\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.3083820939064026, accuracy: 0.91455078125\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.3669241666793823, accuracy: 0.919921875\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.33063608407974243, accuracy: 0.92333984375\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.32510408759117126, accuracy: 0.922119140625\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.25994673371315, accuracy: 0.92333984375\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.31566059589385986, accuracy: 0.923828125\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.29461050033569336, accuracy: 0.924072265625\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.24002231657505035, accuracy: 0.9384765625\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.3193279802799225, accuracy: 0.931396484375\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.2567465007305145, accuracy: 0.934326171875\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.27197685837745667, accuracy: 0.938232421875\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.2518698275089264, accuracy: 0.943115234375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.22371549904346466, accuracy: 0.941650390625\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.2419307827949524, accuracy: 0.943603515625\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.22905594110488892, accuracy: 0.949951171875\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.2521715462207794, accuracy: 0.93701171875\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.238589808344841, accuracy: 0.949462890625\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.20494550466537476, accuracy: 0.94873046875\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.20806613564491272, accuracy: 0.950439453125\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.20996928215026855, accuracy: 0.949462890625\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.19950833916664124, accuracy: 0.950927734375\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.19778504967689514, accuracy: 0.9560546875\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.20787689089775085, accuracy: 0.958984375\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.2083597034215927, accuracy: 0.95703125\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.16917088627815247, accuracy: 0.95849609375\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.19302350282669067, accuracy: 0.956787109375\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.16430097818374634, accuracy: 0.95751953125\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.16878338158130646, accuracy: 0.96484375\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.14664217829704285, accuracy: 0.961181640625\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.17837603390216827, accuracy: 0.963134765625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.17883510887622833, accuracy: 0.9619140625\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.17631271481513977, accuracy: 0.96142578125\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.16174852848052979, accuracy: 0.963134765625\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.15475866198539734, accuracy: 0.958740234375\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.11939746141433716, accuracy: 0.96728515625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.13958941400051117, accuracy: 0.960693359375\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.14834782481193542, accuracy: 0.96630859375\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.14805513620376587, accuracy: 0.96630859375\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.16933400928974152, accuracy: 0.962646484375\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.13987982273101807, accuracy: 0.96435546875\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.1438850462436676, accuracy: 0.96826171875\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.12923486530780792, accuracy: 0.96337890625\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12262535840272903, accuracy: 0.9658203125\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.15477707982063293, accuracy: 0.96826171875\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.11360140889883041, accuracy: 0.96923828125\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.13920198380947113, accuracy: 0.96826171875\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.14551056921482086, accuracy: 0.968994140625\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.15484270453453064, accuracy: 0.972412109375\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.13859282433986664, accuracy: 0.96728515625\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.11130454391241074, accuracy: 0.97021484375\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.1139867901802063, accuracy: 0.971923828125\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.10567829012870789, accuracy: 0.96728515625\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.10752321779727936, accuracy: 0.965576171875\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.12529297173023224, accuracy: 0.966796875\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.09530970454216003, accuracy: 0.9697265625\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.10813792049884796, accuracy: 0.971923828125\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.09854081273078918, accuracy: 0.970703125\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.09868059307336807, accuracy: 0.972412109375\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.11899825930595398, accuracy: 0.9736328125\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.10025111585855484, accuracy: 0.974365234375\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11590232700109482, accuracy: 0.9736328125\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.10727133601903915, accuracy: 0.976318359375\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.09539559483528137, accuracy: 0.9716796875\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.08784317225217819, accuracy: 0.974853515625\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.0817863717675209, accuracy: 0.969970703125\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.10667835921049118, accuracy: 0.9716796875\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.11009155213832855, accuracy: 0.9716796875\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.10298100113868713, accuracy: 0.971923828125\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.1020130068063736, accuracy: 0.973388671875\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.06899028271436691, accuracy: 0.9765625\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.08529811352491379, accuracy: 0.971435546875\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.09472813457250595, accuracy: 0.9716796875\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.07146142423152924, accuracy: 0.97412109375\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.11531991511583328, accuracy: 0.9736328125\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.0741957426071167, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.0966135784983635, accuracy: 0.970947265625\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.07978210598230362, accuracy: 0.9775390625\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.10068954527378082, accuracy: 0.97314453125\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.08661191910505295, accuracy: 0.97705078125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.07460088282823563, accuracy: 0.97509765625\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.07667435705661774, accuracy: 0.975341796875\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.09087568521499634, accuracy: 0.97265625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.09837415814399719, accuracy: 0.97412109375\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.09591470658779144, accuracy: 0.9716796875\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.08946176618337631, accuracy: 0.972412109375\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.08794623613357544, accuracy: 0.9755859375\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.07418891787528992, accuracy: 0.9765625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.08536899089813232, accuracy: 0.9765625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.07304622232913971, accuracy: 0.97705078125\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.09776077419519424, accuracy: 0.972412109375\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.08878019452095032, accuracy: 0.973388671875\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07174748182296753, accuracy: 0.97216796875\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.08794272691011429, accuracy: 0.976318359375\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.07693473994731903, accuracy: 0.9765625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4458446502685547, accuracy: 0.76513671875\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7122569680213928, accuracy: 0.871826171875\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5955060720443726, accuracy: 0.859375\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.5176214575767517, accuracy: 0.876953125\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.37614595890045166, accuracy: 0.90771484375\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.4082476496696472, accuracy: 0.906494140625\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.4119974672794342, accuracy: 0.908935546875\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.38214972615242004, accuracy: 0.916259765625\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.28953948616981506, accuracy: 0.918212890625\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.30910903215408325, accuracy: 0.9208984375\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.29510748386383057, accuracy: 0.93115234375\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.28605788946151733, accuracy: 0.928466796875\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.30320408940315247, accuracy: 0.93017578125\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.23886309564113617, accuracy: 0.93115234375\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.22807180881500244, accuracy: 0.93701171875\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.23455151915550232, accuracy: 0.933837890625\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.26680988073349, accuracy: 0.943603515625\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.2127755582332611, accuracy: 0.937744140625\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.22558562457561493, accuracy: 0.944580078125\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.241763174533844, accuracy: 0.9423828125\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.19072683155536652, accuracy: 0.941650390625\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.23746497929096222, accuracy: 0.94873046875\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.2532287538051605, accuracy: 0.947021484375\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.2291572540998459, accuracy: 0.94873046875\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.2043059915304184, accuracy: 0.945068359375\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.23087303340435028, accuracy: 0.953369140625\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.21718180179595947, accuracy: 0.95263671875\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.22887517511844635, accuracy: 0.953125\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.2059011161327362, accuracy: 0.954833984375\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.2056436538696289, accuracy: 0.959228515625\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.1825706958770752, accuracy: 0.952880859375\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.18607120215892792, accuracy: 0.9580078125\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.16033369302749634, accuracy: 0.95751953125\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.19856314361095428, accuracy: 0.954345703125\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.15817402303218842, accuracy: 0.961669921875\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.15853002667427063, accuracy: 0.9619140625\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1686250865459442, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.18842312693595886, accuracy: 0.958984375\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.17713405191898346, accuracy: 0.962890625\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.1521906703710556, accuracy: 0.963623046875\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.15520910918712616, accuracy: 0.9619140625\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.1368008404970169, accuracy: 0.962158203125\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.1331171840429306, accuracy: 0.965087890625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.15324921905994415, accuracy: 0.96484375\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.13883909583091736, accuracy: 0.964111328125\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.15920494496822357, accuracy: 0.963623046875\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.14255747199058533, accuracy: 0.9638671875\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.15303759276866913, accuracy: 0.963623046875\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12287234514951706, accuracy: 0.9638671875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.1412249356508255, accuracy: 0.970947265625\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.10893608629703522, accuracy: 0.96484375\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.1360340416431427, accuracy: 0.9697265625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.13383616507053375, accuracy: 0.965576171875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.15638339519500732, accuracy: 0.96875\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.1330144852399826, accuracy: 0.970458984375\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.12637647986412048, accuracy: 0.970703125\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.1110549122095108, accuracy: 0.9677734375\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.12028758972883224, accuracy: 0.9658203125\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.09764786809682846, accuracy: 0.967041015625\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.08625785261392593, accuracy: 0.97119140625\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.13009169697761536, accuracy: 0.96728515625\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.12027518451213837, accuracy: 0.97265625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.10399258136749268, accuracy: 0.96728515625\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.14939406514167786, accuracy: 0.970458984375\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.10676778107881546, accuracy: 0.96923828125\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.10124654322862625, accuracy: 0.968505859375\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11450526118278503, accuracy: 0.970703125\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.09611720591783524, accuracy: 0.970703125\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.13877983391284943, accuracy: 0.96923828125\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.08407585322856903, accuracy: 0.974609375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.11272581666707993, accuracy: 0.972412109375\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.11539015918970108, accuracy: 0.97265625\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.07135364413261414, accuracy: 0.970458984375\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.11699751764535904, accuracy: 0.970703125\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.11700233072042465, accuracy: 0.97119140625\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.09308798611164093, accuracy: 0.970458984375\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.16298380494117737, accuracy: 0.973388671875\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.09094971418380737, accuracy: 0.970703125\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.09282450377941132, accuracy: 0.976806640625\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.08990588039159775, accuracy: 0.970703125\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.08290519565343857, accuracy: 0.97314453125\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.0891433134675026, accuracy: 0.9736328125\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.091450534760952, accuracy: 0.971923828125\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.07963788509368896, accuracy: 0.9736328125\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.07910411804914474, accuracy: 0.976318359375\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.09499874711036682, accuracy: 0.974365234375\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.10322606563568115, accuracy: 0.97314453125\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.07274089753627777, accuracy: 0.97265625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08259577304124832, accuracy: 0.97509765625\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.06940378993749619, accuracy: 0.97314453125\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.08318208158016205, accuracy: 0.97705078125\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.07877416163682938, accuracy: 0.972900390625\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.06956307590007782, accuracy: 0.974365234375\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.05916500464081764, accuracy: 0.975341796875\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.0896366611123085, accuracy: 0.976318359375\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.06502776592969894, accuracy: 0.976806640625\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.08003772795200348, accuracy: 0.974853515625\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.05681221932172775, accuracy: 0.977294921875\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.06779038161039352, accuracy: 0.976318359375\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.07669860869646072, accuracy: 0.976806640625\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4316719770431519, accuracy: 0.775634765625\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7495466470718384, accuracy: 0.842529296875\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.6133572459220886, accuracy: 0.852294921875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.49430981278419495, accuracy: 0.87890625\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.4144746661186218, accuracy: 0.903564453125\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.3534969389438629, accuracy: 0.904052734375\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.40086057782173157, accuracy: 0.912109375\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.34351077675819397, accuracy: 0.917724609375\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.3654516339302063, accuracy: 0.91748046875\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.2973935902118683, accuracy: 0.92626953125\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.32268330454826355, accuracy: 0.923828125\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.27363184094429016, accuracy: 0.92919921875\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.28594228625297546, accuracy: 0.927978515625\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.2520906627178192, accuracy: 0.934814453125\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.29623615741729736, accuracy: 0.93505859375\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.24933049082756042, accuracy: 0.930419921875\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.22005634009838104, accuracy: 0.935546875\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.26205793023109436, accuracy: 0.9375\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.24046358466148376, accuracy: 0.945556640625\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.2260684072971344, accuracy: 0.944091796875\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.22594739496707916, accuracy: 0.942138671875\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.2556351125240326, accuracy: 0.937744140625\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.20977438986301422, accuracy: 0.94384765625\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.23961174488067627, accuracy: 0.94970703125\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.25783321261405945, accuracy: 0.947265625\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.17019982635974884, accuracy: 0.9482421875\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.21398572623729706, accuracy: 0.9541015625\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.21810825169086456, accuracy: 0.95703125\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.21416381001472473, accuracy: 0.960693359375\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.19329065084457397, accuracy: 0.953857421875\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.19910810887813568, accuracy: 0.9560546875\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.21289807558059692, accuracy: 0.955322265625\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.1868555098772049, accuracy: 0.962646484375\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.1803121715784073, accuracy: 0.963623046875\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.17718066275119781, accuracy: 0.96240234375\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.198266863822937, accuracy: 0.956787109375\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.20567527413368225, accuracy: 0.965087890625\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.14531521499156952, accuracy: 0.962158203125\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.1420937329530716, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.17632651329040527, accuracy: 0.963134765625\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.16413572430610657, accuracy: 0.962158203125\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.15561933815479279, accuracy: 0.966064453125\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.14203697443008423, accuracy: 0.962890625\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.17914380133152008, accuracy: 0.96044921875\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.12224974483251572, accuracy: 0.965576171875\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.13723374903202057, accuracy: 0.967041015625\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.17367850244045258, accuracy: 0.96484375\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.12167518585920334, accuracy: 0.96533203125\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12550924718379974, accuracy: 0.96875\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.12465198338031769, accuracy: 0.968505859375\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.1379651129245758, accuracy: 0.968505859375\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.11346635222434998, accuracy: 0.970703125\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.1370505839586258, accuracy: 0.9697265625\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.13720522820949554, accuracy: 0.962158203125\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.11712989211082458, accuracy: 0.96923828125\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.10727528482675552, accuracy: 0.96923828125\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.1078643649816513, accuracy: 0.968994140625\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.13949880003929138, accuracy: 0.970947265625\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.10395897924900055, accuracy: 0.971435546875\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.13615065813064575, accuracy: 0.96826171875\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.08897803723812103, accuracy: 0.96875\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.11411214619874954, accuracy: 0.9697265625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.1363103687763214, accuracy: 0.970703125\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.1237652376294136, accuracy: 0.9736328125\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.10332536697387695, accuracy: 0.971923828125\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.09546876698732376, accuracy: 0.968994140625\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11099846661090851, accuracy: 0.97265625\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.12348682433366776, accuracy: 0.974365234375\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.09050010144710541, accuracy: 0.971923828125\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.09019771963357925, accuracy: 0.972412109375\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.09155222773551941, accuracy: 0.97314453125\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.09971883893013, accuracy: 0.975341796875\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.10484237223863602, accuracy: 0.97412109375\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.10564470291137695, accuracy: 0.9716796875\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.11079848557710648, accuracy: 0.97216796875\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.1091204285621643, accuracy: 0.9716796875\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.1104297935962677, accuracy: 0.973876953125\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.08911267668008804, accuracy: 0.97314453125\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.07207932323217392, accuracy: 0.976318359375\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.09771759808063507, accuracy: 0.97314453125\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.09345162659883499, accuracy: 0.978759765625\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.07723458856344223, accuracy: 0.9775390625\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.07837077230215073, accuracy: 0.975341796875\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.12106821686029434, accuracy: 0.9775390625\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.07888402044773102, accuracy: 0.974609375\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.08588951081037521, accuracy: 0.97216796875\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.08616723120212555, accuracy: 0.9775390625\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.07529749721288681, accuracy: 0.974853515625\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.06436274945735931, accuracy: 0.9736328125\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.08774901926517487, accuracy: 0.974853515625\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.10466501861810684, accuracy: 0.976318359375\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.10146098583936691, accuracy: 0.976806640625\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.06920825690031052, accuracy: 0.976318359375\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.09737234562635422, accuracy: 0.97607421875\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.08372792601585388, accuracy: 0.97412109375\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.09509085863828659, accuracy: 0.9736328125\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.09922721982002258, accuracy: 0.97802734375\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.07524514943361282, accuracy: 0.97705078125\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.09220686554908752, accuracy: 0.978759765625\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.06790925562381744, accuracy: 0.977294921875\n",
            "Epoch: 1, learning_rate:[0.0999],costo: 1.4495775699615479, accuracy: 0.765380859375\n",
            "Epoch: 2, learning_rate:[0.0998],costo: 0.7058829069137573, accuracy: 0.858154296875\n",
            "Epoch: 3, learning_rate:[0.0997],costo: 0.5532220005989075, accuracy: 0.877685546875\n",
            "Epoch: 4, learning_rate:[0.0996],costo: 0.4631373882293701, accuracy: 0.885009765625\n",
            "Epoch: 5, learning_rate:[0.09949999999999999],costo: 0.43581700325012207, accuracy: 0.900634765625\n",
            "Epoch: 6, learning_rate:[0.09939999999999999],costo: 0.3915761113166809, accuracy: 0.91357421875\n",
            "Epoch: 7, learning_rate:[0.09929999999999999],costo: 0.41496843099594116, accuracy: 0.91064453125\n",
            "Epoch: 8, learning_rate:[0.09919999999999998],costo: 0.32808759808540344, accuracy: 0.91552734375\n",
            "Epoch: 9, learning_rate:[0.09909999999999998],costo: 0.38884809613227844, accuracy: 0.92041015625\n",
            "Epoch: 10, learning_rate:[0.09899999999999998],costo: 0.3125315010547638, accuracy: 0.916259765625\n",
            "Epoch: 11, learning_rate:[0.09889999999999997],costo: 0.27772656083106995, accuracy: 0.9228515625\n",
            "Epoch: 12, learning_rate:[0.09879999999999997],costo: 0.2775494158267975, accuracy: 0.932861328125\n",
            "Epoch: 13, learning_rate:[0.09869999999999997],costo: 0.2634921669960022, accuracy: 0.93359375\n",
            "Epoch: 14, learning_rate:[0.09859999999999997],costo: 0.30786269903182983, accuracy: 0.933837890625\n",
            "Epoch: 15, learning_rate:[0.09849999999999996],costo: 0.28635087609291077, accuracy: 0.935546875\n",
            "Epoch: 16, learning_rate:[0.09839999999999996],costo: 0.25172826647758484, accuracy: 0.93603515625\n",
            "Epoch: 17, learning_rate:[0.09829999999999996],costo: 0.2738805115222931, accuracy: 0.93896484375\n",
            "Epoch: 18, learning_rate:[0.09819999999999995],costo: 0.26637110114097595, accuracy: 0.9384765625\n",
            "Epoch: 19, learning_rate:[0.09809999999999995],costo: 0.22257931530475616, accuracy: 0.947509765625\n",
            "Epoch: 20, learning_rate:[0.09799999999999995],costo: 0.2113991528749466, accuracy: 0.940185546875\n",
            "Epoch: 21, learning_rate:[0.09789999999999995],costo: 0.20388329029083252, accuracy: 0.94873046875\n",
            "Epoch: 22, learning_rate:[0.09779999999999994],costo: 0.2202245444059372, accuracy: 0.94873046875\n",
            "Epoch: 23, learning_rate:[0.09769999999999994],costo: 0.17999152839183807, accuracy: 0.94775390625\n",
            "Epoch: 24, learning_rate:[0.09759999999999994],costo: 0.24466852843761444, accuracy: 0.95166015625\n",
            "Epoch: 25, learning_rate:[0.09749999999999993],costo: 0.17521417140960693, accuracy: 0.9521484375\n",
            "Epoch: 26, learning_rate:[0.09739999999999993],costo: 0.200188547372818, accuracy: 0.954345703125\n",
            "Epoch: 27, learning_rate:[0.09729999999999993],costo: 0.182698592543602, accuracy: 0.95166015625\n",
            "Epoch: 28, learning_rate:[0.09719999999999993],costo: 0.20376117527484894, accuracy: 0.9541015625\n",
            "Epoch: 29, learning_rate:[0.09709999999999992],costo: 0.15247735381126404, accuracy: 0.957275390625\n",
            "Epoch: 30, learning_rate:[0.09699999999999992],costo: 0.19002999365329742, accuracy: 0.956298828125\n",
            "Epoch: 31, learning_rate:[0.09689999999999992],costo: 0.2071392983198166, accuracy: 0.955810546875\n",
            "Epoch: 32, learning_rate:[0.09679999999999991],costo: 0.15183740854263306, accuracy: 0.957763671875\n",
            "Epoch: 33, learning_rate:[0.09669999999999991],costo: 0.13993902504444122, accuracy: 0.955078125\n",
            "Epoch: 34, learning_rate:[0.09659999999999991],costo: 0.16668443381786346, accuracy: 0.9638671875\n",
            "Epoch: 35, learning_rate:[0.0964999999999999],costo: 0.17805244028568268, accuracy: 0.9580078125\n",
            "Epoch: 36, learning_rate:[0.0963999999999999],costo: 0.18307936191558838, accuracy: 0.962158203125\n",
            "Epoch: 37, learning_rate:[0.0962999999999999],costo: 0.1407758891582489, accuracy: 0.957275390625\n",
            "Epoch: 38, learning_rate:[0.0961999999999999],costo: 0.13498781621456146, accuracy: 0.963134765625\n",
            "Epoch: 39, learning_rate:[0.0960999999999999],costo: 0.18855947256088257, accuracy: 0.96337890625\n",
            "Epoch: 40, learning_rate:[0.09599999999999989],costo: 0.1808452606201172, accuracy: 0.96142578125\n",
            "Epoch: 41, learning_rate:[0.09589999999999989],costo: 0.15577353537082672, accuracy: 0.9599609375\n",
            "Epoch: 42, learning_rate:[0.09579999999999989],costo: 0.12304309755563736, accuracy: 0.9619140625\n",
            "Epoch: 43, learning_rate:[0.09569999999999988],costo: 0.13050948083400726, accuracy: 0.964599609375\n",
            "Epoch: 44, learning_rate:[0.09559999999999988],costo: 0.12602436542510986, accuracy: 0.962646484375\n",
            "Epoch: 45, learning_rate:[0.09549999999999988],costo: 0.14612317085266113, accuracy: 0.966552734375\n",
            "Epoch: 46, learning_rate:[0.09539999999999987],costo: 0.15067027509212494, accuracy: 0.967041015625\n",
            "Epoch: 47, learning_rate:[0.09529999999999987],costo: 0.1454278826713562, accuracy: 0.96435546875\n",
            "Epoch: 48, learning_rate:[0.09519999999999987],costo: 0.1289372742176056, accuracy: 0.96923828125\n",
            "Epoch: 49, learning_rate:[0.09509999999999987],costo: 0.12722724676132202, accuracy: 0.96923828125\n",
            "Epoch: 50, learning_rate:[0.09499999999999986],costo: 0.12582668662071228, accuracy: 0.967041015625\n",
            "Epoch: 51, learning_rate:[0.09489999999999986],costo: 0.11289551854133606, accuracy: 0.966796875\n",
            "Epoch: 52, learning_rate:[0.09479999999999986],costo: 0.15723948180675507, accuracy: 0.96728515625\n",
            "Epoch: 53, learning_rate:[0.09469999999999985],costo: 0.13742096722126007, accuracy: 0.9716796875\n",
            "Epoch: 54, learning_rate:[0.09459999999999985],costo: 0.12598726153373718, accuracy: 0.97119140625\n",
            "Epoch: 55, learning_rate:[0.09449999999999985],costo: 0.08528155088424683, accuracy: 0.970703125\n",
            "Epoch: 56, learning_rate:[0.09439999999999985],costo: 0.10379660874605179, accuracy: 0.968505859375\n",
            "Epoch: 57, learning_rate:[0.09429999999999984],costo: 0.12304916232824326, accuracy: 0.96875\n",
            "Epoch: 58, learning_rate:[0.09419999999999984],costo: 0.11935260891914368, accuracy: 0.9677734375\n",
            "Epoch: 59, learning_rate:[0.09409999999999984],costo: 0.12928171455860138, accuracy: 0.969482421875\n",
            "Epoch: 60, learning_rate:[0.09399999999999983],costo: 0.1307591050863266, accuracy: 0.9697265625\n",
            "Epoch: 61, learning_rate:[0.09389999999999983],costo: 0.1301916241645813, accuracy: 0.975830078125\n",
            "Epoch: 62, learning_rate:[0.09379999999999983],costo: 0.11147013306617737, accuracy: 0.97265625\n",
            "Epoch: 63, learning_rate:[0.09369999999999983],costo: 0.10764721781015396, accuracy: 0.968994140625\n",
            "Epoch: 64, learning_rate:[0.09359999999999982],costo: 0.11532513797283173, accuracy: 0.97021484375\n",
            "Epoch: 65, learning_rate:[0.09349999999999982],costo: 0.11607695370912552, accuracy: 0.97021484375\n",
            "Epoch: 66, learning_rate:[0.09339999999999982],costo: 0.11815586686134338, accuracy: 0.970703125\n",
            "Epoch: 67, learning_rate:[0.09329999999999981],costo: 0.11548186838626862, accuracy: 0.97216796875\n",
            "Epoch: 68, learning_rate:[0.09319999999999981],costo: 0.09114959836006165, accuracy: 0.9716796875\n",
            "Epoch: 69, learning_rate:[0.09309999999999981],costo: 0.14018237590789795, accuracy: 0.971923828125\n",
            "Epoch: 70, learning_rate:[0.0929999999999998],costo: 0.09596465528011322, accuracy: 0.971923828125\n",
            "Epoch: 71, learning_rate:[0.0928999999999998],costo: 0.09304991364479065, accuracy: 0.97314453125\n",
            "Epoch: 72, learning_rate:[0.0927999999999998],costo: 0.07095315307378769, accuracy: 0.974365234375\n",
            "Epoch: 73, learning_rate:[0.0926999999999998],costo: 0.0961797758936882, accuracy: 0.973388671875\n",
            "Epoch: 74, learning_rate:[0.0925999999999998],costo: 0.09916326403617859, accuracy: 0.970458984375\n",
            "Epoch: 75, learning_rate:[0.09249999999999979],costo: 0.1100158542394638, accuracy: 0.970458984375\n",
            "Epoch: 76, learning_rate:[0.09239999999999979],costo: 0.1357565075159073, accuracy: 0.973388671875\n",
            "Epoch: 77, learning_rate:[0.09229999999999978],costo: 0.09077474474906921, accuracy: 0.972900390625\n",
            "Epoch: 78, learning_rate:[0.09219999999999978],costo: 0.12165676057338715, accuracy: 0.975830078125\n",
            "Epoch: 79, learning_rate:[0.09209999999999978],costo: 0.09031416475772858, accuracy: 0.972412109375\n",
            "Epoch: 80, learning_rate:[0.09199999999999978],costo: 0.09433169662952423, accuracy: 0.970458984375\n",
            "Epoch: 81, learning_rate:[0.09189999999999977],costo: 0.08988268673419952, accuracy: 0.972900390625\n",
            "Epoch: 82, learning_rate:[0.09179999999999977],costo: 0.10610150545835495, accuracy: 0.97509765625\n",
            "Epoch: 83, learning_rate:[0.09169999999999977],costo: 0.108240507543087, accuracy: 0.974609375\n",
            "Epoch: 84, learning_rate:[0.09159999999999976],costo: 0.06637851148843765, accuracy: 0.974609375\n",
            "Epoch: 85, learning_rate:[0.09149999999999976],costo: 0.07797979563474655, accuracy: 0.9736328125\n",
            "Epoch: 86, learning_rate:[0.09139999999999976],costo: 0.08694330602884293, accuracy: 0.975830078125\n",
            "Epoch: 87, learning_rate:[0.09129999999999976],costo: 0.08216287195682526, accuracy: 0.973388671875\n",
            "Epoch: 88, learning_rate:[0.09119999999999975],costo: 0.07748202234506607, accuracy: 0.975341796875\n",
            "Epoch: 89, learning_rate:[0.09109999999999975],costo: 0.08936311304569244, accuracy: 0.975341796875\n",
            "Epoch: 90, learning_rate:[0.09099999999999975],costo: 0.08792126923799515, accuracy: 0.974365234375\n",
            "Epoch: 91, learning_rate:[0.09089999999999974],costo: 0.06936546415090561, accuracy: 0.974853515625\n",
            "Epoch: 92, learning_rate:[0.09079999999999974],costo: 0.08860170841217041, accuracy: 0.97314453125\n",
            "Epoch: 93, learning_rate:[0.09069999999999974],costo: 0.089241623878479, accuracy: 0.976806640625\n",
            "Epoch: 94, learning_rate:[0.09059999999999974],costo: 0.09601935744285583, accuracy: 0.976806640625\n",
            "Epoch: 95, learning_rate:[0.09049999999999973],costo: 0.06774242967367172, accuracy: 0.974853515625\n",
            "Epoch: 96, learning_rate:[0.09039999999999973],costo: 0.05545932799577713, accuracy: 0.970947265625\n",
            "Epoch: 97, learning_rate:[0.09029999999999973],costo: 0.08511599898338318, accuracy: 0.973388671875\n",
            "Epoch: 98, learning_rate:[0.09019999999999972],costo: 0.10717392712831497, accuracy: 0.97265625\n",
            "Epoch: 99, learning_rate:[0.09009999999999972],costo: 0.07375485450029373, accuracy: 0.972900390625\n",
            "Epoch: 100, learning_rate:[0.08999999999999972],costo: 0.06956595927476883, accuracy: 0.972412109375\n"
          ]
        }
      ],
      "source": [
        "resultados['our_decay'] = {}\n",
        "resultados['our_decay']['val_acc_list'] = [0] * epochs\n",
        "resultados['our_decay']['test_acc'] = 0\n",
        "resultados['our_decay']['cost'] = [0] * epochs\n",
        "resultados['our_decay']['time'] = 0\n",
        "resultados['our_decay']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs = Our_Decay()\n",
        "    resultados['our_decay']['val_acc_list'] = SumList(resultados['our_decay']['val_acc_list'], our_decay_acc_list)\n",
        "    resultados['our_decay']['test_acc'] += our_decay_acc\n",
        "    resultados['our_decay']['cost'] = SumList(resultados['our_decay']['cost'], our_decay_cost_list)\n",
        "    resultados['our_decay']['time'] += our_decay_time\n",
        "    resultados['our_decay']['epochs'] += our_decay_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['our_decay']['name'] = 'Our Decay'\n",
        "resultados['our_decay']['lr'] = our_decay_lr_list\n",
        "resultados['our_decay']['test_acc'] = resultados['our_decay']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['our_decay']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['our_decay']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['our_decay']['cost'] = DeleteZerosFromList(DivideList(resultados['our_decay']['cost'], MAX_ITERATIONS))\n",
        "resultados['our_decay']['time'] = resultados['our_decay']['time'] / MAX_ITERATIONS\n",
        "resultados['our_decay']['epochs'] = resultados['our_decay']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqmMCfIAHpgs"
      },
      "source": [
        "## L-BFGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKIkHE3dhfUD"
      },
      "source": [
        "Derivado del método BFGS pero con memoria limitada. Considera información de las $h$ iteraciones previas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyPeBc3yhn4y"
      },
      "source": [
        "$\\alpha: 1$\n",
        "\n",
        "$h: 10$ iteraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1rzU1bVRfGaY"
      },
      "outputs": [],
      "source": [
        "def LBFGS():\n",
        "    modelLBFGS = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "\n",
        "    optimizer = torch.optim.LBFGS(modelLBFGS.parameters(),\n",
        "                                lr=1,\n",
        "                                history_size=10, #update history size. What's this?\n",
        "                                max_iter=1, #maximal number of iterations per optimization step\n",
        "                                )\n",
        "\n",
        "    lbfgs_cost_list = [0.0]\n",
        "    lbfgs_acc_list = [0.0]\n",
        "    modelLBFGS = modelLBFGS.to(device=device)\n",
        "    x_train_tensor_ = x_train_tensor.to(device=device, dtype=torch.float32)\n",
        "    y_train_tensor_ = y_train_tensor.to(device=device, dtype=torch.long)\n",
        "    i = 0\n",
        "    unregistered = True\n",
        "    iter_found = 0\n",
        "    iteraciones_lbfgs = 0\n",
        "    start.record()\n",
        "    #training\n",
        "    while (i < 100):\n",
        "        if(lbfgs_acc_list[-1] >= 0.95 and unregistered):\n",
        "          iter_found = i\n",
        "          unregistered = False\n",
        "        #print('Iteracion: '+ str(i))\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            scores = modelLBFGS(x_train_tensor_)\n",
        "            cost = F.cross_entropy(input= scores, target=y_train_tensor_.squeeze())\n",
        "            cost.backward()\n",
        "            print(f'costo: {cost.item()}')\n",
        "            return cost\n",
        "        iteraciones_lbfgs += 1\n",
        "        cost = optimizer.step(closure)\n",
        "        lbfgs_cost_list.append(cost.item())\n",
        "        lbfgs_acc_list.append(accuracy(modelLBFGS, x_val_tensor, y_val_tensor, mb_size))\n",
        "        #print(f'accuracy: {lbfgs_acc_list[-1]}')\n",
        "        i+=1\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    lbfgs_time = start.elapsed_time(end)\n",
        "\n",
        "    lbfgs_acc = accuracy(modelLBFGS, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return lbfgs_acc_list, lbfgs_cost_list, [0] ,lbfgs_time, lbfgs_acc, iter_found, iteraciones_lbfgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJSxQ5xeHu2U",
        "outputId": "f3c1c627-cdf5-48a4-c458-21af61d56227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "costo: 2.297842025756836\n",
            "costo: 2.293156147003174\n",
            "costo: 1.7587580680847168\n",
            "costo: 0.9689075946807861\n",
            "costo: 2.4421098232269287\n",
            "costo: 0.702951192855835\n",
            "costo: 0.6287456750869751\n",
            "costo: 0.6043837070465088\n",
            "costo: 0.5707606673240662\n",
            "costo: 0.5598811507225037\n",
            "costo: 0.5225030183792114\n",
            "costo: 0.47984105348587036\n",
            "costo: 0.4422764182090759\n",
            "costo: 0.4141128957271576\n",
            "costo: 0.3980148434638977\n",
            "costo: 0.36788174510002136\n",
            "costo: 0.3456275463104248\n",
            "costo: 0.3336232900619507\n",
            "costo: 0.32183727622032166\n",
            "costo: 0.3121129870414734\n",
            "costo: 0.30226171016693115\n",
            "costo: 0.29016822576522827\n",
            "costo: 0.2772631049156189\n",
            "costo: 0.2617623507976532\n",
            "costo: 0.2531183660030365\n",
            "costo: 0.24637001752853394\n",
            "costo: 0.23306964337825775\n",
            "costo: 0.22396007180213928\n",
            "costo: 0.21526673436164856\n",
            "costo: 0.20873676240444183\n",
            "costo: 0.20022568106651306\n",
            "costo: 0.19200924038887024\n",
            "costo: 0.18501214683055878\n",
            "costo: 0.17767882347106934\n",
            "costo: 0.16947288811206818\n",
            "costo: 0.1586424559354782\n",
            "costo: 0.15157446265220642\n",
            "costo: 0.14435915648937225\n",
            "costo: 0.13914050161838531\n",
            "costo: 0.1337805688381195\n",
            "costo: 0.1275896430015564\n",
            "costo: 0.12280035018920898\n",
            "costo: 0.1156022846698761\n",
            "costo: 0.1138707622885704\n",
            "costo: 0.10668002814054489\n",
            "costo: 0.10288403928279877\n",
            "costo: 0.09830513596534729\n",
            "costo: 0.09277859330177307\n",
            "costo: 0.09154427796602249\n",
            "costo: 0.08210960775613785\n",
            "costo: 0.07994834333658218\n",
            "costo: 0.07630350440740585\n",
            "costo: 0.07590455561876297\n",
            "costo: 0.07143400609493256\n",
            "costo: 0.06901881098747253\n",
            "costo: 0.06528861075639725\n",
            "costo: 0.06161268427968025\n",
            "costo: 0.058853164315223694\n",
            "costo: 0.0550193227827549\n",
            "costo: 0.05314716696739197\n",
            "costo: 0.04997866228222847\n",
            "costo: 0.05001142993569374\n",
            "costo: 0.04549029469490051\n",
            "costo: 0.04371742531657219\n",
            "costo: 0.04087511822581291\n",
            "costo: 0.03792695701122284\n",
            "costo: 0.03947095572948456\n",
            "costo: 0.032489411532878876\n",
            "costo: 0.031496986746788025\n",
            "costo: 0.029371030628681183\n",
            "costo: 0.02812727354466915\n",
            "costo: 0.025793803855776787\n",
            "costo: 0.023820137605071068\n",
            "costo: 0.022462785243988037\n",
            "costo: 0.02000674046576023\n",
            "costo: 0.021334165707230568\n",
            "costo: 0.016025660559535027\n",
            "costo: 0.015274034813046455\n",
            "costo: 0.013517934828996658\n",
            "costo: 0.01279982179403305\n",
            "costo: 0.01143873855471611\n",
            "costo: 0.010363742709159851\n",
            "costo: 0.009346753358840942\n",
            "costo: 0.007941029965877533\n",
            "costo: 0.009618714451789856\n",
            "costo: 0.006205491255968809\n",
            "costo: 0.005975805688649416\n",
            "costo: 0.005047566723078489\n",
            "costo: 0.004103232640773058\n",
            "costo: 0.003320012241601944\n",
            "costo: 0.002850499004125595\n",
            "costo: 0.0025450699031352997\n",
            "costo: 0.002109154127538204\n",
            "costo: 0.0019527542171999812\n",
            "costo: 0.0014357703039422631\n",
            "costo: 0.0012445978354662657\n",
            "costo: 0.0010104983812198043\n",
            "costo: 0.0008243161719292402\n",
            "costo: 0.0006475065601989627\n",
            "costo: 0.0005539307603612542\n",
            "costo: 2.29805064201355\n",
            "costo: 2.2933311462402344\n",
            "costo: 1.7830694913864136\n",
            "costo: 1.0236749649047852\n",
            "costo: 1.07991361618042\n",
            "costo: 0.6630059480667114\n",
            "costo: 0.5936469435691833\n",
            "costo: 0.5673589706420898\n",
            "costo: 0.5437191724777222\n",
            "costo: 0.5132525563240051\n",
            "costo: 0.48702487349510193\n",
            "costo: 0.4566839337348938\n",
            "costo: 0.42165812849998474\n",
            "costo: 0.390470951795578\n",
            "costo: 0.3795107901096344\n",
            "costo: 0.36362937092781067\n",
            "costo: 0.33260631561279297\n",
            "costo: 0.3129679560661316\n",
            "costo: 0.30657458305358887\n",
            "costo: 0.2984641194343567\n",
            "costo: 0.288336843252182\n",
            "costo: 0.2704143524169922\n",
            "costo: 0.26727235317230225\n",
            "costo: 0.2502751052379608\n",
            "costo: 0.24513769149780273\n",
            "costo: 0.2373298704624176\n",
            "costo: 0.23989631235599518\n",
            "costo: 0.22161908447742462\n",
            "costo: 0.21471089124679565\n",
            "costo: 0.20771220326423645\n",
            "costo: 0.2012648582458496\n",
            "costo: 0.19614875316619873\n",
            "costo: 0.1834956258535385\n",
            "costo: 0.17645925283432007\n",
            "costo: 0.16859984397888184\n",
            "costo: 0.17014577984809875\n",
            "costo: 0.1597440540790558\n",
            "costo: 0.15590009093284607\n",
            "costo: 0.14776286482810974\n",
            "costo: 0.1414671391248703\n",
            "costo: 0.14657436311244965\n",
            "costo: 0.13179147243499756\n",
            "costo: 0.12914182245731354\n",
            "costo: 0.12410591542720795\n",
            "costo: 0.11950172483921051\n",
            "costo: 0.11424780637025833\n",
            "costo: 0.10773725807666779\n",
            "costo: 0.10439273715019226\n",
            "costo: 0.1010628417134285\n",
            "costo: 0.09671357274055481\n",
            "costo: 0.09104956686496735\n",
            "costo: 0.08598470687866211\n",
            "costo: 0.08039576560258865\n",
            "costo: 0.07958125323057175\n",
            "costo: 0.07539450377225876\n",
            "costo: 0.07315056771039963\n",
            "costo: 0.07036823779344559\n",
            "costo: 0.0668589249253273\n",
            "costo: 0.06547971069812775\n",
            "costo: 0.06015247106552124\n",
            "costo: 0.05860140174627304\n",
            "costo: 0.056524887681007385\n",
            "costo: 0.05409469082951546\n",
            "costo: 0.05037229135632515\n",
            "costo: 0.047386664897203445\n",
            "costo: 0.0448591448366642\n",
            "costo: 0.04314786568284035\n",
            "costo: 0.04108540341258049\n",
            "costo: 0.036671508103609085\n",
            "costo: 0.03524351492524147\n",
            "costo: 0.033076558262109756\n",
            "costo: 0.031348202377557755\n",
            "costo: 0.029071513563394547\n",
            "costo: 0.02665914222598076\n",
            "costo: 0.02406040020287037\n",
            "costo: 0.022584350779652596\n",
            "costo: 0.021271977573633194\n",
            "costo: 0.019928015768527985\n",
            "costo: 0.01816074177622795\n",
            "costo: 0.01632414013147354\n",
            "costo: 0.014997072517871857\n",
            "costo: 0.013311430811882019\n",
            "costo: 0.01184223871678114\n",
            "costo: 0.010222433134913445\n",
            "costo: 0.00897395983338356\n",
            "costo: 0.007903049699962139\n",
            "costo: 0.006962751504033804\n",
            "costo: 0.006369120441377163\n",
            "costo: 0.005568122956901789\n",
            "costo: 0.005111849866807461\n",
            "costo: 0.004469235427677631\n",
            "costo: 0.003723267000168562\n",
            "costo: 0.0031789366621524096\n",
            "costo: 0.0026910912711173296\n",
            "costo: 0.0021587989758700132\n",
            "costo: 0.0019347755005583167\n",
            "costo: 0.001570571563206613\n",
            "costo: 0.0013488840777426958\n",
            "costo: 0.0011351199354976416\n",
            "costo: 0.0009497186983935535\n",
            "costo: 2.3102331161499023\n",
            "costo: 2.3060414791107178\n",
            "costo: 1.841364860534668\n",
            "costo: 1.0043280124664307\n",
            "costo: 3.2074637413024902\n",
            "costo: 0.8222578763961792\n",
            "costo: 0.7309977412223816\n",
            "costo: 1.0290814638137817\n",
            "costo: 0.6274188160896301\n",
            "costo: 0.6027995944023132\n",
            "costo: 0.5746739506721497\n",
            "costo: 0.5566877126693726\n",
            "costo: 0.5116651654243469\n",
            "costo: 0.46590179204940796\n",
            "costo: 0.4420856535434723\n",
            "costo: 0.4100370705127716\n",
            "costo: 0.38538897037506104\n",
            "costo: 0.36571547389030457\n",
            "costo: 0.3560037612915039\n",
            "costo: 0.3474719226360321\n",
            "costo: 0.3306712806224823\n",
            "costo: 0.3157244026660919\n",
            "costo: 0.3067784011363983\n",
            "costo: 0.2881735861301422\n",
            "costo: 0.2823093831539154\n",
            "costo: 0.2757315933704376\n",
            "costo: 0.2658441960811615\n",
            "costo: 0.2540305256843567\n",
            "costo: 0.2404288351535797\n",
            "costo: 0.23389016091823578\n",
            "costo: 0.22647011280059814\n",
            "costo: 0.2173917591571808\n",
            "costo: 0.23064152896404266\n",
            "costo: 0.20350083708763123\n",
            "costo: 0.20038437843322754\n",
            "costo: 0.192478209733963\n",
            "costo: 0.18709395825862885\n",
            "costo: 0.18003521859645844\n",
            "costo: 0.16980060935020447\n",
            "costo: 0.16360272467136383\n",
            "costo: 0.1579262912273407\n",
            "costo: 0.1518687903881073\n",
            "costo: 0.1485404670238495\n",
            "costo: 0.1409241259098053\n",
            "costo: 0.13508988916873932\n",
            "costo: 0.12867626547813416\n",
            "costo: 0.1253426969051361\n",
            "costo: 0.12113809585571289\n",
            "costo: 0.11712425947189331\n",
            "costo: 0.1079888641834259\n",
            "costo: 0.10304123908281326\n",
            "costo: 0.0970945730805397\n",
            "costo: 0.0937666967511177\n",
            "costo: 0.08917658030986786\n",
            "costo: 0.0990949496626854\n",
            "costo: 0.08291812241077423\n",
            "costo: 0.08119013160467148\n",
            "costo: 0.0766025111079216\n",
            "costo: 0.07262260466814041\n",
            "costo: 0.07276172935962677\n",
            "costo: 0.0644439235329628\n",
            "costo: 0.06330189108848572\n",
            "costo: 0.06033216416835785\n",
            "costo: 0.05693792924284935\n",
            "costo: 0.05321214720606804\n",
            "costo: 0.05097111314535141\n",
            "costo: 0.04749085381627083\n",
            "costo: 0.043694254010915756\n",
            "costo: 0.041258618235588074\n",
            "costo: 0.037866510450839996\n",
            "costo: 0.03643106296658516\n",
            "costo: 0.034541405737400055\n",
            "costo: 0.0318499319255352\n",
            "costo: 0.030823389068245888\n",
            "costo: 0.027487406507134438\n",
            "costo: 0.026565715670585632\n",
            "costo: 0.024415859952569008\n",
            "costo: 0.02166546694934368\n",
            "costo: 0.019744902849197388\n",
            "costo: 0.017929738387465477\n",
            "costo: 0.016489366069436073\n",
            "costo: 0.01473964937031269\n",
            "costo: 0.013583401218056679\n",
            "costo: 0.01146524678915739\n",
            "costo: 0.010589131154119968\n",
            "costo: 0.00949601735919714\n",
            "costo: 0.008415967226028442\n",
            "costo: 0.007412215694785118\n",
            "costo: 0.00632647518068552\n",
            "costo: 0.005628363229334354\n",
            "costo: 0.00500757759436965\n",
            "costo: 0.004054384771734476\n",
            "costo: 0.0033786077983677387\n",
            "costo: 0.0029538830276578665\n",
            "costo: 0.0022773523814976215\n",
            "costo: 0.0018914337269961834\n",
            "costo: 0.0016063436632975936\n",
            "costo: 0.0011330526322126389\n",
            "costo: 0.0010166505817323923\n",
            "costo: 0.0007996134227141738\n",
            "costo: 2.3117387294769287\n",
            "costo: 2.3077521324157715\n",
            "costo: 1.8169349431991577\n",
            "costo: 0.9357165694236755\n",
            "costo: 3.076356887817383\n",
            "costo: 0.7345091700553894\n",
            "costo: 0.6649908423423767\n",
            "costo: 0.6282462477684021\n",
            "costo: 0.5731322765350342\n",
            "costo: 0.5632004141807556\n",
            "costo: 0.5177679061889648\n",
            "costo: 0.4906996786594391\n",
            "costo: 0.4585943818092346\n",
            "costo: 0.4361366033554077\n",
            "costo: 0.41444531083106995\n",
            "costo: 0.3906855583190918\n",
            "costo: 0.3661484718322754\n",
            "costo: 0.3363252878189087\n",
            "costo: 0.3327726125717163\n",
            "costo: 0.31663012504577637\n",
            "costo: 0.3120683431625366\n",
            "costo: 0.2984882593154907\n",
            "costo: 0.2839275300502777\n",
            "costo: 0.2926160991191864\n",
            "costo: 0.2652120292186737\n",
            "costo: 0.2609913647174835\n",
            "costo: 0.2534078061580658\n",
            "costo: 0.244167760014534\n",
            "costo: 0.23238235712051392\n",
            "costo: 0.22060053050518036\n",
            "costo: 0.21525979042053223\n",
            "costo: 0.20521435141563416\n",
            "costo: 0.20139968395233154\n",
            "costo: 0.19474537670612335\n",
            "costo: 0.18833576142787933\n",
            "costo: 0.1824125349521637\n",
            "costo: 0.17240044474601746\n",
            "costo: 0.17802859842777252\n",
            "costo: 0.15632015466690063\n",
            "costo: 0.15183408558368683\n",
            "costo: 0.14442551136016846\n",
            "costo: 0.1398395448923111\n",
            "costo: 0.13413670659065247\n",
            "costo: 0.1278819441795349\n",
            "costo: 0.12210255116224289\n",
            "costo: 0.11295819282531738\n",
            "costo: 0.11734554916620255\n",
            "costo: 0.10104738175868988\n",
            "costo: 0.09853366017341614\n",
            "costo: 0.09247980266809464\n",
            "costo: 0.08821911364793777\n",
            "costo: 0.08380234986543655\n",
            "costo: 0.07785498350858688\n",
            "costo: 0.07361172139644623\n",
            "costo: 0.06940726190805435\n",
            "costo: 0.06682109087705612\n",
            "costo: 0.06236768886446953\n",
            "costo: 0.058890361338853836\n",
            "costo: 0.055783502757549286\n",
            "costo: 0.05188237875699997\n",
            "costo: 0.05032309144735336\n",
            "costo: 0.047153227031230927\n",
            "costo: 0.0449378564953804\n",
            "costo: 0.04234766587615013\n",
            "costo: 0.03890737146139145\n",
            "costo: 0.038963478058576584\n",
            "costo: 0.032661132514476776\n",
            "costo: 0.03130678832530975\n",
            "costo: 0.02917945571243763\n",
            "costo: 0.026897961273789406\n",
            "costo: 0.02390345185995102\n",
            "costo: 0.021434606984257698\n",
            "costo: 0.019400373101234436\n",
            "costo: 0.01779767870903015\n",
            "costo: 0.015762437134981155\n",
            "costo: 0.014131980948150158\n",
            "costo: 0.013041652739048004\n",
            "costo: 0.011954647488892078\n",
            "costo: 0.010838396847248077\n",
            "costo: 0.008650628849864006\n",
            "costo: 0.00870565790683031\n",
            "costo: 0.006335038226097822\n",
            "costo: 0.005966976750642061\n",
            "costo: 0.005180233623832464\n",
            "costo: 0.004453751724213362\n",
            "costo: 0.0036113031674176455\n",
            "costo: 0.00294881802983582\n",
            "costo: 0.0023609346244484186\n",
            "costo: 0.0020561721175909042\n",
            "costo: 0.0017333521973341703\n",
            "costo: 0.0014258918818086386\n",
            "costo: 0.001112865167669952\n",
            "costo: 0.0009445490431971848\n",
            "costo: 0.0007202685810625553\n",
            "costo: 0.0006524709169752896\n",
            "costo: 0.0005344103556126356\n",
            "costo: 0.00040336413076147437\n",
            "costo: 0.00029429118148982525\n",
            "costo: 0.0001672518119448796\n",
            "costo: 0.0001360866881441325\n",
            "costo: 2.2931082248687744\n",
            "costo: 2.288252115249634\n",
            "costo: 1.767441749572754\n",
            "costo: 0.8973468542098999\n",
            "costo: 2.959493637084961\n",
            "costo: 0.6696732640266418\n",
            "costo: 0.6309128403663635\n",
            "costo: 0.5821107625961304\n",
            "costo: 0.567505419254303\n",
            "costo: 0.5413654446601868\n",
            "costo: 0.5080281496047974\n",
            "costo: 0.47609445452690125\n",
            "costo: 0.4470721185207367\n",
            "costo: 0.40669679641723633\n",
            "costo: 0.39678218960762024\n",
            "costo: 0.38522452116012573\n",
            "costo: 0.3650707006454468\n",
            "costo: 0.3407387137413025\n",
            "costo: 0.33612698316574097\n",
            "costo: 0.3184789717197418\n",
            "costo: 0.31316077709198\n",
            "costo: 0.2978091537952423\n",
            "costo: 0.28822553157806396\n",
            "costo: 0.274730920791626\n",
            "costo: 0.26624590158462524\n",
            "costo: 0.25741708278656006\n",
            "costo: 0.2503620386123657\n",
            "costo: 0.24347859621047974\n",
            "costo: 0.23098084330558777\n",
            "costo: 0.22461137175559998\n",
            "costo: 0.2169438898563385\n",
            "costo: 0.20795634388923645\n",
            "costo: 0.1985936164855957\n",
            "costo: 0.18805256485939026\n",
            "costo: 0.18123556673526764\n",
            "costo: 0.17509879171848297\n",
            "costo: 0.17163588106632233\n",
            "costo: 0.16474726796150208\n",
            "costo: 0.15962833166122437\n",
            "costo: 0.15172602236270905\n",
            "costo: 0.1446112096309662\n",
            "costo: 0.13919515907764435\n",
            "costo: 0.13169053196907043\n",
            "costo: 0.12359517812728882\n",
            "costo: 0.11639030277729034\n",
            "costo: 0.11077210307121277\n",
            "costo: 0.10754843801259995\n",
            "costo: 0.10409305989742279\n",
            "costo: 0.09968732297420502\n",
            "costo: 0.09399143606424332\n",
            "costo: 0.09028039872646332\n",
            "costo: 0.08618853241205215\n",
            "costo: 0.0967261791229248\n",
            "costo: 0.08132808655500412\n",
            "costo: 0.07959340512752533\n",
            "costo: 0.07336942106485367\n",
            "costo: 0.07291579246520996\n",
            "costo: 0.06964646279811859\n",
            "costo: 0.06733947992324829\n",
            "costo: 0.0642574205994606\n",
            "costo: 0.06061246618628502\n",
            "costo: 0.06262373179197311\n",
            "costo: 0.05527294799685478\n",
            "costo: 0.054043740034103394\n",
            "costo: 0.051546357572078705\n",
            "costo: 0.04858265444636345\n",
            "costo: 0.05048995465040207\n",
            "costo: 0.04286549240350723\n",
            "costo: 0.04208008199930191\n",
            "costo: 0.039918202906847\n",
            "costo: 0.03767413645982742\n",
            "costo: 0.034692760556936264\n",
            "costo: 0.03236468881368637\n",
            "costo: 0.03049139678478241\n",
            "costo: 0.028458479791879654\n",
            "costo: 0.026168815791606903\n",
            "costo: 0.024595391005277634\n",
            "costo: 0.022749856114387512\n",
            "costo: 0.021002424880862236\n",
            "costo: 0.01923980750143528\n",
            "costo: 0.017701994627714157\n",
            "costo: 0.0164453387260437\n",
            "costo: 0.015390623360872269\n",
            "costo: 0.014003852382302284\n",
            "costo: 0.01185296755284071\n",
            "costo: 0.01111553143709898\n",
            "costo: 0.010172167792916298\n",
            "costo: 0.009064017795026302\n",
            "costo: 0.007611207198351622\n",
            "costo: 0.006606290116906166\n",
            "costo: 0.005990650504827499\n",
            "costo: 0.0053702788427472115\n",
            "costo: 0.004607716109603643\n",
            "costo: 0.004462692886590958\n",
            "costo: 0.003356854896992445\n",
            "costo: 0.003095373511314392\n",
            "costo: 0.0027302864473313093\n",
            "costo: 0.002322249813005328\n",
            "costo: 0.0021640374325215816\n",
            "costo: 0.0014807939296588302\n",
            "costo: 2.311954975128174\n",
            "costo: 2.3068385124206543\n",
            "costo: 1.8315823078155518\n",
            "costo: 1.0445021390914917\n",
            "costo: 2.6144931316375732\n",
            "costo: 0.7679212689399719\n",
            "costo: 0.6656391620635986\n",
            "costo: 0.7368666529655457\n",
            "costo: 0.5791947245597839\n",
            "costo: 0.5663957595825195\n",
            "costo: 0.5408434867858887\n",
            "costo: 0.5172518491744995\n",
            "costo: 0.4727380573749542\n",
            "costo: 0.44614192843437195\n",
            "costo: 0.41376301646232605\n",
            "costo: 0.391824334859848\n",
            "costo: 0.36591705679893494\n",
            "costo: 0.3511505722999573\n",
            "costo: 0.33173036575317383\n",
            "costo: 0.31695762276649475\n",
            "costo: 0.307756245136261\n",
            "costo: 0.29949110746383667\n",
            "costo: 0.28866150975227356\n",
            "costo: 0.2751510441303253\n",
            "costo: 0.2646315097808838\n",
            "costo: 0.2560836374759674\n",
            "costo: 0.2512471675872803\n",
            "costo: 0.2451387494802475\n",
            "costo: 0.23336941003799438\n",
            "costo: 0.2248024344444275\n",
            "costo: 0.21099868416786194\n",
            "costo: 0.205936998128891\n",
            "costo: 0.1993330717086792\n",
            "costo: 0.19275116920471191\n",
            "costo: 0.18368475139141083\n",
            "costo: 0.17517541348934174\n",
            "costo: 0.16663163900375366\n",
            "costo: 0.16286377608776093\n",
            "costo: 0.15661224722862244\n",
            "costo: 0.15090326964855194\n",
            "costo: 0.14133355021476746\n",
            "costo: 0.13533110916614532\n",
            "costo: 0.13111409544944763\n",
            "costo: 0.12602774798870087\n",
            "costo: 0.12239135056734085\n",
            "costo: 0.11467670649290085\n",
            "costo: 0.1114395335316658\n",
            "costo: 0.10606737434864044\n",
            "costo: 0.09973987191915512\n",
            "costo: 0.09593670070171356\n",
            "costo: 0.09058694541454315\n",
            "costo: 0.08807533979415894\n",
            "costo: 0.08520130068063736\n",
            "costo: 0.07992465049028397\n",
            "costo: 0.0947282686829567\n",
            "costo: 0.07292800396680832\n",
            "costo: 0.07127249240875244\n",
            "costo: 0.06676510721445084\n",
            "costo: 0.06311573088169098\n",
            "costo: 0.05989135801792145\n",
            "costo: 0.05610872432589531\n",
            "costo: 0.05465308204293251\n",
            "costo: 0.05246946960687637\n",
            "costo: 0.05142385885119438\n",
            "costo: 0.04733900725841522\n",
            "costo: 0.045148059725761414\n",
            "costo: 0.04315977171063423\n",
            "costo: 0.0399102158844471\n",
            "costo: 0.036334335803985596\n",
            "costo: 0.03286832198500633\n",
            "costo: 0.031563639640808105\n",
            "costo: 0.029694020748138428\n",
            "costo: 0.027303125709295273\n",
            "costo: 0.025335419923067093\n",
            "costo: 0.02314910478889942\n",
            "costo: 0.022040674462914467\n",
            "costo: 0.02031533606350422\n",
            "costo: 0.018644079566001892\n",
            "costo: 0.01659385859966278\n",
            "costo: 0.015109535306692123\n",
            "costo: 0.01395323220640421\n",
            "costo: 0.01203661598265171\n",
            "costo: 0.011766820214688778\n",
            "costo: 0.009414292871952057\n",
            "costo: 0.008842458948493004\n",
            "costo: 0.007982847280800343\n",
            "costo: 0.007201186381280422\n",
            "costo: 0.006198509596288204\n",
            "costo: 0.005378017667680979\n",
            "costo: 0.004841971676796675\n",
            "costo: 0.003914999309927225\n",
            "costo: 0.003500832011923194\n",
            "costo: 0.0028723813593387604\n",
            "costo: 0.0026503042317926884\n",
            "costo: 0.0022129726130515337\n",
            "costo: 0.0019084514351561666\n",
            "costo: 0.0015647643012925982\n",
            "costo: 0.0014201418962329626\n",
            "costo: 0.0012095981510356069\n",
            "costo: 0.001003383076749742\n",
            "costo: 2.315390110015869\n",
            "costo: 2.310858964920044\n",
            "costo: 1.8141628503799438\n",
            "costo: 0.9046334624290466\n",
            "costo: 3.644437074661255\n",
            "costo: 0.7306420803070068\n",
            "costo: 0.6710772514343262\n",
            "costo: 0.598396360874176\n",
            "costo: 0.5791753530502319\n",
            "costo: 0.5609521269798279\n",
            "costo: 0.5450599789619446\n",
            "costo: 0.4958823323249817\n",
            "costo: 0.4438990652561188\n",
            "costo: 0.45417460799217224\n",
            "costo: 0.3961842954158783\n",
            "costo: 0.38693124055862427\n",
            "costo: 0.371378630399704\n",
            "costo: 0.3548060655593872\n",
            "costo: 0.3320061266422272\n",
            "costo: 0.317786306142807\n",
            "costo: 0.30753907561302185\n",
            "costo: 0.3000071048736572\n",
            "costo: 0.28822091221809387\n",
            "costo: 0.27568113803863525\n",
            "costo: 0.2603330612182617\n",
            "costo: 0.251266747713089\n",
            "costo: 0.2377355843782425\n",
            "costo: 0.23207396268844604\n",
            "costo: 0.2229594737291336\n",
            "costo: 0.21775270998477936\n",
            "costo: 0.21320565044879913\n",
            "costo: 0.20643028616905212\n",
            "costo: 0.19096140563488007\n",
            "costo: 0.17772096395492554\n",
            "costo: 0.16926953196525574\n",
            "costo: 0.16231252253055573\n",
            "costo: 0.15591752529144287\n",
            "costo: 0.14738863706588745\n",
            "costo: 0.13854312896728516\n",
            "costo: 0.1319553405046463\n",
            "costo: 0.12707464396953583\n",
            "costo: 0.12312126904726028\n",
            "costo: 0.11844728887081146\n",
            "costo: 0.11174185574054718\n",
            "costo: 0.1024424284696579\n",
            "costo: 0.09659092128276825\n",
            "costo: 0.08944196999073029\n",
            "costo: 0.08585003018379211\n",
            "costo: 0.08069346845149994\n",
            "costo: 0.08389807492494583\n",
            "costo: 0.07383466511964798\n",
            "costo: 0.07131469994783401\n",
            "costo: 0.06661190092563629\n",
            "costo: 0.06355515867471695\n",
            "costo: 0.06541627645492554\n",
            "costo: 0.05688131973147392\n",
            "costo: 0.05559506267309189\n",
            "costo: 0.05158209428191185\n",
            "costo: 0.04759761318564415\n",
            "costo: 0.04316629469394684\n",
            "costo: 0.04006974771618843\n",
            "costo: 0.03718385845422745\n",
            "costo: 0.03490118309855461\n",
            "costo: 0.03236871585249901\n",
            "costo: 0.02982432208955288\n",
            "costo: 0.02746564708650112\n",
            "costo: 0.02488704025745392\n",
            "costo: 0.022562691941857338\n",
            "costo: 0.022423019632697105\n",
            "costo: 0.01946381852030754\n",
            "costo: 0.018637273460626602\n",
            "costo: 0.01680292934179306\n",
            "costo: 0.015067163854837418\n",
            "costo: 0.016496846452355385\n",
            "costo: 0.011879272758960724\n",
            "costo: 0.011266596615314484\n",
            "costo: 0.010129833593964577\n",
            "costo: 0.008898339234292507\n",
            "costo: 0.0076024397276341915\n",
            "costo: 0.006446378771215677\n",
            "costo: 0.00529161561280489\n",
            "costo: 0.004767634905874729\n",
            "costo: 0.003959280904382467\n",
            "costo: 0.0032438694033771753\n",
            "costo: 0.00278016016818583\n",
            "costo: 0.0022448597010225058\n",
            "costo: 0.0019621856044977903\n",
            "costo: 0.001602616743184626\n",
            "costo: 0.0013059302000328898\n",
            "costo: 0.0009853227529674768\n",
            "costo: 0.0008790523279458284\n",
            "costo: 0.0007257460965774953\n",
            "costo: 0.0005934170330874622\n",
            "costo: 0.0004865542287006974\n",
            "costo: 0.00041346705984324217\n",
            "costo: 0.0003405069001019001\n",
            "costo: 0.0002579761203378439\n",
            "costo: 0.00020241166930645704\n",
            "costo: 0.00016465219960082322\n",
            "costo: 0.00014289544196799397\n",
            "costo: 2.3207900524139404\n",
            "costo: 2.315445899963379\n",
            "costo: 1.8337048292160034\n",
            "costo: 1.0362745523452759\n",
            "costo: 1.2005430459976196\n",
            "costo: 0.7230890393257141\n",
            "costo: 0.6344950199127197\n",
            "costo: 0.6069900989532471\n",
            "costo: 0.5749757885932922\n",
            "costo: 0.5635202527046204\n",
            "costo: 0.5308724045753479\n",
            "costo: 0.5142105221748352\n",
            "costo: 0.47940489649772644\n",
            "costo: 0.4454255998134613\n",
            "costo: 0.42053788900375366\n",
            "costo: 0.3850489556789398\n",
            "costo: 0.37703609466552734\n",
            "costo: 0.34583941102027893\n",
            "costo: 0.3359951078891754\n",
            "costo: 0.3226739466190338\n",
            "costo: 0.3172749876976013\n",
            "costo: 0.30454230308532715\n",
            "costo: 0.2955021262168884\n",
            "costo: 0.28242605924606323\n",
            "costo: 0.27466294169425964\n",
            "costo: 0.2644293010234833\n",
            "costo: 0.257999062538147\n",
            "costo: 0.24655146896839142\n",
            "costo: 0.23538143932819366\n",
            "costo: 0.22862011194229126\n",
            "costo: 0.21305857598781586\n",
            "costo: 0.2089109718799591\n",
            "costo: 0.20209060609340668\n",
            "costo: 0.19517146050930023\n",
            "costo: 0.18639446794986725\n",
            "costo: 0.1770695447921753\n",
            "costo: 0.170433908700943\n",
            "costo: 0.16380973160266876\n",
            "costo: 0.15642569959163666\n",
            "costo: 0.1482039839029312\n",
            "costo: 0.14134429395198822\n",
            "costo: 0.13228118419647217\n",
            "costo: 0.12443234026432037\n",
            "costo: 0.11823920905590057\n",
            "costo: 0.11434178054332733\n",
            "costo: 0.1081203892827034\n",
            "costo: 0.10210999101400375\n",
            "costo: 0.09604492038488388\n",
            "costo: 0.09055573493242264\n",
            "costo: 0.08737161755561829\n",
            "costo: 0.08146800100803375\n",
            "costo: 0.0778513252735138\n",
            "costo: 0.0732969269156456\n",
            "costo: 0.06970814615488052\n",
            "costo: 0.06609918922185898\n",
            "costo: 0.06160200759768486\n",
            "costo: 0.056582748889923096\n",
            "costo: 0.05300008878111839\n",
            "costo: 0.049024567008018494\n",
            "costo: 0.04626157879829407\n",
            "costo: 0.04333608224987984\n",
            "costo: 0.0403844378888607\n",
            "costo: 0.03864761069417\n",
            "costo: 0.03544177860021591\n",
            "costo: 0.03257647156715393\n",
            "costo: 0.028658080846071243\n",
            "costo: 0.027156230062246323\n",
            "costo: 0.02505412884056568\n",
            "costo: 0.022741161286830902\n",
            "costo: 0.020277095958590508\n",
            "costo: 0.018498530611395836\n",
            "costo: 0.016895383596420288\n",
            "costo: 0.01454637199640274\n",
            "costo: 0.018020400777459145\n",
            "costo: 0.011969320476055145\n",
            "costo: 0.0115424869582057\n",
            "costo: 0.010062644258141518\n",
            "costo: 0.00824076496064663\n",
            "costo: 0.00966348685324192\n",
            "costo: 0.00605983380228281\n",
            "costo: 0.005673859268426895\n",
            "costo: 0.004675646312534809\n",
            "costo: 0.003950348123908043\n",
            "costo: 0.0031071025878190994\n",
            "costo: 0.0025145302060991526\n",
            "costo: 0.0020073021296411753\n",
            "costo: 0.0016037893947213888\n",
            "costo: 0.0013257467653602362\n",
            "costo: 0.0010992825264111161\n",
            "costo: 0.0009108804515562952\n",
            "costo: 0.0007363527547568083\n",
            "costo: 0.0005629248917102814\n",
            "costo: 0.0004782182222697884\n",
            "costo: 0.0003412933729123324\n",
            "costo: 0.00022020995675120503\n",
            "costo: 0.0001880687486846\n",
            "costo: 0.00013746306649409235\n",
            "costo: 0.00013588172441814095\n",
            "costo: 8.607248309999704e-05\n",
            "costo: 7.638431998202577e-05\n",
            "costo: 2.3044161796569824\n",
            "costo: 2.300964832305908\n",
            "costo: 1.7955142259597778\n",
            "costo: 0.9018186926841736\n",
            "costo: 3.958750009536743\n",
            "costo: 0.731530487537384\n",
            "costo: 0.6612398624420166\n",
            "costo: 0.603463351726532\n",
            "costo: 0.5698129534721375\n",
            "costo: 0.5537199378013611\n",
            "costo: 0.5309419631958008\n",
            "costo: 0.48264405131340027\n",
            "costo: 0.4478837251663208\n",
            "costo: 0.41724202036857605\n",
            "costo: 0.39723655581474304\n",
            "costo: 0.38072264194488525\n",
            "costo: 0.36139535903930664\n",
            "costo: 0.3428128957748413\n",
            "costo: 0.3209824860095978\n",
            "costo: 0.30918073654174805\n",
            "costo: 0.2987203896045685\n",
            "costo: 0.2874031066894531\n",
            "costo: 0.27767592668533325\n",
            "costo: 0.26238617300987244\n",
            "costo: 0.25046977400779724\n",
            "costo: 0.23938876390457153\n",
            "costo: 0.2319917529821396\n",
            "costo: 0.22085155546665192\n",
            "costo: 0.21294042468070984\n",
            "costo: 0.20444685220718384\n",
            "costo: 0.19708873331546783\n",
            "costo: 0.191177636384964\n",
            "costo: 0.1854637712240219\n",
            "costo: 0.17512550950050354\n",
            "costo: 0.1662573367357254\n",
            "costo: 0.15422752499580383\n",
            "costo: 0.1446954309940338\n",
            "costo: 0.13517092168331146\n",
            "costo: 0.1305675059556961\n",
            "costo: 0.126885786652565\n",
            "costo: 0.12148752063512802\n",
            "costo: 0.11599169671535492\n",
            "costo: 0.11191580444574356\n",
            "costo: 0.10511447489261627\n",
            "costo: 0.10123419761657715\n",
            "costo: 0.09620485454797745\n",
            "costo: 0.09069330245256424\n",
            "costo: 0.08506554365158081\n",
            "costo: 0.08110273629426956\n",
            "costo: 0.07614879310131073\n",
            "costo: 0.0712873786687851\n",
            "costo: 0.06644582003355026\n",
            "costo: 0.06298743188381195\n",
            "costo: 0.0590975396335125\n",
            "costo: 0.05565977096557617\n",
            "costo: 0.052309371531009674\n",
            "costo: 0.04742862284183502\n",
            "costo: 0.04342895373702049\n",
            "costo: 0.04020213335752487\n",
            "costo: 0.037115905433893204\n",
            "costo: 0.03495526686310768\n",
            "costo: 0.03315667435526848\n",
            "costo: 0.030653534457087517\n",
            "costo: 0.028138626366853714\n",
            "costo: 0.024635108187794685\n",
            "costo: 0.022270500659942627\n",
            "costo: 0.02064170129597187\n",
            "costo: 0.018675999715924263\n",
            "costo: 0.016252202913165092\n",
            "costo: 0.014823575504124165\n",
            "costo: 0.012383265420794487\n",
            "costo: 0.011501855216920376\n",
            "costo: 0.010246733203530312\n",
            "costo: 0.008919554762542248\n",
            "costo: 0.007355709094554186\n",
            "costo: 0.006388701032847166\n",
            "costo: 0.005676688626408577\n",
            "costo: 0.00477874930948019\n",
            "costo: 0.00426025316119194\n",
            "costo: 0.0035367233213037252\n",
            "costo: 0.0032186280004680157\n",
            "costo: 0.0027630121912807226\n",
            "costo: 0.002110722940415144\n",
            "costo: 0.001910553895868361\n",
            "costo: 0.0012666234979406\n",
            "costo: 0.001136843697167933\n",
            "costo: 0.0009432448423467577\n",
            "costo: 0.0007979376241564751\n",
            "costo: 0.0006412917282432318\n",
            "costo: 0.0005768080009147525\n",
            "costo: 0.00043192124576307833\n",
            "costo: 0.00033795725903473794\n",
            "costo: 0.00025028196978382766\n",
            "costo: 0.00020865804981440306\n",
            "costo: 0.00016290094936266541\n",
            "costo: 0.00012533490371424705\n",
            "costo: 0.00010246656165691093\n",
            "costo: 7.635265501448885e-05\n",
            "costo: 5.927656820858829e-05\n",
            "costo: 4.691682261181995e-05\n",
            "costo: 2.30883526802063\n",
            "costo: 2.303908109664917\n",
            "costo: 1.8636457920074463\n",
            "costo: 1.1277040243148804\n",
            "costo: 4.922482013702393\n",
            "costo: 0.7453672885894775\n",
            "costo: 0.6589717268943787\n",
            "costo: 0.5878214240074158\n",
            "costo: 0.557847797870636\n",
            "costo: 0.5234903693199158\n",
            "costo: 0.4859730005264282\n",
            "costo: 0.4634453058242798\n",
            "costo: 0.4274812638759613\n",
            "costo: 0.4216271936893463\n",
            "costo: 0.3892524540424347\n",
            "costo: 0.3808760643005371\n",
            "costo: 0.36458051204681396\n",
            "costo: 0.3450930118560791\n",
            "costo: 0.3266580402851105\n",
            "costo: 0.309693843126297\n",
            "costo: 0.3014949858188629\n",
            "costo: 0.28721562027931213\n",
            "costo: 0.27746519446372986\n",
            "costo: 0.2642183303833008\n",
            "costo: 0.25471004843711853\n",
            "costo: 0.2468157410621643\n",
            "costo: 0.2388847917318344\n",
            "costo: 0.22260956466197968\n",
            "costo: 0.21695634722709656\n",
            "costo: 0.20740318298339844\n",
            "costo: 0.20255054533481598\n",
            "costo: 0.19413848221302032\n",
            "costo: 0.185324564576149\n",
            "costo: 0.1734301596879959\n",
            "costo: 0.1641264706850052\n",
            "costo: 0.15733426809310913\n",
            "costo: 0.1493329256772995\n",
            "costo: 0.14201633632183075\n",
            "costo: 0.13533727824687958\n",
            "costo: 0.12955307960510254\n",
            "costo: 0.12385579943656921\n",
            "costo: 0.11814750730991364\n",
            "costo: 0.11274287104606628\n",
            "costo: 0.10610125958919525\n",
            "costo: 0.09956472367048264\n",
            "costo: 0.09555091708898544\n",
            "costo: 0.08943413943052292\n",
            "costo: 0.08676856756210327\n",
            "costo: 0.08123986423015594\n",
            "costo: 0.07345737516880035\n",
            "costo: 0.06752758473157883\n",
            "costo: 0.06399250030517578\n",
            "costo: 0.0607522577047348\n",
            "costo: 0.058394066989421844\n",
            "costo: 0.054963450878858566\n",
            "costo: 0.05098719894886017\n",
            "costo: 0.048784345388412476\n",
            "costo: 0.046021949499845505\n",
            "costo: 0.04596429318189621\n",
            "costo: 0.04086580500006676\n",
            "costo: 0.039301443845033646\n",
            "costo: 0.036985427141189575\n",
            "costo: 0.03424898535013199\n",
            "costo: 0.03517178073525429\n",
            "costo: 0.028901295736432076\n",
            "costo: 0.027997750788927078\n",
            "costo: 0.024851033464074135\n",
            "costo: 0.026775769889354706\n",
            "costo: 0.021699445322155952\n",
            "costo: 0.020865632221102715\n",
            "costo: 0.01872519589960575\n",
            "costo: 0.016512935981154442\n",
            "costo: 0.015438553877174854\n",
            "costo: 0.012006525881588459\n",
            "costo: 0.011243033222854137\n",
            "costo: 0.009907864034175873\n",
            "costo: 0.008834492415189743\n",
            "costo: 0.007663155905902386\n",
            "costo: 0.006445235572755337\n",
            "costo: 0.005676353815943003\n",
            "costo: 0.00505182845517993\n",
            "costo: 0.004202100448310375\n",
            "costo: 0.003452465170994401\n",
            "costo: 0.0030941094737499952\n",
            "costo: 0.002457450143992901\n",
            "costo: 0.002184881130233407\n",
            "costo: 0.0017787518445402384\n",
            "costo: 0.0013108511921018362\n",
            "costo: 0.0018706015544012189\n",
            "costo: 0.0008297510794363916\n",
            "costo: 0.0007630441104993224\n",
            "costo: 0.0006041807937435806\n",
            "costo: 0.0004725770268123597\n",
            "costo: 0.0003357662935741246\n",
            "costo: 0.00028115714667364955\n",
            "costo: 0.00022305850870907307\n",
            "costo: 0.00015832672943361104\n",
            "costo: 0.00022111664293333888\n",
            "costo: 9.231531294062734e-05\n",
            "costo: 8.612839883426204e-05\n",
            "costo: 2.302456855773926\n",
            "costo: 2.297983169555664\n",
            "costo: 1.8005882501602173\n",
            "costo: 0.9850414991378784\n",
            "costo: 1.6134753227233887\n",
            "costo: 0.7219071984291077\n",
            "costo: 0.6324511170387268\n",
            "costo: 0.6636370420455933\n",
            "costo: 0.5630247592926025\n",
            "costo: 0.5516468286514282\n",
            "costo: 0.5160653591156006\n",
            "costo: 0.4862050414085388\n",
            "costo: 0.44981852173805237\n",
            "costo: 0.420563280582428\n",
            "costo: 0.3967205882072449\n",
            "costo: 0.3788370192050934\n",
            "costo: 0.3698224127292633\n",
            "costo: 0.34226641058921814\n",
            "costo: 0.32422882318496704\n",
            "costo: 0.3063509464263916\n",
            "costo: 0.2908683717250824\n",
            "costo: 0.28215256333351135\n",
            "costo: 0.26729530096054077\n",
            "costo: 0.25550132989883423\n",
            "costo: 0.25037840008735657\n",
            "costo: 0.2374761551618576\n",
            "costo: 0.22808843851089478\n",
            "costo: 0.21947206556797028\n",
            "costo: 0.21442335844039917\n",
            "costo: 0.2050316333770752\n",
            "costo: 0.19530990719795227\n",
            "costo: 0.1894323229789734\n",
            "costo: 0.17755527794361115\n",
            "costo: 0.17406809329986572\n",
            "costo: 0.16839605569839478\n",
            "costo: 0.16067466139793396\n",
            "costo: 0.16868333518505096\n",
            "costo: 0.1472741961479187\n",
            "costo: 0.1439247578382492\n",
            "costo: 0.13884207606315613\n",
            "costo: 0.13390794396400452\n",
            "costo: 0.12882037460803986\n",
            "costo: 0.12222261726856232\n",
            "costo: 0.11902311444282532\n",
            "costo: 0.11541825532913208\n",
            "costo: 0.10908917337656021\n",
            "costo: 0.1047014519572258\n",
            "costo: 0.09817152470350266\n",
            "costo: 0.0953809842467308\n",
            "costo: 0.09147753566503525\n",
            "costo: 0.08657177537679672\n",
            "costo: 0.08440366387367249\n",
            "costo: 0.07715613394975662\n",
            "costo: 0.07420358061790466\n",
            "costo: 0.07080945372581482\n",
            "costo: 0.0665106326341629\n",
            "costo: 0.0661599263548851\n",
            "costo: 0.05929907411336899\n",
            "costo: 0.05752477049827576\n",
            "costo: 0.05420660972595215\n",
            "costo: 0.05063343420624733\n",
            "costo: 0.04708017036318779\n",
            "costo: 0.044778887182474136\n",
            "costo: 0.04276898875832558\n",
            "costo: 0.04012005776166916\n",
            "costo: 0.03797502815723419\n",
            "costo: 0.03393847122788429\n",
            "costo: 0.03232341259717941\n",
            "costo: 0.029858127236366272\n",
            "costo: 0.027174480259418488\n",
            "costo: 0.02495659701526165\n",
            "costo: 0.023188771679997444\n",
            "costo: 0.02166791819036007\n",
            "costo: 0.02001720294356346\n",
            "costo: 0.01902982033789158\n",
            "costo: 0.016504433006048203\n",
            "costo: 0.015509992837905884\n",
            "costo: 0.01433630846440792\n",
            "costo: 0.012875319458544254\n",
            "costo: 0.013537636958062649\n",
            "costo: 0.010103248059749603\n",
            "costo: 0.009609833359718323\n",
            "costo: 0.008436545729637146\n",
            "costo: 0.007219275925308466\n",
            "costo: 0.006052067037671804\n",
            "costo: 0.0053853620775043964\n",
            "costo: 0.004490240011364222\n",
            "costo: 0.0037245743442326784\n",
            "costo: 0.0033630270045250654\n",
            "costo: 0.0025256038643419743\n",
            "costo: 0.002294278470799327\n",
            "costo: 0.001939135603606701\n",
            "costo: 0.0016718801343813539\n",
            "costo: 0.0014100443804636598\n",
            "costo: 0.001176253193989396\n",
            "costo: 0.0009410014608874917\n",
            "costo: 0.0007289556670002639\n",
            "costo: 0.0005331485881470144\n",
            "costo: 0.0004599178791977465\n",
            "costo: 0.0003653708554338664\n",
            "costo: 2.30501127243042\n",
            "costo: 2.301619291305542\n",
            "costo: 1.819926381111145\n",
            "costo: 1.2537403106689453\n",
            "costo: 1.2402980327606201\n",
            "costo: 0.6917741894721985\n",
            "costo: 0.6411711573600769\n",
            "costo: 0.6075426340103149\n",
            "costo: 0.5818848609924316\n",
            "costo: 0.5516478419303894\n",
            "costo: 0.5136433839797974\n",
            "costo: 0.49408480525016785\n",
            "costo: 0.4425530433654785\n",
            "costo: 0.4246313273906708\n",
            "costo: 0.4029569625854492\n",
            "costo: 0.39317330718040466\n",
            "costo: 0.37273409962654114\n",
            "costo: 0.3531727194786072\n",
            "costo: 0.36384403705596924\n",
            "costo: 0.3267037272453308\n",
            "costo: 0.32292330265045166\n",
            "costo: 0.3114168643951416\n",
            "costo: 0.2978227138519287\n",
            "costo: 0.2861573100090027\n",
            "costo: 0.2727425992488861\n",
            "costo: 0.2663074731826782\n",
            "costo: 0.2572193145751953\n",
            "costo: 0.24845387041568756\n",
            "costo: 0.23851321637630463\n",
            "costo: 0.2286328375339508\n",
            "costo: 0.22121886909008026\n",
            "costo: 0.21472565829753876\n",
            "costo: 0.20567548274993896\n",
            "costo: 0.19754767417907715\n",
            "costo: 0.18775023519992828\n",
            "costo: 0.1788334995508194\n",
            "costo: 0.17125718295574188\n",
            "costo: 0.16399094462394714\n",
            "costo: 0.1553257554769516\n",
            "costo: 0.14822383224964142\n",
            "costo: 0.14211876690387726\n",
            "costo: 0.13689060509204865\n",
            "costo: 0.13166102766990662\n",
            "costo: 0.12533536553382874\n",
            "costo: 0.11912236362695694\n",
            "costo: 0.11402387917041779\n",
            "costo: 0.10788167268037796\n",
            "costo: 0.10380451381206512\n",
            "costo: 0.09876666218042374\n",
            "costo: 0.09518185257911682\n",
            "costo: 0.09100505709648132\n",
            "costo: 0.0846199318766594\n",
            "costo: 0.0822286456823349\n",
            "costo: 0.07645875215530396\n",
            "costo: 0.07457741349935532\n",
            "costo: 0.07027826458215714\n",
            "costo: 0.06699429452419281\n",
            "costo: 0.06438839435577393\n",
            "costo: 0.06139783561229706\n",
            "costo: 0.05895443260669708\n",
            "costo: 0.057712119072675705\n",
            "costo: 0.05234858766198158\n",
            "costo: 0.05062910169363022\n",
            "costo: 0.04741310700774193\n",
            "costo: 0.04363534227013588\n",
            "costo: 0.04016914218664169\n",
            "costo: 0.03778143599629402\n",
            "costo: 0.03544047102332115\n",
            "costo: 0.03372044861316681\n",
            "costo: 0.03152523934841156\n",
            "costo: 0.029540199786424637\n",
            "costo: 0.026828879490494728\n",
            "costo: 0.024442315101623535\n",
            "costo: 0.02285493165254593\n",
            "costo: 0.020242858678102493\n",
            "costo: 0.018560146912932396\n",
            "costo: 0.016642045229673386\n",
            "costo: 0.014820845797657967\n",
            "costo: 0.012728380970656872\n",
            "costo: 0.011493772268295288\n",
            "costo: 0.010454372502863407\n",
            "costo: 0.009422743692994118\n",
            "costo: 0.008412675000727177\n",
            "costo: 0.0074917906895279884\n",
            "costo: 0.006776397116482258\n",
            "costo: 0.005921189673244953\n",
            "costo: 0.005179095547646284\n",
            "costo: 0.00463367672637105\n",
            "costo: 0.0035657810512930155\n",
            "costo: 0.0032675163820385933\n",
            "costo: 0.002737727714702487\n",
            "costo: 0.0021447332110255957\n",
            "costo: 0.002094368916004896\n",
            "costo: 0.0014436178607866168\n",
            "costo: 0.0013476237654685974\n",
            "costo: 0.0011324321385473013\n",
            "costo: 0.0009533437550999224\n",
            "costo: 0.0007637779926881194\n",
            "costo: 0.0006538968882523477\n",
            "costo: 0.0005492917844094336\n",
            "costo: 2.3052825927734375\n",
            "costo: 2.2994730472564697\n",
            "costo: 1.804072618484497\n",
            "costo: 0.9866547584533691\n",
            "costo: 1.733445644378662\n",
            "costo: 0.6922267079353333\n",
            "costo: 0.6367392539978027\n",
            "costo: 0.6151140332221985\n",
            "costo: 0.5686632990837097\n",
            "costo: 0.5574702024459839\n",
            "costo: 0.5336664915084839\n",
            "costo: 0.49744758009910583\n",
            "costo: 0.48809635639190674\n",
            "costo: 0.433883935213089\n",
            "costo: 0.4157774746417999\n",
            "costo: 0.3945416510105133\n",
            "costo: 0.37010496854782104\n",
            "costo: 0.34751519560813904\n",
            "costo: 0.33088359236717224\n",
            "costo: 0.32402125000953674\n",
            "costo: 0.3154222071170807\n",
            "costo: 0.30142316222190857\n",
            "costo: 0.28386175632476807\n",
            "costo: 0.2714882493019104\n",
            "costo: 0.2623128592967987\n",
            "costo: 0.25365135073661804\n",
            "costo: 0.24339325726032257\n",
            "costo: 0.23365886509418488\n",
            "costo: 0.2264777570962906\n",
            "costo: 0.2202421873807907\n",
            "costo: 0.21114274859428406\n",
            "costo: 0.19951757788658142\n",
            "costo: 0.18651580810546875\n",
            "costo: 0.18381863832473755\n",
            "costo: 0.17524543404579163\n",
            "costo: 0.17124547064304352\n",
            "costo: 0.1644950658082962\n",
            "costo: 0.15620291233062744\n",
            "costo: 0.18258710205554962\n",
            "costo: 0.1412425935268402\n",
            "costo: 0.13783887028694153\n",
            "costo: 0.13067707419395447\n",
            "costo: 0.12682439386844635\n",
            "costo: 0.12039364129304886\n",
            "costo: 0.11473201960325241\n",
            "costo: 0.11039625108242035\n",
            "costo: 0.10562373697757721\n",
            "costo: 0.09945204854011536\n",
            "costo: 0.09418362379074097\n",
            "costo: 0.08880963176488876\n",
            "costo: 0.08368146419525146\n",
            "costo: 0.07973066717386246\n",
            "costo: 0.07556119561195374\n",
            "costo: 0.07271770387887955\n",
            "costo: 0.0683869943022728\n",
            "costo: 0.06459441781044006\n",
            "costo: 0.06111724674701691\n",
            "costo: 0.0580989308655262\n",
            "costo: 0.05442943051457405\n",
            "costo: 0.05081416666507721\n",
            "costo: 0.04851572588086128\n",
            "costo: 0.04488656669855118\n",
            "costo: 0.044405438005924225\n",
            "costo: 0.04057495668530464\n",
            "costo: 0.038624778389930725\n",
            "costo: 0.035989612340927124\n",
            "costo: 0.03339791297912598\n",
            "costo: 0.032823819667100906\n",
            "costo: 0.02810276858508587\n",
            "costo: 0.026788881048560143\n",
            "costo: 0.02414165996015072\n",
            "costo: 0.022772427648305893\n",
            "costo: 0.0209666658192873\n",
            "costo: 0.019617542624473572\n",
            "costo: 0.018251148983836174\n",
            "costo: 0.016127150505781174\n",
            "costo: 0.01669842191040516\n",
            "costo: 0.013371394947171211\n",
            "costo: 0.012653978541493416\n",
            "costo: 0.011277026496827602\n",
            "costo: 0.010007547214627266\n",
            "costo: 0.009370459243655205\n",
            "costo: 0.007403557188808918\n",
            "costo: 0.006804426200687885\n",
            "costo: 0.0058870273642241955\n",
            "costo: 0.005237369332462549\n",
            "costo: 0.004577662330120802\n",
            "costo: 0.0038475922774523497\n",
            "costo: 0.0033390228636562824\n",
            "costo: 0.002584960078820586\n",
            "costo: 0.0029806699603796005\n",
            "costo: 0.001679207431152463\n",
            "costo: 0.0015527073992416263\n",
            "costo: 0.001248423708602786\n",
            "costo: 0.001051733153872192\n",
            "costo: 0.000826105650048703\n",
            "costo: 0.0007011870620772243\n",
            "costo: 0.0005498211830854416\n",
            "costo: 0.00046568873221985996\n",
            "costo: 0.00037976738531142473\n",
            "costo: 2.3040225505828857\n",
            "costo: 2.299055337905884\n",
            "costo: 1.796326756477356\n",
            "costo: 1.2080845832824707\n",
            "costo: 1.2561813592910767\n",
            "costo: 0.7038828134536743\n",
            "costo: 0.6419998407363892\n",
            "costo: 0.6062052249908447\n",
            "costo: 0.5814715027809143\n",
            "costo: 0.5516184568405151\n",
            "costo: 0.5177142024040222\n",
            "costo: 0.47087031602859497\n",
            "costo: 0.4377341866493225\n",
            "costo: 0.41535356640815735\n",
            "costo: 0.3920748829841614\n",
            "costo: 0.3675476908683777\n",
            "costo: 0.33862054347991943\n",
            "costo: 0.33057838678359985\n",
            "costo: 0.3235549032688141\n",
            "costo: 0.3191249370574951\n",
            "costo: 0.3049986660480499\n",
            "costo: 0.29061514139175415\n",
            "costo: 0.306527316570282\n",
            "costo: 0.2750442326068878\n",
            "costo: 0.271383136510849\n",
            "costo: 0.2622528374195099\n",
            "costo: 0.25492605566978455\n",
            "costo: 0.24612949788570404\n",
            "costo: 0.23166625201702118\n",
            "costo: 0.22767874598503113\n",
            "costo: 0.22200748324394226\n",
            "costo: 0.21505841612815857\n",
            "costo: 0.20449227094650269\n",
            "costo: 0.19688783586025238\n",
            "costo: 0.1909073293209076\n",
            "costo: 0.1873258799314499\n",
            "costo: 0.18361935019493103\n",
            "costo: 0.17510774731636047\n",
            "costo: 0.17629724740982056\n",
            "costo: 0.1644919514656067\n",
            "costo: 0.1612159013748169\n",
            "costo: 0.15502920746803284\n",
            "costo: 0.14750881493091583\n",
            "costo: 0.15035314857959747\n",
            "costo: 0.1363169103860855\n",
            "costo: 0.13330236077308655\n",
            "costo: 0.1285008043050766\n",
            "costo: 0.1237594336271286\n",
            "costo: 0.11964624375104904\n",
            "costo: 0.11580362170934677\n",
            "costo: 0.11138761043548584\n",
            "costo: 0.10516118258237839\n",
            "costo: 0.10008111596107483\n",
            "costo: 0.09637083113193512\n",
            "costo: 0.09223594516515732\n",
            "costo: 0.08901729434728622\n",
            "costo: 0.08553970605134964\n",
            "costo: 0.08012298494577408\n",
            "costo: 0.0778033584356308\n",
            "costo: 0.07488743960857391\n",
            "costo: 0.07419755309820175\n",
            "costo: 0.06915690004825592\n",
            "costo: 0.0672926977276802\n",
            "costo: 0.06458675116300583\n",
            "costo: 0.061717305332422256\n",
            "costo: 0.05644342675805092\n",
            "costo: 0.052732836455106735\n",
            "costo: 0.050344280898571014\n",
            "costo: 0.04863689839839935\n",
            "costo: 0.046189311891794205\n",
            "costo: 0.04661665856838226\n",
            "costo: 0.041119933128356934\n",
            "costo: 0.0395895391702652\n",
            "costo: 0.037239763885736465\n",
            "costo: 0.034684620797634125\n",
            "costo: 0.03464493900537491\n",
            "costo: 0.030920226126909256\n",
            "costo: 0.03024008311331272\n",
            "costo: 0.02765822224318981\n",
            "costo: 0.02683253213763237\n",
            "costo: 0.024381369352340698\n",
            "costo: 0.023134274408221245\n",
            "costo: 0.021200140938162804\n",
            "costo: 0.019407758489251137\n",
            "costo: 0.01759510301053524\n",
            "costo: 0.016503671184182167\n",
            "costo: 0.015123989433050156\n",
            "costo: 0.01397211104631424\n",
            "costo: 0.012683133594691753\n",
            "costo: 0.011688300408422947\n",
            "costo: 0.010768979787826538\n",
            "costo: 0.009339473210275173\n",
            "costo: 0.008022495545446873\n",
            "costo: 0.006918008904904127\n",
            "costo: 0.006320403888821602\n",
            "costo: 0.005540006328374147\n",
            "costo: 0.005139320157468319\n",
            "costo: 0.004210536368191242\n",
            "costo: 0.003738105995580554\n",
            "costo: 0.0031496468000113964\n",
            "costo: 2.3088977336883545\n",
            "costo: 2.3039002418518066\n",
            "costo: 1.8192857503890991\n",
            "costo: 1.0180554389953613\n",
            "costo: 2.2032604217529297\n",
            "costo: 0.759807825088501\n",
            "costo: 0.6633135080337524\n",
            "costo: 1.0830702781677246\n",
            "costo: 0.5952607989311218\n",
            "costo: 0.5737438797950745\n",
            "costo: 0.5440279245376587\n",
            "costo: 0.5262746810913086\n",
            "costo: 0.47927358746528625\n",
            "costo: 0.44353562593460083\n",
            "costo: 0.4223659634590149\n",
            "costo: 0.4079205393791199\n",
            "costo: 0.37713250517845154\n",
            "costo: 0.3601858615875244\n",
            "costo: 0.3447960913181305\n",
            "costo: 0.33245009183883667\n",
            "costo: 0.3119952976703644\n",
            "costo: 0.30100521445274353\n",
            "costo: 0.2901367247104645\n",
            "costo: 0.27847862243652344\n",
            "costo: 0.26634883880615234\n",
            "costo: 0.25657591223716736\n",
            "costo: 0.24884068965911865\n",
            "costo: 0.24306976795196533\n",
            "costo: 0.236227348446846\n",
            "costo: 0.2253965437412262\n",
            "costo: 0.21803927421569824\n",
            "costo: 0.2103998064994812\n",
            "costo: 0.20534546673297882\n",
            "costo: 0.20092779397964478\n",
            "costo: 0.19171173870563507\n",
            "costo: 0.19248732924461365\n",
            "costo: 0.17831164598464966\n",
            "costo: 0.17477862536907196\n",
            "costo: 0.17015720903873444\n",
            "costo: 0.16453978419303894\n",
            "costo: 0.16500572860240936\n",
            "costo: 0.1529560089111328\n",
            "costo: 0.14931321144104004\n",
            "costo: 0.143588587641716\n",
            "costo: 0.13754451274871826\n",
            "costo: 0.13140341639518738\n",
            "costo: 0.1242198571562767\n",
            "costo: 0.12084019184112549\n",
            "costo: 0.11713185906410217\n",
            "costo: 0.11320798844099045\n",
            "costo: 0.10769186168909073\n",
            "costo: 0.10167708992958069\n",
            "costo: 0.09860528260469437\n",
            "costo: 0.0967574194073677\n",
            "costo: 0.09138482064008713\n",
            "costo: 0.08864110708236694\n",
            "costo: 0.08554375916719437\n",
            "costo: 0.08188174664974213\n",
            "costo: 0.07899805903434753\n",
            "costo: 0.07456157356500626\n",
            "costo: 0.07196827977895737\n",
            "costo: 0.06869719177484512\n",
            "costo: 0.0644267350435257\n",
            "costo: 0.0603252574801445\n",
            "costo: 0.05788535252213478\n",
            "costo: 0.0558340959250927\n",
            "costo: 0.053520042449235916\n",
            "costo: 0.049333587288856506\n",
            "costo: 0.04855053871870041\n",
            "costo: 0.04586983844637871\n",
            "costo: 0.04495714232325554\n",
            "costo: 0.04273805767297745\n",
            "costo: 0.039851199835538864\n",
            "costo: 0.03616992011666298\n",
            "costo: 0.03407119959592819\n",
            "costo: 0.03209596872329712\n",
            "costo: 0.03123653307557106\n",
            "costo: 0.029441088438034058\n",
            "costo: 0.026623904705047607\n",
            "costo: 0.02419017069041729\n",
            "costo: 0.022671394050121307\n",
            "costo: 0.021164873614907265\n",
            "costo: 0.020031766965985298\n",
            "costo: 0.018321197479963303\n",
            "costo: 0.016219280660152435\n",
            "costo: 0.01529750321060419\n",
            "costo: 0.013701270334422588\n",
            "costo: 0.01337133627384901\n",
            "costo: 0.01130317710340023\n",
            "costo: 0.010470154695212841\n",
            "costo: 0.009469131007790565\n",
            "costo: 0.008511706255376339\n",
            "costo: 0.007521685212850571\n",
            "costo: 0.006712340284138918\n",
            "costo: 0.00591198680922389\n",
            "costo: 0.005079703871160746\n",
            "costo: 0.004178427625447512\n",
            "costo: 0.003509094938635826\n",
            "costo: 0.0029624481685459614\n",
            "costo: 0.002590006683021784\n"
          ]
        }
      ],
      "source": [
        "resultados['lbfgs'] = {}\n",
        "resultados['lbfgs']['val_acc_list'] = [0] * epochs\n",
        "resultados['lbfgs']['test_acc'] = 0\n",
        "resultados['lbfgs']['cost'] = [0] * epochs\n",
        "resultados['lbfgs']['time'] = 0\n",
        "resultados['lbfgs']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    lbfgs_acc_list, lbfgs_cost_list, lbfgs_lr_list, lbfgs_time, lbfgs_acc, lbfgs_epochs, iteraciones_lbfgs = LBFGS()\n",
        "    resultados['lbfgs']['val_acc_list'] = SumList(resultados['lbfgs']['val_acc_list'], lbfgs_acc_list)\n",
        "    resultados['lbfgs']['test_acc'] += lbfgs_acc\n",
        "    resultados['lbfgs']['cost'] = SumList(resultados['lbfgs']['cost'], lbfgs_cost_list)\n",
        "    resultados['lbfgs']['time'] += lbfgs_time\n",
        "    resultados['lbfgs']['epochs'] += lbfgs_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['lbfgs']['name'] = 'LBFGS'\n",
        "resultados['lbfgs']['lr'] = lbfgs_lr_list\n",
        "resultados['lbfgs']['test_acc'] = resultados['lbfgs']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['lbfgs']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['lbfgs']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['lbfgs']['cost'] = DeleteZerosFromList(DivideList(resultados['lbfgs']['cost'], MAX_ITERATIONS))\n",
        "resultados['lbfgs']['time'] = resultados['lbfgs']['time'] / MAX_ITERATIONS\n",
        "resultados['lbfgs']['epochs'] = resultados['lbfgs']['epochs'] / MAX_ITERATIONS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jQLmr_cd9D8"
      },
      "source": [
        "## L-BFGS con búsqueda lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooM11ZyXh0-k"
      },
      "source": [
        "Posee la misma implementación del método L-BFGS con la diferencia de que se agregan *las condiciones fuertes de Wolfe*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MiXaFYWVfGaZ"
      },
      "outputs": [],
      "source": [
        "def LBFGS_LS():\n",
        "    modelLBFGS_LS = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "\n",
        "    optimizer = torch.optim.LBFGS(modelLBFGS_LS.parameters(),\n",
        "                                lr=1,\n",
        "                                history_size=10, #update history size. What's this?\n",
        "                                #max_eval (int) – maximal number of function evaluations per optimization step (default: max_iter * 1.25)\n",
        "                                #max_iter=1,\n",
        "                                line_search_fn=\"strong_wolfe\"\n",
        "                                )\n",
        "\n",
        "    lbfgs_ls_cost_list = [0.0]\n",
        "    lbfgs_ls_acc_list = [0.0]\n",
        "    modelLBFGS_LS = modelLBFGS_LS.to(device=device)\n",
        "    x_train_tensor_ = x_train_tensor.to(device=device, dtype=torch.float32)\n",
        "    y_train_tensor_ = y_train_tensor.to(device=device, dtype=torch.long)\n",
        "    i = 0\n",
        "    iter_found = 0\n",
        "    unregistered = True\n",
        "    iteraciones_lbfgs_ls = []\n",
        "    start.record()\n",
        "    #training\n",
        "    while (i < 100):\n",
        "        if(lbfgs_ls_acc_list[-1] >= 0.95 and unregistered):\n",
        "            iter_found = i\n",
        "            unregistered = False\n",
        "        print('Iteracion: '+ str(i))\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            scores = modelLBFGS_LS(x_train_tensor_)\n",
        "            cost = F.cross_entropy(input= scores, target=y_train_tensor_.squeeze())\n",
        "            cost.backward()\n",
        "            print(f'costo: {cost.item()}')  \n",
        "            iteraciones_lbfgs_ls.append('0')\n",
        "            return cost\n",
        "        lbfgs_ls_cost_list.append(optimizer.step(closure).item())\n",
        "        lbfgs_ls_acc_list.append(accuracy(modelLBFGS_LS, x_val_tensor, y_val_tensor, mb_size))\n",
        "        i+=1\n",
        "            \n",
        "    #print(f'accuracy: {lbfgs_ls_acc_list[-1]}')\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    lbfgs_ls_time = start.elapsed_time(end)\n",
        "\n",
        "    lbfgs_ls_acc = accuracy(modelLBFGS_LS, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return lbfgs_ls_acc_list, lbfgs_ls_cost_list, [0] ,lbfgs_ls_time, lbfgs_ls_acc, iter_found, iteraciones_lbfgs_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oofvD4gNeC4t",
        "outputId": "c515716a-81d4-4006-8d61-dfa22c1d21ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteracion: 0\n",
            "costo: 2.3188297748565674\n",
            "costo: 2.3187716007232666\n",
            "costo: 2.3177928924560547\n",
            "costo: 2.3191497325897217\n",
            "costo: 2.3182544708251953\n",
            "costo: 1.7816613912582397\n",
            "costo: 1.0074045658111572\n",
            "costo: 1.1038328409194946\n",
            "costo: 0.7845368981361389\n",
            "costo: 0.6998282670974731\n",
            "costo: 0.6483263969421387\n",
            "costo: 0.6234530210494995\n",
            "costo: 0.5956738591194153\n",
            "costo: 0.5500451922416687\n",
            "costo: 0.5131680965423584\n",
            "costo: 0.45112696290016174\n",
            "costo: 0.447538286447525\n",
            "costo: 0.41234707832336426\n",
            "costo: 0.3944701850414276\n",
            "costo: 0.36982792615890503\n",
            "costo: 0.34030118584632874\n",
            "costo: 0.3550247251987457\n",
            "costo: 0.32776641845703125\n",
            "costo: 0.3117769658565521\n",
            "costo: 0.2962077856063843\n",
            "Iteracion: 1\n",
            "costo: 0.27176570892333984\n",
            "costo: 0.2575420141220093\n",
            "costo: 0.234414204955101\n",
            "costo: 0.23100610077381134\n",
            "costo: 0.21703429520130157\n",
            "costo: 0.20869259536266327\n",
            "costo: 0.19614526629447937\n",
            "costo: 0.18451407551765442\n",
            "costo: 0.17145144939422607\n",
            "costo: 0.1624191403388977\n",
            "costo: 0.14758145809173584\n",
            "costo: 0.14316318929195404\n",
            "costo: 0.1341094970703125\n",
            "costo: 0.12840981781482697\n",
            "costo: 0.12090439349412918\n",
            "costo: 0.11134371906518936\n",
            "costo: 0.10688144713640213\n",
            "costo: 0.0975957065820694\n",
            "costo: 0.09399545937776566\n",
            "costo: 0.08669019490480423\n",
            "costo: 0.0780494287610054\n",
            "Iteracion: 2\n",
            "costo: 0.0780494287610054\n",
            "costo: 0.08397410809993744\n",
            "costo: 0.07364233583211899\n",
            "costo: 0.06844508647918701\n",
            "costo: 0.06518431007862091\n",
            "costo: 0.06074261665344238\n",
            "costo: 0.05874364823102951\n",
            "costo: 0.05248544365167618\n",
            "costo: 0.050626277923583984\n",
            "costo: 0.04706379771232605\n",
            "costo: 0.04257705435156822\n",
            "costo: 0.040282707661390305\n",
            "costo: 0.03608419746160507\n",
            "costo: 0.03464836999773979\n",
            "costo: 0.03124907985329628\n",
            "costo: 0.028740787878632545\n",
            "costo: 0.025289950892329216\n",
            "costo: 0.023317541927099228\n",
            "costo: 0.02135474421083927\n",
            "costo: 0.019472535699605942\n",
            "costo: 0.01753467135131359\n",
            "costo: 0.015400220640003681\n",
            "Iteracion: 3\n",
            "costo: 0.015400220640003681\n",
            "costo: 0.013582090847194195\n",
            "costo: 0.012711739167571068\n",
            "costo: 0.010275597684085369\n",
            "costo: 0.009595569223165512\n",
            "costo: 0.008059583604335785\n",
            "costo: 0.007188923191279173\n",
            "costo: 0.00592502998188138\n",
            "costo: 0.004812943749129772\n",
            "costo: 0.0038315150886774063\n",
            "costo: 0.0032663072925060987\n",
            "costo: 0.0028774007223546505\n",
            "costo: 0.002238574903458357\n",
            "costo: 0.002090989612042904\n",
            "costo: 0.0015141252661123872\n",
            "costo: 0.0013076507020741701\n",
            "costo: 0.0010705619351938367\n",
            "costo: 0.0008271131664514542\n",
            "costo: 0.0005533851799555123\n",
            "costo: 0.00041089500882662833\n",
            "costo: 0.00030444233561865985\n",
            "Iteracion: 4\n",
            "costo: 0.00030444233561865985\n",
            "costo: 0.00027475503156892955\n",
            "costo: 0.00022296150564216077\n",
            "costo: 0.00016310918726958334\n",
            "costo: 0.00021936846314929426\n",
            "costo: 0.00013754187966696918\n",
            "costo: 8.791550499154255e-05\n",
            "costo: 6.614231824642047e-05\n",
            "costo: 4.5322085497900844e-05\n",
            "costo: 2.9996606826898642e-05\n",
            "costo: 2.3491909814765677e-05\n",
            "costo: 1.61318985192338e-05\n",
            "costo: 1.0863775059988257e-05\n",
            "costo: 6.388836482074112e-06\n",
            "costo: 4.48239507022663e-06\n",
            "costo: 2.711510433073272e-06\n",
            "costo: 1.812102254916681e-06\n",
            "costo: 1.165637740996317e-06\n",
            "costo: 7.841537126296316e-07\n",
            "costo: 4.838285576624912e-07\n",
            "costo: 2.8883462732665066e-07\n",
            "costo: 2.0290299573844095e-07\n",
            "Iteracion: 5\n",
            "costo: 2.0290299573844095e-07\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 6\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 7\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 8\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 9\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 10\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 11\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 12\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 13\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 14\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 15\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 16\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 17\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 18\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 19\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 20\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 21\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 22\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 23\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 24\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 25\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 26\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 27\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 28\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 29\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 30\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 31\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 32\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 33\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 34\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 35\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 36\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 37\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 38\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 39\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 40\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 41\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 42\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 43\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 44\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 45\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 46\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 47\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 48\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 49\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 50\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 51\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 52\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 53\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 54\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 55\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 56\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 57\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 58\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 59\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 60\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 61\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 62\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 63\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 64\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 65\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 66\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 67\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 68\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 69\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 70\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 71\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 72\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 73\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 74\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 75\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 76\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 77\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 78\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 79\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 80\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 81\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 82\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 83\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 84\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 85\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 86\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 87\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 88\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 89\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 90\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 91\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 92\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 93\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 94\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 95\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 96\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 97\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 98\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 99\n",
            "costo: 1.2481231692618167e-07\n",
            "Iteracion: 0\n",
            "costo: 2.315002202987671\n",
            "costo: 2.3135955333709717\n",
            "costo: 2.313704013824463\n",
            "costo: 2.313499927520752\n",
            "costo: 2.312941789627075\n",
            "costo: 2.3130075931549072\n",
            "costo: 1.8043099641799927\n",
            "costo: 1.1998296976089478\n",
            "costo: 0.9556931853294373\n",
            "costo: 0.7835710048675537\n",
            "costo: 0.6668606996536255\n",
            "costo: 0.609479546546936\n",
            "costo: 0.5863246321678162\n",
            "costo: 0.5503146648406982\n",
            "costo: 0.49630239605903625\n",
            "costo: 0.44841495156288147\n",
            "costo: 0.41609498858451843\n",
            "costo: 0.39040011167526245\n",
            "costo: 0.3587309718132019\n",
            "costo: 0.32448795437812805\n",
            "costo: 0.3058164119720459\n",
            "costo: 0.2868042588233948\n",
            "costo: 0.2649928331375122\n",
            "costo: 0.24439287185668945\n",
            "costo: 0.22994893789291382\n",
            "Iteracion: 1\n",
            "costo: 0.20759466290473938\n",
            "costo: 0.19492247700691223\n",
            "costo: 0.18242964148521423\n",
            "costo: 0.17048394680023193\n",
            "costo: 0.15940870344638824\n",
            "costo: 0.1462767869234085\n",
            "costo: 0.13638430833816528\n",
            "costo: 0.12732088565826416\n",
            "costo: 0.12065140902996063\n",
            "costo: 0.11298590898513794\n",
            "costo: 0.10441496223211288\n",
            "costo: 0.09610463678836823\n",
            "costo: 0.08748606592416763\n",
            "costo: 0.08068584650754929\n",
            "costo: 0.07372750341892242\n",
            "costo: 0.06872253119945526\n",
            "costo: 0.06357690691947937\n",
            "costo: 0.057724110782146454\n",
            "costo: 0.05303986743092537\n",
            "costo: 0.04950664937496185\n",
            "costo: 0.04684198647737503\n",
            "Iteracion: 2\n",
            "costo: 0.04684198647737503\n",
            "costo: 0.04258114844560623\n",
            "costo: 0.038925573229789734\n",
            "costo: 0.03608548268675804\n",
            "costo: 0.032589737325906754\n",
            "costo: 0.029658112674951553\n",
            "costo: 0.02612181194126606\n",
            "costo: 0.02218078076839447\n",
            "costo: 0.02050669677555561\n",
            "costo: 0.018398141488432884\n",
            "costo: 0.015711838379502296\n",
            "costo: 0.014226384460926056\n",
            "costo: 0.011079863645136356\n",
            "costo: 0.01022268459200859\n",
            "costo: 0.008854296058416367\n",
            "costo: 0.007621274795383215\n",
            "costo: 0.006598721258342266\n",
            "costo: 0.005268894601613283\n",
            "costo: 0.004234275780618191\n",
            "costo: 0.0035514351911842823\n",
            "costo: 0.002851100405678153\n",
            "Iteracion: 3\n",
            "costo: 0.002851100405678153\n",
            "costo: 0.0024790968745946884\n",
            "costo: 0.002018459839746356\n",
            "costo: 0.0015083315083757043\n",
            "costo: 0.0010892634745687246\n",
            "costo: 0.0008704891079105437\n",
            "costo: 0.0007082037627696991\n",
            "costo: 0.0005571999354287982\n",
            "costo: 0.0004493157612159848\n",
            "costo: 0.0003406437754165381\n",
            "costo: 0.0002840864472091198\n",
            "costo: 0.00020677459542639554\n",
            "costo: 0.00017547086463309824\n",
            "costo: 0.0001246416795765981\n",
            "costo: 0.00010489320993656293\n",
            "costo: 8.084259752649814e-05\n",
            "costo: 5.978746776236221e-05\n",
            "costo: 4.395265204948373e-05\n",
            "costo: 2.851566569006536e-05\n",
            "costo: 2.3342996428254992e-05\n",
            "costo: 1.5533227269770578e-05\n",
            "Iteracion: 4\n",
            "costo: 1.5533227269770578e-05\n",
            "costo: 9.822747415455524e-06\n",
            "costo: 7.4600916377676185e-06\n",
            "costo: 4.790544608113123e-06\n",
            "costo: 3.1665047117712675e-06\n",
            "costo: 1.8572170574771008e-06\n",
            "costo: 1.3583602367361891e-06\n",
            "costo: 8.839375027491769e-07\n",
            "costo: 5.699109806300839e-07\n",
            "costo: 3.5807207154903153e-07\n",
            "costo: 2.4684158006493817e-07\n",
            "costo: 1.4957127802972536e-07\n",
            "costo: 7.856763062363825e-08\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 5\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 6\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 7\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 8\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 9\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 10\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 11\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 12\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 13\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 14\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 15\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 16\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 17\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 18\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 19\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 20\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 21\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 22\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 23\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 24\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 25\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 26\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 27\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 28\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 29\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 30\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 31\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 32\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 33\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 34\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 35\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 36\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 37\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 38\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 39\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 40\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 41\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 42\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 43\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 44\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 45\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 46\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 47\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 48\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 49\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 50\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 51\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 52\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 53\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 54\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 55\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 56\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 57\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 58\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 59\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 60\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 61\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 62\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 63\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 64\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 65\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 66\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 67\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 68\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 69\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 70\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 71\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 72\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 73\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 74\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 75\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 76\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 77\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 78\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 79\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 80\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 81\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 82\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 83\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 84\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 85\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 86\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 87\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 88\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 89\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 90\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 91\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 92\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 93\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 94\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 95\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 96\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 97\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 98\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 99\n",
            "costo: 5.4876441168971724e-08\n",
            "Iteracion: 0\n",
            "costo: 2.3093645572662354\n",
            "costo: 2.307591676712036\n",
            "costo: 2.3070380687713623\n",
            "costo: 2.307375907897949\n",
            "costo: 2.3079099655151367\n",
            "costo: 2.306812047958374\n",
            "costo: 2.3073015213012695\n",
            "costo: 1.8414946794509888\n",
            "costo: 1.0106362104415894\n",
            "costo: 3.005016326904297\n",
            "costo: 0.7839950919151306\n",
            "costo: 0.6836279630661011\n",
            "costo: 0.6504117250442505\n",
            "costo: 0.6127252578735352\n",
            "costo: 0.5986137390136719\n",
            "costo: 0.5487012267112732\n",
            "costo: 0.49571117758750916\n",
            "costo: 0.525963306427002\n",
            "costo: 0.4713138937950134\n",
            "costo: 0.43531081080436707\n",
            "costo: 0.42005375027656555\n",
            "costo: 0.3984741270542145\n",
            "costo: 0.3680850863456726\n",
            "costo: 0.3491220772266388\n",
            "costo: 0.3368092179298401\n",
            "Iteracion: 1\n",
            "costo: 0.3072427809238434\n",
            "costo: 0.29185256361961365\n",
            "costo: 0.272728830575943\n",
            "costo: 0.2514963150024414\n",
            "costo: 0.23937612771987915\n",
            "costo: 0.2277321219444275\n",
            "costo: 0.21670132875442505\n",
            "costo: 0.20380833745002747\n",
            "costo: 0.19224154949188232\n",
            "costo: 0.17851568758487701\n",
            "costo: 0.16980333626270294\n",
            "costo: 0.16196154057979584\n",
            "costo: 0.15327639877796173\n",
            "costo: 0.1406441479921341\n",
            "costo: 0.13270515203475952\n",
            "costo: 0.1260668933391571\n",
            "costo: 0.11693455278873444\n",
            "costo: 0.11968337744474411\n",
            "costo: 0.11080696433782578\n",
            "costo: 0.1042896956205368\n",
            "costo: 0.09953995048999786\n",
            "costo: 0.09189137816429138\n",
            "Iteracion: 2\n",
            "costo: 0.09189137816429138\n",
            "costo: 0.08666878193616867\n",
            "costo: 0.07996010035276413\n",
            "costo: 0.07599447667598724\n",
            "costo: 0.0719563215970993\n",
            "costo: 0.06488150358200073\n",
            "costo: 0.060866497457027435\n",
            "costo: 0.056272752583026886\n",
            "costo: 0.054161664098501205\n",
            "costo: 0.050268832594156265\n",
            "costo: 0.04592978581786156\n",
            "costo: 0.04135219380259514\n",
            "costo: 0.03867137432098389\n",
            "costo: 0.035153500735759735\n",
            "costo: 0.03317392244935036\n",
            "costo: 0.030836623162031174\n",
            "costo: 0.028508475050330162\n",
            "costo: 0.026679279282689095\n",
            "costo: 0.023377351462841034\n",
            "costo: 0.020982781425118446\n",
            "costo: 0.018970400094985962\n",
            "Iteracion: 3\n",
            "costo: 0.018970400094985962\n",
            "costo: 0.01781751960515976\n",
            "costo: 0.016069356352090836\n",
            "costo: 0.015133730135858059\n",
            "costo: 0.013215817511081696\n",
            "costo: 0.01219952292740345\n",
            "costo: 0.01081277709454298\n",
            "costo: 0.008648406714200974\n",
            "costo: 0.008935865014791489\n",
            "costo: 0.007402149494737387\n",
            "costo: 0.005684417672455311\n",
            "costo: 0.0048402403481304646\n",
            "costo: 0.00401072995737195\n",
            "costo: 0.0032415087334811687\n",
            "costo: 0.0026972091291099787\n",
            "costo: 0.0021681219805032015\n",
            "costo: 0.0018005141755566\n",
            "costo: 0.0014776819152757525\n",
            "costo: 0.0011729118414223194\n",
            "costo: 0.0008904945570975542\n",
            "costo: 0.0006669265567325056\n",
            "costo: 0.000525506678968668\n",
            "Iteracion: 4\n",
            "costo: 0.000525506678968668\n",
            "costo: 0.00041631844942457974\n",
            "costo: 0.00033445641747675836\n",
            "costo: 0.00026708151563070714\n",
            "costo: 0.00020362708892207593\n",
            "costo: 0.00013426899386104196\n",
            "costo: 0.00010975754412356764\n",
            "costo: 8.491407061228529e-05\n",
            "costo: 6.309910531854257e-05\n",
            "costo: 5.410310404840857e-05\n",
            "costo: 3.637529880506918e-05\n",
            "costo: 2.518250039429404e-05\n",
            "costo: 1.692739715508651e-05\n",
            "costo: 1.3033728464506567e-05\n",
            "costo: 9.207320545101538e-06\n",
            "costo: 6.470541393355234e-06\n",
            "costo: 4.512312898441451e-06\n",
            "costo: 3.568564125089324e-06\n",
            "costo: 2.3152642825152725e-06\n",
            "costo: 1.4632585134677356e-06\n",
            "costo: 1.0354970072512515e-06\n",
            "Iteracion: 5\n",
            "costo: 1.0354970072512515e-06\n",
            "costo: 7.607727638969664e-07\n",
            "costo: 5.214892553340178e-07\n",
            "costo: 4.5078888888383517e-07\n",
            "costo: 2.551833802044712e-07\n",
            "costo: 2.1043186393399083e-07\n",
            "costo: 1.196557093408046e-07\n",
            "costo: 8.266853512850503e-08\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 6\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 7\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 8\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 9\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 10\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 11\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 12\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 13\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 14\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 15\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 16\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 17\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 18\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 19\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 20\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 21\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 22\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 23\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 24\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 25\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 26\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 27\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 28\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 29\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 30\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 31\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 32\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 33\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 34\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 35\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 36\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 37\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 38\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 39\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 40\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 41\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 42\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 43\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 44\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 45\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 46\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 47\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 48\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 49\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 50\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 51\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 52\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 53\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 54\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 55\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 56\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 57\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 58\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 59\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 60\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 61\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 62\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 63\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 64\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 65\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 66\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 67\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 68\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 69\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 70\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 71\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 72\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 73\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 74\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 75\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 76\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 77\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 78\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 79\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 80\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 81\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 82\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 83\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 84\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 85\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 86\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 87\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 88\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 89\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 90\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 91\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 92\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 93\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 94\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 95\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 96\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 97\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 98\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 99\n",
            "costo: 4.615993276502195e-08\n",
            "Iteracion: 0\n",
            "costo: 2.3059492111206055\n",
            "costo: 2.3039093017578125\n",
            "costo: 2.3039543628692627\n",
            "costo: 2.3040425777435303\n",
            "costo: 2.3037099838256836\n",
            "costo: 2.304093837738037\n",
            "costo: 2.304119110107422\n",
            "costo: 1.7863421440124512\n",
            "costo: 1.2478835582733154\n",
            "costo: 0.9738516211509705\n",
            "costo: 0.7766722440719604\n",
            "costo: 0.6790000796318054\n",
            "costo: 0.6492881178855896\n",
            "costo: 0.6119835376739502\n",
            "costo: 0.5757936239242554\n",
            "costo: 0.5033050775527954\n",
            "costo: 0.4886416494846344\n",
            "costo: 0.4524587094783783\n",
            "costo: 0.4253833293914795\n",
            "costo: 0.4041828215122223\n",
            "costo: 0.3736986815929413\n",
            "costo: 0.3393799662590027\n",
            "costo: 0.32657313346862793\n",
            "costo: 0.30764588713645935\n",
            "costo: 0.28461843729019165\n",
            "Iteracion: 1\n",
            "costo: 0.26062604784965515\n",
            "costo: 0.23994649946689606\n",
            "costo: 0.22851808369159698\n",
            "costo: 0.21578440070152283\n",
            "costo: 0.2004069685935974\n",
            "costo: 0.1934146285057068\n",
            "costo: 0.17788439989089966\n",
            "costo: 0.1721576303243637\n",
            "costo: 0.16168543696403503\n",
            "costo: 0.14955365657806396\n",
            "costo: 0.1373027116060257\n",
            "costo: 0.13037998974323273\n",
            "costo: 0.11989718675613403\n",
            "costo: 0.11074916273355484\n",
            "costo: 0.10084718465805054\n",
            "costo: 0.09167078882455826\n",
            "costo: 0.0847393348813057\n",
            "costo: 0.08149928599596024\n",
            "costo: 0.07274244725704193\n",
            "costo: 0.07646957784891129\n",
            "costo: 0.06937975436449051\n",
            "costo: 0.06632986664772034\n",
            "Iteracion: 2\n",
            "costo: 0.06632986664772034\n",
            "costo: 0.05992971733212471\n",
            "costo: 0.05638798326253891\n",
            "costo: 0.052400633692741394\n",
            "costo: 0.04884939268231392\n",
            "costo: 0.04493319243192673\n",
            "costo: 0.0416225865483284\n",
            "costo: 0.03705841675400734\n",
            "costo: 0.03439437597990036\n",
            "costo: 0.030853571370244026\n",
            "costo: 0.02666632831096649\n",
            "costo: 0.027342408895492554\n",
            "costo: 0.02426062524318695\n",
            "costo: 0.02209695614874363\n",
            "costo: 0.020337644964456558\n",
            "costo: 0.017898961901664734\n",
            "costo: 0.01531885750591755\n",
            "costo: 0.013567958027124405\n",
            "costo: 0.011969126760959625\n",
            "costo: 0.010586735792458057\n",
            "costo: 0.009143293835222721\n",
            "costo: 0.006712714675813913\n",
            "Iteracion: 3\n",
            "costo: 0.006712714675813913\n",
            "costo: 0.00629771314561367\n",
            "costo: 0.004521785769611597\n",
            "costo: 0.004102033097296953\n",
            "costo: 0.003291092813014984\n",
            "costo: 0.00361178582534194\n",
            "costo: 0.002935389056801796\n",
            "costo: 0.002485916716977954\n",
            "costo: 0.0020081843249499798\n",
            "costo: 0.0016148893628269434\n",
            "costo: 0.0012565385550260544\n",
            "costo: 0.0010159441735595465\n",
            "costo: 0.0007583586848340929\n",
            "costo: 0.0005675103166140616\n",
            "costo: 0.00045426952419802547\n",
            "costo: 0.0003278695803601295\n",
            "costo: 0.0002427422587061301\n",
            "costo: 0.00016709469491615891\n",
            "costo: 0.00013344179023988545\n",
            "costo: 0.00010134937474504113\n",
            "costo: 7.724971510469913e-05\n",
            "costo: 5.681014226865955e-05\n",
            "Iteracion: 4\n",
            "costo: 5.681014226865955e-05\n",
            "costo: 4.454865847947076e-05\n",
            "costo: 3.5064032999798656e-05\n",
            "costo: 2.5502931748633273e-05\n",
            "costo: 1.8196651581092738e-05\n",
            "costo: 1.1454348168626893e-05\n",
            "costo: 9.099867384065874e-06\n",
            "costo: 5.752427568950225e-06\n",
            "costo: 4.689799425250385e-06\n",
            "costo: 2.500130221960717e-06\n",
            "costo: 2.0157740436843596e-06\n",
            "costo: 1.1849175507450127e-06\n",
            "costo: 8.299793989863247e-07\n",
            "costo: 5.055805445408623e-07\n",
            "costo: 3.8125946844047576e-07\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 5\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 6\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 7\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 8\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 9\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 10\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 11\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 12\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 13\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 14\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 15\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 16\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 17\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 18\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 19\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 20\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 21\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 22\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 23\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 24\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 25\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 26\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 27\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 28\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 29\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 30\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 31\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 32\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 33\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 34\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 35\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 36\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 37\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 38\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 39\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 40\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 41\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 42\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 43\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 44\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 45\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 46\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 47\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 48\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 49\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 50\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 51\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 52\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 53\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 54\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 55\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 56\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 57\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 58\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 59\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 60\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 61\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 62\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 63\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 64\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 65\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 66\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 67\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 68\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 69\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 70\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 71\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 72\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 73\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 74\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 75\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 76\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 77\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 78\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 79\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 80\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 81\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 82\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 83\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 84\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 85\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 86\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 87\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 88\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 89\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 90\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 91\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 92\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 93\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 94\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 95\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 96\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 97\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 98\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 99\n",
            "costo: 2.4181971980397066e-07\n",
            "Iteracion: 0\n",
            "costo: 2.2989399433135986\n",
            "costo: 2.298570156097412\n",
            "costo: 2.2931253910064697\n",
            "costo: 2.2916054725646973\n",
            "costo: 2.2555654048919678\n",
            "costo: 2.1235439777374268\n",
            "costo: 1.639919638633728\n",
            "costo: 1.103911280632019\n",
            "costo: 0.9332509636878967\n",
            "costo: 0.7787319421768188\n",
            "costo: 0.6968963146209717\n",
            "costo: 0.6227467060089111\n",
            "costo: 0.5934508442878723\n",
            "costo: 0.5715453624725342\n",
            "costo: 0.5310789942741394\n",
            "costo: 0.47250378131866455\n",
            "costo: 0.428676962852478\n",
            "costo: 0.4074011445045471\n",
            "costo: 0.3890688419342041\n",
            "costo: 0.3676125705242157\n",
            "costo: 0.34024909138679504\n",
            "costo: 0.31096816062927246\n",
            "costo: 0.2945786714553833\n",
            "costo: 0.28414660692214966\n",
            "costo: 0.2583938241004944\n",
            "Iteracion: 1\n",
            "costo: 0.23412415385246277\n",
            "costo: 0.2224150449037552\n",
            "costo: 0.20891235768795013\n",
            "costo: 0.1936766654253006\n",
            "costo: 0.18443064391613007\n",
            "costo: 0.17691570520401\n",
            "costo: 0.16736523807048798\n",
            "costo: 0.15757516026496887\n",
            "costo: 0.14268141984939575\n",
            "costo: 0.13190443813800812\n",
            "costo: 0.1265408843755722\n",
            "costo: 0.11636780947446823\n",
            "costo: 0.11085976660251617\n",
            "costo: 0.10268940776586533\n",
            "costo: 0.09623546898365021\n",
            "costo: 0.09080852568149567\n",
            "costo: 0.08525249361991882\n",
            "costo: 0.07816042751073837\n",
            "costo: 0.07393166422843933\n",
            "costo: 0.06695551425218582\n",
            "costo: 0.06683383882045746\n",
            "costo: 0.06309305131435394\n",
            "Iteracion: 2\n",
            "costo: 0.06309305131435394\n",
            "costo: 0.0587751604616642\n",
            "costo: 0.05428627133369446\n",
            "costo: 0.04974851384758949\n",
            "costo: 0.0450294129550457\n",
            "costo: 0.04104156419634819\n",
            "costo: 0.03773725777864456\n",
            "costo: 0.034058522433042526\n",
            "costo: 0.03249036893248558\n",
            "costo: 0.02852228283882141\n",
            "costo: 0.026784731075167656\n",
            "costo: 0.02437702566385269\n",
            "costo: 0.021670812740921974\n",
            "costo: 0.01856253296136856\n",
            "costo: 0.016378240659832954\n",
            "costo: 0.014082392677664757\n",
            "costo: 0.01219604816287756\n",
            "costo: 0.01073343027383089\n",
            "costo: 0.008981053717434406\n",
            "costo: 0.0075110034085810184\n",
            "costo: 0.006014486774802208\n",
            "Iteracion: 3\n",
            "costo: 0.006014486774802208\n",
            "costo: 0.004802306182682514\n",
            "costo: 0.004067820962518454\n",
            "costo: 0.0032930986490100622\n",
            "costo: 0.002751481020823121\n",
            "costo: 0.0022912921849638224\n",
            "costo: 0.0018077896675094962\n",
            "costo: 0.001491270144470036\n",
            "costo: 0.0011155176907777786\n",
            "costo: 0.0008304333314299583\n",
            "costo: 0.0006945152417756617\n",
            "costo: 0.000605402106884867\n",
            "costo: 0.00048021896509453654\n",
            "costo: 0.0003717492800205946\n",
            "costo: 0.00027393936761654913\n",
            "costo: 0.00022792215168010443\n",
            "costo: 0.00017256672435905784\n",
            "costo: 0.00012299811351113021\n",
            "costo: 9.957630390999839e-05\n",
            "costo: 8.045042341109365e-05\n",
            "costo: 6.481393211288378e-05\n",
            "Iteracion: 4\n",
            "costo: 6.481393211288378e-05\n",
            "costo: 4.6334724174812436e-05\n",
            "costo: 3.075352287851274e-05\n",
            "costo: 2.4409104298683815e-05\n",
            "costo: 1.8786169675877318e-05\n",
            "costo: 1.0557054338278249e-05\n",
            "costo: 9.733653314469848e-06\n",
            "costo: 7.363913027802482e-06\n",
            "costo: 5.393516403273679e-06\n",
            "costo: 3.7283300571289146e-06\n",
            "costo: 2.3000206965662073e-06\n",
            "costo: 1.8244199964101426e-06\n",
            "costo: 9.787544286155025e-07\n",
            "costo: 7.581225531794189e-07\n",
            "costo: 5.026486746828596e-07\n",
            "costo: 3.8771483445998456e-07\n",
            "costo: 2.62122455296776e-07\n",
            "costo: 2.1846742015441123e-07\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 5\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 6\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 7\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 8\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 9\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 10\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 11\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 12\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 13\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 14\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 15\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 16\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 17\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 18\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 19\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 20\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 21\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 22\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 23\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 24\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 25\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 26\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 27\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 28\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 29\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 30\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 31\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 32\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 33\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 34\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 35\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 36\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 37\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 38\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 39\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 40\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 41\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 42\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 43\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 44\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 45\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 46\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 47\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 48\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 49\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 50\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 51\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 52\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 53\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 54\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 55\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 56\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 57\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 58\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 59\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 60\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 61\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 62\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 63\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 64\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 65\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 66\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 67\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 68\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 69\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 70\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 71\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 72\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 73\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 74\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 75\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 76\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 77\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 78\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 79\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 80\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 81\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 82\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 83\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 84\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 85\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 86\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 87\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 88\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 89\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 90\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 91\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 92\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 93\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 94\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 95\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 96\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 97\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 98\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 99\n",
            "costo: 1.480935907238745e-07\n",
            "Iteracion: 0\n",
            "costo: 2.302319049835205\n",
            "costo: 2.3017454147338867\n",
            "costo: 2.296682834625244\n",
            "costo: 2.2917494773864746\n",
            "costo: 2.28463077545166\n",
            "costo: 2.208254098892212\n",
            "costo: 1.8836928606033325\n",
            "costo: 1.0923562049865723\n",
            "costo: 1.6489142179489136\n",
            "costo: 0.7421103119850159\n",
            "costo: 0.698444128036499\n",
            "costo: 0.6631346940994263\n",
            "costo: 0.6428698301315308\n",
            "costo: 0.6174622774124146\n",
            "costo: 0.5654260516166687\n",
            "costo: 0.5286721587181091\n",
            "costo: 0.4898766279220581\n",
            "costo: 0.44643041491508484\n",
            "costo: 0.42063984274864197\n",
            "costo: 0.3866252303123474\n",
            "costo: 0.359554260969162\n",
            "costo: 0.3400926887989044\n",
            "costo: 0.3197284936904907\n",
            "costo: 0.30493971705436707\n",
            "costo: 0.2841734290122986\n",
            "Iteracion: 1\n",
            "costo: 0.25919604301452637\n",
            "costo: 0.24115459620952606\n",
            "costo: 0.2285788655281067\n",
            "costo: 0.2102571278810501\n",
            "costo: 0.19853724539279938\n",
            "costo: 0.1838586926460266\n",
            "costo: 0.17454469203948975\n",
            "costo: 0.16756512224674225\n",
            "costo: 0.15282051265239716\n",
            "costo: 0.14122039079666138\n",
            "costo: 0.13280339539051056\n",
            "costo: 0.12727847695350647\n",
            "costo: 0.11908842623233795\n",
            "costo: 0.11228848993778229\n",
            "costo: 0.10703915357589722\n",
            "costo: 0.09792205691337585\n",
            "costo: 0.09182333201169968\n",
            "costo: 0.08373599499464035\n",
            "costo: 0.07726510614156723\n",
            "costo: 0.07316193729639053\n",
            "costo: 0.06535815447568893\n",
            "Iteracion: 2\n",
            "costo: 0.06535815447568893\n",
            "costo: 0.06108049675822258\n",
            "costo: 0.056931547820568085\n",
            "costo: 0.051990311592817307\n",
            "costo: 0.048331424593925476\n",
            "costo: 0.04597026854753494\n",
            "costo: 0.04149450361728668\n",
            "costo: 0.039462167769670486\n",
            "costo: 0.036699362099170685\n",
            "costo: 0.034179218113422394\n",
            "costo: 0.03187112882733345\n",
            "costo: 0.028380800038576126\n",
            "costo: 0.026199987158179283\n",
            "costo: 0.02300320565700531\n",
            "costo: 0.01928108185529709\n",
            "costo: 0.018678024411201477\n",
            "costo: 0.015795456245541573\n",
            "costo: 0.014957988634705544\n",
            "costo: 0.012755138799548149\n",
            "costo: 0.010382097214460373\n",
            "costo: 0.020301667973399162\n",
            "costo: 0.009417430497705936\n",
            "Iteracion: 3\n",
            "costo: 0.009417430497705936\n",
            "costo: 0.00754306698217988\n",
            "costo: 0.006696243304759264\n",
            "costo: 0.005746323149651289\n",
            "costo: 0.004774936009198427\n",
            "costo: 0.003722288878634572\n",
            "costo: 0.002800549380481243\n",
            "costo: 0.0020280908793210983\n",
            "costo: 0.0017470789607614279\n",
            "costo: 0.0011953591601923108\n",
            "costo: 0.000910153379663825\n",
            "costo: 0.0007322317687794566\n",
            "costo: 0.0006328215240500867\n",
            "costo: 0.0005229662056080997\n",
            "costo: 0.0003701675741467625\n",
            "costo: 0.000461503368569538\n",
            "costo: 0.0003025550104212016\n",
            "costo: 0.00019754959794227034\n",
            "costo: 0.0001465079258196056\n",
            "costo: 0.0001037778565660119\n",
            "costo: 7.407749217236415e-05\n",
            "costo: 5.3055839089211076e-05\n",
            "Iteracion: 4\n",
            "costo: 5.3055839089211076e-05\n",
            "costo: 3.626223769970238e-05\n",
            "costo: 2.4617378585389815e-05\n",
            "costo: 1.7005799236358143e-05\n",
            "costo: 1.1460827408882324e-05\n",
            "costo: 9.060292541107628e-06\n",
            "costo: 5.484061148308683e-06\n",
            "costo: 4.0202439777203836e-06\n",
            "costo: 2.367207798670279e-06\n",
            "costo: 1.9060018985328497e-06\n",
            "costo: 9.915843293129e-07\n",
            "costo: 6.479811531789892e-07\n",
            "costo: 3.686761544940964e-07\n",
            "costo: 2.6156271815125365e-07\n",
            "costo: 1.4826198935224966e-07\n",
            "costo: 7.347973252080919e-08\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 5\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 6\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 7\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 8\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 9\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 10\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 11\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 12\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 13\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 14\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 15\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 16\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 17\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 18\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 19\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 20\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 21\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 22\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 23\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 24\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 25\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 26\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 27\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 28\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 29\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 30\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 31\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 32\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 33\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 34\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 35\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 36\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 37\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 38\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 39\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 40\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 41\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 42\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 43\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 44\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 45\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 46\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 47\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 48\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 49\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 50\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 51\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 52\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 53\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 54\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 55\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 56\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 57\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 58\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 59\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 60\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 61\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 62\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 63\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 64\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 65\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 66\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 67\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 68\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 69\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 70\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 71\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 72\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 73\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 74\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 75\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 76\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 77\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 78\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 79\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 80\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 81\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 82\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 83\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 84\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 85\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 86\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 87\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 88\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 89\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 90\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 91\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 92\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 93\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 94\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 95\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 96\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 97\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 98\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 99\n",
            "costo: 5.2334893752004064e-08\n",
            "Iteracion: 0\n",
            "costo: 2.3108041286468506\n",
            "costo: 2.3089241981506348\n",
            "costo: 2.3092405796051025\n",
            "costo: 2.3091318607330322\n",
            "costo: 2.30891489982605\n",
            "costo: 2.308929920196533\n",
            "costo: 1.7458300590515137\n",
            "costo: 0.9993223547935486\n",
            "costo: 1.134608268737793\n",
            "costo: 0.7768147587776184\n",
            "costo: 0.6981648206710815\n",
            "costo: 0.6579137444496155\n",
            "costo: 0.6349409818649292\n",
            "costo: 0.5864830613136292\n",
            "costo: 0.5996732115745544\n",
            "costo: 0.5601829290390015\n",
            "costo: 0.5240680575370789\n",
            "costo: 0.4723159670829773\n",
            "costo: 0.4399396479129791\n",
            "costo: 0.41891801357269287\n",
            "costo: 0.3944186866283417\n",
            "costo: 0.35590609908103943\n",
            "costo: 0.34671711921691895\n",
            "costo: 0.3306500315666199\n",
            "costo: 0.3170534074306488\n",
            "Iteracion: 1\n",
            "costo: 0.2898663580417633\n",
            "costo: 0.27384838461875916\n",
            "costo: 0.2495507448911667\n",
            "costo: 0.2412104308605194\n",
            "costo: 0.23070251941680908\n",
            "costo: 0.21967154741287231\n",
            "costo: 0.20758233964443207\n",
            "costo: 0.18992598354816437\n",
            "costo: 0.21698801219463348\n",
            "costo: 0.1822470873594284\n",
            "costo: 0.17088913917541504\n",
            "costo: 0.16292834281921387\n",
            "costo: 0.15182292461395264\n",
            "costo: 0.13976752758026123\n",
            "costo: 0.12860266864299774\n",
            "costo: 0.12022430449724197\n",
            "costo: 0.11295828968286514\n",
            "costo: 0.10597484558820724\n",
            "costo: 0.09951433539390564\n",
            "costo: 0.09157409518957138\n",
            "costo: 0.08545025438070297\n",
            "costo: 0.08014938980340958\n",
            "Iteracion: 2\n",
            "costo: 0.08014938980340958\n",
            "costo: 0.07508747279644012\n",
            "costo: 0.07023485749959946\n",
            "costo: 0.06914591044187546\n",
            "costo: 0.06580936163663864\n",
            "costo: 0.059972599148750305\n",
            "costo: 0.056187953799963\n",
            "costo: 0.05103689059615135\n",
            "costo: 0.0464644730091095\n",
            "costo: 0.04185190796852112\n",
            "costo: 0.039246004074811935\n",
            "costo: 0.036067232489585876\n",
            "costo: 0.03186725452542305\n",
            "costo: 0.02725813537836075\n",
            "costo: 0.025238974019885063\n",
            "costo: 0.022939035668969154\n",
            "costo: 0.021003056317567825\n",
            "costo: 0.018669337034225464\n",
            "costo: 0.01776101253926754\n",
            "costo: 0.01513710804283619\n",
            "costo: 0.014033392071723938\n",
            "costo: 0.012436369433999062\n",
            "Iteracion: 3\n",
            "costo: 0.012436369433999062\n",
            "costo: 0.010559986345469952\n",
            "costo: 0.01179463230073452\n",
            "costo: 0.009509170427918434\n",
            "costo: 0.007959394715726376\n",
            "costo: 0.00717224320396781\n",
            "costo: 0.005953787826001644\n",
            "costo: 0.00483342120423913\n",
            "costo: 0.003846339415758848\n",
            "costo: 0.003337944857776165\n",
            "costo: 0.0026786942034959793\n",
            "costo: 0.0020943491254001856\n",
            "costo: 0.0015448294579982758\n",
            "costo: 0.001253335503861308\n",
            "costo: 0.0009469131473451853\n",
            "costo: 0.0007672300562262535\n",
            "costo: 0.0006609113188460469\n",
            "costo: 0.0005315350135788321\n",
            "costo: 0.00042948074406012893\n",
            "costo: 0.00030038596014492214\n",
            "costo: 0.0003150547272525728\n",
            "costo: 0.00023131862690206617\n",
            "costo: 0.00016797393618617207\n",
            "Iteracion: 4\n",
            "costo: 0.00016797393618617207\n",
            "costo: 0.00012875966785941273\n",
            "costo: 8.861585956765339e-05\n",
            "costo: 7.643977005500346e-05\n",
            "costo: 4.7990117309382185e-05\n",
            "costo: 4.1445280658081174e-05\n",
            "costo: 3.07211339531932e-05\n",
            "costo: 2.610473893582821e-05\n",
            "costo: 1.7938364180736244e-05\n",
            "costo: 1.5470814105356112e-05\n",
            "costo: 1.0633513738866895e-05\n",
            "costo: 9.118220987147652e-06\n",
            "costo: 5.495738605532097e-06\n",
            "costo: 4.775173238158459e-06\n",
            "costo: 3.157917944918154e-06\n",
            "costo: 2.066549996015965e-06\n",
            "costo: 1.2076288840034977e-06\n",
            "costo: 8.847060257721751e-07\n",
            "costo: 5.28615828443435e-07\n",
            "costo: 3.4512902402639156e-07\n",
            "costo: 2.234523179822645e-07\n",
            "Iteracion: 5\n",
            "costo: 2.234523179822645e-07\n",
            "costo: 1.3813517796279484e-07\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 6\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 7\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 8\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 9\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 10\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 11\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 12\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 13\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 14\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 15\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 16\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 17\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 18\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 19\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 20\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 21\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 22\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 23\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 24\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 25\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 26\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 27\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 28\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 29\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 30\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 31\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 32\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 33\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 34\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 35\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 36\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 37\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 38\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 39\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 40\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 41\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 42\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 43\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 44\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 45\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 46\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 47\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 48\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 49\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 50\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 51\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 52\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 53\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 54\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 55\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 56\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 57\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 58\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 59\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 60\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 61\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 62\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 63\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 64\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 65\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 66\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 67\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 68\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 69\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 70\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 71\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 72\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 73\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 74\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 75\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 76\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 77\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 78\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 79\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 80\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 81\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 82\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 83\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 84\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 85\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 86\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 87\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 88\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 89\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 90\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 91\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 92\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 93\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 94\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 95\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 96\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 97\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 98\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 99\n",
            "costo: 8.224888858876511e-08\n",
            "Iteracion: 0\n",
            "costo: 2.3160345554351807\n",
            "costo: 2.314849376678467\n",
            "costo: 2.3147411346435547\n",
            "costo: 2.3150794506073\n",
            "costo: 2.314577341079712\n",
            "costo: 2.3143250942230225\n",
            "costo: 2.314707040786743\n",
            "costo: 1.8117402791976929\n",
            "costo: 1.1352893114089966\n",
            "costo: 0.818970799446106\n",
            "costo: 0.7190122604370117\n",
            "costo: 0.6566737294197083\n",
            "costo: 0.6352298259735107\n",
            "costo: 0.5962535738945007\n",
            "costo: 0.5743539929389954\n",
            "costo: 0.53095543384552\n",
            "costo: 0.5035857558250427\n",
            "costo: 0.4595644176006317\n",
            "costo: 0.4810325503349304\n",
            "costo: 0.4344446063041687\n",
            "costo: 0.4022860527038574\n",
            "costo: 0.3730033338069916\n",
            "costo: 0.3495774567127228\n",
            "costo: 0.3337760269641876\n",
            "costo: 0.3194352388381958\n",
            "Iteracion: 1\n",
            "costo: 0.2881828546524048\n",
            "costo: 0.26987984776496887\n",
            "costo: 0.24349449574947357\n",
            "costo: 0.22964975237846375\n",
            "costo: 0.21777431666851044\n",
            "costo: 0.20499391853809357\n",
            "costo: 0.19455677270889282\n",
            "costo: 0.18394438922405243\n",
            "costo: 0.17342017590999603\n",
            "costo: 0.16190168261528015\n",
            "costo: 0.15189960598945618\n",
            "costo: 0.14039923250675201\n",
            "costo: 0.12921011447906494\n",
            "costo: 0.11874902248382568\n",
            "costo: 0.10872972011566162\n",
            "costo: 0.10454659909009933\n",
            "costo: 0.09800416976213455\n",
            "costo: 0.09248808771371841\n",
            "costo: 0.08696305751800537\n",
            "costo: 0.07912439107894897\n",
            "costo: 0.07555296272039413\n",
            "Iteracion: 2\n",
            "costo: 0.07555296272039413\n",
            "costo: 0.06912606954574585\n",
            "costo: 0.06667371839284897\n",
            "costo: 0.062035296112298965\n",
            "costo: 0.058089692145586014\n",
            "costo: 0.05522763356566429\n",
            "costo: 0.05148771405220032\n",
            "costo: 0.04849710315465927\n",
            "costo: 0.04214810952544212\n",
            "costo: 0.04073261842131615\n",
            "costo: 0.03675428405404091\n",
            "costo: 0.03548561409115791\n",
            "costo: 0.032493770122528076\n",
            "costo: 0.029407432302832603\n",
            "costo: 0.02622009441256523\n",
            "costo: 0.024262942373752594\n",
            "costo: 0.022466737776994705\n",
            "costo: 0.020614059641957283\n",
            "costo: 0.017978159710764885\n",
            "costo: 0.015491751953959465\n",
            "costo: 0.013525706715881824\n",
            "Iteracion: 3\n",
            "costo: 0.013525706715881824\n",
            "costo: 0.011897281743586063\n",
            "costo: 0.010109907016158104\n",
            "costo: 0.008446727879345417\n",
            "costo: 0.0067354426719248295\n",
            "costo: 0.006194508168846369\n",
            "costo: 0.0050204754807055\n",
            "costo: 0.004536478314548731\n",
            "costo: 0.0035995058715343475\n",
            "costo: 0.003550466615706682\n",
            "costo: 0.0031686490401625633\n",
            "costo: 0.0026939278468489647\n",
            "costo: 0.0021513167303055525\n",
            "costo: 0.0016257509123533964\n",
            "costo: 0.0013691636268049479\n",
            "costo: 0.0010852408595383167\n",
            "costo: 0.0009494773694314063\n",
            "costo: 0.000754327978938818\n",
            "costo: 0.0005724626826122403\n",
            "costo: 0.000401143915951252\n",
            "costo: 0.0003279244701843709\n",
            "costo: 0.00028401584131643176\n",
            "Iteracion: 4\n",
            "costo: 0.00028401584131643176\n",
            "costo: 0.00021152246335987002\n",
            "costo: 0.00017154295346699655\n",
            "costo: 0.00013470991689246148\n",
            "costo: 0.0001137051367550157\n",
            "costo: 8.591918594902381e-05\n",
            "costo: 6.398648110916838e-05\n",
            "costo: 4.498751513892785e-05\n",
            "costo: 3.364207441336475e-05\n",
            "costo: 2.629978916957043e-05\n",
            "costo: 1.8946566342492588e-05\n",
            "costo: 1.5955272829160094e-05\n",
            "costo: 1.0781573109852616e-05\n",
            "costo: 9.249293725588359e-06\n",
            "costo: 6.289207249210449e-06\n",
            "costo: 4.4485286707640626e-06\n",
            "costo: 3.134489361400483e-06\n",
            "costo: 2.3852362573961727e-06\n",
            "costo: 1.7184825082949828e-06\n",
            "costo: 1.226921540364856e-06\n",
            "costo: 7.712851584074087e-07\n",
            "Iteracion: 5\n",
            "costo: 7.712851584074087e-07\n",
            "costo: 6.17735679497855e-07\n",
            "costo: 3.8009395098015375e-07\n",
            "costo: 2.7491617515806865e-07\n",
            "costo: 1.691640107992498e-07\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 6\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 7\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 8\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 9\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 10\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 11\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 12\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 13\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 14\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 15\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 16\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 17\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 18\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 19\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 20\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 21\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 22\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 23\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 24\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 25\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 26\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 27\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 28\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 29\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 30\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 31\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 32\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 33\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 34\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 35\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 36\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 37\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 38\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 39\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 40\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 41\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 42\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 43\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 44\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 45\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 46\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 47\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 48\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 49\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 50\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 51\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 52\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 53\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 54\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 55\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 56\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 57\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 58\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 59\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 60\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 61\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 62\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 63\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 64\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 65\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 66\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 67\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 68\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 69\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 70\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 71\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 72\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 73\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 74\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 75\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 76\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 77\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 78\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 79\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 80\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 81\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 82\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 83\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 84\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 85\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 86\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 87\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 88\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 89\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 90\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 91\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 92\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 93\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 94\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 95\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 96\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 97\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 98\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 99\n",
            "costo: 1.347782756511151e-07\n",
            "Iteracion: 0\n",
            "costo: 2.3125927448272705\n",
            "costo: 2.311345100402832\n",
            "costo: 2.3108861446380615\n",
            "costo: 2.303774356842041\n",
            "costo: 2.292292356491089\n",
            "costo: 2.205315589904785\n",
            "costo: 1.8350845575332642\n",
            "costo: 1.1151118278503418\n",
            "costo: 1.4289740324020386\n",
            "costo: 0.79265958070755\n",
            "costo: 0.6932941675186157\n",
            "costo: 0.6682030558586121\n",
            "costo: 0.644474983215332\n",
            "costo: 0.5984160304069519\n",
            "costo: 0.5596461296081543\n",
            "costo: 0.5221390128135681\n",
            "costo: 0.48774755001068115\n",
            "costo: 0.46193698048591614\n",
            "costo: 0.4299817979335785\n",
            "costo: 0.383179247379303\n",
            "costo: 0.3510454595088959\n",
            "costo: 0.3375242054462433\n",
            "costo: 0.32258477807044983\n",
            "costo: 0.2990274131298065\n",
            "costo: 0.27443450689315796\n",
            "Iteracion: 1\n",
            "costo: 0.24948027729988098\n",
            "costo: 0.23428478837013245\n",
            "costo: 0.2238437533378601\n",
            "costo: 0.21007294952869415\n",
            "costo: 0.20181392133235931\n",
            "costo: 0.19064153730869293\n",
            "costo: 0.1830088496208191\n",
            "costo: 0.1753467172384262\n",
            "costo: 0.15910661220550537\n",
            "costo: 0.1746722012758255\n",
            "costo: 0.1502263844013214\n",
            "costo: 0.13869893550872803\n",
            "costo: 0.13226626813411713\n",
            "costo: 0.12243650108575821\n",
            "costo: 0.11375825107097626\n",
            "costo: 0.10556858032941818\n",
            "costo: 0.10005676746368408\n",
            "costo: 0.09298548847436905\n",
            "costo: 0.09020436555147171\n",
            "costo: 0.08247598260641098\n",
            "costo: 0.0787530392408371\n",
            "costo: 0.07380769401788712\n",
            "Iteracion: 2\n",
            "costo: 0.07380769401788712\n",
            "costo: 0.06822362542152405\n",
            "costo: 0.06256355345249176\n",
            "costo: 0.0584462434053421\n",
            "costo: 0.05359343811869621\n",
            "costo: 0.05137288570404053\n",
            "costo: 0.04711468145251274\n",
            "costo: 0.044609420001506805\n",
            "costo: 0.04151428863406181\n",
            "costo: 0.03747299313545227\n",
            "costo: 0.03515084460377693\n",
            "costo: 0.03131156787276268\n",
            "costo: 0.029856907203793526\n",
            "costo: 0.02710149437189102\n",
            "costo: 0.0247089471668005\n",
            "costo: 0.021872377023100853\n",
            "costo: 0.019887614995241165\n",
            "costo: 0.017676692456007004\n",
            "costo: 0.014534716494381428\n",
            "costo: 0.015410162508487701\n",
            "costo: 0.012943098321557045\n",
            "costo: 0.011181275360286236\n",
            "Iteracion: 3\n",
            "costo: 0.011181275360286236\n",
            "costo: 0.00976195465773344\n",
            "costo: 0.008367999456822872\n",
            "costo: 0.0068898615427315235\n",
            "costo: 0.00562162883579731\n",
            "costo: 0.0048172371461987495\n",
            "costo: 0.004005675669759512\n",
            "costo: 0.003509547794237733\n",
            "costo: 0.0029105651192367077\n",
            "costo: 0.0021297289058566093\n",
            "costo: 0.0017112810164690018\n",
            "costo: 0.0011157875414937735\n",
            "costo: 0.0009823826840147376\n",
            "costo: 0.0007621750701218843\n",
            "costo: 0.0005422593676485121\n",
            "costo: 0.00036207211087457836\n",
            "costo: 0.00028163689421489835\n",
            "costo: 0.00024345761630684137\n",
            "costo: 0.00019183596305083483\n",
            "costo: 0.00014852113963570446\n",
            "costo: 9.917952411342412e-05\n",
            "Iteracion: 4\n",
            "costo: 9.917952411342412e-05\n",
            "costo: 8.353992598131299e-05\n",
            "costo: 5.9924339439021423e-05\n",
            "costo: 3.856409966829233e-05\n",
            "costo: 2.941937964351382e-05\n",
            "costo: 1.799006713554263e-05\n",
            "costo: 1.1085017831646837e-05\n",
            "costo: 5.735318609367823e-06\n",
            "costo: 3.908228791260626e-06\n",
            "costo: 2.395946694377926e-06\n",
            "costo: 1.4212556607162696e-06\n",
            "costo: 8.071214665505977e-07\n",
            "costo: 4.956019097335229e-07\n",
            "costo: 2.8813184371756506e-07\n",
            "costo: 1.7065592317067058e-07\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 5\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 6\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 7\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 8\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 9\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 10\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 11\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 12\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 13\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 14\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 15\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 16\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 17\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 18\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 19\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 20\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 21\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 22\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 23\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 24\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 25\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 26\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 27\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 28\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 29\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 30\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 31\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 32\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 33\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 34\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 35\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 36\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 37\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 38\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 39\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 40\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 41\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 42\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 43\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 44\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 45\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 46\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 47\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 48\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 49\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 50\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 51\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 52\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 53\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 54\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 55\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 56\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 57\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 58\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 59\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 60\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 61\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 62\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 63\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 64\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 65\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 66\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 67\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 68\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 69\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 70\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 71\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 72\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 73\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 74\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 75\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 76\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 77\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 78\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 79\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 80\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 81\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 82\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 83\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 84\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 85\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 86\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 87\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 88\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 89\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 90\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 91\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 92\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 93\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 94\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 95\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 96\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 97\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 98\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 99\n",
            "costo: 7.641965282800811e-08\n",
            "Iteracion: 0\n",
            "costo: 2.3055460453033447\n",
            "costo: 2.3041505813598633\n",
            "costo: 2.3040356636047363\n",
            "costo: 2.3040435314178467\n",
            "costo: 2.3043086528778076\n",
            "costo: 2.3045356273651123\n",
            "costo: 2.3047101497650146\n",
            "costo: 1.7362467050552368\n",
            "costo: 1.2466230392456055\n",
            "costo: 0.9309184551239014\n",
            "costo: 0.6922510266304016\n",
            "costo: 0.6479176878929138\n",
            "costo: 0.6131803393363953\n",
            "costo: 0.5850770473480225\n",
            "costo: 0.5603033304214478\n",
            "costo: 0.5145079493522644\n",
            "costo: 0.5039927959442139\n",
            "costo: 0.4449651539325714\n",
            "costo: 0.42704933881759644\n",
            "costo: 0.40012097358703613\n",
            "costo: 0.3678246736526489\n",
            "costo: 0.3383943736553192\n",
            "costo: 0.316914826631546\n",
            "costo: 0.2992188632488251\n",
            "costo: 0.2842112183570862\n",
            "Iteracion: 1\n",
            "costo: 0.25951337814331055\n",
            "costo: 0.24034011363983154\n",
            "costo: 0.21800802648067474\n",
            "costo: 0.2037707269191742\n",
            "costo: 0.1940866857767105\n",
            "costo: 0.1801028698682785\n",
            "costo: 0.17104893922805786\n",
            "costo: 0.15959839522838593\n",
            "costo: 0.14632479846477509\n",
            "costo: 0.1365092247724533\n",
            "costo: 0.12921002507209778\n",
            "costo: 0.11615630984306335\n",
            "costo: 0.10822706669569016\n",
            "costo: 0.10111995786428452\n",
            "costo: 0.09577102214097977\n",
            "costo: 0.09011813253164291\n",
            "costo: 0.08658192306756973\n",
            "costo: 0.07872836291790009\n",
            "costo: 0.0744539275765419\n",
            "costo: 0.06944262981414795\n",
            "costo: 0.06489484012126923\n",
            "Iteracion: 2\n",
            "costo: 0.06489484012126923\n",
            "costo: 0.059731531888246536\n",
            "costo: 0.05612709000706673\n",
            "costo: 0.052947547286748886\n",
            "costo: 0.049063339829444885\n",
            "costo: 0.04573247954249382\n",
            "costo: 0.042704977095127106\n",
            "costo: 0.038389723747968674\n",
            "costo: 0.03670477122068405\n",
            "costo: 0.031993161886930466\n",
            "costo: 0.030453022569417953\n",
            "costo: 0.028087511658668518\n",
            "costo: 0.025161297991871834\n",
            "costo: 0.021800663322210312\n",
            "costo: 0.01953943632543087\n",
            "costo: 0.017216622829437256\n",
            "costo: 0.01527528464794159\n",
            "costo: 0.013528496026992798\n",
            "costo: 0.012005012482404709\n",
            "costo: 0.010792179964482784\n",
            "costo: 0.009491276927292347\n",
            "Iteracion: 3\n",
            "costo: 0.009491276927292347\n",
            "costo: 0.00819354597479105\n",
            "costo: 0.00657607289031148\n",
            "costo: 0.005584081634879112\n",
            "costo: 0.0044767605140805244\n",
            "costo: 0.003877124283462763\n",
            "costo: 0.003246182342991233\n",
            "costo: 0.002606575610116124\n",
            "costo: 0.0019712885841727257\n",
            "costo: 0.0016943466616794467\n",
            "costo: 0.0012514862464740872\n",
            "costo: 0.0010727520566433668\n",
            "costo: 0.0008752097492106259\n",
            "costo: 0.0007593209738843143\n",
            "costo: 0.0006001951405778527\n",
            "costo: 0.0005099339177832007\n",
            "costo: 0.0003961139591410756\n",
            "costo: 0.0003436969709582627\n",
            "costo: 0.00029038035427220166\n",
            "costo: 0.0002234200801467523\n",
            "costo: 0.0002309749397682026\n",
            "costo: 0.00018802066915668547\n",
            "Iteracion: 4\n",
            "costo: 0.00018802066915668547\n",
            "costo: 0.00012444573803804815\n",
            "costo: 9.961461910279468e-05\n",
            "costo: 7.289530913112685e-05\n",
            "costo: 5.544450687011704e-05\n",
            "costo: 3.791729614022188e-05\n",
            "costo: 3.087852383032441e-05\n",
            "costo: 2.058517020486761e-05\n",
            "costo: 1.4593388186767697e-05\n",
            "costo: 9.002169463201426e-06\n",
            "costo: 7.284656021511182e-06\n",
            "costo: 4.835409981751582e-06\n",
            "costo: 3.537947804943542e-06\n",
            "costo: 2.403041662546457e-06\n",
            "costo: 1.923796617120388e-06\n",
            "costo: 1.2564897815536824e-06\n",
            "costo: 8.758804028730083e-07\n",
            "costo: 5.662556645802397e-07\n",
            "costo: 4.3556104856179445e-07\n",
            "costo: 2.7789050704996043e-07\n",
            "costo: 3.504806045384612e-07\n",
            "costo: 2.1720973109040642e-07\n",
            "Iteracion: 5\n",
            "costo: 2.1720973109040642e-07\n",
            "costo: 1.4514934321141482e-07\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 6\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 7\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 8\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 9\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 10\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 11\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 12\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 13\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 14\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 15\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 16\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 17\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 18\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 19\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 20\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 21\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 22\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 23\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 24\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 25\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 26\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 27\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 28\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 29\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 30\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 31\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 32\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 33\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 34\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 35\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 36\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 37\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 38\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 39\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 40\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 41\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 42\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 43\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 44\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 45\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 46\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 47\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 48\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 49\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 50\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 51\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 52\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 53\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 54\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 55\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 56\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 57\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 58\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 59\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 60\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 61\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 62\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 63\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 64\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 65\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 66\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 67\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 68\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 69\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 70\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 71\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 72\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 73\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 74\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 75\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 76\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 77\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 78\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 79\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 80\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 81\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 82\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 83\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 84\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 85\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 86\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 87\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 88\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 89\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 90\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 91\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 92\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 93\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 94\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 95\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 96\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 97\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 98\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 99\n",
            "costo: 1.0084274038035801e-07\n",
            "Iteracion: 0\n",
            "costo: 2.325901508331299\n",
            "costo: 2.3247780799865723\n",
            "costo: 2.3236498832702637\n",
            "costo: 2.3137941360473633\n",
            "costo: 2.2331228256225586\n",
            "costo: 1.9264415502548218\n",
            "costo: 0.9719653129577637\n",
            "costo: 3.1371238231658936\n",
            "costo: 0.7373770475387573\n",
            "costo: 0.6826757788658142\n",
            "costo: 0.6504712700843811\n",
            "costo: 0.6338681578636169\n",
            "costo: 0.5942965149879456\n",
            "costo: 0.5597047209739685\n",
            "costo: 0.5217158794403076\n",
            "costo: 0.4515160024166107\n",
            "costo: 0.43112996220588684\n",
            "costo: 0.4171673059463501\n",
            "costo: 0.389512300491333\n",
            "costo: 0.3687741458415985\n",
            "costo: 0.3404095768928528\n",
            "costo: 0.32246917486190796\n",
            "costo: 0.30780157446861267\n",
            "costo: 0.2849595248699188\n",
            "costo: 0.2757819890975952\n",
            "Iteracion: 1\n",
            "costo: 0.25256866216659546\n",
            "costo: 0.2392977923154831\n",
            "costo: 0.23060981929302216\n",
            "costo: 0.21550770103931427\n",
            "costo: 0.19866298139095306\n",
            "costo: 0.18864138424396515\n",
            "costo: 0.17482402920722961\n",
            "costo: 0.16877152025699615\n",
            "costo: 0.15668050944805145\n",
            "costo: 0.15327805280685425\n",
            "costo: 0.14512282609939575\n",
            "costo: 0.14031937718391418\n",
            "costo: 0.13141436874866486\n",
            "costo: 0.11984511464834213\n",
            "costo: 0.11726997792720795\n",
            "costo: 0.10492608696222305\n",
            "costo: 0.1015104427933693\n",
            "costo: 0.09164239466190338\n",
            "costo: 0.09000737220048904\n",
            "costo: 0.08058857917785645\n",
            "costo: 0.07770895212888718\n",
            "Iteracion: 2\n",
            "costo: 0.07770895212888718\n",
            "costo: 0.07325464487075806\n",
            "costo: 0.06786269694566727\n",
            "costo: 0.06342519074678421\n",
            "costo: 0.05734914541244507\n",
            "costo: 0.054990265518426895\n",
            "costo: 0.05014391988515854\n",
            "costo: 0.0471121184527874\n",
            "costo: 0.044157493859529495\n",
            "costo: 0.04088551178574562\n",
            "costo: 0.03798873722553253\n",
            "costo: 0.034300439059734344\n",
            "costo: 0.031817615032196045\n",
            "costo: 0.029508166015148163\n",
            "costo: 0.027831489220261574\n",
            "costo: 0.02545562945306301\n",
            "costo: 0.02295525185763836\n",
            "costo: 0.02083441987633705\n",
            "costo: 0.018680840730667114\n",
            "costo: 0.016844848170876503\n",
            "costo: 0.014880038797855377\n",
            "Iteracion: 3\n",
            "costo: 0.014880038797855377\n",
            "costo: 0.013304304331541061\n",
            "costo: 0.010995427146553993\n",
            "costo: 0.009889847598969936\n",
            "costo: 0.008850927464663982\n",
            "costo: 0.00803016684949398\n",
            "costo: 0.007063139695674181\n",
            "costo: 0.00569735886529088\n",
            "costo: 0.005346124060451984\n",
            "costo: 0.003960764035582542\n",
            "costo: 0.003648132551461458\n",
            "costo: 0.002988160355016589\n",
            "costo: 0.0023428676649928093\n",
            "costo: 0.0017926772125065327\n",
            "costo: 0.0015291980234906077\n",
            "costo: 0.0011324855731800199\n",
            "costo: 0.0011070723412558436\n",
            "costo: 0.0007250802009366453\n",
            "costo: 0.0006328705931082368\n",
            "costo: 0.0004922831431031227\n",
            "costo: 0.00037850101944059134\n",
            "Iteracion: 4\n",
            "costo: 0.00037850101944059134\n",
            "costo: 0.0002721328637562692\n",
            "costo: 0.00022857349540572613\n",
            "costo: 0.00016916534514166415\n",
            "costo: 0.00012042136222589761\n",
            "costo: 7.686532626394182e-05\n",
            "costo: 5.829495785292238e-05\n",
            "costo: 4.0175233152695e-05\n",
            "costo: 2.5653402190073393e-05\n",
            "costo: 1.5025800166768022e-05\n",
            "costo: 9.902189049171284e-06\n",
            "costo: 6.453682090068469e-06\n",
            "costo: 4.3802983782370575e-06\n",
            "costo: 2.7306621177558554e-06\n",
            "costo: 1.3368286317927414e-06\n",
            "costo: 1.0493337185835117e-06\n",
            "costo: 6.443994493565697e-07\n",
            "costo: 4.0000449530452897e-07\n",
            "costo: 2.3764127377035038e-07\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 5\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 6\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 7\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 8\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 9\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 10\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 11\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 12\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 13\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 14\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 15\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 16\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 17\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 18\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 19\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 20\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 21\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 22\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 23\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 24\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 25\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 26\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 27\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 28\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 29\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 30\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 31\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 32\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 33\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 34\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 35\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 36\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 37\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 38\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 39\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 40\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 41\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 42\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 43\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 44\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 45\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 46\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 47\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 48\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 49\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 50\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 51\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 52\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 53\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 54\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 55\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 56\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 57\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 58\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 59\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 60\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 61\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 62\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 63\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 64\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 65\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 66\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 67\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 68\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 69\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 70\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 71\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 72\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 73\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 74\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 75\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 76\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 77\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 78\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 79\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 80\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 81\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 82\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 83\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 84\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 85\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 86\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 87\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 88\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 89\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 90\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 91\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 92\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 93\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 94\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 95\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 96\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 97\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 98\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 99\n",
            "costo: 1.5404147291064874e-07\n",
            "Iteracion: 0\n",
            "costo: 2.3143789768218994\n",
            "costo: 2.3137896060943604\n",
            "costo: 2.3087708950042725\n",
            "costo: 2.3046717643737793\n",
            "costo: 2.2612171173095703\n",
            "costo: 2.0080275535583496\n",
            "costo: 1.151293396949768\n",
            "costo: 1.714257836341858\n",
            "costo: 0.7774880528450012\n",
            "costo: 0.779554545879364\n",
            "costo: 0.7238754630088806\n",
            "costo: 0.6955869793891907\n",
            "costo: 0.6626270413398743\n",
            "costo: 0.6078416705131531\n",
            "costo: 0.553326427936554\n",
            "costo: 0.5153998732566833\n",
            "costo: 0.47952374815940857\n",
            "costo: 0.45574089884757996\n",
            "costo: 0.42513394355773926\n",
            "costo: 0.41863852739334106\n",
            "costo: 0.385012686252594\n",
            "costo: 0.36479106545448303\n",
            "costo: 0.35036101937294006\n",
            "costo: 0.3309950828552246\n",
            "costo: 0.3095681667327881\n",
            "Iteracion: 1\n",
            "costo: 0.2830025255680084\n",
            "costo: 0.274455189704895\n",
            "costo: 0.25113335251808167\n",
            "costo: 0.23565587401390076\n",
            "costo: 0.2227305918931961\n",
            "costo: 0.21284566819667816\n",
            "costo: 0.19443418085575104\n",
            "costo: 0.18873721361160278\n",
            "costo: 0.17540498077869415\n",
            "costo: 0.16902953386306763\n",
            "costo: 0.15936261415481567\n",
            "costo: 0.14830060303211212\n",
            "costo: 0.153703972697258\n",
            "costo: 0.14188039302825928\n",
            "costo: 0.1341398060321808\n",
            "costo: 0.12686268985271454\n",
            "costo: 0.1177315041422844\n",
            "costo: 0.10979937762022018\n",
            "costo: 0.10243027657270432\n",
            "costo: 0.09724531322717667\n",
            "costo: 0.08963590860366821\n",
            "costo: 0.08042775094509125\n",
            "Iteracion: 2\n",
            "costo: 0.08042775094509125\n",
            "costo: 0.07515808194875717\n",
            "costo: 0.06876281648874283\n",
            "costo: 0.06593959033489227\n",
            "costo: 0.060869812965393066\n",
            "costo: 0.05997276306152344\n",
            "costo: 0.05715955048799515\n",
            "costo: 0.052335262298583984\n",
            "costo: 0.04872521385550499\n",
            "costo: 0.045484501868486404\n",
            "costo: 0.04155641421675682\n",
            "costo: 0.0374702513217926\n",
            "costo: 0.03319766744971275\n",
            "costo: 0.02970731258392334\n",
            "costo: 0.027144385501742363\n",
            "costo: 0.023300208151340485\n",
            "costo: 0.020451469346880913\n",
            "costo: 0.01888834871351719\n",
            "costo: 0.016529910266399384\n",
            "costo: 0.015234215185046196\n",
            "costo: 0.01383259054273367\n",
            "costo: 0.011214587837457657\n",
            "Iteracion: 3\n",
            "costo: 0.011214587837457657\n",
            "costo: 0.010184135288000107\n",
            "costo: 0.00920033361762762\n",
            "costo: 0.008085127919912338\n",
            "costo: 0.0069837868213653564\n",
            "costo: 0.005366147495806217\n",
            "costo: 0.005587688181549311\n",
            "costo: 0.004364333115518093\n",
            "costo: 0.003440004773437977\n",
            "costo: 0.0028181481175124645\n",
            "costo: 0.0022492650896310806\n",
            "costo: 0.0017542093992233276\n",
            "costo: 0.00141245499253273\n",
            "costo: 0.001074840547516942\n",
            "costo: 0.0008752074209041893\n",
            "costo: 0.0007584015838801861\n",
            "costo: 0.000570916454307735\n",
            "costo: 0.00041117332875728607\n",
            "costo: 0.0003452482633292675\n",
            "costo: 0.0002299224870512262\n",
            "costo: 0.00015346302825491875\n",
            "costo: 0.0001190665498143062\n",
            "Iteracion: 4\n",
            "costo: 0.0001190665498143062\n",
            "costo: 9.581032645655796e-05\n",
            "costo: 7.536596240242943e-05\n",
            "costo: 4.984506085747853e-05\n",
            "costo: 3.861140430672094e-05\n",
            "costo: 2.1055302568129264e-05\n",
            "costo: 1.6800398952909745e-05\n",
            "costo: 1.0879875844693743e-05\n",
            "costo: 9.159917681245133e-06\n",
            "costo: 5.92180958847166e-06\n",
            "costo: 5.233936462900601e-06\n",
            "costo: 3.7494596654141787e-06\n",
            "costo: 2.5742936031747377e-06\n",
            "costo: 1.5354706874859403e-06\n",
            "costo: 1.1594971738304594e-06\n",
            "costo: 7.201303446890961e-07\n",
            "costo: 4.212104158796137e-07\n",
            "costo: 2.3073036459209106e-07\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 5\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 6\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 7\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 8\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 9\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 10\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 11\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 12\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 13\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 14\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 15\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 16\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 17\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 18\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 19\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 20\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 21\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 22\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 23\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 24\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 25\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 26\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 27\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 28\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 29\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 30\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 31\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 32\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 33\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 34\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 35\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 36\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 37\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 38\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 39\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 40\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 41\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 42\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 43\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 44\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 45\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 46\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 47\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 48\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 49\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 50\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 51\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 52\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 53\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 54\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 55\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 56\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 57\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 58\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 59\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 60\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 61\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 62\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 63\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 64\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 65\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 66\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 67\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 68\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 69\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 70\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 71\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 72\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 73\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 74\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 75\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 76\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 77\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 78\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 79\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 80\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 81\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 82\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 83\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 84\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 85\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 86\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 87\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 88\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 89\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 90\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 91\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 92\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 93\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 94\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 95\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 96\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 97\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 98\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 99\n",
            "costo: 1.5584446089178527e-07\n",
            "Iteracion: 0\n",
            "costo: 2.3023126125335693\n",
            "costo: 2.3010506629943848\n",
            "costo: 2.300978660583496\n",
            "costo: 2.300912857055664\n",
            "costo: 2.300527811050415\n",
            "costo: 2.3003859519958496\n",
            "costo: 2.3007373809814453\n",
            "costo: 1.5484281778335571\n",
            "costo: 1.1920517683029175\n",
            "costo: 0.8202328681945801\n",
            "costo: 0.7157374024391174\n",
            "costo: 0.6264312267303467\n",
            "costo: 0.6193309426307678\n",
            "costo: 0.5579606294631958\n",
            "costo: 0.5362787246704102\n",
            "costo: 0.4917994439601898\n",
            "costo: 0.43725401163101196\n",
            "costo: 0.4189056158065796\n",
            "costo: 0.38720765709877014\n",
            "costo: 0.3748687207698822\n",
            "costo: 0.3512312173843384\n",
            "costo: 0.3261658251285553\n",
            "costo: 0.30608507990837097\n",
            "costo: 0.2856632471084595\n",
            "costo: 0.2750762403011322\n",
            "Iteracion: 1\n",
            "costo: 0.25050848722457886\n",
            "costo: 0.23518091440200806\n",
            "costo: 0.22016580402851105\n",
            "costo: 0.20538845658302307\n",
            "costo: 0.19435328245162964\n",
            "costo: 0.17998115718364716\n",
            "costo: 0.17157629132270813\n",
            "costo: 0.16285590827465057\n",
            "costo: 0.15453453361988068\n",
            "costo: 0.14496910572052002\n",
            "costo: 0.13075664639472961\n",
            "costo: 0.12722156941890717\n",
            "costo: 0.12197999656200409\n",
            "costo: 0.11617071181535721\n",
            "costo: 0.10969550162553787\n",
            "costo: 0.10152013599872589\n",
            "costo: 0.09456353634595871\n",
            "costo: 0.08994520455598831\n",
            "costo: 0.08052190393209457\n",
            "costo: 0.07714619487524033\n",
            "costo: 0.07254631072282791\n",
            "costo: 0.06935188174247742\n",
            "Iteracion: 2\n",
            "costo: 0.06935188174247742\n",
            "costo: 0.06611186265945435\n",
            "costo: 0.06063395366072655\n",
            "costo: 0.0558486171066761\n",
            "costo: 0.04954928159713745\n",
            "costo: 0.04729338362812996\n",
            "costo: 0.04378242790699005\n",
            "costo: 0.04265214875340462\n",
            "costo: 0.03844771906733513\n",
            "costo: 0.03606713190674782\n",
            "costo: 0.03324349969625473\n",
            "costo: 0.029655858874320984\n",
            "costo: 0.03316653147339821\n",
            "costo: 0.027327070012688637\n",
            "costo: 0.024032702669501305\n",
            "costo: 0.022570693865418434\n",
            "costo: 0.020309248939156532\n",
            "costo: 0.018157001584768295\n",
            "costo: 0.016032084822654724\n",
            "costo: 0.014196950942277908\n",
            "costo: 0.012423000298440456\n",
            "costo: 0.010872661136090755\n",
            "Iteracion: 3\n",
            "costo: 0.010872661136090755\n",
            "costo: 0.009348740801215172\n",
            "costo: 0.008153502829372883\n",
            "costo: 0.007002177648246288\n",
            "costo: 0.006442929618060589\n",
            "costo: 0.005100991111248732\n",
            "costo: 0.004510446451604366\n",
            "costo: 0.0036486745811998844\n",
            "costo: 0.0030945572070777416\n",
            "costo: 0.002379812067374587\n",
            "costo: 0.002057798905298114\n",
            "costo: 0.0016167765716090798\n",
            "costo: 0.0012154454598203301\n",
            "costo: 0.0011314611183479428\n",
            "costo: 0.0006789334584027529\n",
            "costo: 0.0006063824985176325\n",
            "costo: 0.0004920466453768313\n",
            "costo: 0.00041951201274059713\n",
            "costo: 0.00033294555032625794\n",
            "costo: 0.0002800760848913342\n",
            "costo: 0.0002235949068563059\n",
            "Iteracion: 4\n",
            "costo: 0.0002235949068563059\n",
            "costo: 0.00016040274931583554\n",
            "costo: 0.00012108845839975402\n",
            "costo: 7.031406130408868e-05\n",
            "costo: 5.607035200227983e-05\n",
            "costo: 3.9520618884125724e-05\n",
            "costo: 2.8928254323545843e-05\n",
            "costo: 1.9541050278348848e-05\n",
            "costo: 1.5482090020668693e-05\n",
            "costo: 1.0231761734758038e-05\n",
            "costo: 7.401621132885339e-06\n",
            "costo: 5.1701672418857925e-06\n",
            "costo: 3.9885944715933874e-06\n",
            "costo: 2.61495688391733e-06\n",
            "costo: 1.913061851155362e-06\n",
            "costo: 1.192104946312611e-06\n",
            "costo: 9.32114630813885e-07\n",
            "costo: 5.641483653562318e-07\n",
            "costo: 3.6978084949623735e-07\n",
            "costo: 2.2833866353266785e-07\n",
            "costo: 1.7631106175031164e-07\n",
            "Iteracion: 5\n",
            "costo: 1.7631106175031164e-07\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 6\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 7\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 8\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 9\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 10\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 11\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 12\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 13\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 14\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 15\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 16\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 17\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 18\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 19\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 20\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 21\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 22\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 23\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 24\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 25\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 26\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 27\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 28\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 29\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 30\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 31\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 32\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 33\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 34\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 35\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 36\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 37\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 38\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 39\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 40\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 41\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 42\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 43\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 44\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 45\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 46\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 47\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 48\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 49\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 50\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 51\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 52\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 53\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 54\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 55\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 56\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 57\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 58\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 59\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 60\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 61\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 62\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 63\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 64\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 65\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 66\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 67\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 68\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 69\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 70\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 71\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 72\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 73\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 74\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 75\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 76\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 77\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 78\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 79\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 80\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 81\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 82\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 83\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 84\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 85\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 86\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 87\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 88\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 89\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 90\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 91\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 92\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 93\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 94\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 95\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 96\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 97\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 98\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 99\n",
            "costo: 1.0997627697406642e-07\n",
            "Iteracion: 0\n",
            "costo: 2.318939447402954\n",
            "costo: 2.317699909210205\n",
            "costo: 2.3168647289276123\n",
            "costo: 2.317234754562378\n",
            "costo: 2.317477226257324\n",
            "costo: 2.317131519317627\n",
            "costo: 2.3167381286621094\n",
            "costo: 2.317326307296753\n",
            "costo: 2.3172757625579834\n",
            "costo: 1.7406712770462036\n",
            "costo: 0.9314581751823425\n",
            "costo: 0.9247736930847168\n",
            "costo: 0.7357907891273499\n",
            "costo: 0.6836645603179932\n",
            "costo: 0.6541759967803955\n",
            "costo: 0.6170758008956909\n",
            "costo: 0.5721346735954285\n",
            "costo: 0.567305862903595\n",
            "costo: 0.4822378158569336\n",
            "costo: 0.4629586637020111\n",
            "costo: 0.4366186261177063\n",
            "costo: 0.40152308344841003\n",
            "costo: 0.3728272020816803\n",
            "costo: 0.3532804548740387\n",
            "costo: 0.3403126895427704\n",
            "Iteracion: 1\n",
            "costo: 0.31283387541770935\n",
            "costo: 0.2975114583969116\n",
            "costo: 0.2758014500141144\n",
            "costo: 0.25750958919525146\n",
            "costo: 0.24417611956596375\n",
            "costo: 0.23207324743270874\n",
            "costo: 0.21568933129310608\n",
            "costo: 0.20264339447021484\n",
            "costo: 0.19019876420497894\n",
            "costo: 0.18152333796024323\n",
            "costo: 0.17124955356121063\n",
            "costo: 0.1604515165090561\n",
            "costo: 0.14954011142253876\n",
            "costo: 0.14009036123752594\n",
            "costo: 0.1304413229227066\n",
            "costo: 0.12174008786678314\n",
            "costo: 0.11266128718852997\n",
            "costo: 0.1082126572728157\n",
            "costo: 0.10249850898981094\n",
            "costo: 0.09605789184570312\n",
            "costo: 0.08956164866685867\n",
            "Iteracion: 2\n",
            "costo: 0.08956164866685867\n",
            "costo: 0.08249427378177643\n",
            "costo: 0.07909324020147324\n",
            "costo: 0.07499291747808456\n",
            "costo: 0.06982164829969406\n",
            "costo: 0.06623862683773041\n",
            "costo: 0.05945665016770363\n",
            "costo: 0.05865570902824402\n",
            "costo: 0.055073123425245285\n",
            "costo: 0.05064137279987335\n",
            "costo: 0.04724878817796707\n",
            "costo: 0.04354814067482948\n",
            "costo: 0.03951252996921539\n",
            "costo: 0.03662632405757904\n",
            "costo: 0.034210167825222015\n",
            "costo: 0.03160201013088226\n",
            "costo: 0.029815485700964928\n",
            "costo: 0.026786893606185913\n",
            "costo: 0.023680314421653748\n",
            "costo: 0.023295901715755463\n",
            "costo: 0.02155599184334278\n",
            "costo: 0.01939285360276699\n",
            "costo: 0.017763419076800346\n",
            "Iteracion: 3\n",
            "costo: 0.017763419076800346\n",
            "costo: 0.015545087866485119\n",
            "costo: 0.013056037947535515\n",
            "costo: 0.010812365449965\n",
            "costo: 0.009937127120792866\n",
            "costo: 0.008527928031980991\n",
            "costo: 0.007082573138177395\n",
            "costo: 0.005519617814570665\n",
            "costo: 0.004663232713937759\n",
            "costo: 0.0040051983669400215\n",
            "costo: 0.003344530938193202\n",
            "costo: 0.0026854968164116144\n",
            "costo: 0.0021771506872028112\n",
            "costo: 0.0017087843734771013\n",
            "costo: 0.0014232847606763244\n",
            "costo: 0.0011266188230365515\n",
            "costo: 0.0008282086346298456\n",
            "costo: 0.0007041501812636852\n",
            "costo: 0.0005447228904813528\n",
            "costo: 0.0005068934988230467\n",
            "costo: 0.0003812588984146714\n",
            "Iteracion: 4\n",
            "costo: 0.0003812588984146714\n",
            "costo: 0.00034190129372291267\n",
            "costo: 0.0002821848029270768\n",
            "costo: 0.0002149238425772637\n",
            "costo: 0.0001264399179490283\n",
            "costo: 0.00013575064076576382\n",
            "costo: 9.12773102754727e-05\n",
            "costo: 6.484403274953365e-05\n",
            "costo: 4.9187990953214467e-05\n",
            "costo: 3.626261604949832e-05\n",
            "costo: 2.649705857038498e-05\n",
            "costo: 2.0512692572083324e-05\n",
            "costo: 1.7647800632403232e-05\n",
            "costo: 1.2568378224386834e-05\n",
            "costo: 1.0532778105698526e-05\n",
            "costo: 6.928746643097838e-06\n",
            "costo: 5.756121936428826e-06\n",
            "costo: 4.094240466656629e-06\n",
            "costo: 2.713068397497409e-06\n",
            "costo: 1.5979079535100027e-06\n",
            "costo: 1.1503109362820396e-06\n",
            "costo: 8.237287261181336e-07\n",
            "Iteracion: 5\n",
            "costo: 8.237287261181336e-07\n",
            "costo: 5.833913974129246e-07\n",
            "costo: 3.099079037838237e-07\n",
            "costo: 2.446111579956778e-07\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 6\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 7\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 8\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 9\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 10\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 11\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 12\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 13\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 14\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 15\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 16\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 17\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 18\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 19\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 20\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 21\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 22\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 23\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 24\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 25\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 26\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 27\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 28\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 29\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 30\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 31\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 32\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 33\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 34\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 35\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 36\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 37\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 38\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 39\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 40\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 41\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 42\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 43\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 44\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 45\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 46\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 47\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 48\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 49\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 50\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 51\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 52\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 53\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 54\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 55\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 56\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 57\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 58\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 59\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 60\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 61\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 62\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 63\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 64\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 65\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 66\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 67\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 68\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 69\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 70\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 71\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 72\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 73\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 74\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 75\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 76\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 77\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 78\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 79\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 80\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 81\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 82\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 83\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 84\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 85\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 86\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 87\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 88\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 89\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 90\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 91\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 92\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 93\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 94\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 95\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 96\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 97\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 98\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 99\n",
            "costo: 1.515105623184354e-07\n",
            "Iteracion: 0\n",
            "costo: 2.3252322673797607\n",
            "costo: 2.3248848915100098\n",
            "costo: 2.3204329013824463\n",
            "costo: 2.29529070854187\n",
            "costo: 2.2131571769714355\n",
            "costo: 1.8453747034072876\n",
            "costo: 0.9917942881584167\n",
            "costo: 4.020241737365723\n",
            "costo: 0.7883846163749695\n",
            "costo: 0.755700945854187\n",
            "costo: 0.7187801003456116\n",
            "costo: 0.6781354546546936\n",
            "costo: 0.6577349901199341\n",
            "costo: 0.6135319471359253\n",
            "costo: 0.5807570219039917\n",
            "costo: 0.6390300989151001\n",
            "costo: 0.5477533340454102\n",
            "costo: 0.48751208186149597\n",
            "costo: 0.46488675475120544\n",
            "costo: 0.4268127679824829\n",
            "costo: 0.39388787746429443\n",
            "costo: 0.360696941614151\n",
            "costo: 0.34304898977279663\n",
            "costo: 0.3314598500728607\n",
            "costo: 0.3115280568599701\n",
            "Iteracion: 1\n",
            "costo: 0.28177231550216675\n",
            "costo: 0.2682899534702301\n",
            "costo: 0.25223538279533386\n",
            "costo: 0.24121150374412537\n",
            "costo: 0.23062968254089355\n",
            "costo: 0.21670101583003998\n",
            "costo: 0.20019878447055817\n",
            "costo: 0.1918267160654068\n",
            "costo: 0.17865461111068726\n",
            "costo: 0.1703493893146515\n",
            "costo: 0.16363216936588287\n",
            "costo: 0.15478231012821198\n",
            "costo: 0.1476583033800125\n",
            "costo: 0.13477790355682373\n",
            "costo: 0.1364961564540863\n",
            "costo: 0.12663410604000092\n",
            "costo: 0.11751775443553925\n",
            "costo: 0.11077766865491867\n",
            "costo: 0.10101990401744843\n",
            "costo: 0.09509676694869995\n",
            "costo: 0.08985892683267593\n",
            "costo: 0.08624689280986786\n",
            "Iteracion: 2\n",
            "costo: 0.08624689280986786\n",
            "costo: 0.08039339631795883\n",
            "costo: 0.07229319214820862\n",
            "costo: 0.07839620113372803\n",
            "costo: 0.06834903359413147\n",
            "costo: 0.06443076580762863\n",
            "costo: 0.06065169349312782\n",
            "costo: 0.05566355586051941\n",
            "costo: 0.053644731640815735\n",
            "costo: 0.04715098813176155\n",
            "costo: 0.044789861887693405\n",
            "costo: 0.041007332503795624\n",
            "costo: 0.03875713795423508\n",
            "costo: 0.03460191190242767\n",
            "costo: 0.03274461254477501\n",
            "costo: 0.030741095542907715\n",
            "costo: 0.02738439477980137\n",
            "costo: 0.027268730103969574\n",
            "costo: 0.02488086186349392\n",
            "costo: 0.0210654865950346\n",
            "costo: 0.019221479073166847\n",
            "costo: 0.017326533794403076\n",
            "costo: 0.015484306961297989\n",
            "Iteracion: 3\n",
            "costo: 0.015484306961297989\n",
            "costo: 0.013492128811776638\n",
            "costo: 0.011633324436843395\n",
            "costo: 0.009871033020317554\n",
            "costo: 0.008761282078921795\n",
            "costo: 0.007598291151225567\n",
            "costo: 0.006688167341053486\n",
            "costo: 0.005425905343145132\n",
            "costo: 0.006006154231727123\n",
            "costo: 0.004782075062394142\n",
            "costo: 0.00370202399790287\n",
            "costo: 0.0030692629516124725\n",
            "costo: 0.0024332485627382994\n",
            "costo: 0.001879344810731709\n",
            "costo: 0.0014193652896210551\n",
            "costo: 0.0012039690045639873\n",
            "costo: 0.0008635909180156887\n",
            "costo: 0.0006359022809192538\n",
            "costo: 0.000536384410224855\n",
            "costo: 0.0004032498982269317\n",
            "costo: 0.00029425136744976044\n",
            "costo: 0.0002442591357976198\n",
            "Iteracion: 4\n",
            "costo: 0.0002442591357976198\n",
            "costo: 0.00017016593483276665\n",
            "costo: 0.00010986960114678368\n",
            "costo: 8.717544551473111e-05\n",
            "costo: 7.274838571902364e-05\n",
            "costo: 5.296721792547032e-05\n",
            "costo: 3.677620770758949e-05\n",
            "costo: 2.261203007947188e-05\n",
            "costo: 1.745548979670275e-05\n",
            "costo: 1.2087037248420529e-05\n",
            "costo: 7.881578312662896e-06\n",
            "costo: 4.6987011046439875e-06\n",
            "costo: 2.9586119580926606e-06\n",
            "costo: 1.980689830816118e-06\n",
            "costo: 1.2865838243669714e-06\n",
            "costo: 7.082707611516526e-07\n",
            "costo: 5.072204203315778e-07\n",
            "costo: 3.0432204312091926e-07\n",
            "costo: 1.8530560907947802e-07\n",
            "costo: 1.2242115587923763e-07\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 5\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 6\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 7\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 8\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 9\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 10\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 11\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 12\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 13\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 14\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 15\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 16\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 17\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 18\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 19\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 20\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 21\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 22\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 23\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 24\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 25\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 26\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 27\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 28\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 29\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 30\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 31\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 32\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 33\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 34\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 35\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 36\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 37\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 38\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 39\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 40\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 41\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 42\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 43\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 44\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 45\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 46\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 47\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 48\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 49\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 50\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 51\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 52\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 53\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 54\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 55\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 56\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 57\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 58\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 59\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 60\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 61\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 62\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 63\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 64\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 65\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 66\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 67\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 68\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 69\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 70\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 71\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 72\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 73\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 74\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 75\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 76\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 77\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 78\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 79\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 80\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 81\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 82\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 83\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 84\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 85\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 86\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 87\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 88\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 89\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 90\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 91\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 92\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 93\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 94\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 95\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 96\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 97\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 98\n",
            "costo: 7.2509550363975e-08\n",
            "Iteracion: 99\n",
            "costo: 7.2509550363975e-08\n"
          ]
        }
      ],
      "source": [
        "resultados['lbfgs_ls'] = {}\n",
        "resultados['lbfgs_ls']['val_acc_list'] = [0] * epochs\n",
        "resultados['lbfgs_ls']['test_acc'] = 0\n",
        "resultados['lbfgs_ls']['cost'] = [0] * epochs\n",
        "resultados['lbfgs_ls']['time'] = 0\n",
        "resultados['lbfgs_ls']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    lbfgs_ls_acc_list, lbfgs_ls_cost_list, lbfgs_ls_lr_list ,lbfgs_ls_time, lbfgs_ls_acc, lbfgs_ls_epochs, iteraciones_lbfgs_ls = LBFGS_LS()\n",
        "    resultados['lbfgs_ls']['val_acc_list'] = SumList(resultados['lbfgs_ls']['val_acc_list'], lbfgs_ls_acc_list)\n",
        "    resultados['lbfgs_ls']['test_acc'] += lbfgs_ls_acc\n",
        "    resultados['lbfgs_ls']['cost'] = SumList(resultados['lbfgs_ls']['cost'], lbfgs_ls_cost_list)\n",
        "    resultados['lbfgs_ls']['time'] += lbfgs_ls_time\n",
        "    resultados['lbfgs_ls']['epochs'] += lbfgs_ls_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['lbfgs_ls']['name'] = 'LBFGS With LS'\n",
        "resultados['lbfgs_ls']['lr'] = lbfgs_ls_lr_list\n",
        "resultados['lbfgs_ls']['test_acc'] = resultados['lbfgs_ls']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['lbfgs_ls']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['lbfgs_ls']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['lbfgs_ls']['cost'] = DeleteZerosFromList(DivideList(resultados['lbfgs_ls']['cost'], MAX_ITERATIONS))\n",
        "resultados['lbfgs_ls']['time'] = resultados['lbfgs_ls']['time'] / MAX_ITERATIONS\n",
        "resultados['lbfgs_ls']['epochs'] = resultados['lbfgs_ls']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhXFwQqymLvv"
      },
      "source": [
        "## Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSLpyoyDiIj1"
      },
      "source": [
        "$\\alpha: 1x10^{-2}$ \n",
        "\n",
        "$beta1: 0.9$\n",
        "\n",
        "$beta2: 0.999$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8Z9uCM6afGaa"
      },
      "outputs": [],
      "source": [
        "def Adam():\n",
        "    modelAdam = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimiserAdam = torch.optim.Adam(modelAdam.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "    start.record()\n",
        "    adam_acc_list, adam_cost_list,adam_lr_list, adam_epochs = train(modelAdam,optimiserAdam,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    adam_time = start.elapsed_time(end)\n",
        "\n",
        "    adam_acc = accuracy(modelAdam, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return adam_acc_list, adam_cost_list, adam_lr_list, adam_time, adam_acc, adam_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZeKlCWWmNpH",
        "outputId": "d1a8f640-61a9-4af7-a708-6a2367ad1b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:0.01,costo: 0.8952559232711792, accuracy: 0.7939453125\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.4399622678756714, accuracy: 0.92236328125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.2472192496061325, accuracy: 0.945556640625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.255056768655777, accuracy: 0.9599609375\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.18355566263198853, accuracy: 0.960693359375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.15914031863212585, accuracy: 0.968017578125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.12116514146327972, accuracy: 0.96337890625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.13154694437980652, accuracy: 0.971923828125\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.11823759973049164, accuracy: 0.96826171875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.1351875513792038, accuracy: 0.97021484375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.11879081279039383, accuracy: 0.9716796875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.08971110731363297, accuracy: 0.97412109375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.1093442291021347, accuracy: 0.97412109375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.09642506390810013, accuracy: 0.978515625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.0780882015824318, accuracy: 0.9755859375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.06606444716453552, accuracy: 0.97314453125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.11316604167222977, accuracy: 0.97412109375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.0836775079369545, accuracy: 0.97314453125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.1121026873588562, accuracy: 0.975341796875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.07876239717006683, accuracy: 0.97265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.06662918627262115, accuracy: 0.977294921875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.08481928706169128, accuracy: 0.972900390625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.10056161880493164, accuracy: 0.973876953125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.10001704096794128, accuracy: 0.974609375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.09800062328577042, accuracy: 0.9765625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.05557115748524666, accuracy: 0.970703125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.07944869250059128, accuracy: 0.975341796875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.08196592330932617, accuracy: 0.974609375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.051150932908058167, accuracy: 0.9736328125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.053697504103183746, accuracy: 0.976318359375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.06882376968860626, accuracy: 0.977294921875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.07257835566997528, accuracy: 0.97705078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.04243612661957741, accuracy: 0.981201171875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.07194066792726517, accuracy: 0.97802734375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.0864211767911911, accuracy: 0.97900390625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.09044160693883896, accuracy: 0.977294921875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.07543158531188965, accuracy: 0.97802734375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.05953262001276016, accuracy: 0.978271484375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.08706003427505493, accuracy: 0.974609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.05944226309657097, accuracy: 0.9765625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.09445478022098541, accuracy: 0.977783203125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.046910930424928665, accuracy: 0.9765625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.05464645102620125, accuracy: 0.977783203125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.047462135553359985, accuracy: 0.980224609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.050293222069740295, accuracy: 0.978271484375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.049172863364219666, accuracy: 0.975830078125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.05035801976919174, accuracy: 0.97802734375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.08679661899805069, accuracy: 0.974365234375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.034986525774002075, accuracy: 0.977783203125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.04812585189938545, accuracy: 0.97509765625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.0317174457013607, accuracy: 0.97705078125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.06885910779237747, accuracy: 0.9736328125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.04540369287133217, accuracy: 0.975341796875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.04936572164297104, accuracy: 0.975830078125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.033687129616737366, accuracy: 0.97314453125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.050044238567352295, accuracy: 0.97314453125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.042081017047166824, accuracy: 0.973876953125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.0690922886133194, accuracy: 0.9755859375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.03466315567493439, accuracy: 0.977294921875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.04072774574160576, accuracy: 0.9775390625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.03056340105831623, accuracy: 0.977783203125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.042549408972263336, accuracy: 0.975830078125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.04944923520088196, accuracy: 0.97314453125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.04243713617324829, accuracy: 0.97412109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.055157992988824844, accuracy: 0.976318359375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.055022258311510086, accuracy: 0.978515625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.06132286787033081, accuracy: 0.971923828125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.06670600175857544, accuracy: 0.9736328125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.02603273279964924, accuracy: 0.979736328125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.043432772159576416, accuracy: 0.9775390625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.03832785040140152, accuracy: 0.97705078125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.04063796252012253, accuracy: 0.977783203125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.041399676352739334, accuracy: 0.978271484375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.04582894966006279, accuracy: 0.9775390625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.030463848263025284, accuracy: 0.97802734375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.06286636739969254, accuracy: 0.97607421875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.045087169855833054, accuracy: 0.976806640625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.041067540645599365, accuracy: 0.975341796875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.02736479975283146, accuracy: 0.977294921875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.0648706927895546, accuracy: 0.974609375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.05205565690994263, accuracy: 0.97900390625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.041421063244342804, accuracy: 0.9765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.04647532477974892, accuracy: 0.97802734375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.04272892326116562, accuracy: 0.97265625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.05006038770079613, accuracy: 0.973876953125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.094845712184906, accuracy: 0.9775390625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.05241541191935539, accuracy: 0.976806640625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0922771766781807, accuracy: 0.976806640625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.038038499653339386, accuracy: 0.972900390625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.024379489943385124, accuracy: 0.970947265625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.04552624374628067, accuracy: 0.97265625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.04670540615916252, accuracy: 0.976318359375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.04410017281770706, accuracy: 0.976806640625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05321574583649635, accuracy: 0.97216796875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.049537915736436844, accuracy: 0.97607421875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06368238478899002, accuracy: 0.97900390625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.03529413789510727, accuracy: 0.975341796875\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.05406707525253296, accuracy: 0.977783203125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.04818911477923393, accuracy: 0.978759765625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.04273954778909683, accuracy: 0.973876953125\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.6554539799690247, accuracy: 0.87841796875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.3515855073928833, accuracy: 0.9365234375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.24109581112861633, accuracy: 0.954345703125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.21838559210300446, accuracy: 0.965087890625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.23328956961631775, accuracy: 0.965087890625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.17886266112327576, accuracy: 0.967529296875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.12618288397789001, accuracy: 0.97216796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.13381046056747437, accuracy: 0.967529296875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.11245553195476532, accuracy: 0.971435546875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.12067721039056778, accuracy: 0.970703125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.11009567975997925, accuracy: 0.97509765625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.11303727328777313, accuracy: 0.972900390625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.08445632457733154, accuracy: 0.97265625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.07694456726312637, accuracy: 0.97509765625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.09165002405643463, accuracy: 0.975830078125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.0720888301730156, accuracy: 0.970703125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.1262844055891037, accuracy: 0.97314453125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.1278925985097885, accuracy: 0.972900390625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.08727437257766724, accuracy: 0.97607421875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.10873732715845108, accuracy: 0.9765625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.0775536298751831, accuracy: 0.97509765625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.08882644027471542, accuracy: 0.9765625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.09247223287820816, accuracy: 0.973388671875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.08281941711902618, accuracy: 0.972900390625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.08308879286050797, accuracy: 0.976318359375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.08726072311401367, accuracy: 0.976318359375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.05635301023721695, accuracy: 0.977294921875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.06154848635196686, accuracy: 0.972900390625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.05953487753868103, accuracy: 0.977294921875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.05541626363992691, accuracy: 0.97607421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.07208678126335144, accuracy: 0.974365234375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.06507868319749832, accuracy: 0.977294921875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.06721635907888412, accuracy: 0.97705078125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.06732241809368134, accuracy: 0.977783203125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.0792599618434906, accuracy: 0.979736328125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.06687349826097488, accuracy: 0.974365234375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.052262358367443085, accuracy: 0.977294921875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.0702517181634903, accuracy: 0.978515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.0731261745095253, accuracy: 0.975341796875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.0654447004199028, accuracy: 0.972900390625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06495153903961182, accuracy: 0.975341796875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.053470976650714874, accuracy: 0.975341796875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.061312075704336166, accuracy: 0.976318359375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.08344576507806778, accuracy: 0.978515625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.0648985356092453, accuracy: 0.977294921875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.04359787702560425, accuracy: 0.975341796875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.06856773793697357, accuracy: 0.97607421875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.08988162875175476, accuracy: 0.977294921875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.061128176748752594, accuracy: 0.973876953125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.05067550018429756, accuracy: 0.978271484375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.05578567087650299, accuracy: 0.97900390625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.07713243365287781, accuracy: 0.977783203125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.04723895713686943, accuracy: 0.974853515625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.08609570562839508, accuracy: 0.97705078125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.050615739077329636, accuracy: 0.976318359375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.0491352304816246, accuracy: 0.97509765625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.041373662650585175, accuracy: 0.978759765625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.03719554468989372, accuracy: 0.974853515625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.06103886663913727, accuracy: 0.977294921875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.05339157208800316, accuracy: 0.976806640625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.0779712051153183, accuracy: 0.9765625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.05195796862244606, accuracy: 0.977294921875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.06852446496486664, accuracy: 0.977294921875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07496120780706406, accuracy: 0.9794921875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.07764596492052078, accuracy: 0.97998046875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.04551755636930466, accuracy: 0.980712890625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.08938636630773544, accuracy: 0.974853515625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.05001911148428917, accuracy: 0.97998046875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.03751126676797867, accuracy: 0.9765625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.07017216831445694, accuracy: 0.975341796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.06204861402511597, accuracy: 0.974365234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.06058966740965843, accuracy: 0.9765625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.045850176364183426, accuracy: 0.979248046875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.0449875108897686, accuracy: 0.9775390625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.03238534927368164, accuracy: 0.9775390625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.037118054926395416, accuracy: 0.98046875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.02797173522412777, accuracy: 0.975341796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.04418061673641205, accuracy: 0.97705078125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.03537902235984802, accuracy: 0.976318359375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.04624750092625618, accuracy: 0.973876953125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.04454851523041725, accuracy: 0.973876953125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09383591264486313, accuracy: 0.9755859375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08063948899507523, accuracy: 0.975830078125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.03597666323184967, accuracy: 0.978515625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.04734786972403526, accuracy: 0.977783203125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.056757502257823944, accuracy: 0.977294921875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07094568759202957, accuracy: 0.97509765625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0486280620098114, accuracy: 0.977783203125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.05703139305114746, accuracy: 0.979736328125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09084077924489975, accuracy: 0.97705078125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.0331641286611557, accuracy: 0.9755859375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05054115876555443, accuracy: 0.98046875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.04729384928941727, accuracy: 0.974853515625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.04380201920866966, accuracy: 0.975341796875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.039599835872650146, accuracy: 0.976806640625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.059231311082839966, accuracy: 0.976806640625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.044666510075330734, accuracy: 0.980712890625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.02364087849855423, accuracy: 0.97607421875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.04259438067674637, accuracy: 0.976806640625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.03705325722694397, accuracy: 0.976318359375\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.6410725712776184, accuracy: 0.85546875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.3597988188266754, accuracy: 0.927978515625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.281004935503006, accuracy: 0.94970703125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.24464182555675507, accuracy: 0.955322265625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.21354927122592926, accuracy: 0.964111328125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.15192171931266785, accuracy: 0.964599609375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.18009218573570251, accuracy: 0.9677734375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.1588171124458313, accuracy: 0.971435546875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.13189321756362915, accuracy: 0.970703125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.10978109389543533, accuracy: 0.971435546875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.15683872997760773, accuracy: 0.970458984375\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.13060103356838226, accuracy: 0.97119140625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.09221121668815613, accuracy: 0.9755859375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.10000160336494446, accuracy: 0.97509765625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.08689869940280914, accuracy: 0.97216796875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.09719088673591614, accuracy: 0.97216796875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.10276378691196442, accuracy: 0.977783203125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.08231691271066666, accuracy: 0.971923828125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.07582782208919525, accuracy: 0.973388671875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.12594866752624512, accuracy: 0.976806640625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.08595102280378342, accuracy: 0.97802734375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.08350560069084167, accuracy: 0.97509765625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.07775425165891647, accuracy: 0.971923828125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.08920401334762573, accuracy: 0.975341796875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.05847560986876488, accuracy: 0.976318359375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.043806105852127075, accuracy: 0.968994140625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.07529553771018982, accuracy: 0.974853515625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.0556667223572731, accuracy: 0.9755859375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.09786151349544525, accuracy: 0.97412109375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.058985017240047455, accuracy: 0.97607421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.057673901319503784, accuracy: 0.972900390625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.05255173146724701, accuracy: 0.979248046875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.06238412484526634, accuracy: 0.9755859375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.07629796862602234, accuracy: 0.97802734375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.05485996976494789, accuracy: 0.976318359375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.08691084384918213, accuracy: 0.975830078125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.06118015572428703, accuracy: 0.977783203125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.060089319944381714, accuracy: 0.974853515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.08505192399024963, accuracy: 0.978271484375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.06036239117383957, accuracy: 0.976318359375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06390060484409332, accuracy: 0.9755859375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.05629493668675423, accuracy: 0.977294921875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.03864232450723648, accuracy: 0.978515625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.05844767764210701, accuracy: 0.975341796875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.05114743486046791, accuracy: 0.981201171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.05183554068207741, accuracy: 0.9794921875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.07321389019489288, accuracy: 0.97509765625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.04258853569626808, accuracy: 0.97509765625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.04992011934518814, accuracy: 0.97802734375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.060460109263658524, accuracy: 0.97900390625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.05533524602651596, accuracy: 0.978271484375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.06408818066120148, accuracy: 0.97265625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.06880439072847366, accuracy: 0.976318359375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.07133515924215317, accuracy: 0.975341796875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.045721396803855896, accuracy: 0.978759765625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.041876569390296936, accuracy: 0.974853515625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.02847132831811905, accuracy: 0.977783203125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.045739538967609406, accuracy: 0.973876953125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.06925822049379349, accuracy: 0.978515625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.054680824279785156, accuracy: 0.9755859375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.05050600320100784, accuracy: 0.97998046875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.044039350003004074, accuracy: 0.977294921875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.08560971170663834, accuracy: 0.97900390625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07131680846214294, accuracy: 0.977294921875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.06242756173014641, accuracy: 0.978515625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.08591576665639877, accuracy: 0.9755859375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.03612629324197769, accuracy: 0.97509765625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.06919676065444946, accuracy: 0.9765625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.05052172392606735, accuracy: 0.97802734375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.05225246772170067, accuracy: 0.97314453125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.045406583696603775, accuracy: 0.977783203125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.03280041739344597, accuracy: 0.976806640625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.049759261310100555, accuracy: 0.974365234375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.0338788777589798, accuracy: 0.978515625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.038855139166116714, accuracy: 0.977294921875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.03571322560310364, accuracy: 0.97900390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.030101604759693146, accuracy: 0.980712890625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.026318464428186417, accuracy: 0.974853515625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.06215394660830498, accuracy: 0.979248046875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.052047159522771835, accuracy: 0.975341796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.06447550654411316, accuracy: 0.974609375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07572620362043381, accuracy: 0.976318359375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.061551593244075775, accuracy: 0.97607421875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.0441264733672142, accuracy: 0.976318359375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.044905222952365875, accuracy: 0.978515625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.039339564740657806, accuracy: 0.979248046875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.04590669646859169, accuracy: 0.9716796875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.06573651731014252, accuracy: 0.978271484375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.05979960039258003, accuracy: 0.975341796875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07355380058288574, accuracy: 0.97998046875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.05058879777789116, accuracy: 0.975341796875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07075387984514236, accuracy: 0.975830078125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.03874726966023445, accuracy: 0.978515625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0614541657269001, accuracy: 0.979248046875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.03658336400985718, accuracy: 0.976806640625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.05607149749994278, accuracy: 0.9775390625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.04924716055393219, accuracy: 0.97998046875\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.08164012432098389, accuracy: 0.9794921875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.0564165934920311, accuracy: 0.975341796875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0690251812338829, accuracy: 0.97900390625\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.7377825975418091, accuracy: 0.87158203125\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.41873252391815186, accuracy: 0.925048828125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.2723682224750519, accuracy: 0.94140625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.23021133244037628, accuracy: 0.95654296875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.16487093269824982, accuracy: 0.9677734375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.18065059185028076, accuracy: 0.961181640625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.19546541571617126, accuracy: 0.9677734375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.16579723358154297, accuracy: 0.96337890625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.12691573798656464, accuracy: 0.96630859375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.11720118671655655, accuracy: 0.9697265625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.11244344711303711, accuracy: 0.9658203125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.13328330218791962, accuracy: 0.96826171875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.10108975321054459, accuracy: 0.97021484375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.08662053197622299, accuracy: 0.969970703125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.0787733942270279, accuracy: 0.970458984375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.11332162469625473, accuracy: 0.972412109375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.10698932409286499, accuracy: 0.970947265625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.11411145329475403, accuracy: 0.97119140625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.1292528659105301, accuracy: 0.974609375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.11628132313489914, accuracy: 0.974609375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.10133977234363556, accuracy: 0.97021484375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.05705674737691879, accuracy: 0.9736328125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.0821332335472107, accuracy: 0.97509765625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.07557640224695206, accuracy: 0.973876953125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.06362274289131165, accuracy: 0.974853515625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.0911739394068718, accuracy: 0.973876953125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.10832006484270096, accuracy: 0.97607421875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.08767417818307877, accuracy: 0.971435546875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.07511589676141739, accuracy: 0.974853515625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.08648765087127686, accuracy: 0.97412109375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.08730346709489822, accuracy: 0.97216796875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.09276159107685089, accuracy: 0.971435546875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.1092851385474205, accuracy: 0.974609375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.053560107946395874, accuracy: 0.9716796875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.06720270961523056, accuracy: 0.975830078125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.07331684976816177, accuracy: 0.974365234375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.07715055346488953, accuracy: 0.97314453125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.05505584925413132, accuracy: 0.976806640625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.06537067890167236, accuracy: 0.974365234375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.09047126024961472, accuracy: 0.97705078125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.10223637521266937, accuracy: 0.976318359375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.0721128061413765, accuracy: 0.97216796875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.05454143509268761, accuracy: 0.978271484375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.03606632724404335, accuracy: 0.976806640625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.05713347718119621, accuracy: 0.97509765625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.08392763882875443, accuracy: 0.973388671875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.053573839366436005, accuracy: 0.97314453125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.07857604324817657, accuracy: 0.9775390625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.05552433431148529, accuracy: 0.975341796875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.04030473902821541, accuracy: 0.9775390625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.050447188317775726, accuracy: 0.976318359375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.04731505364179611, accuracy: 0.973388671875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.032590147107839584, accuracy: 0.97412109375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.04567679390311241, accuracy: 0.974609375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.05500934645533562, accuracy: 0.97998046875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.04821837693452835, accuracy: 0.975341796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.06333068758249283, accuracy: 0.9755859375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.05216185376048088, accuracy: 0.97412109375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.0636073499917984, accuracy: 0.97412109375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.06609620153903961, accuracy: 0.977783203125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.04506911337375641, accuracy: 0.9736328125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.05749659985303879, accuracy: 0.976806640625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.04336118325591087, accuracy: 0.978271484375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.03767785802483559, accuracy: 0.9736328125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.04988003522157669, accuracy: 0.972412109375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.054825559258461, accuracy: 0.973876953125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.06159958243370056, accuracy: 0.974609375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.05418003723025322, accuracy: 0.97998046875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.04099337384104729, accuracy: 0.9775390625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.05223846063017845, accuracy: 0.974853515625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.042511265724897385, accuracy: 0.974365234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.040238991379737854, accuracy: 0.974365234375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.0215581227093935, accuracy: 0.976318359375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.06496075540781021, accuracy: 0.97607421875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.0529785118997097, accuracy: 0.977294921875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.043405357748270035, accuracy: 0.974609375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.03538798913359642, accuracy: 0.978759765625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.06383469700813293, accuracy: 0.97412109375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.055539004504680634, accuracy: 0.9833984375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.03664841875433922, accuracy: 0.9755859375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.04875417426228523, accuracy: 0.979248046875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.04216356948018074, accuracy: 0.976806640625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.0696413666009903, accuracy: 0.973876953125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.058112554252147675, accuracy: 0.97802734375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.05445075035095215, accuracy: 0.975830078125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05101098492741585, accuracy: 0.978271484375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.03317387029528618, accuracy: 0.96875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.061847150325775146, accuracy: 0.970947265625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.042786382138729095, accuracy: 0.97705078125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.04214056208729744, accuracy: 0.974609375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.05169675499200821, accuracy: 0.97119140625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.03833238407969475, accuracy: 0.974853515625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06961113214492798, accuracy: 0.976806640625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05958567559719086, accuracy: 0.975830078125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.036159344017505646, accuracy: 0.97412109375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.04535455256700516, accuracy: 0.9794921875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.05690312385559082, accuracy: 0.9765625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.05151565000414848, accuracy: 0.976806640625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.048576079308986664, accuracy: 0.977294921875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.03933349996805191, accuracy: 0.974365234375\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.6798023581504822, accuracy: 0.8701171875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.34991905093193054, accuracy: 0.935302734375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.23363283276557922, accuracy: 0.955078125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.22525343298912048, accuracy: 0.95849609375\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.20164763927459717, accuracy: 0.965576171875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.18541985750198364, accuracy: 0.96337890625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.1515491008758545, accuracy: 0.9677734375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.11372752487659454, accuracy: 0.972900390625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.1652757227420807, accuracy: 0.968017578125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.11263509094715118, accuracy: 0.9697265625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.14272332191467285, accuracy: 0.97314453125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.1069963276386261, accuracy: 0.971435546875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.12186050415039062, accuracy: 0.971923828125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.1126229465007782, accuracy: 0.973388671875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.09959139674901962, accuracy: 0.97119140625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.12042871862649918, accuracy: 0.97216796875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.07949968427419662, accuracy: 0.969970703125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.08198607712984085, accuracy: 0.97216796875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.09240171313285828, accuracy: 0.9736328125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.08300187438726425, accuracy: 0.971435546875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.07962340116500854, accuracy: 0.9755859375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.11813090741634369, accuracy: 0.97216796875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.0575980618596077, accuracy: 0.97216796875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.08920343965291977, accuracy: 0.9716796875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.05386929214000702, accuracy: 0.9677734375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.08888909220695496, accuracy: 0.97705078125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.09722515195608139, accuracy: 0.9716796875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.09973429888486862, accuracy: 0.96923828125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.07989190518856049, accuracy: 0.977783203125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.06941376626491547, accuracy: 0.9736328125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.11065028607845306, accuracy: 0.976318359375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.05482509359717369, accuracy: 0.97412109375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.06951768696308136, accuracy: 0.97314453125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.05759120732545853, accuracy: 0.976806640625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.06237877532839775, accuracy: 0.974609375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.08018697053194046, accuracy: 0.978271484375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.03731195256114006, accuracy: 0.97705078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.05316454544663429, accuracy: 0.9765625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.06141282990574837, accuracy: 0.972900390625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.04233759641647339, accuracy: 0.973876953125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.07342930883169174, accuracy: 0.974853515625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.057974230498075485, accuracy: 0.9716796875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.07211650162935257, accuracy: 0.978759765625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.05265498533844948, accuracy: 0.974609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.06000184267759323, accuracy: 0.97216796875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.0520075298845768, accuracy: 0.97314453125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.05164329335093498, accuracy: 0.972900390625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.04982515051960945, accuracy: 0.97705078125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.050467874854803085, accuracy: 0.97265625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.0360000841319561, accuracy: 0.969970703125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.06591639667749405, accuracy: 0.973388671875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.07277713716030121, accuracy: 0.97802734375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.040507808327674866, accuracy: 0.974365234375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.04995260015130043, accuracy: 0.974365234375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.07540947943925858, accuracy: 0.978271484375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.08669787645339966, accuracy: 0.97314453125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.03534075245261192, accuracy: 0.9765625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.06049268692731857, accuracy: 0.976318359375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.05575832352042198, accuracy: 0.9736328125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.05546990782022476, accuracy: 0.97509765625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.04173929616808891, accuracy: 0.97802734375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.047216884791851044, accuracy: 0.972900390625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.08460652083158493, accuracy: 0.971923828125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.05162283033132553, accuracy: 0.9765625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.07961048185825348, accuracy: 0.978515625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.06458346545696259, accuracy: 0.9755859375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.04060890153050423, accuracy: 0.971435546875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.06580306589603424, accuracy: 0.980224609375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.04025392234325409, accuracy: 0.970703125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.037709791213274, accuracy: 0.97509765625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.04538973048329353, accuracy: 0.97509765625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.03765546903014183, accuracy: 0.974853515625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.045475393533706665, accuracy: 0.973876953125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.046809203922748566, accuracy: 0.97607421875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.05098168924450874, accuracy: 0.973876953125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.04635730758309364, accuracy: 0.97509765625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.06316517293453217, accuracy: 0.977294921875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.07008519023656845, accuracy: 0.971923828125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.051788195967674255, accuracy: 0.977783203125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.05500509589910507, accuracy: 0.978515625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.05566330626606941, accuracy: 0.974365234375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.053579170256853104, accuracy: 0.97705078125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.07357846200466156, accuracy: 0.97265625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.042169153690338135, accuracy: 0.97509765625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07974763959646225, accuracy: 0.977294921875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.024871591478586197, accuracy: 0.976806640625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.049594469368457794, accuracy: 0.976806640625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.050062522292137146, accuracy: 0.97607421875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.04981718957424164, accuracy: 0.97900390625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.039983127266168594, accuracy: 0.9794921875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.059538450092077255, accuracy: 0.97607421875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07190097123384476, accuracy: 0.97607421875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.05168723687529564, accuracy: 0.97900390625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.04219239205121994, accuracy: 0.972412109375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.026936626061797142, accuracy: 0.979248046875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.04023338854312897, accuracy: 0.98046875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.013173825107514858, accuracy: 0.977783203125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.04668888822197914, accuracy: 0.97802734375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.046178072690963745, accuracy: 0.974609375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06151439994573593, accuracy: 0.97802734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.8933236598968506, accuracy: 0.846435546875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.4469015300273895, accuracy: 0.925537109375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.3291148543357849, accuracy: 0.93896484375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.24724864959716797, accuracy: 0.95458984375\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.21590347588062286, accuracy: 0.95556640625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.20153315365314484, accuracy: 0.9658203125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.1669127494096756, accuracy: 0.963623046875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.1621752828359604, accuracy: 0.964599609375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.17194610834121704, accuracy: 0.96337890625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.11560025066137314, accuracy: 0.9697265625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.1343400478363037, accuracy: 0.965576171875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.12773758172988892, accuracy: 0.97412109375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.1384807527065277, accuracy: 0.968505859375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.09587763249874115, accuracy: 0.969482421875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.11023266613483429, accuracy: 0.973388671875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.11449936777353287, accuracy: 0.970458984375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.09295766055583954, accuracy: 0.9697265625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.13098424673080444, accuracy: 0.971923828125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.10579515248537064, accuracy: 0.96923828125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.0733719915151596, accuracy: 0.969482421875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.12253747135400772, accuracy: 0.966552734375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.07699291408061981, accuracy: 0.9736328125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.11621198803186417, accuracy: 0.973876953125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.10546905547380447, accuracy: 0.97607421875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.09347105771303177, accuracy: 0.969970703125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.09545760601758957, accuracy: 0.971923828125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.10820822417736053, accuracy: 0.97705078125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.09980126470327377, accuracy: 0.9736328125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.08396374434232712, accuracy: 0.974609375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.09037330001592636, accuracy: 0.9736328125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.060467429459095, accuracy: 0.9716796875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.08553037792444229, accuracy: 0.97021484375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.07320566475391388, accuracy: 0.97314453125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.054728321731090546, accuracy: 0.97021484375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.08095704019069672, accuracy: 0.972900390625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.055618591606616974, accuracy: 0.975341796875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.07907448709011078, accuracy: 0.974365234375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.0633670762181282, accuracy: 0.97216796875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.05525261163711548, accuracy: 0.969970703125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.07381603866815567, accuracy: 0.974609375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06743402034044266, accuracy: 0.975830078125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.08786027878522873, accuracy: 0.973388671875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.06922315806150436, accuracy: 0.972412109375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.10455919802188873, accuracy: 0.979248046875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.08383561670780182, accuracy: 0.972412109375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.057299356907606125, accuracy: 0.97412109375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.07257172465324402, accuracy: 0.975341796875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.09062355756759644, accuracy: 0.971923828125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.0669594332575798, accuracy: 0.977294921875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.06594828516244888, accuracy: 0.97412109375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.0525282546877861, accuracy: 0.977294921875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.057480957359075546, accuracy: 0.978515625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.07649602741003036, accuracy: 0.97119140625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.07310358434915543, accuracy: 0.9755859375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.06590645015239716, accuracy: 0.97802734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.054372020065784454, accuracy: 0.974609375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.07893296331167221, accuracy: 0.97314453125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.09270874410867691, accuracy: 0.972412109375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.05572102218866348, accuracy: 0.972900390625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.05119797959923744, accuracy: 0.97509765625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.06770600378513336, accuracy: 0.979248046875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.0956636443734169, accuracy: 0.976806640625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.05712854489684105, accuracy: 0.97900390625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07739007472991943, accuracy: 0.97216796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.04348306357860565, accuracy: 0.97216796875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.05965796858072281, accuracy: 0.975830078125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.05936791002750397, accuracy: 0.97412109375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.057633206248283386, accuracy: 0.9775390625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.05954473465681076, accuracy: 0.9765625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.07836458086967468, accuracy: 0.973388671875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.04049190133810043, accuracy: 0.9765625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.07865103334188461, accuracy: 0.97314453125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.059206511825323105, accuracy: 0.974609375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.0698641911149025, accuracy: 0.97412109375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.07420941442251205, accuracy: 0.977783203125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.038382306694984436, accuracy: 0.9716796875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.02677597850561142, accuracy: 0.977783203125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.06891875714063644, accuracy: 0.977783203125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.060479722917079926, accuracy: 0.974609375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.06296484172344208, accuracy: 0.975341796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.0786551982164383, accuracy: 0.97705078125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.047754574567079544, accuracy: 0.973876953125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.04642658680677414, accuracy: 0.978515625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.03723584860563278, accuracy: 0.977783203125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06218220293521881, accuracy: 0.974365234375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07707000523805618, accuracy: 0.978515625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.04458446428179741, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.026707148179411888, accuracy: 0.9775390625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.04216265678405762, accuracy: 0.976318359375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07203773409128189, accuracy: 0.97705078125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.04985335096716881, accuracy: 0.97412109375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05742355063557625, accuracy: 0.9794921875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06014763563871384, accuracy: 0.9736328125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.03754713013768196, accuracy: 0.978759765625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.02827380783855915, accuracy: 0.977783203125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.04740084335207939, accuracy: 0.97119140625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.09615682810544968, accuracy: 0.9765625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06364157050848007, accuracy: 0.978759765625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.044836584478616714, accuracy: 0.975341796875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.040458887815475464, accuracy: 0.97509765625\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.7957720756530762, accuracy: 0.843994140625\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.364454984664917, accuracy: 0.923583984375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.23400220274925232, accuracy: 0.94140625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.19737349450588226, accuracy: 0.957763671875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.1978049874305725, accuracy: 0.963623046875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.19240155816078186, accuracy: 0.966064453125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.15678490698337555, accuracy: 0.96435546875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.15214556455612183, accuracy: 0.965576171875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.10122594982385635, accuracy: 0.969970703125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.15188607573509216, accuracy: 0.97265625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.14272227883338928, accuracy: 0.9716796875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.11180626600980759, accuracy: 0.97216796875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.12090092897415161, accuracy: 0.975341796875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.11063202470541, accuracy: 0.9736328125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.10553014278411865, accuracy: 0.971923828125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.09644903242588043, accuracy: 0.970947265625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.10882382839918137, accuracy: 0.9736328125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.09807128459215164, accuracy: 0.969482421875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.082199327647686, accuracy: 0.976318359375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.11302509158849716, accuracy: 0.972900390625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.09375102818012238, accuracy: 0.972900390625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.10771357268095016, accuracy: 0.9755859375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.12315975874662399, accuracy: 0.972412109375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.0694558322429657, accuracy: 0.972900390625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.08363156020641327, accuracy: 0.972900390625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.08460720628499985, accuracy: 0.977783203125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.1100866049528122, accuracy: 0.974853515625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.051763225346803665, accuracy: 0.9765625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.07545677572488785, accuracy: 0.97607421875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.04117126017808914, accuracy: 0.977294921875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.06665974855422974, accuracy: 0.97412109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.07825081050395966, accuracy: 0.972900390625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.07541361451148987, accuracy: 0.977783203125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.07458792626857758, accuracy: 0.9736328125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.06570561975240707, accuracy: 0.9775390625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.05762472376227379, accuracy: 0.978271484375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.06523604691028595, accuracy: 0.974365234375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.05225097015500069, accuracy: 0.974365234375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.0951814278960228, accuracy: 0.974609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13022711873054504, accuracy: 0.978271484375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.05173209309577942, accuracy: 0.9775390625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.11401276290416718, accuracy: 0.973388671875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.09046606719493866, accuracy: 0.97607421875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.06990193575620651, accuracy: 0.97900390625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.05575193837285042, accuracy: 0.978515625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.06748055666685104, accuracy: 0.97802734375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.058159392327070236, accuracy: 0.977294921875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.06484191864728928, accuracy: 0.979248046875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.06977613270282745, accuracy: 0.977294921875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.08489995449781418, accuracy: 0.97802734375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.06226380541920662, accuracy: 0.97900390625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.06924526393413544, accuracy: 0.977294921875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.05066680908203125, accuracy: 0.97802734375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.07476194202899933, accuracy: 0.97607421875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.06402216106653214, accuracy: 0.977294921875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.036380887031555176, accuracy: 0.9755859375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.05314168334007263, accuracy: 0.978515625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.06696353107690811, accuracy: 0.978271484375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.07097695022821426, accuracy: 0.97705078125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.057588569819927216, accuracy: 0.974609375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.044349126517772675, accuracy: 0.97705078125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.07405305653810501, accuracy: 0.97802734375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.04723053425550461, accuracy: 0.975830078125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.028143849223852158, accuracy: 0.974609375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.04506058245897293, accuracy: 0.975830078125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.05511230230331421, accuracy: 0.97900390625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.03356367349624634, accuracy: 0.977294921875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.06454993784427643, accuracy: 0.97412109375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.039192311465740204, accuracy: 0.976318359375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.05014536529779434, accuracy: 0.975830078125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.05214376375079155, accuracy: 0.982666015625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.050154369324445724, accuracy: 0.977294921875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.03822052851319313, accuracy: 0.97607421875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.05244071036577225, accuracy: 0.97998046875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.061908721923828125, accuracy: 0.97705078125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.03959741070866585, accuracy: 0.97900390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.054788172245025635, accuracy: 0.98095703125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.04980937018990517, accuracy: 0.977294921875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.10642963647842407, accuracy: 0.978515625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.05218176543712616, accuracy: 0.975830078125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.04146258905529976, accuracy: 0.981201171875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.044554274529218674, accuracy: 0.972412109375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.04495630040764809, accuracy: 0.97509765625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.06037105992436409, accuracy: 0.977294921875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.029663754627108574, accuracy: 0.974365234375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.037983618676662445, accuracy: 0.977783203125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.06452184170484543, accuracy: 0.97802734375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0432671383023262, accuracy: 0.978759765625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.04186122491955757, accuracy: 0.978759765625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.03133721277117729, accuracy: 0.975830078125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.051429688930511475, accuracy: 0.976806640625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05893349274992943, accuracy: 0.97998046875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.03691951557993889, accuracy: 0.974609375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.04391191899776459, accuracy: 0.9794921875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.048508334904909134, accuracy: 0.9775390625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.046640243381261826, accuracy: 0.97802734375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.0326833575963974, accuracy: 0.979736328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.04251573979854584, accuracy: 0.977294921875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.050951067358255386, accuracy: 0.97802734375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.03063143603503704, accuracy: 0.980224609375\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.8335544466972351, accuracy: 0.8134765625\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.46936458349227905, accuracy: 0.924560546875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.3414585590362549, accuracy: 0.939453125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.23304791748523712, accuracy: 0.9501953125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.18891987204551697, accuracy: 0.964599609375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.16032616794109344, accuracy: 0.9638671875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.15253913402557373, accuracy: 0.96240234375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.13109765946865082, accuracy: 0.962890625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.1428275853395462, accuracy: 0.968994140625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.12610256671905518, accuracy: 0.96826171875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.12069696933031082, accuracy: 0.970703125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.08762124180793762, accuracy: 0.968994140625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.09788916260004044, accuracy: 0.97119140625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.11794653534889221, accuracy: 0.97021484375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.08721768110990524, accuracy: 0.972900390625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.09126796573400497, accuracy: 0.974365234375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.118826724588871, accuracy: 0.972900390625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.09080608189105988, accuracy: 0.97216796875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.08128611743450165, accuracy: 0.972412109375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.08540035039186478, accuracy: 0.97216796875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.1234058290719986, accuracy: 0.9775390625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.11063211411237717, accuracy: 0.971923828125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.09562106430530548, accuracy: 0.97705078125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.07406864315271378, accuracy: 0.970458984375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.07898594439029694, accuracy: 0.971435546875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.07438260316848755, accuracy: 0.9736328125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.07378536462783813, accuracy: 0.97265625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.0495496429502964, accuracy: 0.974365234375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.06326328217983246, accuracy: 0.97705078125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.07202474027872086, accuracy: 0.975341796875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.05114131420850754, accuracy: 0.978271484375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.07533206790685654, accuracy: 0.980224609375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.0872364416718483, accuracy: 0.975341796875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.09111163020133972, accuracy: 0.974365234375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.05626611039042473, accuracy: 0.97412109375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.06356093287467957, accuracy: 0.973388671875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.06574930995702744, accuracy: 0.97607421875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.06179900839924812, accuracy: 0.973876953125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.07927579432725906, accuracy: 0.976318359375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.07691338658332825, accuracy: 0.97314453125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.07331191003322601, accuracy: 0.972412109375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.053524840623140335, accuracy: 0.972900390625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.04775197431445122, accuracy: 0.973388671875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.05983656644821167, accuracy: 0.974609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.06988579034805298, accuracy: 0.974853515625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.08507315069437027, accuracy: 0.973388671875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.07892011106014252, accuracy: 0.972900390625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.07940683513879776, accuracy: 0.973876953125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.037673089653253555, accuracy: 0.97607421875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.06683081388473511, accuracy: 0.9775390625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.069219209253788, accuracy: 0.974609375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.04759245365858078, accuracy: 0.973876953125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.041279688477516174, accuracy: 0.97607421875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.058886002749204636, accuracy: 0.970703125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.062517911195755, accuracy: 0.974609375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.03627387434244156, accuracy: 0.977294921875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.05718493089079857, accuracy: 0.977783203125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.04087188467383385, accuracy: 0.974609375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.03537093475461006, accuracy: 0.971923828125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.03345971181988716, accuracy: 0.978271484375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.04267524927854538, accuracy: 0.9775390625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.0557871051132679, accuracy: 0.9765625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.058175038546323776, accuracy: 0.978515625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.05297986790537834, accuracy: 0.9775390625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.050903141498565674, accuracy: 0.97705078125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.056773461401462555, accuracy: 0.97607421875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.0596543624997139, accuracy: 0.974853515625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.05493950843811035, accuracy: 0.97509765625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.041299574077129364, accuracy: 0.97705078125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.0549837164580822, accuracy: 0.97509765625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.06324990838766098, accuracy: 0.972412109375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.12135449796915054, accuracy: 0.974609375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.055530186742544174, accuracy: 0.9755859375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.05653377249836922, accuracy: 0.976806640625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.04812415689229965, accuracy: 0.9765625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0847550630569458, accuracy: 0.97607421875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.07361229509115219, accuracy: 0.97265625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.05650947988033295, accuracy: 0.976318359375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08167928457260132, accuracy: 0.975830078125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.07684671878814697, accuracy: 0.96826171875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.06333214789628983, accuracy: 0.9736328125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.04082228243350983, accuracy: 0.972900390625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.07527795433998108, accuracy: 0.9765625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.05910998955368996, accuracy: 0.97412109375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.05567722022533417, accuracy: 0.9765625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05548301339149475, accuracy: 0.977294921875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.03046077862381935, accuracy: 0.9755859375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.03359420970082283, accuracy: 0.9755859375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.04723689332604408, accuracy: 0.97998046875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.06055863946676254, accuracy: 0.973388671875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.046788543462753296, accuracy: 0.976318359375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.03621842712163925, accuracy: 0.975341796875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.04494598135352135, accuracy: 0.975341796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.036929767578840256, accuracy: 0.9775390625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.044849079102277756, accuracy: 0.97607421875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.04308618605136871, accuracy: 0.972412109375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.04234585165977478, accuracy: 0.975830078125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.029128417372703552, accuracy: 0.97509765625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07081200927495956, accuracy: 0.97900390625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.029528750106692314, accuracy: 0.973876953125\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.8615995645523071, accuracy: 0.847900390625\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.4049815535545349, accuracy: 0.92919921875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.28730538487434387, accuracy: 0.947998046875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.1679292768239975, accuracy: 0.961669921875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.14802996814250946, accuracy: 0.960693359375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.23134927451610565, accuracy: 0.96484375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.1729005128145218, accuracy: 0.964111328125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.22539080679416656, accuracy: 0.97216796875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.1564355492591858, accuracy: 0.97021484375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.13368864357471466, accuracy: 0.972900390625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.12391887605190277, accuracy: 0.9736328125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.1146882101893425, accuracy: 0.970947265625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.11708824336528778, accuracy: 0.97314453125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.06976538151502609, accuracy: 0.97119140625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.1344490349292755, accuracy: 0.969482421875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.09204379469156265, accuracy: 0.9755859375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.09692057222127914, accuracy: 0.970947265625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.07714863866567612, accuracy: 0.977294921875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.11138651520013809, accuracy: 0.97216796875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.10120073705911636, accuracy: 0.97119140625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.07552850246429443, accuracy: 0.9716796875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.09568339586257935, accuracy: 0.975341796875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.0954437181353569, accuracy: 0.978759765625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.09077660739421844, accuracy: 0.97314453125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.09675426036119461, accuracy: 0.97265625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.11036017537117004, accuracy: 0.97509765625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.12289510667324066, accuracy: 0.97509765625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.08620866388082504, accuracy: 0.972900390625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.08423508703708649, accuracy: 0.9775390625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.1019790917634964, accuracy: 0.974365234375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.08761712908744812, accuracy: 0.97216796875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.0687059834599495, accuracy: 0.97412109375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.08792973309755325, accuracy: 0.978271484375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.09522472321987152, accuracy: 0.974853515625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.07759658247232437, accuracy: 0.97509765625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.07847373187541962, accuracy: 0.976806640625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.08880338072776794, accuracy: 0.9755859375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.056423645466566086, accuracy: 0.9794921875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.06390020996332169, accuracy: 0.976318359375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.07216602563858032, accuracy: 0.97705078125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06291881948709488, accuracy: 0.979736328125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.05839896574616432, accuracy: 0.978271484375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.06048964709043503, accuracy: 0.9775390625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.06970010697841644, accuracy: 0.9736328125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.050910867750644684, accuracy: 0.974365234375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.08070482313632965, accuracy: 0.974365234375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.055014025419950485, accuracy: 0.974609375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.07773347944021225, accuracy: 0.973388671875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.060612741857767105, accuracy: 0.97265625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.047589536756277084, accuracy: 0.97412109375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.05491612106561661, accuracy: 0.97265625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.04585295170545578, accuracy: 0.978759765625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.08113987743854523, accuracy: 0.974853515625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.06290832161903381, accuracy: 0.97216796875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.07290172576904297, accuracy: 0.973876953125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.06249818578362465, accuracy: 0.975341796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.0441959910094738, accuracy: 0.974365234375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.04623233526945114, accuracy: 0.977294921875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.06922520697116852, accuracy: 0.978759765625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.04870438203215599, accuracy: 0.97900390625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.05882461741566658, accuracy: 0.97265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.09271787106990814, accuracy: 0.975341796875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.06982195377349854, accuracy: 0.9755859375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.040984153747558594, accuracy: 0.9755859375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.052458539605140686, accuracy: 0.974609375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.046538397669792175, accuracy: 0.972900390625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.03986198455095291, accuracy: 0.971435546875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.07950650155544281, accuracy: 0.978759765625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.04138914868235588, accuracy: 0.978271484375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.06125194579362869, accuracy: 0.972900390625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.05261076241731644, accuracy: 0.9736328125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.05922381207346916, accuracy: 0.9775390625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.04589597135782242, accuracy: 0.9765625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.07717183232307434, accuracy: 0.976806640625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.08492377400398254, accuracy: 0.9775390625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.04730253294110298, accuracy: 0.97607421875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.030099913477897644, accuracy: 0.976318359375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.041504427790641785, accuracy: 0.975830078125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.029124613851308823, accuracy: 0.975830078125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.05059514939785004, accuracy: 0.976806640625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.04233073815703392, accuracy: 0.9814453125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.06370344012975693, accuracy: 0.975341796875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.03385055437684059, accuracy: 0.973876953125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.05409816652536392, accuracy: 0.975830078125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.027370072901248932, accuracy: 0.97607421875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05276177078485489, accuracy: 0.97314453125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.053042732179164886, accuracy: 0.976318359375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08411746472120285, accuracy: 0.97900390625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.05250983312726021, accuracy: 0.974365234375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.0667334794998169, accuracy: 0.9736328125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.06478407979011536, accuracy: 0.97216796875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.03669987618923187, accuracy: 0.974365234375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.04029977694153786, accuracy: 0.977294921875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.04704555124044418, accuracy: 0.974853515625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.05765056610107422, accuracy: 0.978271484375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.05075232312083244, accuracy: 0.977294921875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.05675579980015755, accuracy: 0.976806640625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.05133716017007828, accuracy: 0.972900390625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.041876837611198425, accuracy: 0.979736328125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.04647977277636528, accuracy: 0.980224609375\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.7408763766288757, accuracy: 0.86279296875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.42947202920913696, accuracy: 0.9296875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.2537737488746643, accuracy: 0.947509765625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.23516802489757538, accuracy: 0.9541015625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.18280470371246338, accuracy: 0.961181640625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.17945513129234314, accuracy: 0.965087890625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.18137533962726593, accuracy: 0.966552734375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.12690815329551697, accuracy: 0.971435546875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.14600254595279694, accuracy: 0.965576171875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.14237067103385925, accuracy: 0.966064453125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.14518582820892334, accuracy: 0.96533203125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.172170951962471, accuracy: 0.965576171875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.12253202497959137, accuracy: 0.971923828125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.10964655131101608, accuracy: 0.974609375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.09333214908838272, accuracy: 0.971435546875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.11423555761575699, accuracy: 0.97216796875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.08274136483669281, accuracy: 0.97021484375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.13245056569576263, accuracy: 0.97119140625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.10884465277194977, accuracy: 0.97412109375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.08326667547225952, accuracy: 0.97119140625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.0814201608300209, accuracy: 0.977294921875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.10198362916707993, accuracy: 0.972900390625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.1068250983953476, accuracy: 0.97265625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.08769571781158447, accuracy: 0.972412109375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.10190616548061371, accuracy: 0.971923828125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.07584846019744873, accuracy: 0.97216796875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.10549531131982803, accuracy: 0.97412109375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.09924805909395218, accuracy: 0.975830078125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.10417373478412628, accuracy: 0.9716796875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.08446274697780609, accuracy: 0.974365234375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.08862745761871338, accuracy: 0.9755859375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.06488832086324692, accuracy: 0.975830078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.05384359136223793, accuracy: 0.97412109375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.0764046460390091, accuracy: 0.9775390625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.05899668112397194, accuracy: 0.97314453125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.08701814711093903, accuracy: 0.9775390625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.09373849630355835, accuracy: 0.9755859375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.07314418256282806, accuracy: 0.97216796875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.06644746661186218, accuracy: 0.97314453125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.07320404797792435, accuracy: 0.9736328125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.07115039229393005, accuracy: 0.970458984375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.07613708078861237, accuracy: 0.9755859375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.076629638671875, accuracy: 0.9736328125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.062483157962560654, accuracy: 0.977294921875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.06873427331447601, accuracy: 0.97412109375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.08134707808494568, accuracy: 0.97705078125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.059737637639045715, accuracy: 0.973388671875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.06126601621508598, accuracy: 0.970703125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.054016582667827606, accuracy: 0.97802734375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.06845301389694214, accuracy: 0.97265625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.0744229331612587, accuracy: 0.97607421875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.08259233087301254, accuracy: 0.970947265625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.09039445966482162, accuracy: 0.97314453125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.07970181107521057, accuracy: 0.97607421875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.04863261803984642, accuracy: 0.974853515625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.06552532315254211, accuracy: 0.975341796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.06528712809085846, accuracy: 0.977294921875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.07320499420166016, accuracy: 0.974365234375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.05588701367378235, accuracy: 0.977783203125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.07254379242658615, accuracy: 0.975830078125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.06286748498678207, accuracy: 0.974365234375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.06540852785110474, accuracy: 0.977294921875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.06919552385807037, accuracy: 0.974609375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07898136228322983, accuracy: 0.9736328125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.06655124574899673, accuracy: 0.9765625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.05276573449373245, accuracy: 0.978515625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.04172705113887787, accuracy: 0.97607421875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.03771364688873291, accuracy: 0.975830078125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.11621774733066559, accuracy: 0.974365234375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.06409388780593872, accuracy: 0.975341796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.048655446618795395, accuracy: 0.975830078125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.056649692356586456, accuracy: 0.9775390625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.09030961990356445, accuracy: 0.974365234375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.052880916744470596, accuracy: 0.975830078125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.04868849366903305, accuracy: 0.97607421875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.05264611169695854, accuracy: 0.97802734375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.0409931018948555, accuracy: 0.975341796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.055010147392749786, accuracy: 0.973876953125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.04373500123620033, accuracy: 0.9716796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.07870660722255707, accuracy: 0.974365234375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.051154542714357376, accuracy: 0.97314453125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.05980057269334793, accuracy: 0.97607421875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.029687199741601944, accuracy: 0.975341796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.047950226813554764, accuracy: 0.974609375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.04705655202269554, accuracy: 0.973876953125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.03765071555972099, accuracy: 0.978271484375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.03744325414299965, accuracy: 0.973876953125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.039633966982364655, accuracy: 0.976318359375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08075401932001114, accuracy: 0.9775390625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.050928644835948944, accuracy: 0.97314453125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.040448449552059174, accuracy: 0.97509765625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.04728288576006889, accuracy: 0.976318359375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07152873277664185, accuracy: 0.9755859375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05551348254084587, accuracy: 0.974853515625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.054635632783174515, accuracy: 0.974853515625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.046562157571315765, accuracy: 0.971923828125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06232210993766785, accuracy: 0.9736328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06430506706237793, accuracy: 0.9716796875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.053215958178043365, accuracy: 0.97314453125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06478985399007797, accuracy: 0.977294921875\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.7571621537208557, accuracy: 0.873046875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.3660687208175659, accuracy: 0.92919921875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.28236401081085205, accuracy: 0.94482421875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.2519083619117737, accuracy: 0.9560546875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.2166014015674591, accuracy: 0.961181640625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.17183373868465424, accuracy: 0.9638671875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.13354715704917908, accuracy: 0.96875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.14433272182941437, accuracy: 0.968505859375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.15789560973644257, accuracy: 0.967529296875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.13685409724712372, accuracy: 0.970703125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.09773562103509903, accuracy: 0.97265625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.09966342896223068, accuracy: 0.97119140625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.09675100445747375, accuracy: 0.97021484375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.1198076456785202, accuracy: 0.97265625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.12981237471103668, accuracy: 0.976318359375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.1000373512506485, accuracy: 0.969482421875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.13124586641788483, accuracy: 0.972900390625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.0634530633687973, accuracy: 0.97705078125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.08899398893117905, accuracy: 0.976318359375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.09851013123989105, accuracy: 0.97021484375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.07295408844947815, accuracy: 0.97265625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.10564568638801575, accuracy: 0.96923828125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.09973356872797012, accuracy: 0.974853515625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.13245762884616852, accuracy: 0.97119140625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.07642463594675064, accuracy: 0.977783203125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.08115588128566742, accuracy: 0.96923828125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.07497285306453705, accuracy: 0.97119140625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.07508900761604309, accuracy: 0.969482421875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.07883227616548538, accuracy: 0.972900390625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.0770985409617424, accuracy: 0.966796875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.06044862046837807, accuracy: 0.973876953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.06591092050075531, accuracy: 0.974365234375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.07518672198057175, accuracy: 0.9755859375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.10787258297204971, accuracy: 0.970703125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.10685881227254868, accuracy: 0.974609375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.06678536534309387, accuracy: 0.9736328125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.08164125680923462, accuracy: 0.973388671875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.06295716017484665, accuracy: 0.97412109375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.08505232632160187, accuracy: 0.97998046875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.08845283091068268, accuracy: 0.972900390625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06448660045862198, accuracy: 0.97412109375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.048257626593112946, accuracy: 0.97119140625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.0368393175303936, accuracy: 0.974365234375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.06905622035264969, accuracy: 0.974853515625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.08634492754936218, accuracy: 0.9755859375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.08091358095407486, accuracy: 0.968994140625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.08372069895267487, accuracy: 0.968994140625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.04342805966734886, accuracy: 0.9765625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.056044988334178925, accuracy: 0.9755859375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.042470548301935196, accuracy: 0.973876953125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.08850959688425064, accuracy: 0.974609375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.05449224263429642, accuracy: 0.97607421875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.08464518189430237, accuracy: 0.974609375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.056220103055238724, accuracy: 0.974609375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.0859173983335495, accuracy: 0.97314453125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.032849472016096115, accuracy: 0.9765625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.05612850934267044, accuracy: 0.975830078125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.06938563287258148, accuracy: 0.973876953125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.08168124407529831, accuracy: 0.97216796875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.05488382279872894, accuracy: 0.97314453125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.05714984983205795, accuracy: 0.972900390625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.051015209406614304, accuracy: 0.9736328125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.06035976856946945, accuracy: 0.978515625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.053949590772390366, accuracy: 0.97314453125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.06323764473199844, accuracy: 0.976318359375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.025094106793403625, accuracy: 0.97314453125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.04266299679875374, accuracy: 0.976806640625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.0760180875658989, accuracy: 0.971923828125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.07556965947151184, accuracy: 0.9736328125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.07187565416097641, accuracy: 0.97509765625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.07158423960208893, accuracy: 0.973388671875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.06307080388069153, accuracy: 0.970703125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.04366251826286316, accuracy: 0.9755859375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.05646246299147606, accuracy: 0.97802734375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.06207837536931038, accuracy: 0.9755859375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0536150224506855, accuracy: 0.975341796875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.05879378318786621, accuracy: 0.975830078125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.0521349236369133, accuracy: 0.977294921875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08149164915084839, accuracy: 0.975830078125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.10405386984348297, accuracy: 0.9716796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.06461150199174881, accuracy: 0.968994140625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.044975396245718, accuracy: 0.97509765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.020125648006796837, accuracy: 0.97412109375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.04178815335035324, accuracy: 0.977294921875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.030909139662981033, accuracy: 0.9736328125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.051582396030426025, accuracy: 0.9765625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.06466097384691238, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0657457485795021, accuracy: 0.97412109375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.03849129378795624, accuracy: 0.9755859375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.050019919872283936, accuracy: 0.9755859375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.03405289724469185, accuracy: 0.9775390625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.089840829372406, accuracy: 0.973876953125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.0420280285179615, accuracy: 0.97265625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.06780979037284851, accuracy: 0.97607421875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.09491048753261566, accuracy: 0.973388671875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.05575405806303024, accuracy: 0.97705078125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.04987247660756111, accuracy: 0.971923828125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.047129396349191666, accuracy: 0.97412109375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.038012273609638214, accuracy: 0.972412109375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0558573342859745, accuracy: 0.97265625\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.8348724246025085, accuracy: 0.842529296875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.33827289938926697, accuracy: 0.925537109375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.29024481773376465, accuracy: 0.940673828125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.22919249534606934, accuracy: 0.951171875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.20105287432670593, accuracy: 0.962158203125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.15334513783454895, accuracy: 0.962646484375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.1822124719619751, accuracy: 0.96728515625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.18662984669208527, accuracy: 0.9658203125\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.1149941086769104, accuracy: 0.968017578125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.09905692934989929, accuracy: 0.966796875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.11629074066877365, accuracy: 0.965576171875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.15043452382087708, accuracy: 0.966796875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.1357412487268448, accuracy: 0.97314453125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.09416386485099792, accuracy: 0.97412109375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.1282082498073578, accuracy: 0.9716796875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.06954000145196915, accuracy: 0.972900390625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.08250211179256439, accuracy: 0.976806640625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.10970976948738098, accuracy: 0.97509765625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.10263416171073914, accuracy: 0.9736328125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.12264932692050934, accuracy: 0.97314453125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.09650786966085434, accuracy: 0.975341796875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.13508005440235138, accuracy: 0.97265625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.08894439786672592, accuracy: 0.976318359375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.10379428416490555, accuracy: 0.9755859375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.08433887362480164, accuracy: 0.9765625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.10091646760702133, accuracy: 0.975341796875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.10510332882404327, accuracy: 0.974609375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.09933199733495712, accuracy: 0.9755859375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.09024963527917862, accuracy: 0.97314453125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.07684404402971268, accuracy: 0.975341796875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.09917010366916656, accuracy: 0.97412109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.09141014516353607, accuracy: 0.975341796875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.09618012607097626, accuracy: 0.974853515625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.08182442933320999, accuracy: 0.975341796875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.0831439197063446, accuracy: 0.975830078125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.06160133704543114, accuracy: 0.97314453125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.09665713459253311, accuracy: 0.97314453125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.10404735058546066, accuracy: 0.978759765625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.07053600996732712, accuracy: 0.97900390625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.09984786808490753, accuracy: 0.970458984375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06836806237697601, accuracy: 0.9765625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.07210401445627213, accuracy: 0.974853515625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.07710514217615128, accuracy: 0.97509765625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.07405406981706619, accuracy: 0.980224609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.07790027558803558, accuracy: 0.974853515625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.07657309621572495, accuracy: 0.974609375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.07110563665628433, accuracy: 0.977783203125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.05234113335609436, accuracy: 0.974365234375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.045130256563425064, accuracy: 0.975830078125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.07685976475477219, accuracy: 0.974365234375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.06838361918926239, accuracy: 0.977294921875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.051189251244068146, accuracy: 0.976806640625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.07819760590791702, accuracy: 0.97412109375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.05775732547044754, accuracy: 0.974853515625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.0563078448176384, accuracy: 0.9775390625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.0673181489109993, accuracy: 0.9755859375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.05733831971883774, accuracy: 0.9765625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.05574605613946915, accuracy: 0.971435546875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.054246313869953156, accuracy: 0.972412109375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.05795775726437569, accuracy: 0.97705078125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.045958999544382095, accuracy: 0.9755859375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.05901312455534935, accuracy: 0.974853515625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.060211338102817535, accuracy: 0.979248046875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.05053071305155754, accuracy: 0.974365234375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.05446666106581688, accuracy: 0.973876953125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.08328119665384293, accuracy: 0.9794921875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.05642356351017952, accuracy: 0.973388671875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.06351625174283981, accuracy: 0.973876953125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.04506521299481392, accuracy: 0.974853515625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.043310731649398804, accuracy: 0.978271484375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.03784342482686043, accuracy: 0.97705078125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.05030060559511185, accuracy: 0.9736328125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.07189632207155228, accuracy: 0.97509765625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.05891897529363632, accuracy: 0.976318359375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.06768462806940079, accuracy: 0.981689453125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.07858316600322723, accuracy: 0.9775390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.0518706776201725, accuracy: 0.974609375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.05198926851153374, accuracy: 0.976318359375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.036190684884786606, accuracy: 0.97314453125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.06448055058717728, accuracy: 0.97216796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.04502970725297928, accuracy: 0.975830078125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.05728543549776077, accuracy: 0.97412109375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.06979867815971375, accuracy: 0.97509765625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.03504336252808571, accuracy: 0.97412109375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.04752224683761597, accuracy: 0.979248046875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05198287218809128, accuracy: 0.9794921875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07283902913331985, accuracy: 0.979736328125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.049558255821466446, accuracy: 0.981201171875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.04307594522833824, accuracy: 0.97900390625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.05404072254896164, accuracy: 0.9755859375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.041503146290779114, accuracy: 0.978759765625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.06321229785680771, accuracy: 0.9794921875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.04815227910876274, accuracy: 0.9736328125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.02574225701391697, accuracy: 0.973876953125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.04411571845412254, accuracy: 0.978515625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06598247587680817, accuracy: 0.9814453125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.032811421900987625, accuracy: 0.976806640625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07617989182472229, accuracy: 0.97607421875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.060137275606393814, accuracy: 0.976806640625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07262326031923294, accuracy: 0.9765625\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.7126884460449219, accuracy: 0.854736328125\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.4087045192718506, accuracy: 0.93017578125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.2603439390659332, accuracy: 0.95556640625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.2215915024280548, accuracy: 0.95703125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.20069903135299683, accuracy: 0.963623046875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.19940170645713806, accuracy: 0.9619140625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.13167603313922882, accuracy: 0.9658203125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.1642836630344391, accuracy: 0.970458984375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.17742671072483063, accuracy: 0.966552734375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.17821530997753143, accuracy: 0.970703125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.15820354223251343, accuracy: 0.96728515625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.1454927623271942, accuracy: 0.967529296875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.1182193011045456, accuracy: 0.97021484375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.1252688765525818, accuracy: 0.97119140625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.09113924205303192, accuracy: 0.973388671875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.11129260808229446, accuracy: 0.974853515625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.10061805695295334, accuracy: 0.970947265625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.10370955616235733, accuracy: 0.970703125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.10545942187309265, accuracy: 0.969970703125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.14564096927642822, accuracy: 0.97265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.08780256658792496, accuracy: 0.97216796875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.08073034137487411, accuracy: 0.97314453125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.10238438844680786, accuracy: 0.9755859375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.10770811140537262, accuracy: 0.970458984375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.09350241720676422, accuracy: 0.970947265625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.08103977143764496, accuracy: 0.973876953125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.08978449553251266, accuracy: 0.973388671875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.056400347501039505, accuracy: 0.9716796875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.06998328864574432, accuracy: 0.971923828125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.08347468823194504, accuracy: 0.970947265625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.09028080850839615, accuracy: 0.972412109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.07851119339466095, accuracy: 0.973388671875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.08042515814304352, accuracy: 0.972412109375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.07152586430311203, accuracy: 0.971923828125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.047759734094142914, accuracy: 0.97216796875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.06673718988895416, accuracy: 0.973876953125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.07235165685415268, accuracy: 0.975341796875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.06740573793649673, accuracy: 0.977294921875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.0622074119746685, accuracy: 0.97314453125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.05130975693464279, accuracy: 0.974609375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.06023753434419632, accuracy: 0.973388671875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.05587257444858551, accuracy: 0.974853515625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.0888393446803093, accuracy: 0.97021484375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.0701315850019455, accuracy: 0.973388671875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.07679875195026398, accuracy: 0.97119140625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.09099267423152924, accuracy: 0.9716796875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.075299471616745, accuracy: 0.974853515625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.06191963702440262, accuracy: 0.973388671875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.062138479202985764, accuracy: 0.97314453125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.07138405740261078, accuracy: 0.976318359375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.0536591112613678, accuracy: 0.97705078125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.07038279622793198, accuracy: 0.976318359375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.04826890677213669, accuracy: 0.97509765625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.046608202159404755, accuracy: 0.972900390625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.07357577234506607, accuracy: 0.9775390625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.09853049367666245, accuracy: 0.97412109375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.07199706882238388, accuracy: 0.97509765625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.06449999660253525, accuracy: 0.97705078125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.0660567358136177, accuracy: 0.974609375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.0871867686510086, accuracy: 0.973876953125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.05620719492435455, accuracy: 0.979248046875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.06927158683538437, accuracy: 0.974853515625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.0578334704041481, accuracy: 0.971923828125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.059180501848459244, accuracy: 0.975341796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.08082548528909683, accuracy: 0.97265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.07618118077516556, accuracy: 0.97314453125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.038472190499305725, accuracy: 0.9775390625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.06806322932243347, accuracy: 0.979248046875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.09167171269655228, accuracy: 0.973388671875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.06981345266103745, accuracy: 0.9755859375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.0533820204436779, accuracy: 0.9775390625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.04728981852531433, accuracy: 0.977294921875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.05999105051159859, accuracy: 0.979248046875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.06483758240938187, accuracy: 0.97802734375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.05779151991009712, accuracy: 0.97412109375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.02957915887236595, accuracy: 0.9755859375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.03043799288570881, accuracy: 0.977783203125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.04752356931567192, accuracy: 0.9736328125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.029306739568710327, accuracy: 0.980712890625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.04045047238469124, accuracy: 0.9765625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.047189757227897644, accuracy: 0.974853515625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.05077463760972023, accuracy: 0.9765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.05531035736203194, accuracy: 0.969482421875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.04261146858334541, accuracy: 0.9736328125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06135570630431175, accuracy: 0.975830078125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.06711418926715851, accuracy: 0.975830078125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.058944422751665115, accuracy: 0.974609375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07182461023330688, accuracy: 0.974853515625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08394157886505127, accuracy: 0.978515625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07105707377195358, accuracy: 0.9755859375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.061183780431747437, accuracy: 0.97265625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.06759605556726456, accuracy: 0.974853515625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.0271882563829422, accuracy: 0.97216796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05495400354266167, accuracy: 0.97412109375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07833486795425415, accuracy: 0.97900390625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.045222122222185135, accuracy: 0.97314453125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.04208270460367203, accuracy: 0.9775390625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.04017776995897293, accuracy: 0.977294921875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.05455576628446579, accuracy: 0.97607421875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.03919059783220291, accuracy: 0.975830078125\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.7572898268699646, accuracy: 0.828125\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.521170437335968, accuracy: 0.9189453125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.23303094506263733, accuracy: 0.93896484375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.27365660667419434, accuracy: 0.95947265625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.20208404958248138, accuracy: 0.962890625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.19272381067276, accuracy: 0.96533203125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.15943165123462677, accuracy: 0.967041015625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.16355584561824799, accuracy: 0.971923828125\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.16813738644123077, accuracy: 0.969970703125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.1253749430179596, accuracy: 0.9736328125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.11109235882759094, accuracy: 0.970703125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.11199826747179031, accuracy: 0.96875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.08509571850299835, accuracy: 0.971435546875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.0778132826089859, accuracy: 0.970458984375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.0780237466096878, accuracy: 0.971435546875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.08379387110471725, accuracy: 0.971923828125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.09538747370243073, accuracy: 0.97265625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.11413010954856873, accuracy: 0.97705078125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.10428180545568466, accuracy: 0.97314453125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.08832021057605743, accuracy: 0.970458984375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.09635335952043533, accuracy: 0.974853515625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.10629615187644958, accuracy: 0.977294921875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.09864488989114761, accuracy: 0.9716796875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.08754851669073105, accuracy: 0.971923828125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.13365218043327332, accuracy: 0.974365234375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.10038947314023972, accuracy: 0.976806640625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.07333290576934814, accuracy: 0.9755859375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.06063058227300644, accuracy: 0.973388671875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.09393462538719177, accuracy: 0.97509765625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.06224856153130531, accuracy: 0.974365234375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.06599018722772598, accuracy: 0.975830078125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.08164399862289429, accuracy: 0.975341796875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.07208769768476486, accuracy: 0.974609375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.0503527857363224, accuracy: 0.978271484375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.05841527506709099, accuracy: 0.97705078125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.05416611582040787, accuracy: 0.97802734375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.041998669505119324, accuracy: 0.97900390625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.07120298594236374, accuracy: 0.97900390625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.05964760482311249, accuracy: 0.983642578125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.05741453915834427, accuracy: 0.981201171875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.09173877537250519, accuracy: 0.9755859375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.04880432412028313, accuracy: 0.9765625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.0837492048740387, accuracy: 0.976318359375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.07917483150959015, accuracy: 0.97607421875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.043439414352178574, accuracy: 0.97802734375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.08160903304815292, accuracy: 0.98095703125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.06214013695716858, accuracy: 0.97998046875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.07042752206325531, accuracy: 0.97705078125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.05456406623125076, accuracy: 0.9755859375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.04808138310909271, accuracy: 0.97705078125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.04012252390384674, accuracy: 0.97802734375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.04907521232962608, accuracy: 0.978759765625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.0471617728471756, accuracy: 0.978271484375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.050903744995594025, accuracy: 0.976806640625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.07004288583993912, accuracy: 0.98046875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.059970658272504807, accuracy: 0.980224609375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.050229765474796295, accuracy: 0.978759765625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.028960496187210083, accuracy: 0.978759765625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.040364496409893036, accuracy: 0.977294921875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.06255414336919785, accuracy: 0.978271484375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.05689118802547455, accuracy: 0.978759765625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.04701933637261391, accuracy: 0.9736328125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.05845880135893822, accuracy: 0.979736328125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.06740476191043854, accuracy: 0.979248046875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.04469827935099602, accuracy: 0.974609375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.04750508815050125, accuracy: 0.9814453125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.03795654699206352, accuracy: 0.98046875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.036622099578380585, accuracy: 0.982666015625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.035773683339357376, accuracy: 0.979248046875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.04767234995961189, accuracy: 0.978759765625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.03789784759283066, accuracy: 0.976806640625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.07490087300539017, accuracy: 0.974853515625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.033985402435064316, accuracy: 0.9775390625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.048383262008428574, accuracy: 0.976806640625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.040878765285015106, accuracy: 0.980224609375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.05736681818962097, accuracy: 0.97802734375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.04548582807183266, accuracy: 0.97802734375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.03752755746245384, accuracy: 0.975830078125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.050073422491550446, accuracy: 0.98046875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.06128701567649841, accuracy: 0.97607421875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.04800987243652344, accuracy: 0.976806640625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.03083888068795204, accuracy: 0.979248046875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.049185726791620255, accuracy: 0.977783203125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.04692305997014046, accuracy: 0.978271484375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.024019325152039528, accuracy: 0.978271484375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05376360937952995, accuracy: 0.97314453125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.035382457077503204, accuracy: 0.97900390625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0600375235080719, accuracy: 0.982177734375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.0497589148581028, accuracy: 0.98046875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.02803044021129608, accuracy: 0.981201171875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.035420119762420654, accuracy: 0.977783203125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05347613990306854, accuracy: 0.980224609375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.02594562992453575, accuracy: 0.97802734375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07482022047042847, accuracy: 0.979736328125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.06462672352790833, accuracy: 0.975830078125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.04033105820417404, accuracy: 0.978271484375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.062032196670770645, accuracy: 0.97998046875\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.03828290104866028, accuracy: 0.9755859375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.048208195716142654, accuracy: 0.9775390625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.04816688969731331, accuracy: 0.97802734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 0.8220489025115967, accuracy: 0.846435546875\n",
            "Epoch: 2, learning_rate:0.01,costo: 0.37340784072875977, accuracy: 0.925048828125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.327165424823761, accuracy: 0.94384765625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.2435220330953598, accuracy: 0.955810546875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.21772882342338562, accuracy: 0.95947265625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.19863703846931458, accuracy: 0.958740234375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.1908862441778183, accuracy: 0.966796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.1686117798089981, accuracy: 0.970458984375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.1355159729719162, accuracy: 0.967041015625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.11590965837240219, accuracy: 0.97265625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.14997905492782593, accuracy: 0.9736328125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.16530542075634003, accuracy: 0.974609375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.13334539532661438, accuracy: 0.970947265625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.08040476590394974, accuracy: 0.970703125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.1706410050392151, accuracy: 0.971923828125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.10504242777824402, accuracy: 0.974365234375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.10083045810461044, accuracy: 0.969970703125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.08964560180902481, accuracy: 0.97412109375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.06965085864067078, accuracy: 0.974853515625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.13241858780384064, accuracy: 0.972900390625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.08053923398256302, accuracy: 0.97314453125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.08822493255138397, accuracy: 0.9775390625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.0887802243232727, accuracy: 0.975341796875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.13611985743045807, accuracy: 0.97412109375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.1325080692768097, accuracy: 0.97509765625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.09333714097738266, accuracy: 0.9736328125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.09866465628147125, accuracy: 0.976806640625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.09694044291973114, accuracy: 0.972412109375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.08300083875656128, accuracy: 0.97412109375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.07552174478769302, accuracy: 0.97412109375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.07418696582317352, accuracy: 0.97802734375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.0826740637421608, accuracy: 0.976806640625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.08509831130504608, accuracy: 0.971923828125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.10369575023651123, accuracy: 0.975830078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.058149755001068115, accuracy: 0.97265625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.07348423451185226, accuracy: 0.973388671875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.08786269277334213, accuracy: 0.970703125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.060531288385391235, accuracy: 0.97509765625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.057273589074611664, accuracy: 0.97705078125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.07498078793287277, accuracy: 0.97412109375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.10178256779909134, accuracy: 0.973388671875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.08660159260034561, accuracy: 0.974609375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.07322458177804947, accuracy: 0.97412109375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.05503561347723007, accuracy: 0.974609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.07368427515029907, accuracy: 0.972412109375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.06443854421377182, accuracy: 0.975341796875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.06853531301021576, accuracy: 0.974853515625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.06864026188850403, accuracy: 0.97314453125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.07019857317209244, accuracy: 0.974609375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.08769260346889496, accuracy: 0.970703125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.07514353841543198, accuracy: 0.974853515625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.08597678691148758, accuracy: 0.97509765625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.06342339515686035, accuracy: 0.97705078125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.09184666723012924, accuracy: 0.976318359375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.07199954241514206, accuracy: 0.976806640625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.08831105381250381, accuracy: 0.98046875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.07361850887537003, accuracy: 0.971923828125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.050333015620708466, accuracy: 0.9775390625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.0648069977760315, accuracy: 0.973388671875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.07478760927915573, accuracy: 0.974365234375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.06440742313861847, accuracy: 0.974853515625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.08705944567918777, accuracy: 0.972900390625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.0494401752948761, accuracy: 0.972900390625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.06865555047988892, accuracy: 0.972412109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.054511453956365585, accuracy: 0.9794921875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.05313195660710335, accuracy: 0.974365234375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.06365180760622025, accuracy: 0.972900390625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.04509483277797699, accuracy: 0.975830078125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.060270484536886215, accuracy: 0.97705078125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.09886481612920761, accuracy: 0.9736328125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.0405796617269516, accuracy: 0.97314453125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.04775004833936691, accuracy: 0.973876953125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.05489536374807358, accuracy: 0.976318359375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.04377011954784393, accuracy: 0.977783203125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.04452160745859146, accuracy: 0.974609375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.08719740808010101, accuracy: 0.976806640625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.051199764013290405, accuracy: 0.97900390625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.05067196860909462, accuracy: 0.9736328125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.062204014509916306, accuracy: 0.97314453125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.06827308982610703, accuracy: 0.97509765625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.06552699953317642, accuracy: 0.97509765625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.038773663341999054, accuracy: 0.97216796875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.05290570855140686, accuracy: 0.97607421875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.07167132943868637, accuracy: 0.974853515625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06828649342060089, accuracy: 0.97900390625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05904083326458931, accuracy: 0.981201171875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.04767932370305061, accuracy: 0.9736328125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.06444645673036575, accuracy: 0.975830078125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.050565071403980255, accuracy: 0.978759765625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.06627435237169266, accuracy: 0.972412109375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.034923747181892395, accuracy: 0.975830078125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.026203077286481857, accuracy: 0.976318359375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.040973830968141556, accuracy: 0.972900390625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.04789959266781807, accuracy: 0.97705078125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08949469029903412, accuracy: 0.974853515625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.07078233361244202, accuracy: 0.978271484375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.052326809614896774, accuracy: 0.974609375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06607026606798172, accuracy: 0.97802734375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.03643077239394188, accuracy: 0.972900390625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.035288695245981216, accuracy: 0.976806640625\n"
          ]
        }
      ],
      "source": [
        "\n",
        "resultados['adam'] = {}\n",
        "resultados['adam']['val_acc_list'] = [0] * epochs\n",
        "resultados['adam']['test_acc'] = 0\n",
        "resultados['adam']['cost'] = [0] * epochs\n",
        "resultados['adam']['time'] = 0\n",
        "resultados['adam']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    adam_acc_list, adam_cost_list, adam_lr_list, adam_time, adam_acc, adam_epochs = Adam()\n",
        "    resultados['adam']['val_acc_list'] = SumList(resultados['adam']['val_acc_list'], adam_acc_list)\n",
        "    resultados['adam']['test_acc'] += adam_acc\n",
        "    resultados['adam']['cost'] = SumList(resultados['adam']['cost'], adam_cost_list)\n",
        "    resultados['adam']['time'] += adam_time\n",
        "    resultados['adam']['epochs'] += adam_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['adam']['name'] = 'Adam'\n",
        "resultados['adam']['lr'] = adam_lr_list\n",
        "resultados['adam']['test_acc'] = resultados['adam']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['adam']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['adam']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['adam']['cost'] = DeleteZerosFromList(DivideList(resultados['adam']['cost'], MAX_ITERATIONS))\n",
        "resultados['adam']['time'] = resultados['adam']['time'] / MAX_ITERATIONS\n",
        "resultados['adam']['epochs'] = resultados['adam']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzehV-6emhDY"
      },
      "source": [
        "## Momentum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtAUfdA2iA3z"
      },
      "source": [
        "Se utiliza una optimización por el descenso del gradiente estocástico empleando Momentum.\n",
        "\n",
        "$beta: 0.9$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_WhsNUpTfGab"
      },
      "outputs": [],
      "source": [
        "def SGDM():\n",
        "    modelSGDM = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimiserSGDM = torch.optim.SGD(modelSGDM.parameters(), lr=lr, momentum=0.9)\n",
        "    start.record()\n",
        "    SGDM_acc_list, SGDM_cost_list,SGDM_lr_list, SGDM_epochs = train(modelSGDM, optimiserSGDM,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    SGDM_time = start.elapsed_time(end)\n",
        "\n",
        "    SGDM_acc = accuracy(modelSGDM, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return SGDM_acc_list, SGDM_cost_list, SGDM_lr_list, SGDM_time, SGDM_acc, SGDM_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4bdgJL-mkx3",
        "outputId": "420e40e3-3515-4e37-88e7-da391ff7251b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:0.01,costo: 1.993465542793274, accuracy: 0.695556640625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2104578018188477, accuracy: 0.8193359375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6821402311325073, accuracy: 0.8583984375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.46640950441360474, accuracy: 0.88134765625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4496564567089081, accuracy: 0.896240234375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4156055152416229, accuracy: 0.907470703125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.39511731266975403, accuracy: 0.90869140625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.36368557810783386, accuracy: 0.914794921875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3480892777442932, accuracy: 0.91943359375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3082643449306488, accuracy: 0.917236328125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.37527287006378174, accuracy: 0.926025390625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.26484841108322144, accuracy: 0.927978515625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3202211558818817, accuracy: 0.924072265625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.26861634850502014, accuracy: 0.92919921875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.3102811276912689, accuracy: 0.926025390625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2834077775478363, accuracy: 0.933837890625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.22362017631530762, accuracy: 0.940185546875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.25104647874832153, accuracy: 0.938720703125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.22916275262832642, accuracy: 0.93603515625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.27179598808288574, accuracy: 0.9375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2544429302215576, accuracy: 0.93505859375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.22106292843818665, accuracy: 0.947509765625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.22336003184318542, accuracy: 0.944091796875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.19357870519161224, accuracy: 0.942138671875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.20919591188430786, accuracy: 0.94921875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.16929160058498383, accuracy: 0.951904296875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.17608506977558136, accuracy: 0.95458984375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.22000078856945038, accuracy: 0.9521484375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.18088167905807495, accuracy: 0.95458984375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.18021485209465027, accuracy: 0.955322265625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.2177201807498932, accuracy: 0.9580078125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1674051135778427, accuracy: 0.95458984375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.18768008053302765, accuracy: 0.95849609375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.15531893074512482, accuracy: 0.956298828125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.21193894743919373, accuracy: 0.95703125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.15671347081661224, accuracy: 0.960205078125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.15866193175315857, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.16336658596992493, accuracy: 0.965576171875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.13932493329048157, accuracy: 0.962158203125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13635985553264618, accuracy: 0.96044921875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.14204414188861847, accuracy: 0.9638671875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1626581996679306, accuracy: 0.965087890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1664356142282486, accuracy: 0.964111328125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.1748269498348236, accuracy: 0.963134765625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1323036104440689, accuracy: 0.96435546875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.1636670082807541, accuracy: 0.96533203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.11422359943389893, accuracy: 0.9638671875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1358078420162201, accuracy: 0.967041015625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.12418966740369797, accuracy: 0.965087890625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12467849254608154, accuracy: 0.966796875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.14855924248695374, accuracy: 0.965087890625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11036020517349243, accuracy: 0.968017578125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.15384195744991302, accuracy: 0.966796875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.12164004892110825, accuracy: 0.96875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.15624994039535522, accuracy: 0.97021484375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.13279829919338226, accuracy: 0.9677734375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.12782728672027588, accuracy: 0.973388671875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11970211565494537, accuracy: 0.968994140625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1213950589299202, accuracy: 0.97216796875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.12434983998537064, accuracy: 0.969970703125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.10905729979276657, accuracy: 0.970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.11352226138114929, accuracy: 0.974365234375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.1077980175614357, accuracy: 0.9716796875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.09013179689645767, accuracy: 0.968994140625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.12188972532749176, accuracy: 0.970458984375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.0887475311756134, accuracy: 0.969482421875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.11349045485258102, accuracy: 0.96923828125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.08768787235021591, accuracy: 0.97314453125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.11189218610525131, accuracy: 0.9716796875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.08751983195543289, accuracy: 0.97119140625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.10154003649950027, accuracy: 0.971923828125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.10824165493249893, accuracy: 0.97314453125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.07888060808181763, accuracy: 0.970703125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09817087650299072, accuracy: 0.976318359375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09139429032802582, accuracy: 0.971435546875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09136489033699036, accuracy: 0.968505859375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.07315772771835327, accuracy: 0.97021484375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.11924278736114502, accuracy: 0.973388671875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09047447890043259, accuracy: 0.97998046875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09138280898332596, accuracy: 0.972412109375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.07776814699172974, accuracy: 0.97119140625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09995734691619873, accuracy: 0.973388671875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.07344678044319153, accuracy: 0.971435546875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.08042977750301361, accuracy: 0.974365234375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09318143874406815, accuracy: 0.97412109375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.10558422654867172, accuracy: 0.97509765625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08184195309877396, accuracy: 0.97119140625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08321257680654526, accuracy: 0.97705078125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.09489389508962631, accuracy: 0.97216796875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08007895946502686, accuracy: 0.974365234375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07444486767053604, accuracy: 0.970703125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05456750839948654, accuracy: 0.976318359375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.09722214937210083, accuracy: 0.973876953125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05621609464287758, accuracy: 0.97802734375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08517368137836456, accuracy: 0.97802734375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06615453958511353, accuracy: 0.974365234375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.10143400728702545, accuracy: 0.974609375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06505468487739563, accuracy: 0.972900390625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07491479068994522, accuracy: 0.9765625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.04421788826584816, accuracy: 0.97607421875\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.014618158340454, accuracy: 0.685546875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2904658317565918, accuracy: 0.790283203125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6909067630767822, accuracy: 0.8544921875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5251819491386414, accuracy: 0.877685546875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.45067885518074036, accuracy: 0.89306640625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4075891077518463, accuracy: 0.904296875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3950989842414856, accuracy: 0.90966796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.36577773094177246, accuracy: 0.916015625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.39926233887672424, accuracy: 0.923828125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3683813810348511, accuracy: 0.91845703125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3670708239078522, accuracy: 0.920654296875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3147074282169342, accuracy: 0.923828125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2783372402191162, accuracy: 0.928955078125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2712971270084381, accuracy: 0.9287109375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.3005179166793823, accuracy: 0.936279296875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.3031080961227417, accuracy: 0.9384765625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.29143351316452026, accuracy: 0.935791015625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.23855753242969513, accuracy: 0.939453125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.22147543728351593, accuracy: 0.93505859375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2684491276741028, accuracy: 0.93994140625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.22021880745887756, accuracy: 0.939453125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.25442779064178467, accuracy: 0.9462890625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.22807200253009796, accuracy: 0.947509765625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.23981459438800812, accuracy: 0.94580078125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.29235759377479553, accuracy: 0.948974609375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.20509439706802368, accuracy: 0.951416015625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.20982392132282257, accuracy: 0.952880859375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.2029626965522766, accuracy: 0.949951171875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.15292610228061676, accuracy: 0.94921875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.17311884462833405, accuracy: 0.95458984375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19867391884326935, accuracy: 0.95361328125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1919509917497635, accuracy: 0.953369140625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.14923158288002014, accuracy: 0.958984375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1813620626926422, accuracy: 0.961181640625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.18356221914291382, accuracy: 0.95361328125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17841146886348724, accuracy: 0.9560546875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.15511320531368256, accuracy: 0.9580078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.14601381123065948, accuracy: 0.961181640625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.16715967655181885, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.17755091190338135, accuracy: 0.95361328125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16395246982574463, accuracy: 0.96142578125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1427566260099411, accuracy: 0.962646484375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1469298154115677, accuracy: 0.961669921875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.13659369945526123, accuracy: 0.961669921875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13584662973880768, accuracy: 0.962158203125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.1265973597764969, accuracy: 0.963623046875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.12972386181354523, accuracy: 0.966552734375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1495935618877411, accuracy: 0.964111328125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.13379250466823578, accuracy: 0.968017578125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.13840432465076447, accuracy: 0.966064453125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.16907060146331787, accuracy: 0.9677734375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12738028168678284, accuracy: 0.960693359375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.12349579483270645, accuracy: 0.965576171875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.13290049135684967, accuracy: 0.9638671875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.15154601633548737, accuracy: 0.966552734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.11778370290994644, accuracy: 0.967529296875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.13520462810993195, accuracy: 0.97021484375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.12804336845874786, accuracy: 0.96875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1285909116268158, accuracy: 0.97265625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11177139729261398, accuracy: 0.96923828125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.1147097647190094, accuracy: 0.972412109375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.07846275717020035, accuracy: 0.970458984375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.13659439980983734, accuracy: 0.969970703125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.11035367101430893, accuracy: 0.970458984375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.13379089534282684, accuracy: 0.96826171875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.11193995177745819, accuracy: 0.970947265625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.13093255460262299, accuracy: 0.97021484375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.09715177118778229, accuracy: 0.968994140625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10327847301959991, accuracy: 0.9697265625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10809093713760376, accuracy: 0.96923828125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.09423073381185532, accuracy: 0.972900390625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.14415892958641052, accuracy: 0.96923828125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.0659671276807785, accuracy: 0.973876953125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.10463124513626099, accuracy: 0.971923828125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.0998157486319542, accuracy: 0.976318359375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.10283412039279938, accuracy: 0.970458984375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.10941656678915024, accuracy: 0.971435546875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09114570170640945, accuracy: 0.976318359375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.07418624311685562, accuracy: 0.9736328125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09120084345340729, accuracy: 0.9736328125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08499554544687271, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07327430695295334, accuracy: 0.9736328125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.09238675981760025, accuracy: 0.974365234375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.11197826266288757, accuracy: 0.97509765625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.11853791773319244, accuracy: 0.976806640625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07364904880523682, accuracy: 0.97314453125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08213785290718079, accuracy: 0.971923828125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07161421328783035, accuracy: 0.97509765625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08312057703733444, accuracy: 0.973876953125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09591002762317657, accuracy: 0.970947265625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.060812074691057205, accuracy: 0.976318359375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.08309584110975266, accuracy: 0.975341796875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06433016061782837, accuracy: 0.9736328125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.09449362009763718, accuracy: 0.97509765625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07315818965435028, accuracy: 0.976806640625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08153190463781357, accuracy: 0.97607421875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07239873707294464, accuracy: 0.972412109375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07326876372098923, accuracy: 0.974365234375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07067643105983734, accuracy: 0.9716796875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07249108701944351, accuracy: 0.9765625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.023603916168213, accuracy: 0.69921875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2870911359786987, accuracy: 0.79150390625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6676195859909058, accuracy: 0.8466796875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5377461910247803, accuracy: 0.8935546875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4585619866847992, accuracy: 0.899169921875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4146827161312103, accuracy: 0.9033203125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3977946639060974, accuracy: 0.90625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.34791404008865356, accuracy: 0.915771484375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3054726719856262, accuracy: 0.91259765625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3238182067871094, accuracy: 0.925537109375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.2638288140296936, accuracy: 0.922607421875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3310425877571106, accuracy: 0.92333984375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.28774935007095337, accuracy: 0.922607421875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.3462802469730377, accuracy: 0.931396484375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.26081907749176025, accuracy: 0.93408203125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.3017607629299164, accuracy: 0.93212890625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.27560076117515564, accuracy: 0.93603515625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.27234095335006714, accuracy: 0.93115234375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2092704176902771, accuracy: 0.940185546875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.27038463950157166, accuracy: 0.941162109375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2044178694486618, accuracy: 0.94384765625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2666407823562622, accuracy: 0.9462890625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.23096813261508942, accuracy: 0.952392578125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.2125374972820282, accuracy: 0.947265625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.20957650244235992, accuracy: 0.951416015625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.2283044010400772, accuracy: 0.948486328125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.18192966282367706, accuracy: 0.9501953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.1811845898628235, accuracy: 0.951416015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.2117483913898468, accuracy: 0.9599609375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.18381783366203308, accuracy: 0.955810546875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.24629269540309906, accuracy: 0.95751953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.19666501879692078, accuracy: 0.95556640625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16240251064300537, accuracy: 0.958984375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.168913334608078, accuracy: 0.9609375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.17811299860477448, accuracy: 0.9580078125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.15736322104930878, accuracy: 0.95947265625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1530025452375412, accuracy: 0.95947265625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.20720413327217102, accuracy: 0.959228515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.1699863225221634, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.15060646831989288, accuracy: 0.96044921875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.17332929372787476, accuracy: 0.959228515625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.18591010570526123, accuracy: 0.96337890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.167295902967453, accuracy: 0.963134765625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.1394563764333725, accuracy: 0.96240234375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.12488140910863876, accuracy: 0.96484375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.18438497185707092, accuracy: 0.967041015625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.17115634679794312, accuracy: 0.965576171875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1345491111278534, accuracy: 0.962646484375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.14804628491401672, accuracy: 0.967041015625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.11616452783346176, accuracy: 0.9697265625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12902913987636566, accuracy: 0.96728515625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.15318787097930908, accuracy: 0.966796875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.15679465234279633, accuracy: 0.969970703125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.11672650277614594, accuracy: 0.96435546875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.14384298026561737, accuracy: 0.970458984375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10462874174118042, accuracy: 0.96728515625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.12074331194162369, accuracy: 0.963623046875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11370805650949478, accuracy: 0.970947265625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.09258335828781128, accuracy: 0.968994140625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.112814761698246, accuracy: 0.9697265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.1255427449941635, accuracy: 0.970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.1267917901277542, accuracy: 0.9697265625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.14114612340927124, accuracy: 0.9716796875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10166662186384201, accuracy: 0.968505859375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.11883034557104111, accuracy: 0.968505859375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.10231312364339828, accuracy: 0.968994140625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.11090210825204849, accuracy: 0.97216796875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.09299760311841965, accuracy: 0.970458984375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10127027332782745, accuracy: 0.9736328125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.09224256128072739, accuracy: 0.97119140625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.0846083015203476, accuracy: 0.972900390625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.13452056050300598, accuracy: 0.9736328125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.1157422810792923, accuracy: 0.9736328125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.1253533661365509, accuracy: 0.970947265625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.08997608721256256, accuracy: 0.97216796875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.1447879821062088, accuracy: 0.97412109375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.12552383542060852, accuracy: 0.974609375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09145982563495636, accuracy: 0.9736328125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08803470432758331, accuracy: 0.973388671875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.08329414576292038, accuracy: 0.97607421875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.07981178164482117, accuracy: 0.976318359375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.08848831057548523, accuracy: 0.977294921875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.09643512964248657, accuracy: 0.96826171875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.11438104510307312, accuracy: 0.973876953125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06842176616191864, accuracy: 0.97314453125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.08142358809709549, accuracy: 0.976806640625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08279696106910706, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08799697458744049, accuracy: 0.974853515625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.0716337263584137, accuracy: 0.97802734375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.0654120072722435, accuracy: 0.974853515625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.09848655760288239, accuracy: 0.97607421875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.09310365468263626, accuracy: 0.9755859375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.08401112258434296, accuracy: 0.97607421875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0557277575135231, accuracy: 0.97314453125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.06516743451356888, accuracy: 0.976806640625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.11392533034086227, accuracy: 0.974609375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.08707505464553833, accuracy: 0.979736328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06301523000001907, accuracy: 0.976318359375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.058798350393772125, accuracy: 0.97802734375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.069508858025074, accuracy: 0.97900390625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.0386321544647217, accuracy: 0.72119140625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2877799272537231, accuracy: 0.802734375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7219449877738953, accuracy: 0.85693359375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5474444031715393, accuracy: 0.88232421875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4467657208442688, accuracy: 0.898193359375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.3863273859024048, accuracy: 0.905029296875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.38094794750213623, accuracy: 0.908203125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.36623185873031616, accuracy: 0.912841796875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3307918906211853, accuracy: 0.915771484375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3238539397716522, accuracy: 0.91748046875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3602125346660614, accuracy: 0.922607421875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.30306780338287354, accuracy: 0.92724609375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2986842691898346, accuracy: 0.9267578125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2899983823299408, accuracy: 0.934326171875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.3077728748321533, accuracy: 0.924560546875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2892349064350128, accuracy: 0.935546875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.22622565925121307, accuracy: 0.93408203125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.25239983201026917, accuracy: 0.93701171875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.23384268581867218, accuracy: 0.9365234375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.24135571718215942, accuracy: 0.93896484375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.22965191304683685, accuracy: 0.94287109375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2159186154603958, accuracy: 0.94580078125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.22273270785808563, accuracy: 0.9443359375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.2141578048467636, accuracy: 0.94287109375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.20699885487556458, accuracy: 0.9482421875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.19679006934165955, accuracy: 0.950927734375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.21785078942775726, accuracy: 0.952392578125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.20733366906642914, accuracy: 0.957275390625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.23253941535949707, accuracy: 0.953857421875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.21396856009960175, accuracy: 0.955322265625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.16215896606445312, accuracy: 0.955078125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1949610859155655, accuracy: 0.958740234375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.15413634479045868, accuracy: 0.95654296875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.19549499452114105, accuracy: 0.960205078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1900203675031662, accuracy: 0.959228515625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17771366238594055, accuracy: 0.95703125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.20546334981918335, accuracy: 0.962158203125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.17765766382217407, accuracy: 0.959228515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.14703762531280518, accuracy: 0.9638671875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.12778215110301971, accuracy: 0.963134765625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16680866479873657, accuracy: 0.963134765625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.14117152988910675, accuracy: 0.965087890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.13765409588813782, accuracy: 0.9638671875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.14528515934944153, accuracy: 0.965087890625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.14756730198860168, accuracy: 0.971435546875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.16266144812107086, accuracy: 0.96142578125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.17661182582378387, accuracy: 0.9677734375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.13753941655158997, accuracy: 0.96630859375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.14907248318195343, accuracy: 0.96240234375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.15186065435409546, accuracy: 0.968017578125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.11545626819133759, accuracy: 0.964111328125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.17225177586078644, accuracy: 0.97119140625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.14295338094234467, accuracy: 0.96435546875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1294645220041275, accuracy: 0.965087890625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.1361335664987564, accuracy: 0.96826171875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.1206781193614006, accuracy: 0.96875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.11404701322317123, accuracy: 0.968505859375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1222110167145729, accuracy: 0.966796875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.13605812191963196, accuracy: 0.97021484375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11418857425451279, accuracy: 0.96923828125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.13046595454216003, accuracy: 0.966552734375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.10671445727348328, accuracy: 0.96728515625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.1329251378774643, accuracy: 0.9677734375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10835621505975723, accuracy: 0.968994140625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.11636289209127426, accuracy: 0.97412109375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09524866193532944, accuracy: 0.97216796875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.09486101567745209, accuracy: 0.9697265625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11124295741319656, accuracy: 0.976318359375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.0898275077342987, accuracy: 0.975830078125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10560484975576401, accuracy: 0.969970703125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08469740301370621, accuracy: 0.97314453125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.1004081517457962, accuracy: 0.972900390625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08936150372028351, accuracy: 0.972412109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.12617094814777374, accuracy: 0.97509765625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.0821211040019989, accuracy: 0.9755859375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.12085102498531342, accuracy: 0.972900390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09566327929496765, accuracy: 0.97265625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.13365784287452698, accuracy: 0.974365234375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08995308727025986, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.08857280015945435, accuracy: 0.97265625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09163407236337662, accuracy: 0.97216796875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.11862819641828537, accuracy: 0.9765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.1054115891456604, accuracy: 0.975341796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.06527075171470642, accuracy: 0.97119140625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.05903267860412598, accuracy: 0.97265625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07939282059669495, accuracy: 0.97705078125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08111763745546341, accuracy: 0.97216796875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08920484036207199, accuracy: 0.971923828125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08106134831905365, accuracy: 0.973388671875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08713450282812119, accuracy: 0.97412109375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.09239932149648666, accuracy: 0.97216796875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07468032091856003, accuracy: 0.974853515625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.10453615337610245, accuracy: 0.9775390625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0856868103146553, accuracy: 0.976318359375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.0731256976723671, accuracy: 0.9794921875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08000872284173965, accuracy: 0.979736328125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.060813844203948975, accuracy: 0.978759765625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.0688512995839119, accuracy: 0.976318359375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.06736595928668976, accuracy: 0.975830078125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07171638309955597, accuracy: 0.9794921875\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.0282235145568848, accuracy: 0.7197265625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.308837652206421, accuracy: 0.795166015625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6871261596679688, accuracy: 0.86669921875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5178152322769165, accuracy: 0.88134765625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.42339426279067993, accuracy: 0.900390625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.41404205560684204, accuracy: 0.90771484375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3656040132045746, accuracy: 0.91259765625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3800646662712097, accuracy: 0.912841796875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3533870279788971, accuracy: 0.910888671875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3509162366390228, accuracy: 0.921875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3163466155529022, accuracy: 0.9267578125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3298305869102478, accuracy: 0.922119140625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3013767600059509, accuracy: 0.9287109375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.3298024535179138, accuracy: 0.93310546875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.25335201621055603, accuracy: 0.9296875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2946341931819916, accuracy: 0.9306640625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2508719563484192, accuracy: 0.93603515625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2951105535030365, accuracy: 0.933837890625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.24791620671749115, accuracy: 0.9375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.22749540209770203, accuracy: 0.943115234375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2562720775604248, accuracy: 0.940185546875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.23211608827114105, accuracy: 0.939208984375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.18451863527297974, accuracy: 0.949951171875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.26708412170410156, accuracy: 0.946044921875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.2288690209388733, accuracy: 0.948486328125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.23019038140773773, accuracy: 0.947265625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.22038982808589935, accuracy: 0.953369140625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.19558116793632507, accuracy: 0.9501953125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.15259526669979095, accuracy: 0.952392578125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.18893912434577942, accuracy: 0.953857421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.18263384699821472, accuracy: 0.95654296875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.2131984531879425, accuracy: 0.955810546875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.17679794132709503, accuracy: 0.96142578125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.15596917271614075, accuracy: 0.95849609375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.21816885471343994, accuracy: 0.960693359375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1981552243232727, accuracy: 0.95947265625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1833273023366928, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.16007371246814728, accuracy: 0.962158203125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.21029852330684662, accuracy: 0.958740234375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.1334654539823532, accuracy: 0.960205078125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.1737508922815323, accuracy: 0.9609375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1440226286649704, accuracy: 0.964111328125\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.14991188049316406, accuracy: 0.959716796875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.153882697224617, accuracy: 0.965087890625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13209030032157898, accuracy: 0.965576171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.16988028585910797, accuracy: 0.962646484375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.12899036705493927, accuracy: 0.9677734375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.14854221045970917, accuracy: 0.966796875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.14778319001197815, accuracy: 0.96875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.14440569281578064, accuracy: 0.96337890625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.10718957334756851, accuracy: 0.9677734375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.07939346134662628, accuracy: 0.96630859375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.10486220568418503, accuracy: 0.969970703125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.13594190776348114, accuracy: 0.966064453125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.12414094805717468, accuracy: 0.967041015625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.1266138106584549, accuracy: 0.966552734375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1362215280532837, accuracy: 0.96728515625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11952372640371323, accuracy: 0.96923828125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1171305775642395, accuracy: 0.970703125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.09882023930549622, accuracy: 0.968505859375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.0847829133272171, accuracy: 0.969970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.13614311814308167, accuracy: 0.964599609375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.10104504227638245, accuracy: 0.9697265625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.1015205979347229, accuracy: 0.973388671875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.1024542823433876, accuracy: 0.971435546875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.11821776628494263, accuracy: 0.970703125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.1165623664855957, accuracy: 0.968505859375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10875603556632996, accuracy: 0.97119140625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.127805694937706, accuracy: 0.970947265625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.13844899833202362, accuracy: 0.97216796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.09825055301189423, accuracy: 0.97412109375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.0909251719713211, accuracy: 0.967529296875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.10527171194553375, accuracy: 0.970458984375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.10408886522054672, accuracy: 0.972900390625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09959278255701065, accuracy: 0.97265625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.06575170904397964, accuracy: 0.971923828125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.11843142658472061, accuracy: 0.972900390625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.07973955571651459, accuracy: 0.974365234375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09663833677768707, accuracy: 0.97314453125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09983044117689133, accuracy: 0.97412109375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.11162999272346497, accuracy: 0.974853515625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09433881938457489, accuracy: 0.970947265625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.1098611131310463, accuracy: 0.975341796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.0884261280298233, accuracy: 0.97265625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06947819888591766, accuracy: 0.9775390625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07872658967971802, accuracy: 0.97412109375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.0963243916630745, accuracy: 0.975341796875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.06975745409727097, accuracy: 0.970947265625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07097363471984863, accuracy: 0.9765625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08250250667333603, accuracy: 0.97412109375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.09145428240299225, accuracy: 0.974365234375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.08148473501205444, accuracy: 0.9736328125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07539135217666626, accuracy: 0.9736328125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0634441077709198, accuracy: 0.971923828125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08363601565361023, accuracy: 0.977294921875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.07549341768026352, accuracy: 0.97509765625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.08081456273794174, accuracy: 0.9755859375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.09409236162900925, accuracy: 0.972900390625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07042253762483597, accuracy: 0.978515625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.11426787078380585, accuracy: 0.97509765625\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.9806408882141113, accuracy: 0.732421875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.1891683340072632, accuracy: 0.81005859375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6783420443534851, accuracy: 0.860107421875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5748252272605896, accuracy: 0.87841796875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.49261972308158875, accuracy: 0.905029296875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.40963953733444214, accuracy: 0.91064453125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.39436405897140503, accuracy: 0.908203125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.32817140221595764, accuracy: 0.913818359375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3745800256729126, accuracy: 0.92138671875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3513524830341339, accuracy: 0.921630859375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.2976243197917938, accuracy: 0.927978515625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.30207592248916626, accuracy: 0.931884765625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.36133745312690735, accuracy: 0.933349609375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.3134549558162689, accuracy: 0.93017578125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.316930890083313, accuracy: 0.934814453125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.26195451617240906, accuracy: 0.935791015625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.25805410742759705, accuracy: 0.933349609375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.25150567293167114, accuracy: 0.94189453125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.23172326385974884, accuracy: 0.9453125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2612077295780182, accuracy: 0.942626953125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2646011710166931, accuracy: 0.942138671875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.23605136573314667, accuracy: 0.947265625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.2277963012456894, accuracy: 0.94677734375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.2597717344760895, accuracy: 0.9453125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.19093386828899384, accuracy: 0.9482421875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.19106103479862213, accuracy: 0.95068359375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.1601945459842682, accuracy: 0.953857421875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.22492516040802002, accuracy: 0.951904296875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.15901054441928864, accuracy: 0.95556640625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19590862095355988, accuracy: 0.953857421875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19939276576042175, accuracy: 0.958251953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.20146974921226501, accuracy: 0.958984375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.20872870087623596, accuracy: 0.956787109375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.16250136494636536, accuracy: 0.958984375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.19050589203834534, accuracy: 0.9619140625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.2044227123260498, accuracy: 0.963623046875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1482086479663849, accuracy: 0.96142578125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1553584784269333, accuracy: 0.963623046875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.21114018559455872, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.1644989252090454, accuracy: 0.961669921875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.13826151192188263, accuracy: 0.95947265625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.14680206775665283, accuracy: 0.96533203125\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.13616377115249634, accuracy: 0.962890625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.17356519401073456, accuracy: 0.96435546875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.136549711227417, accuracy: 0.96630859375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.14445462822914124, accuracy: 0.966064453125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.11316022276878357, accuracy: 0.96533203125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1624324768781662, accuracy: 0.969970703125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.09226817637681961, accuracy: 0.967041015625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12622733414173126, accuracy: 0.96875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13844017684459686, accuracy: 0.96630859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11442150175571442, accuracy: 0.9658203125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.11307594180107117, accuracy: 0.964111328125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.12097810208797455, accuracy: 0.967529296875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.09753052890300751, accuracy: 0.963134765625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.13156405091285706, accuracy: 0.97265625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.15902431309223175, accuracy: 0.9677734375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.12197547405958176, accuracy: 0.970703125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.14219854772090912, accuracy: 0.968505859375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.126431405544281, accuracy: 0.9697265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.14335398375988007, accuracy: 0.9697265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.12248042970895767, accuracy: 0.9736328125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.08526904881000519, accuracy: 0.9736328125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.12238061428070068, accuracy: 0.972412109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.10158967226743698, accuracy: 0.969970703125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09002790600061417, accuracy: 0.9716796875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.09071492403745651, accuracy: 0.973388671875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11185725778341293, accuracy: 0.9716796875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10284960269927979, accuracy: 0.974365234375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.08280458301305771, accuracy: 0.970703125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.10731776803731918, accuracy: 0.97216796875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.11674447357654572, accuracy: 0.969482421875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08187082409858704, accuracy: 0.9736328125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.0993175208568573, accuracy: 0.972900390625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.07822567224502563, accuracy: 0.972900390625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0788893848657608, accuracy: 0.974365234375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.06549340486526489, accuracy: 0.969970703125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09647298604249954, accuracy: 0.971435546875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08119695633649826, accuracy: 0.967529296875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09109337627887726, accuracy: 0.96923828125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.10595215857028961, accuracy: 0.972900390625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.10283266752958298, accuracy: 0.973388671875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08457423746585846, accuracy: 0.976318359375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.07708961516618729, accuracy: 0.97802734375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08541757613420486, accuracy: 0.9755859375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09629158675670624, accuracy: 0.974365234375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08490069210529327, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.06595504283905029, accuracy: 0.974853515625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.09118051081895828, accuracy: 0.97265625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07863162457942963, accuracy: 0.973388671875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.0656047910451889, accuracy: 0.9775390625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.060609184205532074, accuracy: 0.979248046875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07763291895389557, accuracy: 0.974853515625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0809219628572464, accuracy: 0.973876953125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.06931325048208237, accuracy: 0.976318359375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08262855559587479, accuracy: 0.974853515625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.10273060947656631, accuracy: 0.978271484375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07186044752597809, accuracy: 0.97412109375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07566244155168533, accuracy: 0.97607421875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07492233067750931, accuracy: 0.974609375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.021925449371338, accuracy: 0.68798828125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.267628788948059, accuracy: 0.791015625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6984384655952454, accuracy: 0.8447265625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.46698155999183655, accuracy: 0.88427734375\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.49355730414390564, accuracy: 0.88720703125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.455854594707489, accuracy: 0.902587890625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3851689398288727, accuracy: 0.9091796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.35906463861465454, accuracy: 0.91552734375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.31992727518081665, accuracy: 0.915283203125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.38555246591567993, accuracy: 0.923583984375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.31046655774116516, accuracy: 0.915283203125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.33674782514572144, accuracy: 0.923828125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3152320086956024, accuracy: 0.92626953125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.3073483109474182, accuracy: 0.93212890625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2513931095600128, accuracy: 0.935546875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.26826098561286926, accuracy: 0.930419921875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.27430781722068787, accuracy: 0.936767578125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.22312362492084503, accuracy: 0.936767578125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.23309311270713806, accuracy: 0.94189453125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.24149420857429504, accuracy: 0.945068359375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.25946593284606934, accuracy: 0.94677734375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.23361414670944214, accuracy: 0.946533203125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.1997729241847992, accuracy: 0.94775390625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.18033745884895325, accuracy: 0.94677734375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.22055427730083466, accuracy: 0.9501953125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.1818191558122635, accuracy: 0.95068359375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.22713319957256317, accuracy: 0.947998046875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.23075273633003235, accuracy: 0.94970703125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.22155073285102844, accuracy: 0.955810546875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19399186968803406, accuracy: 0.95703125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19679540395736694, accuracy: 0.956787109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.14257952570915222, accuracy: 0.9580078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.17776338756084442, accuracy: 0.9599609375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.18289823830127716, accuracy: 0.956298828125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1660957634449005, accuracy: 0.9609375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.22743262350559235, accuracy: 0.9619140625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.17239749431610107, accuracy: 0.95703125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1841723471879959, accuracy: 0.95947265625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.19051146507263184, accuracy: 0.956787109375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.1703530102968216, accuracy: 0.958251953125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16975033283233643, accuracy: 0.96484375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.14743927121162415, accuracy: 0.965087890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.16848434507846832, accuracy: 0.961181640625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.14099657535552979, accuracy: 0.964599609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.16042129695415497, accuracy: 0.9677734375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.10679566115140915, accuracy: 0.96337890625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.19169141352176666, accuracy: 0.965087890625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.13517960906028748, accuracy: 0.967529296875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.15066687762737274, accuracy: 0.966796875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.14536552131175995, accuracy: 0.9697265625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13651782274246216, accuracy: 0.966064453125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11768855899572372, accuracy: 0.966796875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1161152794957161, accuracy: 0.9677734375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1334424465894699, accuracy: 0.964599609375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.13655522465705872, accuracy: 0.968994140625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10593396425247192, accuracy: 0.9736328125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1417810469865799, accuracy: 0.9697265625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.12848858535289764, accuracy: 0.966552734375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11995546519756317, accuracy: 0.9697265625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.09742610156536102, accuracy: 0.970947265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.09073575586080551, accuracy: 0.970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.10060814023017883, accuracy: 0.971435546875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.13061845302581787, accuracy: 0.97265625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10978224873542786, accuracy: 0.97119140625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.07251252979040146, accuracy: 0.970947265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09892161935567856, accuracy: 0.96923828125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.11228127032518387, accuracy: 0.970458984375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.13182026147842407, accuracy: 0.9697265625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.09519552439451218, accuracy: 0.9697265625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10475479066371918, accuracy: 0.971923828125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.11713416874408722, accuracy: 0.971923828125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08488953858613968, accuracy: 0.972900390625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.10915251821279526, accuracy: 0.97314453125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09393289685249329, accuracy: 0.9736328125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.07561071217060089, accuracy: 0.973876953125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0957326591014862, accuracy: 0.972900390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.10890407115221024, accuracy: 0.97509765625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.10902399569749832, accuracy: 0.971435546875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.0984882339835167, accuracy: 0.9736328125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.08083557337522507, accuracy: 0.970458984375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08753065764904022, accuracy: 0.974365234375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07044213265180588, accuracy: 0.97607421875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.10867317765951157, accuracy: 0.97216796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.07011573016643524, accuracy: 0.975341796875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07841344177722931, accuracy: 0.974853515625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.05985166132450104, accuracy: 0.976806640625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.09417275339365005, accuracy: 0.9755859375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.09670300781726837, accuracy: 0.977294921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.060950543731451035, accuracy: 0.97412109375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09641870111227036, accuracy: 0.97412109375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.06464073807001114, accuracy: 0.973388671875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07848411053419113, accuracy: 0.9755859375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06229795515537262, accuracy: 0.975341796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07986956834793091, accuracy: 0.97607421875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08099953830242157, accuracy: 0.97314453125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06053495034575462, accuracy: 0.976806640625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07900473475456238, accuracy: 0.97509765625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.08449822664260864, accuracy: 0.97705078125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.09026118367910385, accuracy: 0.97802734375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0765395313501358, accuracy: 0.976806640625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.020242691040039, accuracy: 0.68603515625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.308630347251892, accuracy: 0.778076171875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.668353796005249, accuracy: 0.84912109375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5367300510406494, accuracy: 0.88232421875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.5011027455329895, accuracy: 0.90087890625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.45053935050964355, accuracy: 0.9072265625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3954678177833557, accuracy: 0.907958984375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3306736350059509, accuracy: 0.9091796875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.34535107016563416, accuracy: 0.91357421875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.34905344247817993, accuracy: 0.916015625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.34822314977645874, accuracy: 0.920166015625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.29075682163238525, accuracy: 0.927734375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.29497960209846497, accuracy: 0.926513671875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.31935784220695496, accuracy: 0.93212890625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.28166642785072327, accuracy: 0.930908203125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2177901715040207, accuracy: 0.931640625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.28913676738739014, accuracy: 0.934326171875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.26132017374038696, accuracy: 0.935302734375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.21531787514686584, accuracy: 0.942626953125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.23895204067230225, accuracy: 0.940185546875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.23157308995723724, accuracy: 0.9423828125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2510295510292053, accuracy: 0.941162109375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.24208994209766388, accuracy: 0.939208984375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.23465730249881744, accuracy: 0.951171875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.23593859374523163, accuracy: 0.9521484375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.19932503998279572, accuracy: 0.948486328125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.2189120501279831, accuracy: 0.950439453125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.22165533900260925, accuracy: 0.95166015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.20180755853652954, accuracy: 0.958984375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19531302154064178, accuracy: 0.952392578125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.1571287363767624, accuracy: 0.957275390625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.16443489491939545, accuracy: 0.95263671875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.1599731296300888, accuracy: 0.96044921875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1747966855764389, accuracy: 0.95654296875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.16392281651496887, accuracy: 0.95654296875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.18186822533607483, accuracy: 0.960205078125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1658981293439865, accuracy: 0.95751953125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.13889743387699127, accuracy: 0.964599609375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.18030722439289093, accuracy: 0.96044921875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13913556933403015, accuracy: 0.960693359375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.14883676171302795, accuracy: 0.962646484375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1493699997663498, accuracy: 0.960205078125\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.12905354797840118, accuracy: 0.96142578125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.13391496241092682, accuracy: 0.966064453125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.15058688819408417, accuracy: 0.965576171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.15178227424621582, accuracy: 0.968017578125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.15550988912582397, accuracy: 0.964599609375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.12025508284568787, accuracy: 0.961669921875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.11718969792127609, accuracy: 0.963134765625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.1432165950536728, accuracy: 0.964111328125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.11691850423812866, accuracy: 0.96826171875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.14142921566963196, accuracy: 0.96875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1494196206331253, accuracy: 0.96435546875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1130189597606659, accuracy: 0.97021484375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.1339552104473114, accuracy: 0.969482421875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10629770159721375, accuracy: 0.970458984375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.11538060009479523, accuracy: 0.96826171875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11993680894374847, accuracy: 0.9697265625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.12576931715011597, accuracy: 0.971923828125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11569784581661224, accuracy: 0.971435546875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.12356237322092056, accuracy: 0.9658203125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.11432205140590668, accuracy: 0.969970703125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.09738088399171829, accuracy: 0.969970703125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.12407352030277252, accuracy: 0.96923828125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.12759777903556824, accuracy: 0.9677734375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09533501416444778, accuracy: 0.971923828125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.08702825754880905, accuracy: 0.9697265625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.1035311296582222, accuracy: 0.96875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.09897592663764954, accuracy: 0.97265625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.09824678301811218, accuracy: 0.973388671875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.07527107745409012, accuracy: 0.9736328125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08061065524816513, accuracy: 0.9697265625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.12574318051338196, accuracy: 0.97265625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.12939022481441498, accuracy: 0.976806640625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09073838591575623, accuracy: 0.97216796875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.08455004543066025, accuracy: 0.973876953125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08710865676403046, accuracy: 0.97314453125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09436207264661789, accuracy: 0.971435546875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09002268314361572, accuracy: 0.970458984375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.1048787459731102, accuracy: 0.970458984375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09160450100898743, accuracy: 0.973876953125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07870302349328995, accuracy: 0.97265625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.082582488656044, accuracy: 0.97607421875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09992767870426178, accuracy: 0.976318359375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09097789227962494, accuracy: 0.9755859375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.10370910167694092, accuracy: 0.971435546875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.1245073527097702, accuracy: 0.97314453125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.10438671708106995, accuracy: 0.970458984375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07127436250448227, accuracy: 0.97216796875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08328491449356079, accuracy: 0.97705078125\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07868080586194992, accuracy: 0.974853515625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.10508017987012863, accuracy: 0.973876953125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.12104932963848114, accuracy: 0.974853515625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0917569026350975, accuracy: 0.974853515625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07216914743185043, accuracy: 0.975830078125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08674246072769165, accuracy: 0.97509765625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.05935125797986984, accuracy: 0.978515625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07543826848268509, accuracy: 0.973388671875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07889237254858017, accuracy: 0.976318359375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07419299334287643, accuracy: 0.975341796875\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.0008747577667236, accuracy: 0.6826171875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2605000734329224, accuracy: 0.795654296875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7004178762435913, accuracy: 0.860107421875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5882050395011902, accuracy: 0.87939453125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.48105016350746155, accuracy: 0.88916015625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.3995799422264099, accuracy: 0.8955078125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.36727309226989746, accuracy: 0.91015625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3028531074523926, accuracy: 0.915771484375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.376713365316391, accuracy: 0.916748046875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.29034438729286194, accuracy: 0.927978515625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3366323411464691, accuracy: 0.924560546875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.26140302419662476, accuracy: 0.9287109375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3537044823169708, accuracy: 0.919189453125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2715553045272827, accuracy: 0.924072265625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2680513560771942, accuracy: 0.931884765625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.24545098841190338, accuracy: 0.93408203125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2536051273345947, accuracy: 0.930908203125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.3072992265224457, accuracy: 0.936279296875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2370452731847763, accuracy: 0.9404296875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.25403928756713867, accuracy: 0.9423828125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.208290696144104, accuracy: 0.946044921875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.21713949739933014, accuracy: 0.950927734375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.24599362909793854, accuracy: 0.951416015625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.18940801918506622, accuracy: 0.955322265625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.19774185121059418, accuracy: 0.950927734375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.20485694706439972, accuracy: 0.951416015625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.18223051726818085, accuracy: 0.95361328125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.20956851541996002, accuracy: 0.9580078125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.1445246934890747, accuracy: 0.955322265625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.2003239542245865, accuracy: 0.95263671875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.15782752633094788, accuracy: 0.958984375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.14997942745685577, accuracy: 0.95458984375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16559293866157532, accuracy: 0.961669921875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.13329927623271942, accuracy: 0.955810546875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.20733501017093658, accuracy: 0.961181640625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.19194714725017548, accuracy: 0.96044921875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.15715478360652924, accuracy: 0.958740234375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1729944497346878, accuracy: 0.958251953125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.16843169927597046, accuracy: 0.964111328125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.15208584070205688, accuracy: 0.962890625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.1765860766172409, accuracy: 0.962890625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13849087059497833, accuracy: 0.959716796875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.17139758169651031, accuracy: 0.961181640625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.14270445704460144, accuracy: 0.960693359375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.14280015230178833, accuracy: 0.962158203125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.12852805852890015, accuracy: 0.9658203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.15420429408550262, accuracy: 0.963623046875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.12215283513069153, accuracy: 0.966064453125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.13457554578781128, accuracy: 0.964599609375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.14907704293727875, accuracy: 0.9638671875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.16592653095722198, accuracy: 0.9658203125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12211568653583527, accuracy: 0.96826171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.14178331196308136, accuracy: 0.96826171875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.13470321893692017, accuracy: 0.966552734375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.139370858669281, accuracy: 0.970947265625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.14319008588790894, accuracy: 0.966796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.15200184285640717, accuracy: 0.9697265625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.10924147814512253, accuracy: 0.97265625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.10469260066747665, accuracy: 0.968994140625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11414708197116852, accuracy: 0.970458984375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.11894243210554123, accuracy: 0.968505859375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.08435948193073273, accuracy: 0.971435546875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.12052500993013382, accuracy: 0.968017578125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10884913057088852, accuracy: 0.971435546875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.14137081801891327, accuracy: 0.969970703125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.1042645052075386, accuracy: 0.969970703125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.11286701261997223, accuracy: 0.97314453125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10275711119174957, accuracy: 0.97021484375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.13403679430484772, accuracy: 0.96875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.09015297144651413, accuracy: 0.97216796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.11725158244371414, accuracy: 0.9697265625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08927652984857559, accuracy: 0.968017578125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08541128784418106, accuracy: 0.973388671875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.08932369947433472, accuracy: 0.974609375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.12671025097370148, accuracy: 0.970947265625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.1218671202659607, accuracy: 0.975830078125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.11521022766828537, accuracy: 0.971435546875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09923531115055084, accuracy: 0.972900390625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09016066044569016, accuracy: 0.975830078125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09330003708600998, accuracy: 0.975830078125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.07048462331295013, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.08479747176170349, accuracy: 0.971923828125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08642691373825073, accuracy: 0.97314453125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.06958188116550446, accuracy: 0.974365234375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07595926523208618, accuracy: 0.9736328125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.08489516377449036, accuracy: 0.9736328125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.06640949845314026, accuracy: 0.9697265625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.11310169100761414, accuracy: 0.97314453125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07907911390066147, accuracy: 0.974365234375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07306987792253494, accuracy: 0.97509765625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07506263256072998, accuracy: 0.977294921875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07243120670318604, accuracy: 0.9775390625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.10162578523159027, accuracy: 0.974609375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07837475836277008, accuracy: 0.973876953125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08074778318405151, accuracy: 0.977294921875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08051620423793793, accuracy: 0.977294921875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07512611895799637, accuracy: 0.980224609375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.08264122903347015, accuracy: 0.974609375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07232075184583664, accuracy: 0.9775390625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.09925585240125656, accuracy: 0.97802734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.015723705291748, accuracy: 0.72119140625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2783006429672241, accuracy: 0.784912109375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6156176924705505, accuracy: 0.856689453125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5164235830307007, accuracy: 0.8828125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.46633264422416687, accuracy: 0.896240234375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.3910050690174103, accuracy: 0.89990234375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3839910924434662, accuracy: 0.9033203125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.33618009090423584, accuracy: 0.9130859375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.32628437876701355, accuracy: 0.923095703125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.31859296560287476, accuracy: 0.91796875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.30746331810951233, accuracy: 0.927734375\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3305389881134033, accuracy: 0.9267578125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2537856996059418, accuracy: 0.930419921875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2849028408527374, accuracy: 0.927734375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2340894192457199, accuracy: 0.930419921875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2572365403175354, accuracy: 0.931396484375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.26045650243759155, accuracy: 0.935791015625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.22222186625003815, accuracy: 0.94091796875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.28641244769096375, accuracy: 0.936767578125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2508312463760376, accuracy: 0.939208984375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2505636513233185, accuracy: 0.94287109375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2233853042125702, accuracy: 0.94482421875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.23318098485469818, accuracy: 0.94873046875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.20661260187625885, accuracy: 0.9521484375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.1897852122783661, accuracy: 0.95068359375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.21202601492404938, accuracy: 0.94970703125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.19922491908073425, accuracy: 0.953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.2225048840045929, accuracy: 0.9482421875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.25010132789611816, accuracy: 0.95703125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.1703946590423584, accuracy: 0.9580078125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19024215638637543, accuracy: 0.958740234375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.20733322203159332, accuracy: 0.961669921875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.21647785604000092, accuracy: 0.95654296875\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.15789125859737396, accuracy: 0.959228515625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1390933245420456, accuracy: 0.9560546875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.15514755249023438, accuracy: 0.957275390625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.19873873889446259, accuracy: 0.958251953125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.15940847992897034, accuracy: 0.959228515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.162161722779274, accuracy: 0.962646484375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.18197153508663177, accuracy: 0.961181640625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16020704805850983, accuracy: 0.960205078125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13787513971328735, accuracy: 0.96142578125\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1408071666955948, accuracy: 0.963134765625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.16521358489990234, accuracy: 0.965576171875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1424224078655243, accuracy: 0.9638671875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.14565221965312958, accuracy: 0.965576171875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.12718285620212555, accuracy: 0.963623046875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.15252293646335602, accuracy: 0.96435546875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.16853494942188263, accuracy: 0.968017578125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.10622751712799072, accuracy: 0.96533203125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13073398172855377, accuracy: 0.96728515625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.1226382777094841, accuracy: 0.963623046875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.13321809470653534, accuracy: 0.965087890625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.12354256212711334, accuracy: 0.9658203125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.12253597378730774, accuracy: 0.965576171875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.16263863444328308, accuracy: 0.96484375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1067211851477623, accuracy: 0.969970703125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11149752140045166, accuracy: 0.972412109375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11943315714597702, accuracy: 0.968994140625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.15155254304409027, accuracy: 0.963623046875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.10691910982131958, accuracy: 0.970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.12278961390256882, accuracy: 0.97021484375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.13452306389808655, accuracy: 0.9697265625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.1289595365524292, accuracy: 0.970947265625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.11272916197776794, accuracy: 0.972412109375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.10266534984111786, accuracy: 0.969970703125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.12140370905399323, accuracy: 0.973876953125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10888481140136719, accuracy: 0.97119140625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.11227847635746002, accuracy: 0.968994140625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.11974392086267471, accuracy: 0.97314453125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08939013630151749, accuracy: 0.96923828125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.10361115634441376, accuracy: 0.9716796875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08452719449996948, accuracy: 0.970947265625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09727112948894501, accuracy: 0.97314453125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.10543710738420486, accuracy: 0.970458984375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.10328634083271027, accuracy: 0.973388671875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09406697750091553, accuracy: 0.97119140625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.089143306016922, accuracy: 0.974365234375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.10100259631872177, accuracy: 0.972412109375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.0801040306687355, accuracy: 0.97119140625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09189179539680481, accuracy: 0.97509765625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.0865761935710907, accuracy: 0.973388671875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.06991858780384064, accuracy: 0.9716796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.1035626009106636, accuracy: 0.974365234375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08331241458654404, accuracy: 0.974609375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.06565971672534943, accuracy: 0.97265625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08760513365268707, accuracy: 0.974365234375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08759763091802597, accuracy: 0.97265625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.09256188571453094, accuracy: 0.971923828125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08622697740793228, accuracy: 0.975341796875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.08511434495449066, accuracy: 0.97509765625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.06824346631765366, accuracy: 0.974853515625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07860326766967773, accuracy: 0.97607421875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.08241584151983261, accuracy: 0.978271484375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08762473613023758, accuracy: 0.9775390625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.09536751359701157, accuracy: 0.975830078125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06826776266098022, accuracy: 0.974365234375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07271793484687805, accuracy: 0.976318359375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08136559277772903, accuracy: 0.9736328125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.08503685146570206, accuracy: 0.97265625\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.9937784671783447, accuracy: 0.708251953125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2299925088882446, accuracy: 0.793701171875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6688814759254456, accuracy: 0.862060546875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5027331113815308, accuracy: 0.881591796875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4244104027748108, accuracy: 0.9033203125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4492586851119995, accuracy: 0.904052734375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.426957905292511, accuracy: 0.91357421875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3901525139808655, accuracy: 0.91015625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.32867032289505005, accuracy: 0.9140625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3214465081691742, accuracy: 0.91796875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3682841658592224, accuracy: 0.923095703125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.2824070155620575, accuracy: 0.92626953125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.25992754101753235, accuracy: 0.931396484375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2671366035938263, accuracy: 0.9306640625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.25472763180732727, accuracy: 0.93310546875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2455095797777176, accuracy: 0.93310546875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.27100804448127747, accuracy: 0.9345703125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.271930456161499, accuracy: 0.93896484375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.258032888174057, accuracy: 0.939453125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2584976255893707, accuracy: 0.93798828125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.25240474939346313, accuracy: 0.946533203125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.22248750925064087, accuracy: 0.947998046875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.29595649242401123, accuracy: 0.948974609375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.20465247333049774, accuracy: 0.94970703125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.20904400944709778, accuracy: 0.94970703125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.20953358709812164, accuracy: 0.950927734375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.23159237205982208, accuracy: 0.952880859375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.20806241035461426, accuracy: 0.955322265625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.18905594944953918, accuracy: 0.9541015625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.22055262327194214, accuracy: 0.955078125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.17802965641021729, accuracy: 0.956787109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.18757401406764984, accuracy: 0.959228515625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.195957213640213, accuracy: 0.95849609375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.21017171442508698, accuracy: 0.960205078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1635071188211441, accuracy: 0.959228515625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1816467046737671, accuracy: 0.958740234375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.18337440490722656, accuracy: 0.960205078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.16022853553295135, accuracy: 0.9609375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.11500953882932663, accuracy: 0.959716796875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.18104329705238342, accuracy: 0.9560546875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.1973067969083786, accuracy: 0.960693359375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13012604415416718, accuracy: 0.962890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15846192836761475, accuracy: 0.96435546875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.15178440511226654, accuracy: 0.963623046875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.16260623931884766, accuracy: 0.96337890625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.16485746204853058, accuracy: 0.9658203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.12392405420541763, accuracy: 0.967529296875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.13200359046459198, accuracy: 0.96337890625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1712656021118164, accuracy: 0.965576171875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.13925935328006744, accuracy: 0.96337890625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12215372920036316, accuracy: 0.967529296875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.1308179497718811, accuracy: 0.9658203125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.13252024352550507, accuracy: 0.968505859375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.15260884165763855, accuracy: 0.97021484375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.0986628532409668, accuracy: 0.97216796875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.13661983609199524, accuracy: 0.968505859375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1310102492570877, accuracy: 0.970947265625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.09212104231119156, accuracy: 0.967041015625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.0982290506362915, accuracy: 0.9716796875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.10350266844034195, accuracy: 0.9697265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.14015908539295197, accuracy: 0.97119140625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.10042118281126022, accuracy: 0.970703125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.08700041472911835, accuracy: 0.96923828125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.1495450735092163, accuracy: 0.9716796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.11708345264196396, accuracy: 0.97216796875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.10695742815732956, accuracy: 0.969970703125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.10106606781482697, accuracy: 0.97265625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10682228952646255, accuracy: 0.970703125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.14361180365085602, accuracy: 0.970703125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.09317539632320404, accuracy: 0.97021484375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.10716260969638824, accuracy: 0.974365234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.0898832306265831, accuracy: 0.97021484375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.10181516408920288, accuracy: 0.97412109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.1015564575791359, accuracy: 0.9697265625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.08762238174676895, accuracy: 0.9716796875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09047383069992065, accuracy: 0.971435546875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09548074007034302, accuracy: 0.97314453125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.10667873173952103, accuracy: 0.97412109375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08649896085262299, accuracy: 0.971923828125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.10008357465267181, accuracy: 0.97802734375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09707389771938324, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07263130694627762, accuracy: 0.971435546875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.09245859831571579, accuracy: 0.9716796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.08899970352649689, accuracy: 0.975830078125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07091152667999268, accuracy: 0.9736328125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.06891407072544098, accuracy: 0.974365234375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07963375002145767, accuracy: 0.971923828125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08024951070547104, accuracy: 0.97607421875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.06104502081871033, accuracy: 0.97802734375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.0781664326786995, accuracy: 0.972412109375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.0832466259598732, accuracy: 0.973388671875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.10983947664499283, accuracy: 0.97802734375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07088690996170044, accuracy: 0.97412109375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07740801572799683, accuracy: 0.9765625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07294292002916336, accuracy: 0.978759765625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08134828507900238, accuracy: 0.974365234375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.097989022731781, accuracy: 0.977294921875\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.05770840868353844, accuracy: 0.9775390625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.06202758476138115, accuracy: 0.9765625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06503388285636902, accuracy: 0.97705078125\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.0119478702545166, accuracy: 0.7236328125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2827945947647095, accuracy: 0.797607421875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6645709276199341, accuracy: 0.8544921875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5479035377502441, accuracy: 0.8701171875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.474586546421051, accuracy: 0.890869140625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4108172655105591, accuracy: 0.904052734375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.41211947798728943, accuracy: 0.90576171875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.34245362877845764, accuracy: 0.909912109375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.33866357803344727, accuracy: 0.90966796875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.35274696350097656, accuracy: 0.925537109375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3104850947856903, accuracy: 0.926513671875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.2909203767776489, accuracy: 0.9267578125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.29794245958328247, accuracy: 0.93017578125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.28808435797691345, accuracy: 0.936767578125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2775019705295563, accuracy: 0.93017578125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2771950364112854, accuracy: 0.935302734375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.25482049584388733, accuracy: 0.937744140625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2704850435256958, accuracy: 0.935791015625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2890079915523529, accuracy: 0.936767578125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2769952714443207, accuracy: 0.94140625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2195979803800583, accuracy: 0.943359375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2192341536283493, accuracy: 0.94287109375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.18230308592319489, accuracy: 0.943603515625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.21312572062015533, accuracy: 0.942626953125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.2106098085641861, accuracy: 0.94970703125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.24743160605430603, accuracy: 0.94873046875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.22700293362140656, accuracy: 0.951416015625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.18429817259311676, accuracy: 0.9560546875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.15428526699543, accuracy: 0.955078125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19265712797641754, accuracy: 0.9560546875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19617703557014465, accuracy: 0.958251953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.152889221906662, accuracy: 0.958740234375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16198179125785828, accuracy: 0.958984375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.14909878373146057, accuracy: 0.960693359375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.17223523557186127, accuracy: 0.957763671875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.19355779886245728, accuracy: 0.958740234375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1576499342918396, accuracy: 0.9580078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.16753147542476654, accuracy: 0.958984375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.17022626101970673, accuracy: 0.961181640625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.16318610310554504, accuracy: 0.963623046875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.15744329988956451, accuracy: 0.96484375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1500862091779709, accuracy: 0.96533203125\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15323451161384583, accuracy: 0.96728515625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.15216697752475739, accuracy: 0.964599609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.16193348169326782, accuracy: 0.965576171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.17954204976558685, accuracy: 0.96533203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.14401142299175262, accuracy: 0.96728515625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1345602124929428, accuracy: 0.969482421875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1511695832014084, accuracy: 0.965576171875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.14150306582450867, accuracy: 0.968505859375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12848466634750366, accuracy: 0.96826171875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11771929264068604, accuracy: 0.965576171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.14349813759326935, accuracy: 0.968017578125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.10977853834629059, accuracy: 0.969970703125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.10994432866573334, accuracy: 0.96923828125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.16036100685596466, accuracy: 0.964111328125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1154952347278595, accuracy: 0.967529296875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1348850429058075, accuracy: 0.967041015625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1072569414973259, accuracy: 0.97021484375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.10524208843708038, accuracy: 0.97021484375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.11840257793664932, accuracy: 0.97021484375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.14139439165592194, accuracy: 0.969970703125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.1566508561372757, accuracy: 0.97314453125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10793929547071457, accuracy: 0.97412109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.07282999157905579, accuracy: 0.968017578125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09704147279262543, accuracy: 0.971435546875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.07973622530698776, accuracy: 0.968994140625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.08409372717142105, accuracy: 0.970458984375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.14270660281181335, accuracy: 0.973388671875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.11312193423509598, accuracy: 0.97216796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.10662833601236343, accuracy: 0.973388671875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.12702858448028564, accuracy: 0.969482421875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.11206845194101334, accuracy: 0.9736328125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09075610339641571, accuracy: 0.97509765625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.10053855925798416, accuracy: 0.968994140625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.07625503093004227, accuracy: 0.973388671875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09105850011110306, accuracy: 0.975341796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09002422541379929, accuracy: 0.973876953125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.1025058701634407, accuracy: 0.973876953125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09266506880521774, accuracy: 0.97265625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.10916537046432495, accuracy: 0.975341796875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07536888122558594, accuracy: 0.972900390625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.06375344842672348, accuracy: 0.97412109375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.07941640168428421, accuracy: 0.97607421875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08462018519639969, accuracy: 0.976318359375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09226702153682709, accuracy: 0.976806640625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07824216783046722, accuracy: 0.974853515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08612033724784851, accuracy: 0.977294921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.05895722657442093, accuracy: 0.979248046875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.10041683167219162, accuracy: 0.9775390625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07297267019748688, accuracy: 0.9775390625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.06904833018779755, accuracy: 0.97802734375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06643586605787277, accuracy: 0.973388671875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05265766754746437, accuracy: 0.97607421875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.0763888955116272, accuracy: 0.979248046875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08840934932231903, accuracy: 0.97900390625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.058291882276535034, accuracy: 0.9765625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06044882535934448, accuracy: 0.974853515625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.06547907739877701, accuracy: 0.978515625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0695769339799881, accuracy: 0.975341796875\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.99348783493042, accuracy: 0.6884765625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2349506616592407, accuracy: 0.7939453125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6720675826072693, accuracy: 0.852294921875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.4973510205745697, accuracy: 0.8759765625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.44385525584220886, accuracy: 0.896240234375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4423273503780365, accuracy: 0.904541015625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.43425148725509644, accuracy: 0.909423828125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.33875396847724915, accuracy: 0.909423828125\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3273933231830597, accuracy: 0.92236328125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3631095886230469, accuracy: 0.925048828125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3275323808193207, accuracy: 0.916748046875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.32705047726631165, accuracy: 0.929931640625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3403705060482025, accuracy: 0.938720703125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2572968304157257, accuracy: 0.93212890625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.24675734341144562, accuracy: 0.93212890625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.3414630591869354, accuracy: 0.933349609375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.23902486264705658, accuracy: 0.93408203125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.23336556553840637, accuracy: 0.93310546875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.23321649432182312, accuracy: 0.9365234375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2871828079223633, accuracy: 0.93798828125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2646210491657257, accuracy: 0.942626953125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.19767455756664276, accuracy: 0.942626953125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.22425539791584015, accuracy: 0.94580078125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.24261873960494995, accuracy: 0.94970703125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.18834474682807922, accuracy: 0.952392578125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.20205633342266083, accuracy: 0.95263671875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.21800345182418823, accuracy: 0.949951171875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.21920619904994965, accuracy: 0.954345703125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.20526020228862762, accuracy: 0.94873046875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.1764620989561081, accuracy: 0.950439453125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.22976937890052795, accuracy: 0.953857421875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.18239159882068634, accuracy: 0.95751953125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.22219258546829224, accuracy: 0.95556640625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.18281817436218262, accuracy: 0.96044921875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.12466543912887573, accuracy: 0.956787109375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.16275784373283386, accuracy: 0.958984375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.21241118013858795, accuracy: 0.96484375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1673830896615982, accuracy: 0.961669921875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.15785633027553558, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.19250081479549408, accuracy: 0.965087890625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.14715993404388428, accuracy: 0.96240234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.157063290476799, accuracy: 0.96435546875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.14463898539543152, accuracy: 0.9619140625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.1373831331729889, accuracy: 0.964599609375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1351698786020279, accuracy: 0.965087890625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.13151657581329346, accuracy: 0.96533203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.11083517968654633, accuracy: 0.96630859375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.14315633475780487, accuracy: 0.968017578125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.12029924243688583, accuracy: 0.964599609375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.1483995020389557, accuracy: 0.965576171875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13783423602581024, accuracy: 0.96435546875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.09821251779794693, accuracy: 0.97216796875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1813535839319229, accuracy: 0.965087890625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.09382393956184387, accuracy: 0.971923828125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.11070551723241806, accuracy: 0.968505859375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10510142147541046, accuracy: 0.9697265625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.14653280377388, accuracy: 0.967041015625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1472139209508896, accuracy: 0.96728515625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.12526935338974, accuracy: 0.97021484375\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.1295652985572815, accuracy: 0.969482421875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.09710860997438431, accuracy: 0.97412109375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.09621244668960571, accuracy: 0.9716796875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.10260343551635742, accuracy: 0.970458984375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10248974710702896, accuracy: 0.96875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.09497721493244171, accuracy: 0.970947265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.08771955966949463, accuracy: 0.974609375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.09704893827438354, accuracy: 0.970458984375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11901449412107468, accuracy: 0.97314453125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10710710287094116, accuracy: 0.974365234375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10331214219331741, accuracy: 0.97607421875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.10592428594827652, accuracy: 0.97412109375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.09712441265583038, accuracy: 0.972412109375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.07775011658668518, accuracy: 0.9716796875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.07868822664022446, accuracy: 0.973876953125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09992202371358871, accuracy: 0.966552734375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.08813133090734482, accuracy: 0.97119140625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08591078221797943, accuracy: 0.97412109375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.1126716360449791, accuracy: 0.97216796875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08077847212553024, accuracy: 0.970703125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09754224866628647, accuracy: 0.974609375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09826067835092545, accuracy: 0.9697265625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09438224136829376, accuracy: 0.97705078125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08222437649965286, accuracy: 0.972412109375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.08592400699853897, accuracy: 0.97314453125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08927811682224274, accuracy: 0.97607421875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07838991284370422, accuracy: 0.97265625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07987840473651886, accuracy: 0.974609375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07167025655508041, accuracy: 0.970703125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07284247130155563, accuracy: 0.975341796875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09848091006278992, accuracy: 0.973388671875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07033205032348633, accuracy: 0.974609375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.08260352909564972, accuracy: 0.97314453125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.09076717495918274, accuracy: 0.97607421875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.08065337687730789, accuracy: 0.975830078125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.06801539659500122, accuracy: 0.974853515625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.07285232096910477, accuracy: 0.97509765625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.0686938613653183, accuracy: 0.9736328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.05774510279297829, accuracy: 0.973876953125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07560854405164719, accuracy: 0.976806640625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06519642472267151, accuracy: 0.974853515625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.030488967895508, accuracy: 0.682861328125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2973546981811523, accuracy: 0.784423828125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7194143533706665, accuracy: 0.85693359375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5391255021095276, accuracy: 0.87939453125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4136863648891449, accuracy: 0.896240234375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.3761279881000519, accuracy: 0.901123046875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3665015995502472, accuracy: 0.90771484375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3802467882633209, accuracy: 0.9150390625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.33606159687042236, accuracy: 0.921142578125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3197391927242279, accuracy: 0.920166015625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.34141355752944946, accuracy: 0.927001953125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.28355899453163147, accuracy: 0.9248046875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3243047595024109, accuracy: 0.925048828125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2645496428012848, accuracy: 0.922607421875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.24285036325454712, accuracy: 0.931884765625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.24967601895332336, accuracy: 0.934814453125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2327084243297577, accuracy: 0.93603515625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2848014533519745, accuracy: 0.931640625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2443849742412567, accuracy: 0.9384765625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2611818313598633, accuracy: 0.943603515625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.22770269215106964, accuracy: 0.941162109375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.19364063441753387, accuracy: 0.94482421875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.19411560893058777, accuracy: 0.94580078125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.22450995445251465, accuracy: 0.94970703125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.20154114067554474, accuracy: 0.944580078125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.24379751086235046, accuracy: 0.951171875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.24440757930278778, accuracy: 0.9482421875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.22232143580913544, accuracy: 0.95361328125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.2330193817615509, accuracy: 0.953857421875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19238081574440002, accuracy: 0.952880859375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.20143187046051025, accuracy: 0.95751953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.19085149466991425, accuracy: 0.957275390625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.1418883502483368, accuracy: 0.958984375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.19259034097194672, accuracy: 0.9580078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.21200814843177795, accuracy: 0.95947265625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.16858606040477753, accuracy: 0.95703125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.13939888775348663, accuracy: 0.961669921875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.15929250419139862, accuracy: 0.96044921875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.18333366513252258, accuracy: 0.961669921875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13931021094322205, accuracy: 0.9619140625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.18274664878845215, accuracy: 0.9619140625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.16535983979701996, accuracy: 0.968505859375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1744976043701172, accuracy: 0.9658203125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.12191884219646454, accuracy: 0.968017578125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.16817884147167206, accuracy: 0.962646484375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.13929690420627594, accuracy: 0.964111328125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.12537434697151184, accuracy: 0.963134765625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.13976895809173584, accuracy: 0.965087890625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.17022131383419037, accuracy: 0.963623046875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.13055503368377686, accuracy: 0.969482421875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13404658436775208, accuracy: 0.960205078125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.13010719418525696, accuracy: 0.968017578125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.12968777120113373, accuracy: 0.967041015625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1172451600432396, accuracy: 0.96728515625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.1280113309621811, accuracy: 0.973388671875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.15416091680526733, accuracy: 0.966796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1137639656662941, accuracy: 0.96826171875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.10047566890716553, accuracy: 0.97265625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11340869218111038, accuracy: 0.969970703125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.1152036115527153, accuracy: 0.973388671875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.11359800398349762, accuracy: 0.97119140625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.12775099277496338, accuracy: 0.9697265625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.11593780666589737, accuracy: 0.972900390625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.14374254643917084, accuracy: 0.9716796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.1202777773141861, accuracy: 0.9697265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.08178596943616867, accuracy: 0.97216796875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.09761165082454681, accuracy: 0.970703125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.09951844066381454, accuracy: 0.971435546875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.08108429610729218, accuracy: 0.96923828125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.13726529479026794, accuracy: 0.972412109375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.07552667707204819, accuracy: 0.9716796875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.10001806169748306, accuracy: 0.97265625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08500545471906662, accuracy: 0.97509765625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09882329404354095, accuracy: 0.971435546875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.06853947043418884, accuracy: 0.97412109375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.10303901135921478, accuracy: 0.974365234375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.10403410345315933, accuracy: 0.97412109375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.12161106616258621, accuracy: 0.974853515625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09266125410795212, accuracy: 0.972412109375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.08332980424165726, accuracy: 0.97509765625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08532089740037918, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.08222359418869019, accuracy: 0.973876953125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.0963563621044159, accuracy: 0.975341796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09893258661031723, accuracy: 0.97412109375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09952188283205032, accuracy: 0.974609375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.10223034769296646, accuracy: 0.97412109375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.10111112147569656, accuracy: 0.978515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.1058114692568779, accuracy: 0.975830078125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08405441045761108, accuracy: 0.9755859375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.0804935023188591, accuracy: 0.9765625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.06982294470071793, accuracy: 0.974365234375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05854088440537453, accuracy: 0.973388671875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06112487241625786, accuracy: 0.973388671875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07463836669921875, accuracy: 0.974853515625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.05935509130358696, accuracy: 0.978271484375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06187155097723007, accuracy: 0.9716796875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07913437485694885, accuracy: 0.975830078125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07944760471582413, accuracy: 0.975341796875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.06312321871519089, accuracy: 0.9755859375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06947531551122665, accuracy: 0.976318359375\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.9994394779205322, accuracy: 0.717041015625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.242367148399353, accuracy: 0.802001953125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6880810856819153, accuracy: 0.8583984375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5248346328735352, accuracy: 0.87744140625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.5095288753509521, accuracy: 0.898193359375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4134746789932251, accuracy: 0.8984375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.34492117166519165, accuracy: 0.90380859375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3857681453227997, accuracy: 0.91357421875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3361559510231018, accuracy: 0.92138671875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.31356877088546753, accuracy: 0.921875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3402791917324066, accuracy: 0.924072265625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.31736236810684204, accuracy: 0.925048828125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2548653483390808, accuracy: 0.921630859375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.288828045129776, accuracy: 0.93212890625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.27402353286743164, accuracy: 0.933349609375\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.24426132440567017, accuracy: 0.93603515625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.24744002521038055, accuracy: 0.930908203125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2750580906867981, accuracy: 0.933837890625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.24019327759742737, accuracy: 0.931640625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.22894111275672913, accuracy: 0.942138671875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2170838564634323, accuracy: 0.931396484375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.19372569024562836, accuracy: 0.942138671875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.2263466864824295, accuracy: 0.940185546875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.223880335688591, accuracy: 0.9443359375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.21969656646251678, accuracy: 0.94873046875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.18039903044700623, accuracy: 0.947021484375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.22330006957054138, accuracy: 0.953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.20759840309619904, accuracy: 0.956787109375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.21939349174499512, accuracy: 0.9541015625\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.2115684300661087, accuracy: 0.95361328125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19826224446296692, accuracy: 0.960205078125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.18315427005290985, accuracy: 0.95849609375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.23316770792007446, accuracy: 0.956298828125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.17922373116016388, accuracy: 0.961669921875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1929168701171875, accuracy: 0.95947265625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1725379079580307, accuracy: 0.959716796875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.17015117406845093, accuracy: 0.959228515625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.13786083459854126, accuracy: 0.95703125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.14951667189598083, accuracy: 0.962158203125\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.14960864186286926, accuracy: 0.96044921875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.19619883596897125, accuracy: 0.96240234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1999070644378662, accuracy: 0.961181640625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.18375641107559204, accuracy: 0.962646484375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.15991906821727753, accuracy: 0.967041015625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1774049550294876, accuracy: 0.964111328125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.1293056309223175, accuracy: 0.96337890625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.16517896950244904, accuracy: 0.964599609375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.15333868563175201, accuracy: 0.963134765625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.14617358148097992, accuracy: 0.965576171875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.11821749806404114, accuracy: 0.96435546875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.16026118397712708, accuracy: 0.971435546875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.14120036363601685, accuracy: 0.968505859375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.12951906025409698, accuracy: 0.970703125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.11190427094697952, accuracy: 0.962890625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.16032885015010834, accuracy: 0.96533203125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.12719078361988068, accuracy: 0.966796875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.11653804779052734, accuracy: 0.969482421875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1318417638540268, accuracy: 0.969482421875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11657232791185379, accuracy: 0.96728515625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.09060229361057281, accuracy: 0.970947265625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.08348146826028824, accuracy: 0.969970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.09310326725244522, accuracy: 0.966064453125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.10859402269124985, accuracy: 0.970703125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.09919612854719162, accuracy: 0.969482421875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.10118337720632553, accuracy: 0.970458984375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09243570268154144, accuracy: 0.97119140625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.0891517624258995, accuracy: 0.96923828125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.12731073796749115, accuracy: 0.973388671875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.11260111629962921, accuracy: 0.97509765625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.1288565844297409, accuracy: 0.974609375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08468903601169586, accuracy: 0.97216796875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.09488093107938766, accuracy: 0.97509765625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.1123761534690857, accuracy: 0.973876953125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09808216243982315, accuracy: 0.973388671875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09497513622045517, accuracy: 0.970458984375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.08840504288673401, accuracy: 0.9716796875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.1046457290649414, accuracy: 0.97216796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.12205345183610916, accuracy: 0.97265625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.0882139801979065, accuracy: 0.970703125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.11968717724084854, accuracy: 0.97412109375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08037788420915604, accuracy: 0.974365234375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.08182837814092636, accuracy: 0.97119140625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.09286290407180786, accuracy: 0.97705078125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.06620823591947556, accuracy: 0.972412109375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06153719872236252, accuracy: 0.975830078125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09901297837495804, accuracy: 0.9755859375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07868814468383789, accuracy: 0.977783203125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.106369249522686, accuracy: 0.972900390625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.10094282031059265, accuracy: 0.974853515625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08170372247695923, accuracy: 0.97509765625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07853195071220398, accuracy: 0.972900390625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07008769363164902, accuracy: 0.974853515625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06232774630188942, accuracy: 0.97705078125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.06183525174856186, accuracy: 0.974853515625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.09676427394151688, accuracy: 0.97265625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.09768392145633698, accuracy: 0.976806640625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07197050750255585, accuracy: 0.972900390625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06930072605609894, accuracy: 0.9775390625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.10726160556077957, accuracy: 0.974853515625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.062034089118242264, accuracy: 0.9794921875\n"
          ]
        }
      ],
      "source": [
        "resultados['SGDM'] = {}\n",
        "resultados['SGDM']['val_acc_list'] = [0] * epochs\n",
        "resultados['SGDM']['test_acc'] = 0\n",
        "resultados['SGDM']['cost'] = [0] * epochs\n",
        "resultados['SGDM']['time'] = 0\n",
        "resultados['SGDM']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    SGDM_acc_list, SGDM_cost_list, SGDM_lr_list, SGDM_time, SGDM_acc, SGDM_epochs = SGDM()\n",
        "    resultados['SGDM']['val_acc_list'] = SumList(resultados['SGDM']['val_acc_list'], SGDM_acc_list)\n",
        "    resultados['SGDM']['test_acc'] += SGDM_acc\n",
        "    resultados['SGDM']['cost'] = SumList(resultados['SGDM']['cost'], SGDM_cost_list)\n",
        "    resultados['SGDM']['time'] += SGDM_time\n",
        "    resultados['SGDM']['epochs'] += SGDM_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['SGDM']['name'] = 'SGDM'\n",
        "resultados['SGDM']['lr'] = SGDM_lr_list\n",
        "resultados['SGDM']['test_acc'] = resultados['SGDM']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['SGDM']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['SGDM']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['SGDM']['cost'] = DeleteZerosFromList(DivideList(resultados['SGDM']['cost'], MAX_ITERATIONS))\n",
        "resultados['SGDM']['time'] = resultados['SGDM']['time'] / MAX_ITERATIONS\n",
        "resultados['SGDM']['epochs'] = resultados['SGDM']['epochs'] / MAX_ITERATIONS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb5Poi8cmVHP"
      },
      "source": [
        "## RMSProp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqKQ6cfiKqa"
      },
      "source": [
        "$\\alpha: 1x10^{-2}$ \n",
        "\n",
        "$beta: 0.9$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pEqYnO8vfGac"
      },
      "outputs": [],
      "source": [
        "def RMSP():\n",
        "    modelRMSP = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(), nn.Dropout(dropout),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimiserRMSP = torch.optim.RMSprop(modelRMSP.parameters(), lr=lr, alpha=0.9)\n",
        "    start.record()\n",
        "    RMSP_acc_list, RMSP_cost_list,RMSP_lr_list, RMSP_epochs = train(modelRMSP, optimiserRMSP,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    RMSP_time = start.elapsed_time(end)\n",
        "\n",
        "    RMSP_acc = accuracy(modelRMSP, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return RMSP_acc_list, RMSP_cost_list, RMSP_lr_list, RMSP_time, RMSP_acc, RMSP_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv7uCfwOmXN3",
        "outputId": "0c45ab5b-7cd7-44b9-96e5-a6bae3f06128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, learning_rate:0.01,costo: 2.01393723487854, accuracy: 0.67236328125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2801907062530518, accuracy: 0.782958984375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6904789805412292, accuracy: 0.8583984375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5533510446548462, accuracy: 0.882080078125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.40522342920303345, accuracy: 0.898193359375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.42398926615715027, accuracy: 0.906494140625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.39787426590919495, accuracy: 0.90283203125\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.33599111437797546, accuracy: 0.911865234375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.36424607038497925, accuracy: 0.916748046875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.34269019961357117, accuracy: 0.91748046875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.368438720703125, accuracy: 0.9208984375\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3039817214012146, accuracy: 0.925048828125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.30652374029159546, accuracy: 0.930419921875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2874533534049988, accuracy: 0.93017578125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.27758708596229553, accuracy: 0.93408203125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.31025248765945435, accuracy: 0.937744140625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.27413210272789, accuracy: 0.933837890625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.25708773732185364, accuracy: 0.936279296875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2126525342464447, accuracy: 0.94140625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.22462260723114014, accuracy: 0.945556640625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.23065511882305145, accuracy: 0.946533203125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.20294122397899628, accuracy: 0.942626953125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.21384474635124207, accuracy: 0.945556640625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.20100046694278717, accuracy: 0.948486328125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.22764021158218384, accuracy: 0.951416015625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.18771494925022125, accuracy: 0.948486328125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.1868332028388977, accuracy: 0.949951171875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.18065883219242096, accuracy: 0.952392578125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.2254650592803955, accuracy: 0.95703125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19559946656227112, accuracy: 0.95458984375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19545084238052368, accuracy: 0.957763671875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.19555695354938507, accuracy: 0.955322265625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.18845152854919434, accuracy: 0.960205078125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1641809642314911, accuracy: 0.9619140625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1531139463186264, accuracy: 0.962646484375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.18705438077449799, accuracy: 0.957763671875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.14478076994419098, accuracy: 0.960205078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.12959302961826324, accuracy: 0.959228515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.1612621396780014, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.15133313834667206, accuracy: 0.96240234375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16460981965065002, accuracy: 0.962646484375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.151754230260849, accuracy: 0.96337890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1850087195634842, accuracy: 0.960693359375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.16352888941764832, accuracy: 0.966064453125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.11642517149448395, accuracy: 0.96142578125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.13499051332473755, accuracy: 0.965087890625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.13424405455589294, accuracy: 0.964599609375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.15153631567955017, accuracy: 0.96875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1661953181028366, accuracy: 0.96728515625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12532779574394226, accuracy: 0.9697265625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.17916153371334076, accuracy: 0.96630859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.10125194489955902, accuracy: 0.966064453125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.12283013015985489, accuracy: 0.9677734375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.11173466593027115, accuracy: 0.968505859375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.11423138529062271, accuracy: 0.9697265625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.13001742959022522, accuracy: 0.96533203125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.12318632006645203, accuracy: 0.969482421875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1148800253868103, accuracy: 0.970703125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1323832869529724, accuracy: 0.969970703125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11858612298965454, accuracy: 0.9716796875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.1372704654932022, accuracy: 0.970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.13597357273101807, accuracy: 0.974609375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.11643778532743454, accuracy: 0.973876953125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07987424731254578, accuracy: 0.97119140625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.10764690488576889, accuracy: 0.974609375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.11578905582427979, accuracy: 0.97509765625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.13032621145248413, accuracy: 0.9736328125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.1378515213727951, accuracy: 0.971435546875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.07100075483322144, accuracy: 0.974609375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.13171371817588806, accuracy: 0.976318359375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08516844362020493, accuracy: 0.978759765625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.07964174449443817, accuracy: 0.973876953125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.07867627590894699, accuracy: 0.97412109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.08682043850421906, accuracy: 0.972900390625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.10951446741819382, accuracy: 0.973388671875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.11097666621208191, accuracy: 0.976806640625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08714714646339417, accuracy: 0.971923828125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.06488907337188721, accuracy: 0.973876953125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.0964946299791336, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.08713995665311813, accuracy: 0.974365234375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.06951858848333359, accuracy: 0.9736328125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.08549617975950241, accuracy: 0.9765625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.09996555745601654, accuracy: 0.9765625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.10377657413482666, accuracy: 0.974609375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07430463284254074, accuracy: 0.972412109375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.08502048254013062, accuracy: 0.977294921875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.06407710164785385, accuracy: 0.978515625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07451342791318893, accuracy: 0.9755859375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07451678067445755, accuracy: 0.974365234375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08144524693489075, accuracy: 0.9755859375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07070279866456985, accuracy: 0.976318359375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.05661480873823166, accuracy: 0.974365234375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.08229464292526245, accuracy: 0.9755859375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.0862630233168602, accuracy: 0.9794921875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.11173205077648163, accuracy: 0.978515625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08526533097028732, accuracy: 0.97705078125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07739455997943878, accuracy: 0.977783203125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.0690065547823906, accuracy: 0.977783203125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.060202647000551224, accuracy: 0.974853515625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07663513720035553, accuracy: 0.97802734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.002662181854248, accuracy: 0.71142578125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2589435577392578, accuracy: 0.78125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7005135416984558, accuracy: 0.8447265625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.4701039791107178, accuracy: 0.870849609375\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4829963743686676, accuracy: 0.89599609375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4029119610786438, accuracy: 0.901123046875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.36652567982673645, accuracy: 0.90625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3291018605232239, accuracy: 0.913818359375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.31918197870254517, accuracy: 0.911865234375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.29320228099823, accuracy: 0.921142578125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.33329132199287415, accuracy: 0.925048828125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3557548224925995, accuracy: 0.9306640625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3021305799484253, accuracy: 0.927490234375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2575439512729645, accuracy: 0.930908203125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2355874925851822, accuracy: 0.93017578125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.24159137904644012, accuracy: 0.935791015625\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.33823201060295105, accuracy: 0.933837890625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.25329023599624634, accuracy: 0.93310546875\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.26902005076408386, accuracy: 0.935546875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.21891318261623383, accuracy: 0.9375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.25948429107666016, accuracy: 0.94091796875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2112922966480255, accuracy: 0.949462890625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.2872631847858429, accuracy: 0.9462890625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.23722338676452637, accuracy: 0.94873046875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.2248173952102661, accuracy: 0.944580078125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.2316913604736328, accuracy: 0.951171875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.19542118906974792, accuracy: 0.9521484375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.2016984224319458, accuracy: 0.951904296875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.18939773738384247, accuracy: 0.951904296875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.21549910306930542, accuracy: 0.950439453125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.14236880838871002, accuracy: 0.951171875\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.20381228625774384, accuracy: 0.957763671875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.18819725513458252, accuracy: 0.952880859375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.21191900968551636, accuracy: 0.957763671875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.16673722863197327, accuracy: 0.958984375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17703744769096375, accuracy: 0.955322265625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.16515196859836578, accuracy: 0.96142578125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.17954574525356293, accuracy: 0.9580078125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.1631401926279068, accuracy: 0.964599609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13990972936153412, accuracy: 0.960205078125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.1470465511083603, accuracy: 0.961669921875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.15621815621852875, accuracy: 0.96337890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.14935964345932007, accuracy: 0.96435546875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.16124576330184937, accuracy: 0.964111328125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.15752187371253967, accuracy: 0.965087890625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.14520737528800964, accuracy: 0.962158203125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.1259557455778122, accuracy: 0.96337890625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.16252674162387848, accuracy: 0.96240234375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.10753081738948822, accuracy: 0.963623046875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.15398576855659485, accuracy: 0.964599609375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12918445467948914, accuracy: 0.96630859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12193030118942261, accuracy: 0.96630859375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.13747307658195496, accuracy: 0.9658203125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.14779743552207947, accuracy: 0.970947265625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.12236010283231735, accuracy: 0.966552734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.1276373267173767, accuracy: 0.968017578125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.12105489522218704, accuracy: 0.96826171875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11549877375364304, accuracy: 0.967041015625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.10530398786067963, accuracy: 0.970703125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.10829614102840424, accuracy: 0.969482421875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.10114744305610657, accuracy: 0.970947265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.1287911832332611, accuracy: 0.9697265625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.09998422116041183, accuracy: 0.969970703125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10767441242933273, accuracy: 0.967529296875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.13200850784778595, accuracy: 0.970703125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.12317229807376862, accuracy: 0.967041015625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.08529864251613617, accuracy: 0.97119140625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11875356733798981, accuracy: 0.971435546875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10768475383520126, accuracy: 0.973876953125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10271047055721283, accuracy: 0.972900390625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.09718678891658783, accuracy: 0.967529296875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.09394905716180801, accuracy: 0.968017578125\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.09988252073526382, accuracy: 0.972412109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.11962497234344482, accuracy: 0.97021484375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.08845194429159164, accuracy: 0.96923828125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0933583453297615, accuracy: 0.97509765625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.1078459620475769, accuracy: 0.97314453125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.12223301082849503, accuracy: 0.97265625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.10470165312290192, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09906091541051865, accuracy: 0.973876953125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09048210829496384, accuracy: 0.978271484375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09765244275331497, accuracy: 0.9755859375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.06437909603118896, accuracy: 0.97509765625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09133218973875046, accuracy: 0.97314453125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08342035114765167, accuracy: 0.976806640625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.055834028869867325, accuracy: 0.97705078125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.10199723392724991, accuracy: 0.974609375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08811522275209427, accuracy: 0.976806640625\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08348440378904343, accuracy: 0.974365234375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09724663943052292, accuracy: 0.974365234375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.08589400351047516, accuracy: 0.974853515625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.0923108235001564, accuracy: 0.97265625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.09215762466192245, accuracy: 0.97705078125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.09402070939540863, accuracy: 0.973388671875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07273998856544495, accuracy: 0.979736328125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.07425981760025024, accuracy: 0.976806640625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.10621605068445206, accuracy: 0.9775390625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07578809559345245, accuracy: 0.978271484375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07147905230522156, accuracy: 0.976318359375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.08334513753652573, accuracy: 0.976806640625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.013920545578003, accuracy: 0.6923828125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2672957181930542, accuracy: 0.787353515625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6731641292572021, accuracy: 0.855224609375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.503170907497406, accuracy: 0.881591796875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.5036970376968384, accuracy: 0.899169921875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4339245557785034, accuracy: 0.904052734375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.383653849363327, accuracy: 0.904541015625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.402346134185791, accuracy: 0.912109375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3259615898132324, accuracy: 0.9228515625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.29897141456604004, accuracy: 0.918701171875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.31282639503479004, accuracy: 0.92236328125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.29950952529907227, accuracy: 0.923583984375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.32493501901626587, accuracy: 0.92822265625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2606506645679474, accuracy: 0.9296875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2919580936431885, accuracy: 0.926513671875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.3247930109500885, accuracy: 0.9326171875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2792128920555115, accuracy: 0.937255859375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2340843826532364, accuracy: 0.93212890625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.22178404033184052, accuracy: 0.942626953125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.261089026927948, accuracy: 0.942138671875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2718563973903656, accuracy: 0.944091796875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.27052560448646545, accuracy: 0.945556640625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.23138535022735596, accuracy: 0.946533203125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.19714757800102234, accuracy: 0.94775390625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.24162302911281586, accuracy: 0.950439453125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.2178536057472229, accuracy: 0.953369140625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.1756446808576584, accuracy: 0.95458984375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.21689064800739288, accuracy: 0.955078125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.1931908279657364, accuracy: 0.95263671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.2124345600605011, accuracy: 0.956298828125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.23560704290866852, accuracy: 0.955322265625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.21542061865329742, accuracy: 0.9541015625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.19717764854431152, accuracy: 0.9599609375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.19004468619823456, accuracy: 0.95947265625\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.14698991179466248, accuracy: 0.959228515625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.18789120018482208, accuracy: 0.9580078125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.18663395941257477, accuracy: 0.960205078125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.17672808468341827, accuracy: 0.963623046875\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.13518591225147247, accuracy: 0.96240234375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.18862326443195343, accuracy: 0.96533203125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.21214944124221802, accuracy: 0.96240234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.12140143662691116, accuracy: 0.961181640625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15371768176555634, accuracy: 0.96484375\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.16589294373989105, accuracy: 0.964111328125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.14551976323127747, accuracy: 0.95947265625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.126534104347229, accuracy: 0.963134765625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.1383945494890213, accuracy: 0.96435546875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.17338359355926514, accuracy: 0.96240234375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.13292934000492096, accuracy: 0.96484375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.1589883267879486, accuracy: 0.96484375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.14790281653404236, accuracy: 0.963134765625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.14050962030887604, accuracy: 0.9677734375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.11434861272573471, accuracy: 0.96435546875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.09686248749494553, accuracy: 0.964599609375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.12015504390001297, accuracy: 0.970458984375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.11268282681703568, accuracy: 0.96875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.13685186207294464, accuracy: 0.96923828125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.12573717534542084, accuracy: 0.965576171875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.12555523216724396, accuracy: 0.97314453125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.12020491063594818, accuracy: 0.968017578125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.12570242583751678, accuracy: 0.96923828125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.15393789112567902, accuracy: 0.971923828125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.122002974152565, accuracy: 0.96923828125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07396673411130905, accuracy: 0.97119140625\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.12665118277072906, accuracy: 0.96875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.11387269198894501, accuracy: 0.973876953125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.10452266782522202, accuracy: 0.968994140625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.0865742564201355, accuracy: 0.970703125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10174865275621414, accuracy: 0.971923828125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.1287131905555725, accuracy: 0.971923828125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.09218805283308029, accuracy: 0.970703125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.09843834489583969, accuracy: 0.970458984375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.11262665688991547, accuracy: 0.97314453125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09630294144153595, accuracy: 0.972412109375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09658825397491455, accuracy: 0.9736328125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0995461568236351, accuracy: 0.974609375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08781411498785019, accuracy: 0.973876953125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.07260965555906296, accuracy: 0.970458984375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.1055062860250473, accuracy: 0.973388671875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.0885237604379654, accuracy: 0.974609375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08335841447114944, accuracy: 0.9697265625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.10602989047765732, accuracy: 0.97265625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08329234272241592, accuracy: 0.974365234375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.0720985159277916, accuracy: 0.97314453125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07146899402141571, accuracy: 0.974853515625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07878264039754868, accuracy: 0.974365234375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08448593318462372, accuracy: 0.974365234375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07890327274799347, accuracy: 0.972412109375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.06398235261440277, accuracy: 0.97314453125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.06346815824508667, accuracy: 0.97607421875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.06738323718309402, accuracy: 0.972412109375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.0780225396156311, accuracy: 0.968994140625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06884662806987762, accuracy: 0.9716796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.06637969613075256, accuracy: 0.97412109375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07072122395038605, accuracy: 0.97119140625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06739211827516556, accuracy: 0.975830078125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06925126910209656, accuracy: 0.976806640625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.058922577649354935, accuracy: 0.976806640625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07631870359182358, accuracy: 0.977294921875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.08686666935682297, accuracy: 0.970947265625\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.9947320222854614, accuracy: 0.709716796875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2328683137893677, accuracy: 0.81005859375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7458096146583557, accuracy: 0.859619140625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5797951221466064, accuracy: 0.884033203125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.44364896416664124, accuracy: 0.895751953125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.3997778296470642, accuracy: 0.90478515625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3892366588115692, accuracy: 0.917724609375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3267613649368286, accuracy: 0.916748046875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.36122387647628784, accuracy: 0.917236328125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.35926952958106995, accuracy: 0.922119140625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.32921409606933594, accuracy: 0.923828125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.33688610792160034, accuracy: 0.930419921875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.3437179923057556, accuracy: 0.927734375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2423275113105774, accuracy: 0.932861328125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2933489680290222, accuracy: 0.9326171875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2676406800746918, accuracy: 0.938232421875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2812241017818451, accuracy: 0.93359375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.29187852144241333, accuracy: 0.937255859375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.25049352645874023, accuracy: 0.944580078125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.25821995735168457, accuracy: 0.94287109375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.20365765690803528, accuracy: 0.93798828125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.24028034508228302, accuracy: 0.946044921875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.20311112701892853, accuracy: 0.951416015625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.22206442058086395, accuracy: 0.9462890625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.21915698051452637, accuracy: 0.947021484375\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.18517711758613586, accuracy: 0.94921875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.20175302028656006, accuracy: 0.953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.213748499751091, accuracy: 0.951171875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.19522859156131744, accuracy: 0.95458984375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.2369375377893448, accuracy: 0.949951171875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.19228093326091766, accuracy: 0.9580078125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.18657006323337555, accuracy: 0.95751953125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.17132435739040375, accuracy: 0.9580078125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1749955266714096, accuracy: 0.960693359375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.14154446125030518, accuracy: 0.960205078125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1906566619873047, accuracy: 0.9560546875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.19005124270915985, accuracy: 0.96142578125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.18431706726551056, accuracy: 0.958984375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.16923338174819946, accuracy: 0.957763671875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13526496291160583, accuracy: 0.959716796875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.15871697664260864, accuracy: 0.96337890625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.139217346906662, accuracy: 0.96533203125\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15769734978675842, accuracy: 0.961181640625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.14980049431324005, accuracy: 0.966796875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13076408207416534, accuracy: 0.966796875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.1270626187324524, accuracy: 0.96435546875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.14034289121627808, accuracy: 0.967041015625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.14097614586353302, accuracy: 0.96826171875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.15985460579395294, accuracy: 0.96875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.14428532123565674, accuracy: 0.9658203125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12138129770755768, accuracy: 0.963623046875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.15701426565647125, accuracy: 0.967529296875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1604110300540924, accuracy: 0.968994140625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1283310204744339, accuracy: 0.97021484375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.11072394251823425, accuracy: 0.962890625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10505523532629013, accuracy: 0.961669921875\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.12226030230522156, accuracy: 0.96923828125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1326790601015091, accuracy: 0.968017578125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11233304440975189, accuracy: 0.969482421875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11059965193271637, accuracy: 0.96875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.15810400247573853, accuracy: 0.9697265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.1411258578300476, accuracy: 0.969482421875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.12475831806659698, accuracy: 0.970947265625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.1374584287405014, accuracy: 0.972412109375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.11724468320608139, accuracy: 0.97021484375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.12809431552886963, accuracy: 0.97265625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.08332358300685883, accuracy: 0.97216796875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.07893496006727219, accuracy: 0.972900390625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.08124065399169922, accuracy: 0.97509765625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.12193410098552704, accuracy: 0.97314453125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.09324981272220612, accuracy: 0.971923828125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.091789111495018, accuracy: 0.9697265625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.12088324129581451, accuracy: 0.97607421875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.08507279306650162, accuracy: 0.97314453125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.0895732194185257, accuracy: 0.973388671875\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09989210963249207, accuracy: 0.9755859375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08834286779165268, accuracy: 0.970947265625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.10433334857225418, accuracy: 0.97265625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09053066372871399, accuracy: 0.970947265625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.0963456928730011, accuracy: 0.9755859375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09564138948917389, accuracy: 0.97412109375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.08017761260271072, accuracy: 0.972412109375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08581429719924927, accuracy: 0.97412109375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09654846042394638, accuracy: 0.9755859375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09358255565166473, accuracy: 0.974365234375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07684401422739029, accuracy: 0.9765625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.10985048115253448, accuracy: 0.975341796875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0914955586194992, accuracy: 0.974365234375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08529970794916153, accuracy: 0.978515625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.0954795777797699, accuracy: 0.9775390625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.0929848775267601, accuracy: 0.9775390625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07511363178491592, accuracy: 0.976318359375\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07132310420274734, accuracy: 0.975830078125\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07160452008247375, accuracy: 0.97802734375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07228569686412811, accuracy: 0.97509765625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.0727907046675682, accuracy: 0.977783203125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.05727468430995941, accuracy: 0.9765625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.0679374486207962, accuracy: 0.976806640625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07096501439809799, accuracy: 0.978515625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06610316783189774, accuracy: 0.974365234375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.005436420440674, accuracy: 0.6787109375\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.3017266988754272, accuracy: 0.79345703125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6542043089866638, accuracy: 0.863525390625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.49985164403915405, accuracy: 0.87890625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4706447422504425, accuracy: 0.9013671875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4378969669342041, accuracy: 0.90283203125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.41925811767578125, accuracy: 0.908447265625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.32789555191993713, accuracy: 0.909912109375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.357000470161438, accuracy: 0.91748046875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3623948395252228, accuracy: 0.925048828125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3065969944000244, accuracy: 0.923828125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.32835620641708374, accuracy: 0.92724609375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.287991464138031, accuracy: 0.927734375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.23849061131477356, accuracy: 0.931396484375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2506299614906311, accuracy: 0.930908203125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.3285945951938629, accuracy: 0.937255859375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2610965073108673, accuracy: 0.934814453125\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.30038684606552124, accuracy: 0.94140625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2394946664571762, accuracy: 0.939697265625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.22306202352046967, accuracy: 0.94189453125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.24520452320575714, accuracy: 0.946533203125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.24207107722759247, accuracy: 0.943359375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.21978504955768585, accuracy: 0.9482421875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.22510193288326263, accuracy: 0.94970703125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.20793235301971436, accuracy: 0.9541015625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.22365400195121765, accuracy: 0.95166015625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.17118185758590698, accuracy: 0.953125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.17723630368709564, accuracy: 0.951171875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.2319520264863968, accuracy: 0.9521484375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.16643191874027252, accuracy: 0.960205078125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.20700466632843018, accuracy: 0.9501953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1670495718717575, accuracy: 0.95458984375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16704100370407104, accuracy: 0.960205078125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1590816080570221, accuracy: 0.9580078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.16137637197971344, accuracy: 0.958984375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1688137650489807, accuracy: 0.9599609375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.19552204012870789, accuracy: 0.959716796875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.15121348202228546, accuracy: 0.966064453125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.1562313586473465, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.1455492228269577, accuracy: 0.961669921875\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.1351020187139511, accuracy: 0.961669921875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13992901146411896, accuracy: 0.96337890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1589692085981369, accuracy: 0.963134765625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.11964409053325653, accuracy: 0.969482421875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1467420905828476, accuracy: 0.96533203125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.17993450164794922, accuracy: 0.96484375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.11902064830064774, accuracy: 0.960205078125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.14944446086883545, accuracy: 0.965087890625\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.13849963247776031, accuracy: 0.966064453125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12876226007938385, accuracy: 0.965576171875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.17454780638217926, accuracy: 0.966064453125\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11410278081893921, accuracy: 0.96728515625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.14506085216999054, accuracy: 0.96337890625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.13351473212242126, accuracy: 0.969482421875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.10724233835935593, accuracy: 0.970947265625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.13730958104133606, accuracy: 0.966552734375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.10326672345399857, accuracy: 0.96875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.14829659461975098, accuracy: 0.968505859375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.10919380187988281, accuracy: 0.970703125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.12854942679405212, accuracy: 0.970703125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.10984012484550476, accuracy: 0.967041015625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.13821139931678772, accuracy: 0.9736328125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.12762987613677979, accuracy: 0.972412109375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.14699845016002655, accuracy: 0.96923828125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.10014006495475769, accuracy: 0.96875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.07670961320400238, accuracy: 0.969970703125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.10729958862066269, accuracy: 0.968017578125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.09293420612812042, accuracy: 0.969970703125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10034290701150894, accuracy: 0.97607421875\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.0964927077293396, accuracy: 0.969482421875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.12110282480716705, accuracy: 0.97216796875\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08533209562301636, accuracy: 0.9716796875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.06614986807107925, accuracy: 0.97412109375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.08364535868167877, accuracy: 0.9736328125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.07589070498943329, accuracy: 0.973876953125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09255562722682953, accuracy: 0.974853515625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.10524880141019821, accuracy: 0.972412109375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.12016923725605011, accuracy: 0.974853515625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09323021024465561, accuracy: 0.976318359375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.07305780798196793, accuracy: 0.97119140625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08531373739242554, accuracy: 0.97216796875\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09987778216600418, accuracy: 0.974609375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08927730470895767, accuracy: 0.974609375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09449850022792816, accuracy: 0.973876953125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09506042301654816, accuracy: 0.970458984375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07173087447881699, accuracy: 0.97119140625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.08484995365142822, accuracy: 0.9736328125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.10279181599617004, accuracy: 0.9736328125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07821264117956161, accuracy: 0.97021484375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08133115619421005, accuracy: 0.97265625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07780332118272781, accuracy: 0.97412109375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.10099177062511444, accuracy: 0.976806640625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07108627259731293, accuracy: 0.970458984375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.06932428479194641, accuracy: 0.975341796875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08153941482305527, accuracy: 0.9755859375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08264579623937607, accuracy: 0.972412109375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.11449196934700012, accuracy: 0.974853515625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06819021701812744, accuracy: 0.976318359375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07399789988994598, accuracy: 0.974609375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0710538849234581, accuracy: 0.97802734375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.0255825519561768, accuracy: 0.71435546875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.218583345413208, accuracy: 0.803466796875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6414311528205872, accuracy: 0.860595703125\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5608291029930115, accuracy: 0.87939453125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4360302686691284, accuracy: 0.9072265625\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4124261736869812, accuracy: 0.901123046875\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3653919994831085, accuracy: 0.9072265625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3428458869457245, accuracy: 0.91455078125\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.27566075325012207, accuracy: 0.920166015625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3146076798439026, accuracy: 0.926513671875\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3499256372451782, accuracy: 0.926025390625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3135266602039337, accuracy: 0.926025390625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.24746358394622803, accuracy: 0.927001953125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2624429166316986, accuracy: 0.930908203125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2985798120498657, accuracy: 0.933837890625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.27410805225372314, accuracy: 0.939453125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2602613568305969, accuracy: 0.941650390625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2782329022884369, accuracy: 0.937744140625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2444668859243393, accuracy: 0.93798828125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.24068649113178253, accuracy: 0.93994140625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2199554741382599, accuracy: 0.9443359375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2106131762266159, accuracy: 0.9404296875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.21956667304039001, accuracy: 0.94287109375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.17765192687511444, accuracy: 0.952392578125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.2140289545059204, accuracy: 0.94921875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.22173616290092468, accuracy: 0.94775390625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.20470763742923737, accuracy: 0.95703125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.23155462741851807, accuracy: 0.955322265625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.22051431238651276, accuracy: 0.958251953125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.16803444921970367, accuracy: 0.960693359375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.20091280341148376, accuracy: 0.961181640625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.20703063905239105, accuracy: 0.9560546875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16304050385951996, accuracy: 0.95556640625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.19134122133255005, accuracy: 0.960205078125\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.16803592443466187, accuracy: 0.959228515625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17992156744003296, accuracy: 0.962890625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.14937782287597656, accuracy: 0.958251953125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1768101155757904, accuracy: 0.962158203125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.13224941492080688, accuracy: 0.96240234375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.15715529024600983, accuracy: 0.96337890625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16629528999328613, accuracy: 0.967041015625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1723746955394745, accuracy: 0.96337890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15842431783676147, accuracy: 0.9638671875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.15015846490859985, accuracy: 0.9677734375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13028129935264587, accuracy: 0.9677734375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.11693417280912399, accuracy: 0.966064453125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.1333942711353302, accuracy: 0.967041015625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.12894126772880554, accuracy: 0.96533203125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.14412972331047058, accuracy: 0.967041015625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.1348089575767517, accuracy: 0.967041015625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13444744050502777, accuracy: 0.96826171875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.16075904667377472, accuracy: 0.96337890625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.12814797461032867, accuracy: 0.96435546875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.10872519016265869, accuracy: 0.965576171875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.11381083726882935, accuracy: 0.965576171875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.11375556886196136, accuracy: 0.965087890625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.10548426955938339, accuracy: 0.968994140625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.13648216426372528, accuracy: 0.969970703125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.13063615560531616, accuracy: 0.970947265625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.1148432120680809, accuracy: 0.973388671875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.09861395508050919, accuracy: 0.970947265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.1089710146188736, accuracy: 0.965576171875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.11203935742378235, accuracy: 0.97265625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.09272895753383636, accuracy: 0.97216796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.10296943038702011, accuracy: 0.973388671875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.10661071538925171, accuracy: 0.971923828125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.1295504868030548, accuracy: 0.970458984375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10939744859933853, accuracy: 0.971435546875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.11123234033584595, accuracy: 0.971923828125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.1083332821726799, accuracy: 0.970458984375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.1310867965221405, accuracy: 0.974365234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08415557444095612, accuracy: 0.97412109375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08501019328832626, accuracy: 0.975830078125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.0930708795785904, accuracy: 0.975830078125\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.11114377528429031, accuracy: 0.97412109375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.0858939066529274, accuracy: 0.972900390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09985464811325073, accuracy: 0.9736328125\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09015223383903503, accuracy: 0.97412109375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09288730472326279, accuracy: 0.975341796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.1003626212477684, accuracy: 0.97412109375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.1093318834900856, accuracy: 0.974609375\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09606283158063889, accuracy: 0.97705078125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.07636889815330505, accuracy: 0.97509765625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.07262328267097473, accuracy: 0.973876953125\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08088953047990799, accuracy: 0.97509765625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09574516862630844, accuracy: 0.974609375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.05985012650489807, accuracy: 0.9755859375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08944105356931686, accuracy: 0.977294921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07050498574972153, accuracy: 0.973388671875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.060352083295583725, accuracy: 0.974853515625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.0771319717168808, accuracy: 0.974365234375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07586353272199631, accuracy: 0.97509765625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.08326361328363419, accuracy: 0.974365234375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05723903328180313, accuracy: 0.975830078125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.09971526265144348, accuracy: 0.978271484375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.07094436883926392, accuracy: 0.977783203125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.08710452169179916, accuracy: 0.975830078125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07171952724456787, accuracy: 0.9736328125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.07109859585762024, accuracy: 0.97705078125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07853139191865921, accuracy: 0.97705078125\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.044978141784668, accuracy: 0.651123046875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.3194395303726196, accuracy: 0.79150390625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7109032273292542, accuracy: 0.85546875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5492081642150879, accuracy: 0.881103515625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4681548476219177, accuracy: 0.887451171875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4644308388233185, accuracy: 0.9052734375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3485685884952545, accuracy: 0.900634765625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.38500648736953735, accuracy: 0.91162109375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3479847311973572, accuracy: 0.91796875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.29990655183792114, accuracy: 0.921630859375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.35753822326660156, accuracy: 0.92626953125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3108704090118408, accuracy: 0.92919921875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.29567742347717285, accuracy: 0.929443359375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2900411784648895, accuracy: 0.928955078125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2714938819408417, accuracy: 0.932861328125\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2569625973701477, accuracy: 0.932861328125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.30331921577453613, accuracy: 0.933837890625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.30737170577049255, accuracy: 0.9384765625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.24934524297714233, accuracy: 0.93994140625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.24409407377243042, accuracy: 0.9423828125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.31231310963630676, accuracy: 0.946533203125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2347228229045868, accuracy: 0.94482421875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.23852278292179108, accuracy: 0.945068359375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.24056702852249146, accuracy: 0.94921875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.25417426228523254, accuracy: 0.951416015625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.1879568099975586, accuracy: 0.94970703125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.171031191945076, accuracy: 0.949462890625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.17787501215934753, accuracy: 0.951904296875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.18744951486587524, accuracy: 0.951904296875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.20524325966835022, accuracy: 0.95751953125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.18360215425491333, accuracy: 0.950927734375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1640750616788864, accuracy: 0.95556640625\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.17460943758487701, accuracy: 0.957275390625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.19368413090705872, accuracy: 0.959716796875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.11876250803470612, accuracy: 0.95849609375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1902158558368683, accuracy: 0.9609375\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1413867175579071, accuracy: 0.96044921875\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.16772454977035522, accuracy: 0.961181640625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.17910653352737427, accuracy: 0.95947265625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.13736660778522491, accuracy: 0.95947265625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.15455377101898193, accuracy: 0.96240234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1523481011390686, accuracy: 0.962890625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.19060386717319489, accuracy: 0.957763671875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.15894904732704163, accuracy: 0.96875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13456501066684723, accuracy: 0.96337890625\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.1572326421737671, accuracy: 0.961181640625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.15749423205852509, accuracy: 0.96923828125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.15929509699344635, accuracy: 0.967529296875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1428481638431549, accuracy: 0.968017578125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12643802165985107, accuracy: 0.96728515625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12759484350681305, accuracy: 0.969482421875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11774219572544098, accuracy: 0.96728515625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1286013275384903, accuracy: 0.968017578125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.12460677325725555, accuracy: 0.96728515625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.1311960071325302, accuracy: 0.96728515625\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.1200227215886116, accuracy: 0.966552734375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.11724473536014557, accuracy: 0.970703125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11468325555324554, accuracy: 0.96630859375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1532750278711319, accuracy: 0.9638671875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11422227323055267, accuracy: 0.96630859375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.1002473384141922, accuracy: 0.97021484375\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.11230827122926712, accuracy: 0.968994140625\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.11979041993618011, accuracy: 0.968505859375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.11829112470149994, accuracy: 0.97216796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.1170239970088005, accuracy: 0.9697265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.08401509374380112, accuracy: 0.970947265625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.0908723920583725, accuracy: 0.9736328125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.08869129419326782, accuracy: 0.971923828125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.1239127367734909, accuracy: 0.96728515625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.11060848087072372, accuracy: 0.97216796875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.11880968511104584, accuracy: 0.974365234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.12007075548171997, accuracy: 0.9716796875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.09951053559780121, accuracy: 0.97119140625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.08737039566040039, accuracy: 0.97265625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.08426059782505035, accuracy: 0.972412109375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.07919424027204514, accuracy: 0.9716796875\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08692507445812225, accuracy: 0.97216796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.08971773833036423, accuracy: 0.97314453125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.0936354249715805, accuracy: 0.974365234375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09504694491624832, accuracy: 0.97119140625\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08218076080083847, accuracy: 0.972900390625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09758024662733078, accuracy: 0.97314453125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.057222913950681686, accuracy: 0.9755859375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.07161195576190948, accuracy: 0.97119140625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08723558485507965, accuracy: 0.97265625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09287356585264206, accuracy: 0.974365234375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.055083513259887695, accuracy: 0.9755859375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08070065081119537, accuracy: 0.977294921875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.0749431848526001, accuracy: 0.976318359375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.06959304213523865, accuracy: 0.976806640625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.08487004041671753, accuracy: 0.97314453125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.0913412794470787, accuracy: 0.973876953125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.08770936727523804, accuracy: 0.978759765625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07193204760551453, accuracy: 0.972412109375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07465209811925888, accuracy: 0.976318359375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08190552890300751, accuracy: 0.973388671875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.05629725381731987, accuracy: 0.974853515625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.074549600481987, accuracy: 0.97412109375\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08142565935850143, accuracy: 0.976806640625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.07427690178155899, accuracy: 0.978271484375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.045172691345215, accuracy: 0.7314453125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.3189682960510254, accuracy: 0.778564453125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7019320130348206, accuracy: 0.85498046875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5272100567817688, accuracy: 0.878662109375\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.44800031185150146, accuracy: 0.89501953125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.40606582164764404, accuracy: 0.8974609375\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.34541749954223633, accuracy: 0.90771484375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3974136710166931, accuracy: 0.90869140625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.35917285084724426, accuracy: 0.9130859375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3539550006389618, accuracy: 0.915771484375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.2893368899822235, accuracy: 0.927001953125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.300410658121109, accuracy: 0.926025390625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2603527903556824, accuracy: 0.92529296875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2559685707092285, accuracy: 0.930908203125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.271627813577652, accuracy: 0.924072265625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2863173484802246, accuracy: 0.935302734375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.23578792810440063, accuracy: 0.9375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2200300693511963, accuracy: 0.93408203125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.25683149695396423, accuracy: 0.937255859375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.23889179527759552, accuracy: 0.9384765625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.22492460906505585, accuracy: 0.951904296875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.20385891199111938, accuracy: 0.93994140625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.22800737619400024, accuracy: 0.946533203125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.2562384307384491, accuracy: 0.947265625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.21009768545627594, accuracy: 0.9482421875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.16459855437278748, accuracy: 0.950927734375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.19555404782295227, accuracy: 0.955322265625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.19335807859897614, accuracy: 0.9521484375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.19329635798931122, accuracy: 0.957763671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.2077307552099228, accuracy: 0.953369140625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.16621866822242737, accuracy: 0.95458984375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1774701029062271, accuracy: 0.9580078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16523431241512299, accuracy: 0.95947265625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1993992030620575, accuracy: 0.959716796875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.1642855703830719, accuracy: 0.964111328125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.15287432074546814, accuracy: 0.959228515625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.17934082448482513, accuracy: 0.962890625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.149565190076828, accuracy: 0.960693359375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.18658749759197235, accuracy: 0.9619140625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.19720928370952606, accuracy: 0.965087890625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.15383830666542053, accuracy: 0.959716796875\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.1666729748249054, accuracy: 0.96435546875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15440723299980164, accuracy: 0.962158203125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.1703018695116043, accuracy: 0.966064453125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13891661167144775, accuracy: 0.96630859375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.1548590362071991, accuracy: 0.965576171875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.14798687398433685, accuracy: 0.966796875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.12481367588043213, accuracy: 0.96630859375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.11416590213775635, accuracy: 0.968017578125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.17678166925907135, accuracy: 0.967529296875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.10701829195022583, accuracy: 0.96728515625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12705203890800476, accuracy: 0.967041015625\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.14247311651706696, accuracy: 0.969482421875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.105256587266922, accuracy: 0.969970703125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.14341339468955994, accuracy: 0.964111328125\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.1103205680847168, accuracy: 0.967041015625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1097923219203949, accuracy: 0.966796875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1291860044002533, accuracy: 0.973876953125\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.1181657463312149, accuracy: 0.971923828125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11074298620223999, accuracy: 0.9677734375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.12348894774913788, accuracy: 0.970947265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.09835211932659149, accuracy: 0.97021484375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.1297379732131958, accuracy: 0.969482421875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.07676797360181808, accuracy: 0.970703125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.11814980953931808, accuracy: 0.970458984375\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.11585863679647446, accuracy: 0.972900390625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.09858512878417969, accuracy: 0.970458984375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11517711728811264, accuracy: 0.970458984375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.09704285115003586, accuracy: 0.971923828125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10900279879570007, accuracy: 0.969482421875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.09512796252965927, accuracy: 0.972900390625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.11721886694431305, accuracy: 0.972900390625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.10184495896100998, accuracy: 0.97216796875\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.11817163228988647, accuracy: 0.9697265625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.08864367753267288, accuracy: 0.97705078125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.07456093281507492, accuracy: 0.97265625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09012721478939056, accuracy: 0.968994140625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.10242783278226852, accuracy: 0.96923828125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.12911206483840942, accuracy: 0.972900390625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.1083848774433136, accuracy: 0.975341796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.1003299206495285, accuracy: 0.97314453125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.10358043015003204, accuracy: 0.9755859375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.0888468474149704, accuracy: 0.97216796875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09209562093019485, accuracy: 0.973388671875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09038231521844864, accuracy: 0.97900390625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09152249246835709, accuracy: 0.97119140625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.06929704546928406, accuracy: 0.97509765625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.06165226548910141, accuracy: 0.97314453125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08323756605386734, accuracy: 0.9716796875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.061312805861234665, accuracy: 0.9765625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07881810516119003, accuracy: 0.9765625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.059849537909030914, accuracy: 0.9736328125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.06672029197216034, accuracy: 0.976806640625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.06315141171216965, accuracy: 0.974609375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08379268646240234, accuracy: 0.97607421875\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.06569917500019073, accuracy: 0.974365234375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.07085539400577545, accuracy: 0.972900390625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.0910271555185318, accuracy: 0.97265625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.056908831000328064, accuracy: 0.97607421875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0763288140296936, accuracy: 0.975341796875\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.9993805885314941, accuracy: 0.737548828125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.258026361465454, accuracy: 0.797607421875\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.699063777923584, accuracy: 0.859375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5079969763755798, accuracy: 0.88525390625\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4573732316493988, accuracy: 0.891357421875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.43210503458976746, accuracy: 0.90625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.37615180015563965, accuracy: 0.90625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3445802628993988, accuracy: 0.914794921875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.4020218849182129, accuracy: 0.916015625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.2917972505092621, accuracy: 0.91552734375\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.29486823081970215, accuracy: 0.920654296875\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3101068437099457, accuracy: 0.9228515625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.32912880182266235, accuracy: 0.92919921875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.2468598634004593, accuracy: 0.92431640625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.3050786256790161, accuracy: 0.92919921875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.26208847761154175, accuracy: 0.932861328125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2882614731788635, accuracy: 0.93310546875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.2624230980873108, accuracy: 0.94189453125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.22806763648986816, accuracy: 0.94482421875\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.22802482545375824, accuracy: 0.939697265625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2536903917789459, accuracy: 0.946044921875\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.23563557863235474, accuracy: 0.94091796875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.23488079011440277, accuracy: 0.9501953125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.18921320140361786, accuracy: 0.950927734375\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.232736274600029, accuracy: 0.951171875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.22521507740020752, accuracy: 0.950927734375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.21508783102035522, accuracy: 0.950439453125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.16156138479709625, accuracy: 0.95263671875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.1882845014333725, accuracy: 0.95361328125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.17846550047397614, accuracy: 0.951171875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.2240283340215683, accuracy: 0.95556640625\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1780775934457779, accuracy: 0.959716796875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.15545058250427246, accuracy: 0.958740234375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.17591877281665802, accuracy: 0.958984375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.14545652270317078, accuracy: 0.957275390625\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17702555656433105, accuracy: 0.961181640625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.17479893565177917, accuracy: 0.960693359375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.18077293038368225, accuracy: 0.964599609375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.12430482357740402, accuracy: 0.9609375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.14725925028324127, accuracy: 0.96533203125\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16845420002937317, accuracy: 0.962158203125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.17854425311088562, accuracy: 0.964599609375\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.13524313271045685, accuracy: 0.9658203125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.13566580414772034, accuracy: 0.962890625\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.13501524925231934, accuracy: 0.9677734375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.17775021493434906, accuracy: 0.961181640625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.1718367487192154, accuracy: 0.966064453125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1432398110628128, accuracy: 0.963623046875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.14211882650852203, accuracy: 0.965576171875\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.14487174153327942, accuracy: 0.96484375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.14559581875801086, accuracy: 0.96728515625\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12036093324422836, accuracy: 0.96923828125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1326763778924942, accuracy: 0.968994140625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.13088804483413696, accuracy: 0.969482421875\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.14379911124706268, accuracy: 0.9677734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10832501202821732, accuracy: 0.96923828125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.1067812591791153, accuracy: 0.970947265625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.17163294553756714, accuracy: 0.96630859375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.08763519674539566, accuracy: 0.96728515625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.13497886061668396, accuracy: 0.96923828125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.10159330815076828, accuracy: 0.96875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.10579428821802139, accuracy: 0.969482421875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.12519879639148712, accuracy: 0.9716796875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.14190471172332764, accuracy: 0.97216796875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.12540686130523682, accuracy: 0.968994140625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09778676927089691, accuracy: 0.97021484375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.11601629108190536, accuracy: 0.969482421875\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11215383559465408, accuracy: 0.974853515625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10346978902816772, accuracy: 0.972412109375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10255555063486099, accuracy: 0.970703125\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.0746174082159996, accuracy: 0.970458984375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.13271698355674744, accuracy: 0.9716796875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.093019038438797, accuracy: 0.9765625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09531479328870773, accuracy: 0.975341796875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09104633331298828, accuracy: 0.97509765625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.1421380341053009, accuracy: 0.974365234375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.09330528974533081, accuracy: 0.977294921875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.073548823595047, accuracy: 0.974609375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.10173888504505157, accuracy: 0.97216796875\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.1285977065563202, accuracy: 0.970703125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.07729262858629227, accuracy: 0.9697265625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.11227942258119583, accuracy: 0.976318359375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.09684884548187256, accuracy: 0.974609375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.10099133849143982, accuracy: 0.97216796875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07777707278728485, accuracy: 0.974609375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09426159411668777, accuracy: 0.9765625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.0762791708111763, accuracy: 0.975830078125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.0655737817287445, accuracy: 0.972412109375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08233504742383957, accuracy: 0.974609375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09723729640245438, accuracy: 0.975341796875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07798736542463303, accuracy: 0.977783203125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.09041246026754379, accuracy: 0.975341796875\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07795955240726471, accuracy: 0.976318359375\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.05582690238952637, accuracy: 0.97705078125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.0613032765686512, accuracy: 0.97802734375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.07224751263856888, accuracy: 0.97509765625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.09363839030265808, accuracy: 0.97802734375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.08582106977701187, accuracy: 0.97265625\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08869213610887527, accuracy: 0.975830078125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.053883906453847885, accuracy: 0.9775390625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.027251720428467, accuracy: 0.734619140625\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2520638704299927, accuracy: 0.8017578125\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6973173022270203, accuracy: 0.858154296875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5286984443664551, accuracy: 0.887451171875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.47433140873908997, accuracy: 0.892333984375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4377029836177826, accuracy: 0.901611328125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.41232743859291077, accuracy: 0.899169921875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3897651135921478, accuracy: 0.90625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.32521486282348633, accuracy: 0.913330078125\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3203411102294922, accuracy: 0.918212890625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.2811533212661743, accuracy: 0.925537109375\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.32916948199272156, accuracy: 0.924072265625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2825912833213806, accuracy: 0.919189453125\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.26245495676994324, accuracy: 0.926025390625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.27740100026130676, accuracy: 0.933837890625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.2773897349834442, accuracy: 0.9296875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.26387935876846313, accuracy: 0.93505859375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.22559288144111633, accuracy: 0.9365234375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.19676190614700317, accuracy: 0.936767578125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.27502870559692383, accuracy: 0.937255859375\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2176375687122345, accuracy: 0.947509765625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.27141815423965454, accuracy: 0.946533203125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.22467674314975739, accuracy: 0.950439453125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.2134276181459427, accuracy: 0.947265625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.231418639421463, accuracy: 0.94873046875\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.2168777585029602, accuracy: 0.95166015625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.2133689522743225, accuracy: 0.955322265625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.18306122720241547, accuracy: 0.95361328125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.16782788932323456, accuracy: 0.95263671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.1666392982006073, accuracy: 0.95703125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.20339366793632507, accuracy: 0.956298828125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.17692412436008453, accuracy: 0.9580078125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.19236426055431366, accuracy: 0.95703125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.16483049094676971, accuracy: 0.95654296875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.22378358244895935, accuracy: 0.958740234375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.13516020774841309, accuracy: 0.95703125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.16621103882789612, accuracy: 0.95947265625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1791747659444809, accuracy: 0.9599609375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.16122190654277802, accuracy: 0.962646484375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.18653452396392822, accuracy: 0.962890625\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.17744384706020355, accuracy: 0.963134765625\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13766732811927795, accuracy: 0.965576171875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.1477237492799759, accuracy: 0.9638671875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.14561668038368225, accuracy: 0.959716796875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.15824337303638458, accuracy: 0.961669921875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.11353985220193863, accuracy: 0.966064453125\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.16694724559783936, accuracy: 0.966552734375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1587747037410736, accuracy: 0.964111328125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1454285830259323, accuracy: 0.9697265625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.13616439700126648, accuracy: 0.969970703125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.12437009811401367, accuracy: 0.96630859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.135174959897995, accuracy: 0.966064453125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1211736723780632, accuracy: 0.967529296875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1428600400686264, accuracy: 0.966552734375\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.12575039267539978, accuracy: 0.96484375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.15320055186748505, accuracy: 0.96728515625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.11915091425180435, accuracy: 0.968017578125\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.0950416699051857, accuracy: 0.96826171875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.12889406085014343, accuracy: 0.96826171875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.1104716956615448, accuracy: 0.96826171875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.13148637115955353, accuracy: 0.96875\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.08609084039926529, accuracy: 0.96826171875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.10542716085910797, accuracy: 0.96826171875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.10681591182947159, accuracy: 0.96875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.13898713886737823, accuracy: 0.97119140625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.09711377322673798, accuracy: 0.9716796875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.12767399847507477, accuracy: 0.96923828125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.13341453671455383, accuracy: 0.974609375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.10620569437742233, accuracy: 0.971923828125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.08553755283355713, accuracy: 0.967529296875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.12431221455335617, accuracy: 0.970703125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08412425965070724, accuracy: 0.974853515625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.10348740965127945, accuracy: 0.973876953125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09043814986944199, accuracy: 0.968994140625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.1028001606464386, accuracy: 0.972412109375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.08992096036672592, accuracy: 0.97314453125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08309374749660492, accuracy: 0.97216796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09917034208774567, accuracy: 0.970947265625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.086563341319561, accuracy: 0.970458984375\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09401370584964752, accuracy: 0.9736328125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09969314187765121, accuracy: 0.970947265625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.09642589092254639, accuracy: 0.9736328125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08611791580915451, accuracy: 0.97265625\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.08273471146821976, accuracy: 0.9697265625\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.05314895510673523, accuracy: 0.972900390625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.09022112935781479, accuracy: 0.97314453125\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07261624187231064, accuracy: 0.972900390625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07410214841365814, accuracy: 0.973876953125\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.0940241664648056, accuracy: 0.977783203125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.08599798381328583, accuracy: 0.974365234375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.048434942960739136, accuracy: 0.973388671875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.09311792999505997, accuracy: 0.971923828125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.10153459012508392, accuracy: 0.972900390625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07413030415773392, accuracy: 0.971435546875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07037243992090225, accuracy: 0.972900390625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.08309169858694077, accuracy: 0.974609375\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.08144479244947433, accuracy: 0.978515625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.05540341138839722, accuracy: 0.97314453125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08997923135757446, accuracy: 0.97412109375\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.0769352838397026, accuracy: 0.9755859375\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.017528533935547, accuracy: 0.71044921875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2788161039352417, accuracy: 0.786865234375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7141513228416443, accuracy: 0.849609375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.49768099188804626, accuracy: 0.88330078125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4280063807964325, accuracy: 0.89501953125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4183633327484131, accuracy: 0.905517578125\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3585280776023865, accuracy: 0.908447265625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.37785014510154724, accuracy: 0.91748046875\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.33401164412498474, accuracy: 0.916259765625\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3652540147304535, accuracy: 0.920166015625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3054196834564209, accuracy: 0.92041015625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.3493596315383911, accuracy: 0.923583984375\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.33466440439224243, accuracy: 0.92431640625\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.24500031769275665, accuracy: 0.9306640625\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.23011788725852966, accuracy: 0.93310546875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.25442904233932495, accuracy: 0.936279296875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.269130140542984, accuracy: 0.933837890625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.28503966331481934, accuracy: 0.93798828125\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.25884881615638733, accuracy: 0.941162109375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.22571592032909393, accuracy: 0.9423828125\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.23995442688465118, accuracy: 0.939453125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2228042185306549, accuracy: 0.9482421875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.20402571558952332, accuracy: 0.94287109375\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.2452259361743927, accuracy: 0.950439453125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.21401260793209076, accuracy: 0.952392578125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.1804480105638504, accuracy: 0.9541015625\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.23698973655700684, accuracy: 0.95166015625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.24886325001716614, accuracy: 0.9482421875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.16877897083759308, accuracy: 0.953125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.19190631806850433, accuracy: 0.95947265625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.18139207363128662, accuracy: 0.958251953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.16218878328800201, accuracy: 0.95703125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.14417196810245514, accuracy: 0.962158203125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.16396905481815338, accuracy: 0.95654296875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.14987120032310486, accuracy: 0.957763671875\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1447538584470749, accuracy: 0.963134765625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.17465545237064362, accuracy: 0.964111328125\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1633141040802002, accuracy: 0.96142578125\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.15939438343048096, accuracy: 0.963134765625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.15146027505397797, accuracy: 0.962646484375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.16161563992500305, accuracy: 0.96484375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13908889889717102, accuracy: 0.963623046875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.15023969113826752, accuracy: 0.967529296875\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.1335565596818924, accuracy: 0.96435546875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1863691806793213, accuracy: 0.968017578125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.11090613901615143, accuracy: 0.96630859375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.1315193921327591, accuracy: 0.966552734375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.1737736612558365, accuracy: 0.968017578125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.13498413562774658, accuracy: 0.97265625\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.13582970201969147, accuracy: 0.968017578125\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13631488382816315, accuracy: 0.966552734375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.13508646190166473, accuracy: 0.96923828125\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.13483662903308868, accuracy: 0.966064453125\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.1478523463010788, accuracy: 0.97265625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.11727925390005112, accuracy: 0.966552734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.13273882865905762, accuracy: 0.9697265625\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.16515716910362244, accuracy: 0.966552734375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.14184662699699402, accuracy: 0.967041015625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.10267491638660431, accuracy: 0.968017578125\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.12945573031902313, accuracy: 0.970703125\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.12928374111652374, accuracy: 0.971923828125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.15721476078033447, accuracy: 0.969970703125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.09262896329164505, accuracy: 0.97021484375\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.1228615865111351, accuracy: 0.96875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.1306643784046173, accuracy: 0.9697265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.12235180288553238, accuracy: 0.974365234375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.12336160242557526, accuracy: 0.9736328125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10545764118432999, accuracy: 0.972900390625\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.08912865072488785, accuracy: 0.970458984375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.09322495758533478, accuracy: 0.97265625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08878306299448013, accuracy: 0.974365234375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.09458840638399124, accuracy: 0.97119140625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.12513965368270874, accuracy: 0.97119140625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.12190787494182587, accuracy: 0.97412109375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09610668569803238, accuracy: 0.973876953125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09175767004489899, accuracy: 0.97314453125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.0861392468214035, accuracy: 0.972412109375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.1191558986902237, accuracy: 0.972412109375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09541571140289307, accuracy: 0.972900390625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.10244270414113998, accuracy: 0.97705078125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.09463410824537277, accuracy: 0.97265625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.1009988784790039, accuracy: 0.9755859375\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.07894567400217056, accuracy: 0.973388671875\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.06999002397060394, accuracy: 0.974365234375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.08881222456693649, accuracy: 0.976318359375\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.08524668216705322, accuracy: 0.973388671875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.10358672589063644, accuracy: 0.973876953125\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07015862315893173, accuracy: 0.974609375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.11221461743116379, accuracy: 0.975830078125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.06332118809223175, accuracy: 0.9755859375\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.11296068876981735, accuracy: 0.974853515625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.07792618870735168, accuracy: 0.975830078125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07859811186790466, accuracy: 0.975341796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.06907191127538681, accuracy: 0.97705078125\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.08945702761411667, accuracy: 0.974609375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.09144293516874313, accuracy: 0.975341796875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06785719096660614, accuracy: 0.9736328125\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.08416109532117844, accuracy: 0.97705078125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.0645657405257225, accuracy: 0.975830078125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.05754825845360756, accuracy: 0.977294921875\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.019989490509033, accuracy: 0.6943359375\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.3140908479690552, accuracy: 0.78515625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7075417041778564, accuracy: 0.859375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5101190805435181, accuracy: 0.88623046875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.46097254753112793, accuracy: 0.889404296875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.40235790610313416, accuracy: 0.900390625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.381249338388443, accuracy: 0.906494140625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.4017663300037384, accuracy: 0.911376953125\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.3303542137145996, accuracy: 0.9169921875\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.29490578174591064, accuracy: 0.914306640625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3041996955871582, accuracy: 0.924072265625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.2834111750125885, accuracy: 0.926513671875\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.24965471029281616, accuracy: 0.927734375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.27571073174476624, accuracy: 0.92236328125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2644609808921814, accuracy: 0.931640625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.31769949197769165, accuracy: 0.932861328125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.27926334738731384, accuracy: 0.936279296875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.24957111477851868, accuracy: 0.933349609375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.280531108379364, accuracy: 0.9375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2918165922164917, accuracy: 0.940185546875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.21490366756916046, accuracy: 0.9443359375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.23389087617397308, accuracy: 0.946044921875\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.2282886505126953, accuracy: 0.94873046875\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.24768896400928497, accuracy: 0.949462890625\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.22763215005397797, accuracy: 0.948486328125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.19458651542663574, accuracy: 0.95263671875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.18546150624752045, accuracy: 0.951416015625\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.19167381525039673, accuracy: 0.950927734375\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.15279147028923035, accuracy: 0.95458984375\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.18276792764663696, accuracy: 0.95458984375\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.1751318722963333, accuracy: 0.956787109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.19026081264019012, accuracy: 0.956298828125\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.15450513362884521, accuracy: 0.963134765625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.18093985319137573, accuracy: 0.9599609375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.17760337889194489, accuracy: 0.956787109375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17812959849834442, accuracy: 0.96142578125\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.17156893014907837, accuracy: 0.962646484375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.181650772690773, accuracy: 0.958984375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.18963763117790222, accuracy: 0.96630859375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.18305359780788422, accuracy: 0.964599609375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.11714185774326324, accuracy: 0.960205078125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.14209948480129242, accuracy: 0.96044921875\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.16250798106193542, accuracy: 0.960205078125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.15744240581989288, accuracy: 0.964111328125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.1363748013973236, accuracy: 0.96142578125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.13649232685565948, accuracy: 0.96630859375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.13707756996154785, accuracy: 0.96826171875\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.12087405472993851, accuracy: 0.962158203125\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.12865060567855835, accuracy: 0.966064453125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.15562014281749725, accuracy: 0.966552734375\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.13547804951667786, accuracy: 0.96484375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12681560218334198, accuracy: 0.966796875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.11491589993238449, accuracy: 0.9697265625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.14853309094905853, accuracy: 0.9697265625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.1422993689775467, accuracy: 0.9677734375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.10259300470352173, accuracy: 0.96923828125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.11304475367069244, accuracy: 0.967529296875\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.13454988598823547, accuracy: 0.9677734375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.12092520296573639, accuracy: 0.966796875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.09945811331272125, accuracy: 0.967041015625\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.14939358830451965, accuracy: 0.971923828125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.10616476088762283, accuracy: 0.966796875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.12058395892381668, accuracy: 0.9736328125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.13693465292453766, accuracy: 0.973876953125\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.129617840051651, accuracy: 0.97216796875\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.13133282959461212, accuracy: 0.96826171875\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.11108805239200592, accuracy: 0.97021484375\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.11945205181837082, accuracy: 0.970458984375\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.12226364761590958, accuracy: 0.9755859375\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.083772674202919, accuracy: 0.96875\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08866909891366959, accuracy: 0.9736328125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08854219317436218, accuracy: 0.976318359375\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.08934742212295532, accuracy: 0.971923828125\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09828408807516098, accuracy: 0.970947265625\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.09595108032226562, accuracy: 0.97265625\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09686924517154694, accuracy: 0.969970703125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.1089625358581543, accuracy: 0.97216796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09159953892230988, accuracy: 0.972412109375\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.08401944488286972, accuracy: 0.97705078125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09272190183401108, accuracy: 0.971435546875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.08319688588380814, accuracy: 0.972900390625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.10264864563941956, accuracy: 0.974853515625\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08623732626438141, accuracy: 0.974365234375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.09951962530612946, accuracy: 0.974365234375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07832615077495575, accuracy: 0.97509765625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.08475709706544876, accuracy: 0.97509765625\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.07888967543840408, accuracy: 0.9775390625\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.06496301293373108, accuracy: 0.972412109375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.08517496287822723, accuracy: 0.975830078125\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07877901196479797, accuracy: 0.97900390625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.06005929410457611, accuracy: 0.973388671875\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.08404714614152908, accuracy: 0.974853515625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.08296585083007812, accuracy: 0.9775390625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07370128482580185, accuracy: 0.977294921875\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.07233675569295883, accuracy: 0.9755859375\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.09587249904870987, accuracy: 0.975341796875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.10120639950037003, accuracy: 0.976318359375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.07577016204595566, accuracy: 0.977783203125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08292969316244125, accuracy: 0.972900390625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.09040744602680206, accuracy: 0.97509765625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.008864164352417, accuracy: 0.72021484375\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2147024869918823, accuracy: 0.789306640625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.6525328755378723, accuracy: 0.857666015625\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5060235261917114, accuracy: 0.874267578125\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.47966834902763367, accuracy: 0.8984375\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.4313737154006958, accuracy: 0.900634765625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3597881495952606, accuracy: 0.907958984375\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.39335301518440247, accuracy: 0.907958984375\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.40027356147766113, accuracy: 0.917724609375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.30618414282798767, accuracy: 0.9189453125\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.2892158627510071, accuracy: 0.91943359375\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.32858726382255554, accuracy: 0.926025390625\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2616569697856903, accuracy: 0.92529296875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.30341893434524536, accuracy: 0.930419921875\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2781158983707428, accuracy: 0.931884765625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.24926967918872833, accuracy: 0.93408203125\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2143453061580658, accuracy: 0.9365234375\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.237997367978096, accuracy: 0.939697265625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.31876689195632935, accuracy: 0.939453125\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.2850622534751892, accuracy: 0.94140625\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.23978769779205322, accuracy: 0.939453125\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2448679655790329, accuracy: 0.93994140625\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.21935155987739563, accuracy: 0.944580078125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.20466603338718414, accuracy: 0.946533203125\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.22200514376163483, accuracy: 0.947509765625\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.17782112956047058, accuracy: 0.943115234375\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.23067909479141235, accuracy: 0.9453125\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.22002160549163818, accuracy: 0.951171875\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.20249487459659576, accuracy: 0.9560546875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.18557554483413696, accuracy: 0.95361328125\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.2417028695344925, accuracy: 0.953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.18790128827095032, accuracy: 0.95263671875\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.16020655632019043, accuracy: 0.95703125\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1613442748785019, accuracy: 0.958740234375\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.15552859008312225, accuracy: 0.96142578125\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.17616255581378937, accuracy: 0.9619140625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.15229035913944244, accuracy: 0.960693359375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.14823290705680847, accuracy: 0.958740234375\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.16270725429058075, accuracy: 0.959716796875\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.19161692261695862, accuracy: 0.958984375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.18956828117370605, accuracy: 0.96240234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.12501896917819977, accuracy: 0.9619140625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.18062175810337067, accuracy: 0.963134765625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.16364675760269165, accuracy: 0.967529296875\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.12358605861663818, accuracy: 0.9658203125\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.11045211553573608, accuracy: 0.963134765625\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.16653096675872803, accuracy: 0.965087890625\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.12609504163265228, accuracy: 0.966796875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.15365174412727356, accuracy: 0.968017578125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.11595222353935242, accuracy: 0.967041015625\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.15405070781707764, accuracy: 0.968505859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.13135391473770142, accuracy: 0.96826171875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.14617523550987244, accuracy: 0.96875\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.12426523864269257, accuracy: 0.96533203125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.1345648318529129, accuracy: 0.968505859375\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.11694535613059998, accuracy: 0.97021484375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.14073006808757782, accuracy: 0.966552734375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.15708111226558685, accuracy: 0.972412109375\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11871848255395889, accuracy: 0.97119140625\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11630136519670486, accuracy: 0.9677734375\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.11960628628730774, accuracy: 0.9697265625\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.09573782980442047, accuracy: 0.969482421875\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.11467602849006653, accuracy: 0.9697265625\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.12897728383541107, accuracy: 0.9677734375\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.12626390159130096, accuracy: 0.9697265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.1399269700050354, accuracy: 0.96923828125\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.09621866792440414, accuracy: 0.973876953125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.1124129593372345, accuracy: 0.969970703125\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.09184751659631729, accuracy: 0.969970703125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.08890430629253387, accuracy: 0.972412109375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08786322921514511, accuracy: 0.97314453125\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.09945470094680786, accuracy: 0.970947265625\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.11672131717205048, accuracy: 0.9775390625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.13806389272212982, accuracy: 0.9716796875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.06527809053659439, accuracy: 0.970703125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.09116735309362411, accuracy: 0.970703125\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.10751024633646011, accuracy: 0.974609375\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09138868749141693, accuracy: 0.97216796875\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09745912998914719, accuracy: 0.97314453125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.07545284926891327, accuracy: 0.9716796875\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.11372285336256027, accuracy: 0.974853515625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.06584332883358002, accuracy: 0.97314453125\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.08470353484153748, accuracy: 0.976318359375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.11361299455165863, accuracy: 0.9755859375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.09125026315450668, accuracy: 0.97509765625\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07651451230049133, accuracy: 0.9755859375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.10749131441116333, accuracy: 0.976318359375\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08480530977249146, accuracy: 0.974365234375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07476583868265152, accuracy: 0.974853515625\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.09692468494176865, accuracy: 0.973388671875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.09846363216638565, accuracy: 0.9775390625\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.06694402545690536, accuracy: 0.9736328125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.0708739385008812, accuracy: 0.977294921875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07815135270357132, accuracy: 0.970947265625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.0793876126408577, accuracy: 0.975830078125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.09625612199306488, accuracy: 0.973388671875\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06900280714035034, accuracy: 0.978271484375\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.08579617738723755, accuracy: 0.97607421875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.0773359164595604, accuracy: 0.971923828125\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.08102327585220337, accuracy: 0.9775390625\n",
            "Epoch: 1, learning_rate:0.01,costo: 2.027899742126465, accuracy: 0.731689453125\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2634778022766113, accuracy: 0.791259765625\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.7275370955467224, accuracy: 0.854248046875\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.521393895149231, accuracy: 0.877685546875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4707370400428772, accuracy: 0.899169921875\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.40863457322120667, accuracy: 0.906494140625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.39575040340423584, accuracy: 0.9091796875\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.3500278890132904, accuracy: 0.91259765625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.34571021795272827, accuracy: 0.9130859375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.34429481625556946, accuracy: 0.924072265625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.3022209703922272, accuracy: 0.920166015625\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.33967676758766174, accuracy: 0.92626953125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2768878936767578, accuracy: 0.930419921875\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.3229673504829407, accuracy: 0.93505859375\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.2565290629863739, accuracy: 0.9306640625\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.24556033313274384, accuracy: 0.931396484375\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.24610139429569244, accuracy: 0.936279296875\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.29273808002471924, accuracy: 0.935302734375\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.2760491371154785, accuracy: 0.937744140625\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.21245121955871582, accuracy: 0.93701171875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2040397822856903, accuracy: 0.9462890625\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.2608572542667389, accuracy: 0.939453125\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.23515425622463226, accuracy: 0.946533203125\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.22910797595977783, accuracy: 0.949951171875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.19398310780525208, accuracy: 0.9501953125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.20921877026557922, accuracy: 0.9501953125\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.1450047641992569, accuracy: 0.9521484375\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.2306945025920868, accuracy: 0.95361328125\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.19117814302444458, accuracy: 0.95263671875\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.2137185037136078, accuracy: 0.961181640625\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.1843295395374298, accuracy: 0.95751953125\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.15951640903949738, accuracy: 0.958984375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.21046647429466248, accuracy: 0.958984375\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.18238526582717896, accuracy: 0.96044921875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.17589953541755676, accuracy: 0.958740234375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.19337618350982666, accuracy: 0.95947265625\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1417946070432663, accuracy: 0.9619140625\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.18279717862606049, accuracy: 0.959228515625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.1665245145559311, accuracy: 0.959228515625\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.1646929532289505, accuracy: 0.96240234375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.1377098113298416, accuracy: 0.958740234375\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.13543447852134705, accuracy: 0.959228515625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.14623278379440308, accuracy: 0.967041015625\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.11542684584856033, accuracy: 0.96142578125\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.14406892657279968, accuracy: 0.96630859375\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.14629603922367096, accuracy: 0.962646484375\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.17375214397907257, accuracy: 0.962646484375\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.13878612220287323, accuracy: 0.9609375\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1547056883573532, accuracy: 0.96630859375\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12328024953603745, accuracy: 0.967529296875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.15393219888210297, accuracy: 0.965576171875\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.11187877506017685, accuracy: 0.969482421875\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.1340213119983673, accuracy: 0.968994140625\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.13331498205661774, accuracy: 0.9658203125\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.13663789629936218, accuracy: 0.96826171875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.1385214924812317, accuracy: 0.96630859375\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.12407156080007553, accuracy: 0.96630859375\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.11316840350627899, accuracy: 0.96826171875\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.10813239216804504, accuracy: 0.96875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.13237224519252777, accuracy: 0.96875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.1449601948261261, accuracy: 0.970703125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.1193612664937973, accuracy: 0.972412109375\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.13336147367954254, accuracy: 0.969970703125\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.12681937217712402, accuracy: 0.971435546875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.08806952089071274, accuracy: 0.970947265625\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.10990501940250397, accuracy: 0.97021484375\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.13268351554870605, accuracy: 0.970947265625\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.10310173779726028, accuracy: 0.973388671875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.13190041482448578, accuracy: 0.97314453125\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.0839211642742157, accuracy: 0.97119140625\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.11485815048217773, accuracy: 0.970458984375\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08440845459699631, accuracy: 0.9716796875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.1049768403172493, accuracy: 0.970458984375\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.09180444478988647, accuracy: 0.977294921875\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.11418919265270233, accuracy: 0.9736328125\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.10644600540399551, accuracy: 0.972900390625\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.08081294596195221, accuracy: 0.9765625\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.09970343858003616, accuracy: 0.97119140625\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.10104997456073761, accuracy: 0.972900390625\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.09174767136573792, accuracy: 0.97412109375\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.12247337400913239, accuracy: 0.972900390625\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.07264640182256699, accuracy: 0.973388671875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.0758460983633995, accuracy: 0.974609375\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.0775904729962349, accuracy: 0.974609375\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.07320762425661087, accuracy: 0.9716796875\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.105659618973732, accuracy: 0.97412109375\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.1017865240573883, accuracy: 0.975341796875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.08216294646263123, accuracy: 0.975341796875\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.0976824164390564, accuracy: 0.97607421875\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07866637408733368, accuracy: 0.971435546875\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.08834344148635864, accuracy: 0.972412109375\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.06309367716312408, accuracy: 0.973876953125\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.07655329257249832, accuracy: 0.975341796875\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.09091296046972275, accuracy: 0.976318359375\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.0799688771367073, accuracy: 0.973876953125\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.0816197395324707, accuracy: 0.9775390625\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06727578490972519, accuracy: 0.97607421875\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.0787167102098465, accuracy: 0.975830078125\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08465251326560974, accuracy: 0.979248046875\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.073124960064888, accuracy: 0.977783203125\n",
            "Epoch: 1, learning_rate:0.01,costo: 1.9915368556976318, accuracy: 0.711669921875\n",
            "Epoch: 2, learning_rate:0.01,costo: 1.2201343774795532, accuracy: 0.796630859375\n",
            "Epoch: 3, learning_rate:0.01,costo: 0.682553768157959, accuracy: 0.85302734375\n",
            "Epoch: 4, learning_rate:0.01,costo: 0.5377983450889587, accuracy: 0.889404296875\n",
            "Epoch: 5, learning_rate:0.01,costo: 0.4149802327156067, accuracy: 0.89501953125\n",
            "Epoch: 6, learning_rate:0.01,costo: 0.41806742548942566, accuracy: 0.91015625\n",
            "Epoch: 7, learning_rate:0.01,costo: 0.3876118063926697, accuracy: 0.914306640625\n",
            "Epoch: 8, learning_rate:0.01,costo: 0.39389753341674805, accuracy: 0.92041015625\n",
            "Epoch: 9, learning_rate:0.01,costo: 0.32292622327804565, accuracy: 0.917724609375\n",
            "Epoch: 10, learning_rate:0.01,costo: 0.3202556073665619, accuracy: 0.920166015625\n",
            "Epoch: 11, learning_rate:0.01,costo: 0.33037665486335754, accuracy: 0.921142578125\n",
            "Epoch: 12, learning_rate:0.01,costo: 0.30117812752723694, accuracy: 0.925048828125\n",
            "Epoch: 13, learning_rate:0.01,costo: 0.2836219072341919, accuracy: 0.93359375\n",
            "Epoch: 14, learning_rate:0.01,costo: 0.3115583062171936, accuracy: 0.93408203125\n",
            "Epoch: 15, learning_rate:0.01,costo: 0.25810420513153076, accuracy: 0.9296875\n",
            "Epoch: 16, learning_rate:0.01,costo: 0.30064454674720764, accuracy: 0.932373046875\n",
            "Epoch: 17, learning_rate:0.01,costo: 0.2831978499889374, accuracy: 0.937744140625\n",
            "Epoch: 18, learning_rate:0.01,costo: 0.27119362354278564, accuracy: 0.939697265625\n",
            "Epoch: 19, learning_rate:0.01,costo: 0.22813178598880768, accuracy: 0.93896484375\n",
            "Epoch: 20, learning_rate:0.01,costo: 0.23769181966781616, accuracy: 0.936279296875\n",
            "Epoch: 21, learning_rate:0.01,costo: 0.2755591869354248, accuracy: 0.94287109375\n",
            "Epoch: 22, learning_rate:0.01,costo: 0.20908768475055695, accuracy: 0.943359375\n",
            "Epoch: 23, learning_rate:0.01,costo: 0.24764002859592438, accuracy: 0.94140625\n",
            "Epoch: 24, learning_rate:0.01,costo: 0.26034602522850037, accuracy: 0.944091796875\n",
            "Epoch: 25, learning_rate:0.01,costo: 0.21270744502544403, accuracy: 0.944580078125\n",
            "Epoch: 26, learning_rate:0.01,costo: 0.2292235642671585, accuracy: 0.9482421875\n",
            "Epoch: 27, learning_rate:0.01,costo: 0.22605669498443604, accuracy: 0.953857421875\n",
            "Epoch: 28, learning_rate:0.01,costo: 0.23045091331005096, accuracy: 0.95166015625\n",
            "Epoch: 29, learning_rate:0.01,costo: 0.17055216431617737, accuracy: 0.955078125\n",
            "Epoch: 30, learning_rate:0.01,costo: 0.21996332705020905, accuracy: 0.955810546875\n",
            "Epoch: 31, learning_rate:0.01,costo: 0.15928319096565247, accuracy: 0.956787109375\n",
            "Epoch: 32, learning_rate:0.01,costo: 0.1310940384864807, accuracy: 0.95849609375\n",
            "Epoch: 33, learning_rate:0.01,costo: 0.17469319701194763, accuracy: 0.963134765625\n",
            "Epoch: 34, learning_rate:0.01,costo: 0.1704007238149643, accuracy: 0.95654296875\n",
            "Epoch: 35, learning_rate:0.01,costo: 0.21444670855998993, accuracy: 0.962646484375\n",
            "Epoch: 36, learning_rate:0.01,costo: 0.1692628711462021, accuracy: 0.9560546875\n",
            "Epoch: 37, learning_rate:0.01,costo: 0.1281462013721466, accuracy: 0.962646484375\n",
            "Epoch: 38, learning_rate:0.01,costo: 0.1616154909133911, accuracy: 0.9619140625\n",
            "Epoch: 39, learning_rate:0.01,costo: 0.15201492607593536, accuracy: 0.962646484375\n",
            "Epoch: 40, learning_rate:0.01,costo: 0.1613631695508957, accuracy: 0.95849609375\n",
            "Epoch: 41, learning_rate:0.01,costo: 0.15332138538360596, accuracy: 0.962158203125\n",
            "Epoch: 42, learning_rate:0.01,costo: 0.15040390193462372, accuracy: 0.963134765625\n",
            "Epoch: 43, learning_rate:0.01,costo: 0.12887896597385406, accuracy: 0.966064453125\n",
            "Epoch: 44, learning_rate:0.01,costo: 0.16237303614616394, accuracy: 0.96630859375\n",
            "Epoch: 45, learning_rate:0.01,costo: 0.16464091837406158, accuracy: 0.965576171875\n",
            "Epoch: 46, learning_rate:0.01,costo: 0.12573809921741486, accuracy: 0.96435546875\n",
            "Epoch: 47, learning_rate:0.01,costo: 0.17232096195220947, accuracy: 0.9658203125\n",
            "Epoch: 48, learning_rate:0.01,costo: 0.16011574864387512, accuracy: 0.9638671875\n",
            "Epoch: 49, learning_rate:0.01,costo: 0.1464361548423767, accuracy: 0.9658203125\n",
            "Epoch: 50, learning_rate:0.01,costo: 0.12184460461139679, accuracy: 0.965576171875\n",
            "Epoch: 51, learning_rate:0.01,costo: 0.11664796620607376, accuracy: 0.968505859375\n",
            "Epoch: 52, learning_rate:0.01,costo: 0.12649261951446533, accuracy: 0.964599609375\n",
            "Epoch: 53, learning_rate:0.01,costo: 0.15111500024795532, accuracy: 0.964599609375\n",
            "Epoch: 54, learning_rate:0.01,costo: 0.12180929630994797, accuracy: 0.967041015625\n",
            "Epoch: 55, learning_rate:0.01,costo: 0.10939940065145493, accuracy: 0.969482421875\n",
            "Epoch: 56, learning_rate:0.01,costo: 0.15414105355739594, accuracy: 0.969970703125\n",
            "Epoch: 57, learning_rate:0.01,costo: 0.10500754415988922, accuracy: 0.968994140625\n",
            "Epoch: 58, learning_rate:0.01,costo: 0.1158268079161644, accuracy: 0.970947265625\n",
            "Epoch: 59, learning_rate:0.01,costo: 0.11935482919216156, accuracy: 0.967529296875\n",
            "Epoch: 60, learning_rate:0.01,costo: 0.11904436349868774, accuracy: 0.971435546875\n",
            "Epoch: 61, learning_rate:0.01,costo: 0.10724900662899017, accuracy: 0.973876953125\n",
            "Epoch: 62, learning_rate:0.01,costo: 0.10807862132787704, accuracy: 0.9736328125\n",
            "Epoch: 63, learning_rate:0.01,costo: 0.10956627130508423, accuracy: 0.97216796875\n",
            "Epoch: 64, learning_rate:0.01,costo: 0.11424858123064041, accuracy: 0.96826171875\n",
            "Epoch: 65, learning_rate:0.01,costo: 0.10081598907709122, accuracy: 0.970703125\n",
            "Epoch: 66, learning_rate:0.01,costo: 0.10678134858608246, accuracy: 0.970947265625\n",
            "Epoch: 67, learning_rate:0.01,costo: 0.10501307994127274, accuracy: 0.971923828125\n",
            "Epoch: 68, learning_rate:0.01,costo: 0.07606903463602066, accuracy: 0.971435546875\n",
            "Epoch: 69, learning_rate:0.01,costo: 0.08587004244327545, accuracy: 0.970947265625\n",
            "Epoch: 70, learning_rate:0.01,costo: 0.10003553330898285, accuracy: 0.9755859375\n",
            "Epoch: 71, learning_rate:0.01,costo: 0.08830686658620834, accuracy: 0.97509765625\n",
            "Epoch: 72, learning_rate:0.01,costo: 0.08769519627094269, accuracy: 0.969482421875\n",
            "Epoch: 73, learning_rate:0.01,costo: 0.07998362183570862, accuracy: 0.970947265625\n",
            "Epoch: 74, learning_rate:0.01,costo: 0.08543455600738525, accuracy: 0.970458984375\n",
            "Epoch: 75, learning_rate:0.01,costo: 0.1042214184999466, accuracy: 0.974365234375\n",
            "Epoch: 76, learning_rate:0.01,costo: 0.08817189931869507, accuracy: 0.974609375\n",
            "Epoch: 77, learning_rate:0.01,costo: 0.07749560475349426, accuracy: 0.9716796875\n",
            "Epoch: 78, learning_rate:0.01,costo: 0.08559313416481018, accuracy: 0.975830078125\n",
            "Epoch: 79, learning_rate:0.01,costo: 0.09971697628498077, accuracy: 0.9736328125\n",
            "Epoch: 80, learning_rate:0.01,costo: 0.0834030732512474, accuracy: 0.97314453125\n",
            "Epoch: 81, learning_rate:0.01,costo: 0.10037650913000107, accuracy: 0.9736328125\n",
            "Epoch: 82, learning_rate:0.01,costo: 0.0815335363149643, accuracy: 0.973388671875\n",
            "Epoch: 83, learning_rate:0.01,costo: 0.06537291407585144, accuracy: 0.97314453125\n",
            "Epoch: 84, learning_rate:0.01,costo: 0.08258441090583801, accuracy: 0.97607421875\n",
            "Epoch: 85, learning_rate:0.01,costo: 0.06706711649894714, accuracy: 0.97314453125\n",
            "Epoch: 86, learning_rate:0.01,costo: 0.07709227502346039, accuracy: 0.977294921875\n",
            "Epoch: 87, learning_rate:0.01,costo: 0.0684504583477974, accuracy: 0.973388671875\n",
            "Epoch: 88, learning_rate:0.01,costo: 0.07639144361019135, accuracy: 0.97412109375\n",
            "Epoch: 89, learning_rate:0.01,costo: 0.07542134821414948, accuracy: 0.976318359375\n",
            "Epoch: 90, learning_rate:0.01,costo: 0.07380365580320358, accuracy: 0.976806640625\n",
            "Epoch: 91, learning_rate:0.01,costo: 0.07765328884124756, accuracy: 0.975830078125\n",
            "Epoch: 92, learning_rate:0.01,costo: 0.0645752027630806, accuracy: 0.97509765625\n",
            "Epoch: 93, learning_rate:0.01,costo: 0.08537431061267853, accuracy: 0.976806640625\n",
            "Epoch: 94, learning_rate:0.01,costo: 0.07400509715080261, accuracy: 0.976806640625\n",
            "Epoch: 95, learning_rate:0.01,costo: 0.053440697491168976, accuracy: 0.97509765625\n",
            "Epoch: 96, learning_rate:0.01,costo: 0.0794113278388977, accuracy: 0.975830078125\n",
            "Epoch: 97, learning_rate:0.01,costo: 0.06979258358478546, accuracy: 0.976806640625\n",
            "Epoch: 98, learning_rate:0.01,costo: 0.06655079871416092, accuracy: 0.97607421875\n",
            "Epoch: 99, learning_rate:0.01,costo: 0.08377747237682343, accuracy: 0.9765625\n",
            "Epoch: 100, learning_rate:0.01,costo: 0.06279172003269196, accuracy: 0.976806640625\n"
          ]
        }
      ],
      "source": [
        "resultados['RMSP'] = {}\n",
        "resultados['RMSP']['val_acc_list'] = [0] * epochs\n",
        "resultados['RMSP']['test_acc'] = 0\n",
        "resultados['RMSP']['cost'] = [0] * epochs\n",
        "resultados['RMSP']['time'] = 0\n",
        "resultados['RMSP']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    RMSP_acc_list, RMSP_cost_list, RMSP_lr_list, RMSP_time, RMSP_acc, RMSP_epochs = SGDM()\n",
        "    resultados['RMSP']['val_acc_list'] = SumList(resultados['RMSP']['val_acc_list'], RMSP_acc_list)\n",
        "    resultados['RMSP']['test_acc'] += RMSP_acc\n",
        "    resultados['RMSP']['cost'] = SumList(resultados['RMSP']['cost'], RMSP_cost_list)\n",
        "    resultados['RMSP']['time'] += RMSP_time\n",
        "    resultados['RMSP']['epochs'] += RMSP_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['RMSP']['name'] = 'RMSP'\n",
        "resultados['RMSP']['lr'] = RMSP_lr_list\n",
        "resultados['RMSP']['test_acc'] = resultados['RMSP']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['RMSP']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['RMSP']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['RMSP']['cost'] = DeleteZerosFromList(DivideList(resultados['RMSP']['cost'], MAX_ITERATIONS))\n",
        "resultados['RMSP']['time'] = resultados['RMSP']['time'] / MAX_ITERATIONS\n",
        "resultados['RMSP']['epochs'] = resultados['RMSP']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_h21aMdgsB"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJQ2_Q_q-s3a"
      },
      "source": [
        "Al guardar todos los resultados de cada método en sus respectivos diccionarios, se procede a crear un dataframe con estos resultados. Adicionalmente, se generan nuevas columnas derivadas de datos que ya disponemos y se hacen tratamiento de formato para su análisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8JqUvdVzZVNx"
      },
      "outputs": [],
      "source": [
        "for key, _ in resultados.items():\n",
        "    if( resultados[key]['val_acc_list'][0] == 0 ):\n",
        "        continue\n",
        "    resultados[key]['val_acc_list'].insert(0,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7S5hiFtm-9xj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "resultados_df = pd.DataFrame(resultados.copy()).T\n",
        "\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: round(row['val_acc_list'][-1]* 100,2), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: round(row['test_acc']*100,2), axis=1)\n",
        "# resultados_df['epochs'] = resultados_df.apply(lambda row: len(row['val_acc_list']), axis=1)\n",
        "# resultados_df['time'] = resultados_df.apply(lambda row: round(row['time']/(100000),2), axis=1)\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['val_acc']), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['test_acc']), axis=1)\n",
        "\n",
        "resultados_df = resultados_df.sort_values(by=['epochs'],ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OUSb0gK7rHf"
      },
      "source": [
        "### L-BFGS vs L-BFGS con búsqueda lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcpvY8fm8nE_"
      },
      "source": [
        "Comparación de número de veces que se procesa el conjunto de datos de pruebas completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpvVH_d38AkV",
        "outputId": "7bd586db-cced-4cc0-a032-bb74f5e78be2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'iteraciones_lbfgs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\denis\\Desktop\\Seminario\\Codes\\Datasets\\MNIST_ORG\\NN_Tests_DG\\Experimento1.ipynb Cell 93\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/denis/Desktop/Seminario/Codes/Datasets/MNIST_ORG/NN_Tests_DG/Experimento1.ipynb#Y161sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mL-BFGS: \u001b[39m\u001b[39m{\u001b[39;00miteraciones_lbfgs\u001b[39m}\u001b[39;00m\u001b[39m, L-BFGS con búsqueda:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(iteraciones_lbfgs_ls)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'iteraciones_lbfgs' is not defined"
          ]
        }
      ],
      "source": [
        "print(f'L-BFGS: {iteraciones_lbfgs}, L-BFGS con búsqueda:{len(iteraciones_lbfgs_ls)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq4MOLZidpgh"
      },
      "source": [
        "### Comportamiento de las trazas de aprendizaje no adaptativas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "kPz_53-BduvK",
        "outputId": "dce24dff-c581-4e65-d2b6-2be2ce11025b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'fixed_lr_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\denis\\Desktop\\Seminario\\Codes\\Datasets\\MNIST_ORG\\NN_Tests_DG\\Experimento1.ipynb Cell 95\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/denis/Desktop/Seminario/Codes/Datasets/MNIST_ORG/NN_Tests_DG/Experimento1.ipynb#Y163sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mticker\u001b[39;00m \u001b[39mimport\u001b[39;00m MultipleLocator\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/denis/Desktop/Seminario/Codes/Datasets/MNIST_ORG/NN_Tests_DG/Experimento1.ipynb#Y163sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m14\u001b[39m, \u001b[39m15\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/denis/Desktop/Seminario/Codes/Datasets/MNIST_ORG/NN_Tests_DG/Experimento1.ipynb#Y163sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m method \u001b[39m=\u001b[39m [fixed_lr_list, decay_lr_list, our_decay_lr_list,cyclic_lr_list, random_cyclic_lr_list]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/denis/Desktop/Seminario/Codes/Datasets/MNIST_ORG/NN_Tests_DG/Experimento1.ipynb#Y163sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mTasa de aprendizaje constante\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTasa de aprendizaje dereciente (PyTorch)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTasa de aprendizaje dereciente (Propio)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTasa de aprendizaje cíclica\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTasa de aprendizaje cíclica aleatoria\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/denis/Desktop/Seminario/Codes/Datasets/MNIST_ORG/NN_Tests_DG/Experimento1.ipynb#Y163sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'fixed_lr_list' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x1080 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "fig, ax = plt.subplots(3,2,figsize=(14, 15))\n",
        "\n",
        "method = [fixed_lr_list, decay_lr_list, our_decay_lr_list,cyclic_lr_list, random_cyclic_lr_list]\n",
        "names = ['Tasa de aprendizaje constante', 'Tasa de aprendizaje dereciente (PyTorch)', 'Tasa de aprendizaje dereciente (Propio)', 'Tasa de aprendizaje cíclica', 'Tasa de aprendizaje cíclica aleatoria']\n",
        "i = 0\n",
        "for a in range(3):\n",
        "  for b in range(2):\n",
        "    if(a==2 and b==1):\n",
        "      ax[a,b].spines['top'].set_visible(False)\n",
        "      ax[a,b].spines['right'].set_visible(False)\n",
        "      ax[a,b].spines['bottom'].set_visible(False)\n",
        "      ax[a,b].spines['left'].set_visible(False)\n",
        "      plt.axis('off')\n",
        "      break\n",
        "    ax[a,b].plot(range(len(method[i]))[1:], \n",
        "            method[i][1:], \n",
        "            'black',\n",
        "            marker = 'o')\n",
        "    #ax[a,b].set_xlim([1, len(method[i])])\n",
        "    #ax[a,b].set_ylim([0, max(method[i]) + 0.01])\n",
        "    ax[a,b].set_xlabel('# Epochs') #, fontsize = 18)\n",
        "    ax[a,b].set_ylabel('Tasa de aprendizaje') #, fontsize = 18)\n",
        "    ax[a,b].spines['top'].set_visible(False)\n",
        "    ax[a,b].spines['right'].set_visible(False)\n",
        "    #ax[a,b].xaxis.set_major_locator(MultipleLocator(len(method[i])//4))\n",
        "    #ax[a,b].xaxis.set_minor_locator(MultipleLocator(len(method[i])//4))\n",
        "    ax[a,b].set_title(names[i])\n",
        "    i+=1\n",
        "\n",
        "\n",
        "fig.suptitle('Comportamiento de tasas de aprendizaje por epoch')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Qelt3wIs3T"
      },
      "source": [
        "### Velocidad de convergencia basado en epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2dpmMZT72w09"
      },
      "outputs": [],
      "source": [
        "resultados_df = resultados_df.sort_values(by=['epochs'],ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "lruyulJ5C4SR",
        "outputId": "b72e27b1-1915-45c6-cfab-8df37ad194bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_36348\\1767391596.py:1: FutureWarning: this method is deprecated in favour of `Styler.hide(axis='index')`\n",
            "  resultados_df[['name','epochs','time']].style.hide_index()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_6a57b\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_6a57b_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
              "      <th id=\"T_6a57b_level0_col1\" class=\"col_heading level0 col1\" >epochs</th>\n",
              "      <th id=\"T_6a57b_level0_col2\" class=\"col_heading level0 col2\" >time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_6a57b_row0_col0\" class=\"data row0 col0\" >LBFGS With LS</td>\n",
              "      <td id=\"T_6a57b_row0_col1\" class=\"data row0 col1\" >2.000000</td>\n",
              "      <td id=\"T_6a57b_row0_col2\" class=\"data row0 col2\" >21627.787760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1d06fb06da0>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultados_df[['name','epochs','time']].style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFSasuSZ2koT"
      },
      "source": [
        "### Curvas de aprendizaje: precisión\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "cV7izzpfbJ3g",
        "outputId": "573e1768-cd1a-44eb-d293-aa74302feda5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\denis\\AppData\\Local\\Temp\\ipykernel_36348\\4194298493.py:2: FutureWarning: this method is deprecated in favour of `Styler.hide(axis='index')`\n",
            "  resultados_df[['name','val_acc','time','test_acc', 'epochs']].style.hide_index()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_96cb3\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_96cb3_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
              "      <th id=\"T_96cb3_level0_col1\" class=\"col_heading level0 col1\" >val_acc</th>\n",
              "      <th id=\"T_96cb3_level0_col2\" class=\"col_heading level0 col2\" >time</th>\n",
              "      <th id=\"T_96cb3_level0_col3\" class=\"col_heading level0 col3\" >test_acc</th>\n",
              "      <th id=\"T_96cb3_level0_col4\" class=\"col_heading level0 col4\" >epochs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_96cb3_row0_col0\" class=\"data row0 col0\" >LBFGS With LS</td>\n",
              "      <td id=\"T_96cb3_row0_col1\" class=\"data row0 col1\" >98.17%</td>\n",
              "      <td id=\"T_96cb3_row0_col2\" class=\"data row0 col2\" >21627.787760</td>\n",
              "      <td id=\"T_96cb3_row0_col3\" class=\"data row0 col3\" >98.2%</td>\n",
              "      <td id=\"T_96cb3_row0_col4\" class=\"data row0 col4\" >2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1d06fc8bdf0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resultados_df = resultados_df.sort_values(by=['test_acc'],ascending=False)\n",
        "resultados_df[['name','val_acc','time','test_acc', 'epochs']].style.hide_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "bP3C7xC1vql8",
        "outputId": "5c1ca114-d3db-483e-8b15-ec7600efa968"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAFZCAYAAADO/cilAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADxMElEQVR4nOy9d7gkV32n/55KncPNee7cyTMazSiMAiihBAJMxgRjksCYtcH+2V5ss8vuem1jcNy1vThgENFgbBmEAAkUkITEoCxN0uR0c+7c1RXP74/qe+fOzJ08d4JU7/PUU91Vp6pOVVd3ffqbjpBSEhISEhISEhIScnGgnO8OhISEhISEhISEnDyheAsJCQkJCQkJuYgIxVtISEhISEhIyEVEKN5CQkJCQkJCQi4iQvEWEhISEhISEnIREYq3kJCQkJCQkJCLiFC8hYS8QhBCPCqEOHC++xESciRCiNcIIaQQ4kPnuy8hIRcDoXgLCTlN5jxwjjW557uPrxSEEKvnXPcbznd/LmaEEItPcF8fNp3v/p4IIURGCPEZIcSLQoi8EKIshNgvhLhHCPHRM9jvW4UQf3QWuxoSctJo57sDISEvA74N3DfPcv9cd+QVzEeAEmACdwKPn9/uXNRMAO8/YtnbgbcBfwZsX4Bj/gyIAc7Z3KkQIg08AywB7gbuAuz6++uB3wa+dJq7fyvwQeCPzrSfISGnSijeQkLOnOellN883514pSKE0AnExn8ABeBjQojfklKWzm/Pjo8QQgUiUsrq+e7LXKSUFeCw+1kIsYxAvD0opXz0eNsLIVKneu2llD5QO8Wungy/BiwH/j8p5d8euVII0b4AxwwJWXBCt2lIyDlgjivqj4QQ7xVCbBZC1IQQ/fVlR/2REkKsE0J8TwgxVW/7khDi9+sP/SPbtgsh/k4IsU8IYQkhxoUQDwohbp+nbacQ4ttCiJwQoiqE+IkQYsURbaL1fu2st8kLIbYIIf7yBOc54778m2Os/7YQwhZCtNTf9wgh7hJCHJzT741CiA+e6JrO4U1AK/A14KtAAnj3MY6fFkJ8VgixvX5Np4QQTwgh3nNEuxNeTyHEASHEo/Mc46j4LSHEh+rLbhNC/A8hxF4CsfKu+vrXCiG+Uz+eWb/eDwghbjrGeSwTQnxFCDFYv57DQojvCyGurK/fVL+3jvqNF0L8cr0vHzj+ZT0x9f18VQhxa/06loEf1Nd1CiH+uu6uzM25h//gyHv4GNdsdpkQ4sNCiG31z+KgEOL3T7KLy+vzh+dbKaUcneeclgshviGEGKlf2wNCiL8UQiTmtHmUwOo2cw3kkf0PCVlIQstbSMiZExdCNM+z3JZSFo9Y9mYCl80XgNH6+/8F9AIfnmkkhNgAPEbgRppp+ybgz4H1wPvmtF0M/BxoA74OPEsgYK4FbgMenHP8BIGL6kngvwF9BK6j7wsh1kopvXq7LxC4H78O/A3Bb8Vy4JbjXQgp5XYhxDPArwghPjVnfzMurLcA90spJ0QgWB8EuoB/AHYBGWAdcAOBGDsZPgLsBx6XUkohxAv1vh/mDhNCZIEngEsIXGj/CKjA5cAvAf9Wb7eYk7+ep8pfATrwL0AR2Flf/iGgsX68QYJr8lHgYSHEzVLKWTdw/d54uL6fLwNb69veBLwaeK6+/78Hbgd+ckQfPkJgofyPMziPuWwA3lE/5tzPbB2Bu/V7wN56f+8APk/wHfj1k9z/xwk+iy8DeeBXgT8XQgxKKb91gm331ucfFkL8gZTyuHGodfH70/px/hkYIvi+/RZwnRDiJimlA3yWwPhxA4e7mDee5DmFhJwZUspwCqdwOo0JeA0gjzP9cE7bxfVlHnDFnOWC4OEmgWvnLP854ALrjmj77/W2t85Zfl992evm6aMy5/Wj9Xa/f0SbTx25PTAN3Hea1+U36/t7wxHLP1Jf/vb6+3Xz9ecUj9VZv05/NGfZb9f3u/qItv9QX/6xE1ynk72eB4BHj3NffGjOsg/Vl+0E4vNsk5hnWRswOfdzqN8DWwmsduuO1T8gC1SBfz9ifU/9HvyHU7zOf1Tv/2uOWD5zr982zzYxQMyz/Bv1PnSc4JrNLBsGMnOWxwni8n5xEv1uAPrr+xkjEO1/QBDvpszTfhOwA0gdsfxt8/Tvq4A83Xs3nMLpTKbQbRoScuZ8kcDCceT03+dp+6CU8vmZN1JKCfxF/e3bAIQQrQQWlHullJuPaPvZI9o2ElgzfiylPNLCggxiiebiA393xLKf1ufL5ywrAJcIIdbOcw4n4tsEQeFHuuU+QCAKfzjnGAA318/5dPgQgQXk63OW/SuBxfLOmQV19+F7gO1Syi8euZOZ63Qa1/NU+Uc5T4ybDOLMZvqaFEI0EQicp4Br5jS9jMBy+JW598aR/ZNS5gmE/lvq+5rhwwTX68tneB5z2SSlfGievpj1exYhhCGEaKxbqH9S78OGk9z/V6SUM/cK9ev3JIffr/MipcwBVxJYrAsEFsLPEyS07BVCvHamrRDiUoI/FN8CIkKI5pmJwGJbAV5LSMgFQCjeQkLOnN1SyofmmTbN03a+TL2X6vMl9Xlffb7tGNv7c9ouI7DGvHCSfR2WUh4ZGD5Vn899yP9/BFaLLUKIvUKILwkh3jJfDNWRSClnBNpb6q7SGVfkDcC/SSnteruDBGL0tcCIEOI5IcRfCCGuOpkTEUIIAoG2GVDqcWDLCKxOPwfeLw7FEjbXz+fFE+z2VK/nqbJrvoVCiKVCiH8TQuQIsmYnCaxLbyDo9wwzguVk+vdFwKDu1qtfrw8DL0opnzu97s/Lsc5JE0GJjl0ElsIpgnP6Rr1Jw3zbzcO+eZZNcfj9ekyklBNSyj+UUq4guA/eVO9DL/C9+j0DsLo+/9/1fs6dxglc520n2eeQkAUljHkLCXll4R1nnZh5IaX8fl1wvYEgluo2Arfn40KI22YE2HH4OkG807sIYs/eX9//YXFsUsrPCCHuAt5IIO4+CnxKCPEXUso/OMExbgKW1l/vPkabXwLuOcF+Tpdj1Tg73u/qUVY3IUSSIA4xAfxfYAuBgPOBT3OCOMNjdk7KjUKIrQSf2/8FbiVw33/idPZ3HI6VLfs3wCeB7xCI9HECi+gVBJawkzUeHO+ePSWklFMEfyx+KIQYIIj7fA/wpxy6//8a+PExdpE7W30JCTkTQvEWEnJuWT3PsjX1+YyFYX99fsk8bVcRPPRm2u4hEBGXnaX+zVK3oH0T+GbdavN54PcJkg5OFOx+H4H16AMcEm87pJRPz3OcfQTB9X8vhIgSuNV+Xwjx11LK8eMc407Aqh9jPnfmPxMIl3vqfckRBJ8fj1O5ntMEiQJHsmSeZcfjVoLYvTullF+Zu0II8adHtJ2xcp1M/yBIIvhbIcTVBNeiRuBWPhe8H/iZlPLITN5lx2h/rnmyPu+qz2f+AHjzuYHn4YIvUBzy8iV0m4aEnFtuF0JcMfOmLopmyh7cA1AXLBuBN82NOau3/XT97ffqbaeB+4HXCyFuO/Jg9W1OCSGEWs/MnKUeuzTjqptPsByGDDLyvgVcL4T4FQJ332FWNxFUvteP2K7GIdfyMd1qQogM8E7gASnlv0sp7z5yAu4luC4d9ViwbwNrhBAfmWd/on78U7meu4BVQoiuOesjBAkbp8KMZemwz6oej3XNEW03EbjT7xRCHCXu5/m8v0Eg2D5FECf5n/V4uHOBx9HnlAB+5xwdHyHEq468l+fw1vp8JmzhBYJkkI8LIY4S4HU38Nx7v1xffsLvQ0jI2Sa0vIWEnDlXCCF+9Rjr7pFSlue83wT8VAjxBWCEwIp1G/ANKeUv5rT7bYJSIY/X244SuABfB3xLSjm3btUnCMTe/UKIrxGUiogRPPgPEGTXnQopghi0ewkeaOMEcXj/hcB69YOT3M/XCEos/COBZezIQsY3A18UQvwnQRZmmSC4/KPAU1LKnRyb9xKc438ep81/EiQ0fJDAavgZAhfkl+rC6AkCcXE5wW/hTMmHk72e/4/A5faQEOKfOBRfdqpFd58g+Hz/uu6qHiSwrL2fwIV66UxDKaUUQnyYoFTI00KImVIhWQI38o8JrJgz7XNCiLsJymvA6Y8mcDrcDfy6EOI7wEME8WJ3cijG8lzwPoIyIT8CnuZQrNwbCO6/lwhGXZi5tu8nSODZXHfnbyPIbl1GEAbwaYIsUwgsd58A/qG+f4fgvp2xnIeELBznO901nMLpYp04cakQCSyrt11cf/9HBMJjM4HLbwD4Y0CfZ//rCaxx0/W22wmsdOo8bbuAfyIoi2ATlEV4gMNLijwKHJhn29m+1d8bwOc49LCzCETLXcDyU7xGW+r7fnCedX31Pm8nqHlWqb/+Y+aUhjjGfp8heFg2HKdNpL7fnXOWZQmye/fUr9MUQebhu071etbbfZBAeNoE7u7fJxCIxyoV8ppj9HUdgfCaSVh4lCAG8KvMU44CWEkghkfrxx6u3ytXzNP2hvqxdzNP6Y6T/Bz/aL7+15d99RjbxIG/BA4SWP92A39I4CY+VlmQ4y6bs27e6zJPu7UE8Ww/r18ju359X6ifU3qebXrrn/2BOffIcwTfiZ457RSCun2DBFbGefsaTuG0EJOQMnTbh4QsNHWLyn7gf0sp/+j89ibklUQ93u0p4L9JKT93vvsTEhJy5oQxbyEhISEvbz5BYKX8yokahoSEXByEMW8hISEhLzPqiQFvIshY/lXgi3KecTxDQkIuTkLxFhISEvLyo4Ugu7ZMkDhwsgO5h4SEXASEMW8hISEhISEhIRcRYcxbSEhISEhISMhFxCvGbXrHHXfIH//4WCOenGeGnoOvvRmEAivugNVvgmW3gpE43z0LCbl4cS1wqhDNwqnXKg5ZaHwPrCLUCmBXINYIiRZQT/Gx5LmgqKf0GUspcTyJ6XjYro8vJZ4fTL6UTFds9k5U2DtRZs94mb0TZQpVh+ZkhNZ0hNZUlNZ0hExMx7Q9qrZL1fYwbY9izWWsWGO0WGOybDHXuRXRFLqyMTqzMVpTESzXp2S5VCyXcs2lbLlYrofl+Fiuj+3NN3DI2UVXBcmIhul41JxDxxMCmpOR+mTQkozQlDQwNIV81SFfdZiu2OSqNlLCsrYkK1pTrGxPsrwtRVc2RqnmUjBt8lWHgulQsT1iukrCUIlHNBKGiqoIJss2IwUzuG4Fi+mKRUPCoC0dpS0doS0VpSUVIRHRiGgKEV0loikIYM9Emc0DBTYN5tkyVGD7SJHuhjjXL2vmumXNvGpJE5n4oVrgpu0xmKsykKtStjwc18f1fRxP4ng+AlBVBU0RqIpAUwSJiEZ7Okp7JkpTwkBTz5nd65g39SvGbbphwwb57LPPnu9uHM34DvjK6yGSgjt/AumO892jkJCLBiklZqlIbmQYIaCpu5dIPH5e++S5LuXpSfRIlEgiiaqd2X/kSj7H0I5tCEUh09pOprV9wc7Rc11ss4ptVrGqVexqFYkk09JGsqkJRVGP2kZKiVWtYFUqpJqaUdSj28xguz790xXa0lHimsAsFqgWC9TKZZq6e0hkjx5Uw/F8RnJldr7wIoNbXqBse5TUJFMyxqgX5WDNwDUStKSDB3xz0qA5GcGXkKvYTNUFxnTFplRzqTkepuPh+cd49klJzDdJOyUa/BKLDIs2xSTm17Bcn5orMV2fmiNxUbAVHV+Pgh5BGFEMw6BBc8kqDglsol4NDQ+vqZt8ZhFDajNDRZuJkkVUV0hGNBpliabKKAlzGloXoXStIBKJENUVDE3BqIsJbc48pqvEIyoJQyNuqMQMFVUIvHodMM8Hz5d1YVIXg/WpanuUag7Fmku5WqNcKhG1y7T4RZK1HGp5EntqDN3QWbz+Svou30Dr4iXMHcDDdRzG9u5mcMc2pgYOYpaKmKUSZqlIrVxESuhetYZFa9ez6NLLaFm0GKEcX/TM3OsT/Qdo6OiibckyGju65t3ON028XA5SSWzPozSdZ3TPGBMDEyiKRyQuiMQFQnh4joPve/iej/R9PM+lalYw4jEaG9uIZzLEUhni6TR6NIZQFBRFQSgKngdmsYZl1rCrVQrlHPlyDqnAbW9403HP5ywQircLUrzlDsJdd4D04M4fQ+OpDokY8nJl5nt5sqNbea5LrVyiWixgFotYZgXpeXieh++6+H4wApNuRNCjUfRIMCmqilOrYZlV7JqJXa3i1Ew818V1HDzXCX74PBdF1VB1HVXTUDUdIQTVYoFKbppKPkc5N0W1UEAoAlXT61OwTSKbJdXUQrKxmVRTMCmKEvTPc/Hr/TTiCRLZBhINDSQyDSiqipSSSj5HYWyUwvgo+bFR8qPD5EaHyY0MYVUqh12LVFMLzT2LaOrpJdPSVj/fSHDO0SiqriOEcujaCjH7eu4y33UDcVEqBvNCHss0Z/dlxGIY9R/6/Ogw08ODTA0NUhgbwfcOjaVuxGJEk2miySSJTJZEQxPJhgYS2UYSDQ0YsTh6JIJmRNAjERRVY/zAXvq3bmZg22amBvuP+ryjqTSZljZUXcepmdg1E6dWw66ZaLpBqrGJZGMTyaZmkg1NRJPJwx5IQlFwajWKE+MUJ8YpTIxRnJygVioe8x5TVI10SwuZ1nZiqTSF6WkKk5PU8tP4jjXTCL2hhURrJ9n2LlLNLQyNTzM6OkFhehqnVCDqVYl7JlHfOvq+TzVjNi5iKtXNsNaMNzlMS243vdV+DOngikAYavLwseqlomHFMlT0NDklyQQJEIKs4pAS9iERpQhEJI4ai6NF4+jxBIr08Mt5/FIOv5TDLeUCa97c651MEUtnQEqkDASA9CWu6+DUajg1c95rFkkkiCXTICA/OhL0PRKhc/kqWvuWMj00wMieXZjFwmHbGbEYfZdtYNnVr6Lvsg3YZpWJ/v1MHDzAZP8BpoYGUFWVeCZLLJ0hnskST6XRIlEUVUFRNRRVRSgKdrVKJZ+jWshRzuWo5nPUKiWsaiDQPcc+qt+p5hYaO7qolopMHAiGUTaSCbKLOtBTcczJEoX+QTzHASDdUhdAyRSRZAotamCWy4zu301lbCK4NeIRjJ4WjHQyuJ6pNMlUlqgWo7hniNGdOyhNjhzVF1XViWpRoq4DjofrSVzp4yrgKBJfOVUNIwgixgTgnqDtcVAz/N63FnyY4FC8XXDirTwOd70OqlPw4fuhbb4xyENOBseqYZZK1MolpJQ0dnShR6NHtZNSUpqaYHTvbnIjwyBl8CCrP7wlBA9CM3gY2qaJ77pkOzpp7umluaeXxs5uNMMI9uf71CrlwHJQKuG57qEfdinxPY/y9BSF8VEKY6Pkx0cpTowTT2doW7KMtiXLaO1bSuvipVjVMqN7dzO6Zxeje3Yxtn8Pru0QT6eJZbLE0xni6QyKqlKrVLCrleDH16xQK5eOEjBnixnxpagavufiue7sDzaAHomSbGwMhEi2gXg2C4DnOLNtXdumUshRmpqkMj1NMMzoSSAEsVQap1bDta3Dlqeammno6KKhvTOYd3Ti+z5TAweZGuxncuAg08ODh/X1TFFUFSMWx7Xtw/tDIGwaOjpp7OymsauHTFsbrm1TK5eo1e9Ns1yiks9RyU1TLRROeB20SISulYHlomfNpSiqSr4uYINpDOl76NE4RjQQk1okimvblKcnKU1NUp6eolrIH+cgBmq6kUi2mXhTM3qqARONkq+Rd1WmbUGx5qBV8ujVHFEzR8wqYDhVymqcspakrCaoaAlsYZB2izQ4eRqcPBmngEpwjrai40VSRFIZktkslp4g5xuM2Br9VZWK1Gi2J+m2RuiojRLxaof6GEsRX7aOjnVXsmz9FXQ3p9HdKuWp4BxLUxMUJycojo9RmBinODGGWRehiqoRS6WIJoNJCEGtUsaqVKhVyjg1EyEUEo2NpJtaSDU1B4K3qYmGtg7SLW2km1vRjChSSjT9aKui67vUnBrVSpFKpYjjWLQ0dJDJHG6prBYLDG7fyuBLWxncvpXJgYM0dHTRsWwlHctX0L50BQ2dXQy+tJXdz2xk77NPHyXqAGJGnJgSQyKxfBvbs3C9E9/nitBR1BhCTQJxJAaSGEJEQRgIJYFQGxBKFkWC5proroliT+F6A9hylJqSw8cn6kWJ+DFUEUfoSdCTIFNIkcbTsjhGBl+puyrdHJ5zAM8bQHoTSGmDrBEMSFFHRFC0ThStG0XtxPDjOIqF508ivTF8dxTpTQb9FHGEEofZuYYiq8SsAg3FSVqnRhDoWJEmctlWphtaqMRaUVGJ2zVSpkm8VMSwK9h6nHK8gUo0Tc2IIrGQ0kFIB9UrocgSCmVUaRNxJYbjY9guRs1BT8d47Xe/fsLrfoaE4u2CEm9mHr76SzC9Fz7wfei5+nz36Kzi2jaV/DSVfJ5KIUc1n6dayOO57lH//hVFmf2HqCjq7GshxGHCyrEsyrkpyrlpKrlpyrlpqoU8tVIJ91j/HDu7aerqwYjHGd+/l9G9u4//IKszY6ExYjEUJXhg+vV/4kIopFtacCwLs1RE+icWIqqmkW5tJ9vaRrqlldL0FOP791KePnqIR1XTaOnto23pCiKxGNW6xccsFqkU8kjpE4kniMTj9XmCSCJJPJ0hlkoTq88j8TiKFvz7VlUNRVNBgmNZOFZgKXAsC89zMaKxwIoUi89ak1TdQNW0eS1/M8LU9z10I3LC85+L73lU8oGQk76Pqmmz/VRUFataoZLLBSInH1j09GiMbGs7mbbAZZhuaUXT9ZM6llkqHn7ONat+v8ggFklKJBKknH2WyPoLRVFnr2k8nSGSSMxeD9/zcKzA0uW7LsnG5lNyj/q+R7VQoJLP4dRMXMvCsa363Kaxq5uOZStQtUPnKaVktFhj73gQi7VvokzBdHA8ie0FrjHH85ES1DnxOpr0yBXL7BsrUbEcBBJFShTdoCCNY8aKNSYMWlNBzFNUPxRnFNGCmKWObIyubJTOegxXQ9ygXHOZqlhMV2ymSialXI5VvW2s6m46ZpyQ70vGSjXihkY6qoGUTA0NMLp3N01dPbQvXR700XGQnodv6BSdIlPmFNO1aaZr08TUGO3xdtri7cSVBGZ/P/Z0iZovGC3lGC1NM1nKI1WXltYI7dkMLdFGGpQUZq3M/vEd7Bvex/hQDTOXRPjNKHoGTWQwnDiqoyOFxMtUKGUmmUwOMKjtpGL3k6xEyZgpklaKpJUm4ibQfBVDqkSkjiF1NKkDCfz65CpJfDQU3EAk+GWEVwSvjBRRUJL4Io5DFdcfQygJFK0FoTQhlPn/mIIN0gX8+h+DYBLCCIQOEK3liFo5DLuA6lZxlAqWYWLFbGRER1WTKEoiEHIiBkocSQyPKL5v4Dgqvi8RQgdmvjMSIV10v4SqVFF1Cz3qoBsStQZKzYeaj7R8fMdDeC64FsJ38LER0iFhVVH0Cla0QC6RYzxhITtaSXVfQkv3elobVtOktGPoOqohEIZEMUA1oLEpTVQ/dE38SoXa9u2Ym7dgbtlMbfMWnKEhEAK9u5vIkiUYS5cSWboEvasLrakJtbkZkilKUxaqppBqjCKUY3s9pJTIWg0lFjvBN/2MCcXbBSXe/v0DsOM++JXvBIkJFzGe6zLZfyCwGu3dzdjeXUwO9s8raoRQTt7qMh9CEE9nSDQ0kmxoDFwGqXTdBJ8ilkzj+z654cG6C2uA6eFBXNumsbOb9qXLaV+2gvaly2nu7kUoSvCg9uVsv7RI5Ki4Hs91yY+OMDlwkMmBg+RHh9Gj0bpgCuIkYql04I5TlMAlpwTiM9nQRLKhcd6YjUo+x/j+vYwf2IcRj9OxdAXNvX0nJUxCLj7GSzXGi9Zs/NV0xaZgOnQ3xFnblWZZS/IwgVNzPJ47mGPj3kl+sXeKnaMlKvYhd2EyotGUNNBVBV1VMNQgFkoA3pwAfM+XpKM6K9tTrOpIsao9xYq2FKmojuV6FE2XYs2haDr4Us4G40e0o61Mztg4ta1bsPfvR7ouvuNgWSblWg2z5qHYHqoTzIXlgOcSzSaItGTRWhqhuQEvm6JcnqY4PUlxukg1b2KVHFTTJlKtoVVMjLKJXjXxfB1XieFqSRw9iaMnMKNJKrEEtUgST00iRAIF45Q+C82tkigPkyoPIoVKPruUSqITAOG7JKqj6HYJ3SnjqyYVo4SpqxgswtN78LTUMfctpIeQPkg/mCMR0kNzS4FQ80oIrwDSBC2BVNP4ahpPTeIpCVRpoWGiUkNTamiqjZeAWkZQbpDkGiSliElrooW+9BKWJBfTJNL4VRMRiyOiUfDBlxLpS6IJnWRDFCOlkKtOMNG/E6FpNHQuoTHeRFQ7WgwuNNL3kY6DtCyk56FmMieMhzsT3FwOJRZDmccjc4ETircLRrxJCX/RF2SUvvnvz3dvDsNzXQZe2sKep39B/9ZNSOkHcUu6Phvr5FoWlmnimNVgPifWI5pM0b50OW1LlpNtayeezZLIBK60eDqLqmn1QXUD16Lvz8SO+IElp27Nkb6cE1sSzDUjQjyTPeXgb+n7uK5zyhaikJAZCqbD7rESO8dKjORrtKQidGSidGRidGSD7LO5FkopJTXHZ8tQgRf6c7zQn+fFgTyjxdpxjhJkIq7uSLO6I8WBySrP9eewXR9VEVzdonNJdwO9PS0sbUmwrCVJSypywphIz/OplR2qBZtyrkY5Z1HO1ShOm1g1Bz2qogoXkZ9EjA/jF/NUFZWqUDAR1KSC5wliNY+Y6aI7HgKJFAq2nsI20thGGl89sXhSfAfVNVE9G1eL4+qnnnQhhIUmTQy3SqRaxKjk0N0KqmeDpuCko5gZnXwSZAzS0QgN0RiN0TjNsSSuqzFa9JgsCUplnVo1DgIyTQ6LFqXpXpKlbXEaxalh79uHtWcv1r692Hv34RUKaC0tqC2tOM3dFONdWEaWWDpCoiFGoilBoi1NtDGNmoijRKOI8I/YRYPv+1SrVXzfxzAMdF1HVVWk64MAcYTlWEp50jHJZ8AxD/CKKRVywVAeBzMHrec2xq00NcmuJ3/O8K7tRBIJ4unsbDyVEIL9LzzLvueeplYpo0UiLFq7HiMaq8cuObiOg++6RFNp0q3tGNEYkXjgamvs6qF96QoyrW0nvJkDN6gKisqxc9LOHkJRQuEWctJIKdk5VuKnO8Z5at80u8ZKjBQOiS4h4Mj/u6oiEASWjvkSGBc1xrlmSSPru7N0ZmM0JozZKRXVODhVYduBSXbt2M/AvueY2LqHdTWbX3EdWiseVtUgr7YghYqOTTWisCuucjAVhUQSy0hTFgZFqVDxFBxLQVoavhfBF/NYGqSLRx7h1zC8KIgonhpFKr1AL3g+qldDc2skXBPFd/F0lWpKwzU0XF3D0wXEPbSkIJKukcpIYkkDVzrYno3lWdiejeM5KK6OamsopoJalig1SMVs4lmVTHOaxrZmmlpbUBUFz/NxPBfP9fA8n2QiTixpEE3qRBMayhEPUL9axT54ECWVQu/sPCnrzeq5l6L+gc3nIouuXHnCfYWcO6Tr406ZOONV7LEK+eEp8tN5PEMiE2owxRT8KNiei21ZWPXJtm1810N6EtzA24IrsTybqluj6tYwPWs2ZGIGRQp0VAQCX0ikAJ+gtExjuoFP/u5vnaerEYq3c8/E9mDeumrBD1WcnGD3Uz9n55NPMLJrBxBkBbn20fFa0USSpRuuYdlVr6J3/eWh4Am5qJFS8vM9U2wdLpAwVBIRjbihkYxoxIwgllIRgehShGC0WOORneM8umOc4bpYW9We4lVLmljRnqInZWEO/pTq/s0YBQej6KIVLLRCDbUqEL5AQQGU4E+JFChaBNQojohgPxnFFlFqQjAsJcNiJsBOolg2hu2xFp9LJUghqCT6GMkupb+1MWiGg8AD5ogxHyjNnLCP4ZQx7CJJp4xul5GUcXUTO1JDUWqkK3mypRzpfI5oycQ3NMoru6msWUR5TQ/VpT3EYlkWNy2iL9NHWkviV6sgBGoyeU4+t1NFiceJrl594obH4HhxTSGH41QspvsnMAvl2Qzt4HukgADf9vBdD9/xg7nt4lYc/KqDW7Xxqg6+5c6E4iF8EH4Qc1ozPEzDxVRtqopNTdrgSxRPIDxQXMDzqWBRFjXKooYvTuA1lKCjYqChSRWlbsSSMJtwqguNhIjQLFLE9QhxEUHRVDxd4moST5O4qo/v+WD5iJqPrHkoLiTt8/udCMXbuWY8EFG0nP4PzrGQUjI5cJC9zz7F3mefZHTv7uBQvX1c9+73s+La62ns7ArazmRKFgo4Vo2W3r4zrkcVEnK+GCoPkavlyBgZ9oz6/MNPB3lu3zRJx8QXMz/aAilA8SUJzyXt+6RlhZRaJi5dYr7OW40YrZEYTZEoytgU1a2jyHwRz/SISNCVVmwjSyWSoRbNYmcz0HgK3xvpB8W4T4CelKidDnbzKJPpfgYie7ClBVKguQaaE0G3IyRjCdpbWuhNtdKrNNDpt9GQaiPS1YUSOfYfMOn7Qbb1cWqyAaipY8d2hZwcvu9jmiaqqs664qBu9ZPBess+ZCFSFQVNUVEVFU0Ec2VmMCSvHlLiS3zXw6zVqFSrVCoVqmYFVSrEhEFUGsR8HdWul8FRBb4GnuLjCZ+yUyVXLpCrFsiVC+QrBWzXwVB1dKGhKxq60HBth6JZpuRUqErrOE6800Dh0BhPPlADBUFMRIhhBIJQAV9IfEMihSQZT9LV0EpjWxMNTY1kMhmi0SiqqqK6AkououShqzqGoaNoKkIToCooMQ0loaHEdRTjzPw+ftXBq55BmZGzQPi0PtdMbIdYAyRbz8ruauUyw7u2c3DLi+x99kkK42MAtC9bwfXv+QArrr2Oho6uo7YTihJk0qXSZ6UfISFngpvLUdm4MXBz9yzC6OlGzWTwfQlIvLExzE2bMF94EXPzZlxdYWxlKy80KzzvWCjTKVJWIwkrQbaa5DVOgptFAqkk6oHjQRC5Ij18oeKrc4TN3JJhJlRMqADCd0BpQzYxm/2sairxtEGiIUJDWkVPSYh7eMLF9V0c38GVLh4uiWSUbDZFYzZDa1MTzdnsoQe3DLJd5UyWq6xnudbf6mf4cDkRCxkcfrHg11zsgRLSkxg9KdTE/PFpfs3F7i/h5moIVSA0BVQFodVfKwKhCkzHYjw3wURukunpHPlCjlypQKFaxJuTqKUg0FBRpMDFwxUnl8QlpEAhmAQCBxd5AjGlSqVezcw/pvBKyAgZP04CDQcHU5gU8XCEhyIUUkaCxQ1dpNMZss0NJDPJ4Jb1fCRy9juq6CqKpqJoCkJXUXQVNaIFFQXmlmSqFxH26yWVAJLJJMlkkng8jnIR3JtKXEeJn994xlC8nWvGdwRWt9MMdLSqFfY88yTDO7cztPOl2QKeqq6zaO16rn7LL7PkyqtJNjSezV6HhJxVpJSYAwcoPfxTKj99BOv5F8HzsIw0xXQfhfRi8g1LKSV6AAXDLmHYRXQ3hq2txffiuHt6EQMZrgSQHqqdI1ErYDiTqAxiNQgqcbB9F9vzcD0/qD6PhxH1SSUiNDak6GhuobW5Gdvwqeg2Zc2moFn4SYNrF99IV/LoPz9nSvAgg7NrynhlIaXEL9o4Eya+6QaB5Y6PdP16kLlARBQUQ0Vqgho25YkixYEpCiM5qsUSpnDw8dGkSiQZJdaUItaWCqw5Uy7KqI064WJIDQHUcDCFTVVYmNiUhMmUUmZKKVEWh2IjdamSkjHSMka37CEhI8iIwI8IPAM8XeKpYGg6hqoTUYO5rur4QuJJHw8P1/fwpIdHkLjlSYlPIJoieoR4NEYiGicRjRGLxvFVielbVD0L061RtYKEMlVR0RQVTdHQhEoiGqMx20hDJotWL0cjFIEwFIShIjQldClf4ITi7VwiJYxvh0vfcVqbjx/Yx71//VkK42NE4gk6Vqxi1XU30bVyNe3LVqBHLro06JCLlKpTZVduF/g+6lgObWAU0T8Mg2NUhKRk6JQVQUGBIj6ykkMrTBLJT5HI5WnMOzSV4pSSixhoX8TodXfi6YuIeTMxXi7SHSBW/gWO4jKZbMTKZFGUTmJuHFvxGZUWavkAHbndXD75IumoStcdt9J0681EL710Xpeg7dn40j8v5RFCDiGlxCxXmT4wTm5wgvxEjpJdoexUKTtVSlaFcq1CRI+QjiZJRRKkjAQpPY5WC9xjFF0UR6KiYONSFRZVYVMlmNeEjYVDTTg4wju6E3XDiaIo+L4PFjBcn+ZSN9LOWI2OpDHdQE/DItqyzbRkmmnNNJPKplBiOkpERUQ1lKh6VLZiSMiZEIq3c0lpBKwCtK455U13/PwxfvJPf0c0meSX/8ef0bNmbej6CDltvHwec8tWnKFB1HQaJZPBSUXJxyQV1cEwXaJVF6NkoZVruIU8gwM7GR0ZojRdxK1IYk6SmNuEHWnGjDZhxhZRi14GYn6XnwM4KSgnfSZ6HHxxyHUp4xbVlMludYRtlsWo0GlN9nD76mtoSUWwKw75en20XNWmIW5w1eIGruxt5LKeLLGTdDMaJ1HS4pWKlBLHcXBd97DJ8zx8y8UaLuMMlbGHS9jTJk7dteYIF0cE7j8fH1+RQZySkHjCD9rh4kgPW7rYvkPFNXE5XFAJCXEiJGSUrIzQJdNYlkulUmNEFNl9ZJC6gCPLuwkhSMQTpFJJMrEssUiUmBElqhlEtQiJdJJ0RyOJZIJEIjHrpnNdF9u2sW2b6miRWtXEiUPNqmGaJrVaDc/zZt17M1MqlcIwwnsq5NwTirdzyXg907Tl5DNNfc/j8W9/jWd/8F26Vq3hTb/z6XkHbw4JmQ8pJdv7X+LpnzyEtStHfNonUhRojoGjxZCKjur2o7tVNLeK7lZRfBfLSGEZWexIBiuSxTIacfXbg52mgmlmFExNczBSHnqTQrRZkkhqZBJJskaUpKKg+TaeEWd/QbL5QIG9Q0WsikpRcRhVfcZVH0sB3Y1yaVsb713dxm2r21jRljwXdZReNti2ze7du7Ftm6amJpqamojH4wghgritoRJT+8cZ6x9mcnySgl2mqtmBtUrWqDo1PDmPhWo+5n4s9Zi9GRRfQUVBEcFcF2oQBI9GDJ0MMfrSnWQaM2RbG2nobiHb3Uwqk0Lxwbc8pO0jHS+IJ9NVhK6AJqhaJo7rHCYsXdclEomQSqVIJBKnFTOlaRqaphGPx8nWh3gLCbmQCcXbuWSinmnaenKZpmapyA//9i/o3/Ii61/7Rm7+4EcPGy4n5JWN9CXDu/NMj5QRnovwbIRjI+0aA/v3Mro3h21mcYw24FIAigaIRgupWjiGjWdIdDeK6hjg6hxK/5Joho2IOhB3IFWjvS1Fb3svmWyCWFInljJINUUxovP/jDiez7MHcjy8fYz7n+lnKG+iKYJXL2/mjkvaWdGWJB3TycR00lGdqK68YsWalJJKpcLU1BRTU1M4jjMb0D1TzDomIjToKdJ+HKMq8PIWdtniYGGI3eV+DjhjR1mzDKmRIQ4S8qJymPswoujE/ShxGaHNSxN3m4lIHQ0FVVXRdB1N19BjOnpbAr09gd6aQNVVhBBEIhEMw5idG4aBqqpn9hmqoM4zfugMqUiY/RoSAqF4O7eMb4d4MySaT9hU+j7f/6vPMrpnJ6/9+G9x6c2vPQcdDLkQ8MplCt/9HvaBA0jXRToOZq1MoTqFV6ngWhEmlVWMJdZhGceywrai21Ei7iCN6RGWrFvCshs3kOzrPKrQ6QxSShzLw7V9okkd5TgBy6bt0T9dZapgopcVdFVgaAquJ9m4d4pHdozzs90TlGouuiq4flkzv33bcl67po1s/JXtZpJSUstV2L1lB7v37mEiP0WuWsByjx6j91gYUiMj4hSoYuMSVQxWZ/tY0dxHKpogZ5XI14rkakVytQKogktbFtPe20lrdzstLS0kEonD++V4+LYfxmeFhFwEhOLtXDKx46StblseeYChHdtC4fYKwhkbZ/Sr36L/gWcpaK3YsSS+8PGkj4+BpJ1Kcgm1xpVBrTB7B3bt+1TU3diGRjTRQDLdSjrdTltPL6963dvIJk/8R2EGIQRGVMOYWwfWlwzkquwYLbFjpMTOsSI7Rkrsn6ocNdLAXFpTEd6wtoObV7Vy/fJmkpGL56fGdV0OHDjAyMjIrDtN13V0XZ99rWkamqIiJyxE3iXT2oDRlkRriCLUQ6LXK9vYQ2WcwTKFgUn2jvWzvzrEIFN4wiciNZr8FEtkCxmRpEFP0hBJY8QiqHEDLaaj1csSmIZLQVTJuyVy1SLT+Wm6MxkuueQS+vr6ZsuQACw+jfMWunpcq1dISMiFw3n9RRVC3AH8LaACX5JSfv6I9b3AXUALMA38qpRysL7OA7bUm/ZLKd98zjp+OkgJEzth3btP2LScm+Zn3/wKPWsuZe1rbj8HnQs5F7hTU5gvvohv1kDTqToa+bJKPi8Z2jZEvhzBiq6D5euQ+DiqjSpVFFSEH1hC4g06KzYkab88hpbpwPVvIKbFWJRedFaC8Q9OVXh4+zg7RovsHC2xa6yM6QSuNiGgtzHOqvY0b76sk6UtSRQhsD0Px5VYXuDmu2JRA2s60se13F0IeBUH+0ARa3+B4niOg+YoB8wR+qujOP6pFeAUUpAgQlJGSUeSJKMJqpUgc7IialSEhS2CfaYicda1r2blshX0rVyKlowEWYnaia1d3ad1piEhIS83zpt4E0KowBeA24FB4BkhxL1SypfmNPsr4OtSyq8JIW4BPge8v77OlFJedi77fEYUh8AqntSwWI989Yu4js1tv/aJV2wM0MWOb1m4o6OYmzZRfPopxp59kXIlSz67jHKym3KiE0/TmKkQG6npVNX9HOh8lqa1bVx16Tqu7b2etHGoiLLvS4TgrN8TharDD7cM893nh3juYA6ApoTByvYU77m6h1XtKVa0pVjZniJuXDwWNADp+HglG7doYU5XqOZK5EemGB8aY7qUIy+qFJQKRRHUw0qIKMvUTnqVFtq9LF7NwZM+rvBw8fEIXtNoINoiiOYobgIKk3nyUznyxTzD1WkqpSFiaoRUNklLtp1lrQ1kGrIsWbKEjo6O8HsdEhJyRpzPX+KrgT1Syn0AQoh/A94CzBVva4Dfrb9+BLjnXHbwrHKSw2Ltfe4pdj35BNe9+/2zQ1mFXDjYAwMUf3QffrmEdJzZyatZWNMlKpNFzIKJYwtsPUkx3cdUwxpqi28FQCoOZMqQHEdG8/iRHBjTxNeu4HWr3syKhhXHfLCfqSWr5niMFWuMFmqMFmuMFGpsGsjz8PZxbM9neWuSP7hjFW++rJOubOyMjnW28U03sJDtnmDHrp1UHRM9ZmDEIhjxCEYyiut6lAoFiuUyFbNC2a5g+jaWcLBwkUeMhajqKo3ZBrrb+2hrb2P58uVHCSvpS/yqg1918csO0vMxupInrK4upQwFWkhIyIJxPsVbFzAw5/0gcM0RbTYBbydwrb4NSAkhmqSUU0BUCPEs4AKfl1Lec+QBhBAfAz4GsGjRorN+AqfE7ID0xxZvtlnl4S//E03di7jqzW8/Rx0LORFSSqpPP8P0179O+ac/BSnxDQ0rkmKycQ2TDWsppFbi6xHoIJjqeIoFHSa9qw02XLGGjt7sMRMGFgLPlzz40hhf+fl+nto/fdT65qTBr1yziHdc0c3arvQ5FxxexcEZreCOVnDGqkjbOzT6SH1mjVY4ONrPbnWEA8oE3sxwQjZQOHqfGipJLUYykaA91kAsHiOWjBNPJ4hnkqQaMzS3NJPNZk9YVkIoAjVpoCYNOIUR7ULhFhISspBc6D6Q/wr8PyHEh4CfAUMcGomwV0o5JIRYAvxUCLFFSrl37sZSyi8CXwTYsGHDccKrzwHj2yHRCvFjD1v18+98k9L0JO/9478IS4JcAPimSfG++xj/6l3YewfIN7bxi+vWsburjZbqJbSXlqCgUIuUKXcOEG0UZDMpmrJZ2hqb6WppZ3H3sbM7F5KC6fDvzwzwtV8cYDBn0pWN8clblrGoMU5HJkZ7JkJbOkoqevbuMyklfsnGKzv4phtYq6rBa1kLCr1Ky8OveciaizNhUitVmRIlppQS03oFR/URCBSCODKAYaapGDWiRoTL1l7OZZdfRnt7O47jzE5WyUTTdDItWSKRSCieQkJCXtacT/E2BPTMed9dXzaLlHKYwPKGECIJvENKma+vG6rP9wkhHgUuBw4TbxcU49uPa3Ub2bOT53/8A9bf/gY6V5xcRmrI2cdzfUY2bmPfDx9javcU1UgbpdY78bqCkhxxYP0YpDsMllzXwvLLO2hZlDrvYsH3JTvHSjxzYJqn9k/zyI5xqrbH1X2NfOaNq7ltdRvaWRSR0vVxJ03s4TLOcAVnpIwzUsGvzh/o7ymScsQir1fJKRVyssKUKJKPlmbbJJNJotHoUQNXd7UtYv369axYsQJdPyQ2577m5JNqQ0JCQi56zqd4ewZYLoToIxBt7wF+ZW4DIUQzMC2l9IFPE2SeIoRoAKpSSqve5jrgL85l508J3w8yTa94/zGb/OybXyGRbeCG937gHHbslYnjOezK7yKhJcg4Otp0jR2/GGf3liL5koIUKrAGWmpYiWnivTrLejIs7u4k0xIn0xIjljq/tcoKVYctQwU2D+V5/mCOZw7kKJgOAB2ZKG9a18kHXt3LJZ2ZMzqOlBJvqhaItLEq7ljg3nSnTKh7L9EU9I4EsbXN0BqhICtMWwWmqnmmijkmc1NM56aD8SPrpcwaGhroaO/mio4OOjo6aG9vJ5UKC7CGhISEnAznTbxJKV0hxCeAnxCUCrlLSrlNCPHHwLNSynuB1wCfE0JIArfpb9Y3Xw38sxDCJygJ//kjslQvLAoD4FSOOSzW9PAQg9u3cv17P0gknpi3TciZ4YyNY27dwo6NP2LomUdpHjWpWQm2ddzEYNdNuHqSdGGAjL2bgc4pkq9bwxuueytLGpac764DQbLBvZuGeXz3JFsG8xyYqs6uW9Kc4I5L2rm6r5Gr+xrpboidsiVQ+hK/7OAVLNxpE3uojD1QojAyTc4uUsbCEBqJdJJkU5rUyhai7SnyRpWx6jTDI/sZHh5mcsvk7ODdQggaGxtpbm5m1epVtLa20tLSQlNTUzgeZEhISMgZcF5j3qSU9wH3HbHsf855fTdw9zzbbWRmvJ+LgRMMi7Xt0QcRisIlN916Djv18sOdmqL67HO4Y6M4o2O4Y2M4Y6M4B/txJyZwtBh+tAnRvprRK65lkpX4aESSw9D5DBM9ZTZc+1be3XUdmnJhhIOOFEy+8YuDfPvpfnJVh45MlPXdWd51VQ/rurJc2pUhc0Tm44zb8VgCTnoSu7+IuX0a+2ARr2DhFW1c32VAmWRAmSavVsgrVWycwwf/NglSiwYP32cikaCzs5M1a9bMirTGxkY07cK4jiEhISEvJ8Jf1nPBcQak9z2PbT/7KX2XXUmy4djJDCHzI6XEfP55ct/6NsUHHgAncB1KQ6fUtZrh1g1Mrn4j5iUpVOKz2ymKYMU1bVx+ey+NnReOtVNKyUTJYttwkbufH+THW0fRfcmv9TTzSz1xmjQVrSGKqkfQHIFWtLFzFs5oBWekMjv3LQ+9JYbWEkNvjaO1BOde2zFNbed0EJumCtTuOEPNZfYkB9mbG8DxHKKRKG3tbSxqWU5zczMtLS1ks1ls26ZarVKpVKhWq9i2TUtLC52dnaTT5z5TNSQkJOSVSijezgUTOyDVAbHsUav2v/gcldw0az/yX859vy4CvEKB8b/6a2o7dqB3dWF0d6F3d6N3deMMDZL71rexdu3CT0TZdF0rP+kBw7mURYUNNJodeMJlNLOX9k6FK1esoKU1S6opSqY1TiR2/m9/KSWP7pxg495Jto+U2D5SZKpi04DgBt3g641NLCq4iAEbEfVw0wbWrhzS8Y/al9AVZKvBjpYxxqxphC1R9kqU7RJVBskKjubjpgROs8RRPKZy01iWRSwW49L1l7J27Vp6e3sPG2opJCQkJOTC4vw/vV4JjG8/Zrzb1kceJJ7JsuTyq85xpy58So8+yuj//F+4U1PEr7wSa/t2yg8/jKxb1wByvU38+A2rGc4sZXF5PVcPdAJgdLm0rFPou6KTxa3XkImcWeD+2Ua6Pvv2TvGtH++hMFKmRyi8N2LQJeJk1RiaJ8EBxYLYlW3ELmki0pdBaEqQiVlx8HIW7nQNBMgmnRf2bWXjLx6hOlWloaEBDHCEg6u7uI6LRBKLxYhGokSNKPFogvbODlavXs2SJUtCwRYSEhJykRCKt4XG92FyF1z5oaNWVfI59j3/NFe84S2oYWzQLF6xyNjnPk/he98jsnw5Xf/w/5hYlGbP9A52Du5mYvsQ7sEaitlBo7WatmqCNhPaFqdZfEszK65qI9184YwQIB0Pe6CEdaCIfbCIPV7FzVlEgA8DEEXoCmomitYYTGpjFKMnhdGdQtRHVpBS4nkeruvi4OCmPNyYYPv27Wy8fyOmabJ06VJuuumm81+UOiQkJCRkwQgVw0KTPwhOdV7L2/bHH8H3vFfk4PN2fz/F+3+MOzGBMAyEoSMMg5JTpvLv34V8mRdfdw1PLW/H++5/kq200VBtJ+GsoZ01AIiYz+LLm1m+roOe1Y1EkxdGYWPfcrEOFLH2FrAPFLCHyuAFGZjjKYctZo2DqHQvbuSXbuqjqTuNktSxLIuBgQEOHtzPwR0HKT1TwnVdXNedFW0zmZxHsmzZMm666SZ6enrmXR8SEhIS8vIhFG8Lzfj8w2JJKdnyyIN0rFhFU/cr44HrTk5SvP/HFH74A2qbNgOgpNNI28a1PfKZZUw1rWVi2ccxY50olsbqrSBVH6PZp2lJkkWL22ntytDYmSDZcGFU0vfKNs5IBWtfAWtvHnuwFNRAUwVad5Kp1VkeLkywc2wLHc508K3TYKqU4J7HXyCTyZDP5xkdHUVKiaIodHZ2smjRIjRNm51UVUXTNHRdP2x5S0sLHR0dJ+pmSEhISMjLhFC8LTQzY5q2rDxs8cjunUwPDXD7xz55Hjp17pC+T+WJJ5j+5jepPPFz8H0iq1bR8nu/h3L9a9kxUubJX2xFGUqh+xGk6tHUF2fl4hbaFqVp7k6RbYudlyGmpOtj7S8gbQ/pS/Ak0pdIx8cdr+KMVXFGK/jlegyeAkZ3itRNPZRao/zznnEe2HaApUP9LNMmaddUllxyFeuWdlMsFsjn8+TzecbHx0kmk9x444309vbS3d0d1kELCQkJCTkmoXhbaMZ3QLoboocHzG995AG0SIRVr77hPHVsYfHKFQr33EPum9/EOnCAUu+VmG/7faYaO8mVBdZmCc/tAcAxVPQVOa67/mrWrutDM85v4Lxfc6k8NUr550N4RXt2eZkaI0qOcaWAUBQiiSiRxhjRvjjRhjgia1C2S/x89x42PzFNVDjcoU6hGLBhw9XcdOONJJPJ83hmISEhISEvB0LxttBM7IDWw+PdnFqNHRsfZ+W1N2DE4sfY8OJD2jbVZ5+l9NDDFO69F6vmM7L+l9i/4uN4dgqmoFIskIuPkmseQ2ZrLF7exodufA8dyfPv9nPzFuWfD1F5ehRpebAkzvgVPv35EQ4O95Mr5gGIGBGEIrAtG9/0YfzofV2igmEYrFl9Ka95zWuC7M+QkJCQkJCzQCjeFppaHtouOWzRziefwKmZrL3l4k9UcCcmKP/sZ5QffZTKzzdi2ZJSto/9l3+QnLYCRWqMRvZjr9/Gkktbubytl8Xp21iUXkREjZzTvkpfYg+WqO2Yxh4oIWsevu0hLQ/f8pA1l4qoMdxdo1+f5ODIAP6wTyQSobe3l6tfdQ19fX20traiKIEbd9tQjh+8MMD9mwYZK9m8enkLv3fHGtZ0Zi+IeLyQkJCQkJcfoXhbaKQEDn+Ib3/iURo6Oulaueb89OkMcXM5Sj95gOn7HuBAv6Sc7KaYWUvpqtuQIhhc3FZqFHv3s+L6Vn7lyrfTEF1Yy5N0fez+Eu6kCZpAaMrs5Fcdajtz1HZN41dcEKB3JFASOlpKZ0IWOGCOcqA8zFh5EsahqamJV73qVaxcuZKurq7DaqANTFe5d9Mw9744zM6xEqoiuGF5M5+7cQmvXtq8oOcZEhISEhISireFRvogDg+2L4yN0Lli9UVlmXGnpij/7HGK993H+Iv7GGy/jpH2d+CviuKKGoXkJKJxgnR7ie6eFq7fcBVt2TcsSF+klCDBnTKxduep7c5h7Q0SC47Ex6ckasiYQFuUQuvNoHYmyNlV9uzZw+7du6lWg0Heu7u7ufWaW1m1ahUtLS2H7adiudy3ZYT/eG6Qp/dPA3DV4gb+5K1recPadpqS59aKGBISEhKysEgpKZdfQgiNZHLliTc4h4TibaGRPhwh0iqFPPFM9vz05ySRrou5aRPlxx+n8vgTVLbvYqppLf29N1O88j34uIx17mb1jR3csuFVtCfaz7oYla5PdfME5Y3DOCOVwIrpg4+kJEwcXOIyQqIxTfyKVqLLs+idSYrFInv27WVv/z4ODB7EcuygdMeB+lQnFouxbNkyli9fztKlS0kkDh/j1HZ9XujPcfdzg9y3ZYSK7dHXnOBTr1vJWy7rpLvh5ROvGBISEhISYFnjjI7ew8jod6lUdgPQ2HgDi3t/g2z2qgvC8BKKt4XmCMubXTNxLeuCFW++aTL99W8wfddd1CoOky3rmOh7HZM3/hqgUzKmMFdu47bXbeD6pb+xIDexV7apPDlC+akR/JJDvslhpK/MdK3AlJljyizg+YesbMIUpPalSE2kcByH8fEggyCVSnHJpWtZtGgRuq6jqursFI1GaW9vn41dA9g3UebFgTybBwu8OJDnpZEituuTMFR+aV0nv7yhmyt7Gy6IL25ISEhIyCEsa4yhoX9jZPR7KIpOPLaYWHwx8dhi4vHFRCIdRCItqGrysN9wKX0sa5SqeRCzeoCJyYeYmvoZ4JNJX87KlX+C6xTpH/gyz7/wXjKZK1nc+19oanrNeX0WhOJtoZHyMPFWzecBSGQvrOxD6XkU7vk+E3/3d0xYaQYu/y0maQMEFT3PYPNzLFrXwK/c/EYWZc/e0EtSSvyijT1cxhmuYA+Vqe2cBk9iLlF5rqOfHf27oRKIsdb2Vpa2rqSlpYVYLEapVKJUKlEsFimVSkQiEdatW8fy5ctpbW09qS/XWLHG//z+Vn6ybQyAuKGytivDB1/Vy2U9Ddy8qoW4EX5VQkJCQk4Wz6tRre6jUtlDpbqHSmUPtdowQigIoSKEFsxRkXhI6SOlB9JDIgEJUtZfgxAq8fhiUslLSKZWk0quQdPS5PNPMTj4TSYmH0BKn8bG61HVOGb1ANO5jfh+7bB+KUoUw2jBMJrxvDKmeRDfP1QSKhJpZ3Hvr9Pe/nYSiSWzy3t6PsjwyH/Qf/Bf2LT5o6TTl7Hhyn9HiPNT2ip8Ii00R1jeKvkcwAVjeZO+T+Xxxxn/q79mcsRk/7oPMWkswowU2d78EJWuEV5/9S38xorfImmcnRplbq4WJBDsDLI+Z4vcAlpzDO+yJM95e9mycyuapnHjjTdyzTXXHOXWPFN8X/Ktp/v58/t3YHs+v3f7Cl57STvLWpOoSmhdCwkJuXDxvCpVsx+zehDTPIhp9uMdIVQAopF2Uqm1pFJriEZ7jvmHVkof0+ynVN5OubSNUvklHCePqsZR1QSqGkNVg1ARx8njOLnZyXUrgAT8IEcPiZSHfteFUInFFhGNdiMQSOnhSxffd0DWoC7oFKEhlEjwfm6inxD4vsP09EZGR++ZXaxpWVw3j6Zl6On+EF1d7yMe7z3snCxrjKp5AMsaw7YnsK0JbHsSy57AMJpoaryxbqHrJRbrJRrtRIiji8Kraoye7g/Q1flexsbuxbLGzptwg1C8LTxHiLdqIQ+cX/HmjI9T+flGKk88QWXjRsqmwv5L3s1o1yVYWpXnuu5BrM3zoXUf4Oaem1GVU79BpS/xTRe/6gTzsoN1oEht5zTuWJAgoDZEiK5shLYIuWiVcTvH0OgBXnrpJYQQXHPNNVx//fULUth291iJT393C88ezHHdsiY++9ZLWdx8dsVhSEhIyJlg25OUStsxawPUakPUzEHM2hC12iC2PXFYW11vQFWP+A2TPpY9Fli0AE1LkUyuQdez+H4Nz6vh+zV8r4ZZG8LzykAgthLxZRiRVjyviuMU8LwKnlcFJLregK43EI/3oetXoKnJOYJLgBAoSpREfAmJxDLi8cUoytlJ6rLsScqllyiVXqJa3Us2ezVtbb+EqsaOaiuEQjTaQTR69uqIKopOR8c7ztr+TpdQvC00R1re6uItcR7EW/nxxxn/m/+DtT0Ysku2dNC/4UPsdZfgCpfNHQ+iXZbntzZ8iKvbrz6hy9ErWpjbp3Gna/hFG69s4xVt/JKNb7pw5BjqqiDSlyGxoQ19WYZf7HiWnTufZ3z7OL7vA5BMJrn88su58cYbyWQyRx/0DDk4VeFLj+/n357pJxHR+Mt3ruOdV3aHcWwhISHHxPdtLGscRY2iKhEUJYaiaEjpYVljgaAyBzFrgzhOjkikjWikg2i0k0ikA01LUansolQOREe59BJV8yCRSAuxaA/R2CJisR4iRivV6n5K5W2UStuwrNHZPgihB/uMddHUdNOspSgW7yUe60XTUvP23fMsKpWdlEov1ff7EtXqPhQliqpE0bQ0qtFKJnsVqdQaUsnVJBIrUc9xHc6TJWI0E2m6kaamG893V84roXhbaI6MeSsEbtNY+uwLk2N2wXGY+Lu/Y+pfvoSxZAnNv/O7jLZexhNP5PErKjtankK5ZpJPXv1+Lmu97Lj78so25tYpqpsmsA8UAoGmCtSUgZoy0JpiqIvTKAkdJa6jxLXZud4WR4loFAoF/vXuf2dgYIDFixfz6le/mq6uLrq6ukin0wtyDV4cyPPFn+3lx1tH0RSFd17Zze+9diXNYYmPkJCLBscpYlkjdXddfnZuGE0kk6tJJFackuhwnCKuW0DXs4cFskspqVR2MT39c6ZzT5DLPY3vm4dtK4RWb+setlxVE3he5ZjH1PVGUsk1dGSuwHamMM2DFIov4LqlmT0Tjy+lIXsNqdQlJFNriMcWE4m0npabTlUjpNPrSKfXnfK2IRcuoXhbaOZxm0ZTaVTt3Fx6Z2SEod/9PcwXXiD7y7+M9uHf5offeZHqCyUmEsNM3LiFj9/+QS5tufS4+7GHyhQfOEBtdw580FpipG5ZRHxdM1pr/KQtV3v27OG73/0uruvyzne+k7Vr156N0zwKKSV7xss8fWCae18c5qn906SiGr9+01I+/OrFtKajC3LckJCQs4eUkmp1LxOTDzM5+TCFwvMcbdI/hBAaifhSkqnVdcHTTiTSVp/acZxp8oXnKBSep1B4frYMRLCtjq5n0fUGHCc365aMx5fQ2flOUsk1+L6D55v4Xg3PryGAaLSLaLSbWKybaLQTRYnguhUsa4RabZiaNYLr5IknlpFKriESmb+skuMUsKxRYrGe2diykJBjEYq3heaIOm+VfP6cuUxLjzzCyB9+Guk4tP/FX/GU1c6ev3wBSzHZu+ZJfvktt/GaRR84rvDyTZfCAweoPDmCEtdI3dhDbF0zekeCarXKC9u2kXsxR7VapVKpUKlUqFarZDIZuru7Z6dkMsljjz3GY489RmtrK+9617tobj67oxGMFmr8aMsIT++f4pkDOaYrQQZRVzbGZ964mvdcvYhkJLzlQ0IuZGq1EQrFF8jnn2Vq6hFMsx+AVOoS+hZ/kkRyObqWrcddZdH1LJY1Wg+0f4lSeTu56V8wat9zzGNoWppM5nLaWn8pEHVu3ZJnT+O4eRRlFY0Nr6ax8Tqi0c5TPgdNS6Bpy0gklp30NrqeQdfPnUcm5OImfJItNPNY3hLZ7AIf0mfi7/+eqX/8JyKrV5P475/nP384gDVa4EDbZja8rYffXve/0ZRjf/zSl1RfGKdw/378ikPi2g4yt/ciYhqDg4M8870H2LZtG57noWkaiUSCRCJBMpmkpaWF6elpnnrqKTZu3AhAJBLBsizWr1/PG9/4RgzDOGvnW7Zc/unRvXzpiX3UHJ9FjXFuWdXK1Ysbubqvkd6mk7cMhoS8UpHSw/ddgoxBn6CyNbhuKSj3UNlDpbKbSnUvtj1BJNJONNJJNBpMut5AzRqZjf2qmQNY9iTRaHsQmxVbVM847ALp43kmnlfF801ct0SptJVC4fnZOC9FidDQcC2LFv0azU03HzfoPB7vIx7vo6310Kgunmdh22PUrDEsaxTLGkNTk2QyV5BILJs3ozAk5GIhFG8LzTzirX3ZigU7nF+pMPyHf0jpwYdIv+MdjF7/Ie77ygFqosrBDU/y39/7W7Qn2o+7D6/iMPWNl7APFDEWpch+eC1GV5LNmzezceNGRkdHMQyDK664gg0bNhyznprruoyOjjI4OMjIyAh9fX2sX7/+rAkp1/P59jMD/O1Du5gs27x5fSe/e/uKMGs05GWP55lUqweQ0kHTUqhaCk1NoaoRfN/BtiewrFFq1ihWbRTbngziw9w8jlPAcXJ4bhnPt/Dr09zSDsdC1xtIxJeRSl2KbY2TLzyDNT46m80IoKrxuhuxh3R6fWAVK21jYuKBo+LD5hKNdpHNbCCTuZxM5gqSyVUoyun/yVPVyKxgDAl5uRGKt4VmnmzThSoT4gwNMfCbn8DatYvE736GnxeWMfH9fg42bCP72hp/feMfYajH/zGUvmT6OzuxB0o0vGM58SvbEIpgYGCA7373u7S2tvLGN76RdevWEYkcPzBY07RZt+nZwvclu8ZLPL1/mq9tPMDeiQpX9zXy5Q+uZn1P9qwdJyTkXOB5VYQwUOaxgkspse2JepHTvVSr+6hW9lGt7qNmDc+7PyGMugiTRyzXZuO5dC07m52oqFEUJVKfokGdLaEQlHtQECgoapREfCmJxDIMo+moY/q+i22P17Ms29H1xnn/oPm+W48DG0FRNBQlVq8dFtQPO1a2ZEhIyNGE4m2hmSPeHKuGUzMXRLxVn3+BwU9+Et92KP7OF3hks4ftT/PU8nt571vewJuXvemk9lN6ZABrV47s25aRuOqQhW7Lli1omsadd95JNHpug/37p6rcv3WEZw5M88yBHAUzsBAsa03yxfdfye1r2kK3aMgFjWVPUipuOSTCqvupVvdh25OAqMdvNWIYTeh6Ftsap1Ldi+sWZ/ehqkni8T6y2avqbsIlKGoU1y3huWVct4TrllAUIwjUj7bXXZvtaFpmwb4jiqLNuk5P1C4W6yEW61mQfoSEvJIIxdtCM0e8VReoxlvx/vsZ/v0/wFx0KS9c9n7M53wOZl/iwPpf8Cev+1+sbFx5Uvup7c5RfOgg8ctbSVx9SLh5nse2bdtYvnz5ORVuUkq+8eRB/uy+7dQcnyXNCe64pJ2r+hq5anEDixrDWLaQM8P3HfL5ZzBrAyQTy0kkVqJpx3a7Symp1YYpl1+aDZA3zX4Mo4VorItotItYtBtdb6Bc2UWxuIlicRO12tDsPnS9kXi8j6amm4nHevF9G9uZwrancOwpKpU9GEYzbW1vmrV4xRNLiRjhn5SQkJCA8yrehBB3AH8LqMCXpJSfP2J9L3AX0AJMA78qpRysr/sg8Jl60z+VUn7tnHX8ZJH18dnq4q1SH9c0fhYTFoo//jEDn/pD9lzxbvoTV2MVTHZd+hBvuuM1fK7vNw4bHUG6Pu50Da0ldtRDwCtYTP/bTrTWONm3LTts/YEDB6hUKlx66fHLiZxNRgs1PnX3Jh7fPclNK1r47NvW0t0Qps+HnDmOU2Rq6lEmJx9mavqxOfW1IKixtZhkcjWxaDeOW5xTT2wayxqbYw0TxONLiMd6sZ0pJiYewnGmDjtWNNpFOr2e7u4PkE6vJ5lYjq5nz9WphoSEvEw5b+JNBNUGvwDcDgwCzwgh7pVSvjSn2V8BX5dSfk0IcQvwOeD9QohG4H8BGwiCO56rb5s7t2dxAmQ97mRGvNUL9CYyZ2dQ+uJPHqD/U5/m2Q2/SSW6jNH27VzzjsX8zpo/P0y0+TWXytOjlH8+hFew0driJK/rJHF5K0JXkZ7P1Ld2IB2PpvetQzEOLwS5detWDMNg+fLlZ6XfJ+IHm4b5zD1bsV2fP33rWt53zaLQ4vAKwHFyQdX3eYa5OV1ct0y5vOOwMhLl8nakdNH1RlpaXkdz8y0kEyuoVPZQKu8IrGrFrUxMPICmZTCMxvpQQEvIZq8mmVxFKrmaZHLlUfW4PM+kVhvGtieIx5cSibSctXMJCQkJmeF8Wt6uBvZIKfcBCCH+DXgLMFe8rQF+t/76EeCe+uvXAQ9KKafr2z4I3AF8e+G7fQrIINV+1m06Y3k7C27T0sMP0/+pP+S5K3+DcrQP5eZR/viXP36YaPOKFuWfD1N+agRZ84gsyZC8rovqC+Pkv7uH4o8P4K9P0z85SPfBKM3vXY3eevjDyHVdtm/fzqpVq9B1/Yz7fTx2jpb4mwd38pNtY6zvyfJ/3rWeJS1nf1zTkAuDmSr2E5MPMTnxEMXSZoRQSSZW1SvCryedXkc8vnTegP4j8X2bcnkHhbqrsljcRLW6b3a9rjeQSq6hd9Gv0dx8C+n0+sMq1sfjfbS03H5G56SqMRKJpSQSS89oPyEhISHH43yKty5gYM77QeCaI9psAt5O4Fp9G5ASQjQdY9uuhevqaTIr3gKr0aFB6c+sEGPpp49w8Hf/gOeu+E1K0V781wzxiXd/EL/mUjs4jXWwiH2giHWwCL4ktraZ1I3dGD1BNlfyhi5GNh3g8Yd/xs7nD+ALyfVLLmfR+tajjrVnzx5qtdqCukx3jBb5u4d3c9+WURKGyn997Qo+ftNSNDWsw/RywnGKVCq7qFR2Uy7vZGrqMcxaUIA1nV7Pkr7fwfctisXNjI3/kKHh4L+YEEFAfCzWSzy2mFi8F4HAsiewrXEseyIYX9I8gO8HhZkNo5l0+jLa2948O8RQGDMWEhLycuFCT1j4r8D/E0J8CPgZMAR4x91iDkKIjwEfA1i06DzU+jnC8lYp5Ikmkqja6VuwKk8+Sf/vfIrnL/8NitFFmDfs4TdXv52x//s8zlglcCIroHckSb66k+S1HWhNh9xQw8PDPPHEE7z00ktomsYV6y9nYniMpye3cU3pFlKpw9P1t27dSiwWY8mSJafd52Oxe6zE/3loF/dtGSUZ0fjEzcv4yPV9NCTOXgHfkPODbU9SLG6mUHyRYnEzlfIuLHtsdr2ixGhouIbe3o/R3Hwrkcjhfxyk9KlWD9StZ3upmgcxzX5GCi/geWUgGM7IMJqJRFqJxRbR1HgD6cxlZNKXEYl0hEItJCTkZcv5FG9DwNyc8e76slmklMMEljeEEEngHVLKvBBiCHjNEds+euQBpJRfBL4IsGHDhmMPiLdQHGV5y52Ry1RKydCf/SXPr/8NCtFFTL9qK7/d8lZy396J3pEgfesijMUZjJ4USuSQO8h1XXbs2MEzzzzDwYMHiUQi3HDDDVxzzTUkk0mmpqb4whe+wMMPP8xb3/rW2e1s22bnzp2sW7cOVT31AZGPx8Y9k3zka8+iKYLfumUZd17fRzYeirYLFd93MM2BepmLoNTFTAalECpC0RFCQ0qPcnkHtdrg7LpEYgUNja8mkVhez+hcTjTaddwK90IoJBJLSCQO/9MgpcRxcoBE1xvCKvkhISGvSM6neHsGWC6E6CMQbe8BfmVuAyFEMzAtg7FaPk2QeQrwE+DPhBAzkf+vra+/sDgy5q2QP6NM0/Jjj7GN9RTii5i46nk+qb6R8k8HiF/ZRsPbliG0wx9khUKB5557jueff55yuUw2m+X222/nyiuvPKzkR1NTE9deey0bN27kqquuoqsr8EDv3LkTx3HOusv0sV0TfOzrz9LbFOebH7kmHCT+PGDZk0xP/YxiaTOuU8Rxi/U6YUU8t4wvHaR08f2ZucXcwq+63kgstgghFKTvBkMr1YvDptPr6O5+fxCzlrrkrA6yLYTAMBrP2v5CQkJCLkbOm3iTUrpCiE8QCDEVuEtKuU0I8cfAs1LKewmsa58TQkgCt+lv1redFkL8CYEABPjjmeSFC4p5xFvL4tMPZB76l28w0v4uSp17+I3KrVh7psm8oY/kDV2HuYgsy+Lhhx/mmWeeQUrJihUruOqqq1i6dCmKMr+l4sYbb2TTpk3cf//93HnnnSiKwtatW0mlUmfV5fzQS2P8xr8+z7LWJN/86DU0hi7Sc4KUHsXiJianHmNq6lFKpa1AUPjV0BvR9GB4pXh8MZqarFvSdJS6RU1VosRii4LSGPG+cADtkJCQkPPIeY15k1LeB9x3xLL/Oef13cDdx9j2Lg5Z4i5Mjox5y+dZfJqWt+pzz7FvMk0yo/N6fw3epEXTB9YQW334cDV79uzhBz/4AYVCgQ0bNnDdddfR0HDi0iTRaJTbbruN73//+2zZsoUVK1awe/durr766mMKvlPl/i0jfPLbL3BJZ5qv3Xl16CY9C/i+hedV0fWjP2MpJeXyDkbH7mFs9Af1mDOFTOYyliz5XZqabiKVXBO6HkNCXoa4vmTIChJ4GnWNpKqcszjQ/VWLgzWLazJJYguUeFZ2PfprNn2xyCkdQ0rJg1NF/vbgGGO2Q0pVSWkqSVUhpalkNZVGXaPJ0GjSNRp1jagicKTE9uXsPKYq3NaUXpBzOxku9ISFi5xDdd5c28Y2q6dd4238X77MYNftXJK2iCgxWj6+Dr39UCX4arXKT37yEzZt2kRzczN33nnnKVvM1q9fzzPPPMODDz6IaZr4vn9WXKa+L7n7uUE+/b0tXNaT5Ssfvop0dGHLjrzccd0yQ0P/ysH+L+M4U+h6Yz2mbAWJxHJct8jo2PepVHYjhEZT000sa/1DmppuDIvEhrwikVIG+VwXUCKL60ss6WP7EsuXuFLSpGvzipGa57OtbPJCqcqWkomPJK4oxNVgiikKE7bLPtNiX9Wiv2bjyDmhDkLQoKs06BpdEZ1l8SjL4hGWxiMsi0dpNbTjijtPSqZsl5rv02RoJObEQUsp2V6p8aOJPPdPFHipUgMgriq8tinNm1qz3NKYPqbIMj2fgzWLA1Wb/abFsGWjCkFUUYgqwVwVgoM1i90Vi93VGsOWM3uMWxvTvLElw21NaZLa/PHZUkoez5X5/P4Rni9WWRwzeFU2ScX1KboeU47LAdMm77rkHI8TBckvj0dC8fayZU6R3kNlQrKnvJvazl3s217BW52hW9WIXdp8mHDr7+/nO9/5DqZpcuONN3LDDTecVk02RVF4/etfz5e//GUeeOABGhoa6Ow8/niFx6NiuXz3+UG+8vMD7JuscE1fI1/+0FUkI+Ftd7q4bomBga/RP/AVXDdPY+MNNDa8mkp1H5XKHkZGvzebjZnJXMHKFf+b1tY3hHFiIUchpWTUdthXtdhv2uyrWtjSZ20yxvpUnOXxKJpydoSO5fuUXJ+S61HzfRaforXkeFQ9H1VAZB4PQdXzeTxX4v6JAg9OFck5Lo26RrOh0Vyft0d0+mKBiOmLReiI6EcJPNeXjNsO28om28omW+vzUculPaLRGTHojOp0RQx6ogZrUzFWJ6IYR/Rp3HL48WSB+ycLbMyXsfz5JUJWU2mL6LQbOo26yt6qxUsVE7fevMXQiCiCqudjej5mfT8xRaEvZrAqGeX1LRn6YhEUATnHY9pxyTku047HQM3mF/kpTN+fPaYuBBlNpUFXyWgqGU1DIpmwXcZsh0nbxZ/Tx5giZq9l3vE4WLMRwDWZBH+8rJO+WIQHpor8aCLPPeN54qrCqzJJJBLT96l6wVRyfUZt57DzT6gKkkCwzj1mXFVYHo/w6mySFYko3VGDJ/Nl7p8s8IOJPBFF8JrGFMviUVJ1S1paU9GE4OvDk/wiX6ErovPXK3t4V3sj+jHub09K8k4g6KYcF8v3MYSCoQh0RWAIQfw8l7IKn6ILyRy36czoCqcj3ib/5Uv099xCPF5E9ZqIrjz0IDZNk7vvvhvDMHj/+99Pe3v7cfZ0Ynp6eli3bh2bN29m7dq1p2VmH8qbfG3jAb79dD+lmsu67gx/+57LeMOlHehh7baTRkqJbU/Wa6PtoVzZyfj4fbhuieamW1i8+DfJZC47ahvLGgE44UDhIRcvvpTkHI+kpswrWuZDSslLlRo/nSry8FSRTSXzsIe3IQRaXRBAIATWJmNckYlzS2Oaa7OJEx7L9Hw2lao8U6jwVKHCllKVvOsdJVI0AWsSMS5Lx7k8HefSZIyy5zNUsxmsOQxZNiOWQ0/U4Ip6myWxCEIIpJTsqNR4eKrIT6dLPF0o40loM3R6ogY9MYOuiM7uao3HpkuYviStBdaZ3liEKcdl0g6mTaUq9086h/UvWhclNd/H8iWW78+KphkWxwwuSca4rUln3HYZrjlszJUZtR08eeh6rk5GWZ+K02boPDJd5LliFQn0Rg1+taOJJkPDEIKoqmAIgSoEU47LiOUwZjmMWA77TIvFMYPf6GmdvV4dkcNDTnwZCKK4cvKuUV9Khi2HvdXAkjVmORRcj5zjUXBdJuqCqi2ic2kqRpuh02JoRBVlVtRMOS5TtkubofPJ3jZe15ymxThkOLi9OcPnlnfzi3yZH0zkeaZQwVAC4dOka/REA4G1KGrQF4vQG4uwOGbQoAfSRMrATVnzJY4vadDVo4T129sa+NyKbp4pVPjRRJ4HJos8Nl2idsQ912pofHZ5F7/a2XTC+1gVInCbGheuRLpwe/ZyYE6pkNMdlN4eHKL/iR1ULruDK3p8mBJElh3ax49//GNKpRIf/ehHz1i4zXD77bfjOA5XXnnlKW/77IFpPnDX01iuzx1r27nzusVcsaghrLl1DKSU5PNPUyq/hGMHg5Pb9iS2PUnVPIjrFmbbalqahobrWLz4v5BOrZ13f0KIULQtEMM1m91Viw2Z+GEuozPB9HwMJXhoH0nZ9dhRqfFS2WR7pcZQzWbMdhi3gwerKwNryepElPXpOJel4qxPxcjoGjkncP0ElhaXzSWTR6aLjNkuAGuTMd7X2cjSeJQlsQh9MYOuqIEA9lYtNpWqbCpV2Vwy+erQJP88MEFcVbixIcmtTWmuSCeYsB2Gag6DNZtBy2Zv1WJLyZx11S2PR7ipMUWLoR9mBdGF4KW6++97Yzm+Pjx11Lk36ipths7P82XuGpoEAmvU2mSMfaY16zJbk4jy6z2txBSFgZrNYM3m2UKFey2bVkPnPR1N3NGc4VXZxFFWsBlmRMz+qhW4HE2LvOPNuusiiiCiKDToKpckY6xJxkgdwzXnSclgzWZTyaxfvyr3jOcouj7rkjE+1dfO65szrEpEz+pvoiLEKd+TihB0Rw26owY3NaZOvMFpoimCGxpT3HAaxxAisHIZJ/h/ogrBtdkk12aT/El9FEfb9ym6PmXPo+x6LIlHz7u17GwSireFZK7l7TQHpZ/6yl0MdL8GR63S67SiL4nPjj26Y8cONm3axI033jhb3uNskEqlePe7333K220ZLPDhrzxDWzrK1++8mp7GcCD541EsbWXPnj8nl9sIBDXRdL0Jw2jGMJpoS72BRGI5icQyEonlGEZLKILPIb6UvFiq8uBkkQenimwtm0DgLrq1HsdzW1P6sIemLwM304jlMFm3SszMZyw+U47LpOMwZbuYvkQAKU0hq2lkNZWkpjJUszlYs2f3m1QVemMGrYbOqkSMNkOjxdAZtx02larcO57nG/OIoBnSmsJNDWluaUpxS2OatsixwyqWJ6IsT0R5Z3tg4a96Pk/kSjw8VeShqSI/niwe1l4BOiKB1etjPS1cnUmwIZ04rtXirW0Ns9drb9ViW9kkq6t0RQIROfOQ9aRkV6XGC8UqzxerbC5XuTwd5782prm5KXWUBWoGT0oUOKnvy1wRcwNnJmJUIeitW5De3JoFgj9oJc8nfQzBF7IwGIpCs6HQ/DKVOS/Ps7pQmCPeqvm62zSdPenN3akphu/9KZNX/Hfa11r4By1i13cDUKlU+MEPfkB7ezs33njj2e75KbNrrMQH7nqKdEznXz96DZ3Zsze4+MsN0xxg776/YWzsXnS9kRXL/wdtbW8Ki84uMFJKNpdNni1UGKo5DFs2w5bDUM0m73r1f/gCo25tyTsek46LAlydSfCZJR2sTER5eLrEjyby/HCiQEwJ/vFXPJ9hy2bUco5ysQFEFEGTHsRZNRkay+IRmg1t1j1XcDwKrkfe9Si6HuvTcd7b0ciaZIzVyRjdEf24QkRKyQHTZlOpStXzZwPTs7pKoxYccz7r3skQVxVe25zhtc0ZpJTsrNbYUa7RHtHpihp0GPppx8YpQsyKxflQhWB1/Rr8SmfTvG2Otd2FghAiFG4hZ51QvC0kh8W85YnEE2jGyZfHyH3r2wy2vRpfSG5esgrn4DDRVY1IKfnRj36EaZp84AMfQNPO78d4YLLC+770FLqq8K1fC4XbfFjWBIXCc0xPP8HwyH8ihGBx73+ht/fX0bSFc1m8HDloWoxYDrF6ht3MPDVP/JeUki1lk3vH8/xgPD9rzTKEoDOq0xkxeHVDkkZNw5YSux7nZEsZBD83pLilKT0bgwNBHM9nl3fxVL7CDybyPJkv06hrXJtJ0hnR6YgadEb0WaHWrGskFrhMgxCCvniEvnhkwY4xc5xViRirEuF3PCTkfBKKt4VkruWtkD/lZIXhnz7MUOdHMVbUUAaqaK0xtMYoW7Zs4aWXXuLWW2+lra3t7Pf7FBjKm7zvS0/h+ZLvfOxaepsSJ97oZY7rlihXdlEu76RQeJ5C4TlMMxiAXVEitLe/hSV9v0002nGee3puOGhauFKSUgOXYEwRpyxkpJT8Il/hnwfHeWCyeMw0/riq0FCv09Soa0H5AdNGFXBjQ4rfXtzGLY1pWg3tjEpGqELw6oYkr25InvY+QkJCQk6XULwtJGcg3vxqldFSB7Itxh13rMH61z0kr+ukVCrxox/9iO7ubl796lcvTL9PkvFSjff9y5OUag7f+rVrWd72yrQgVav7GR39PsXSViqVXbNjfkIwjFQ2cyVdXe8jm7mSVOoSFOXlX5zYk5IHJ4v808A4TxYqh61TgJSmztamiipi1no2U7ZhSTzC4liERVGDR6eL/PPABJvLJo26yu8sbuPaTJJavdzATNmBsusz7br1kghBaYS+WIRPLmrj9S0ZGvXw5y4kJOTlQfhrtpAc4TZt6ek96U3Lm15kvPVKiE3R6mtMeZLoykYe27gRx3F461vfetYHiz8VClWHD3z5acZLFt/4yDWs7XplDZfk+zYTEw8wNPRtcvknEUIlHl9KJn05XZ3vIZFcSTKxgmi0+xWVZFBxPf5tdJp/GZzggGnTFdH5zJIOOiI6Jc+n7HqUvaDel+nP1KjyMT1JxfPYmC9z91juqP0uj0f4q5U9vKOtYcEqtoeEhIRcLJy0eBNC7AK+DHxNSjm6cF16GXFYkd4c8UvXn/Smux97mGLqVTReamPumEZEVSKL00w9NUVzczPNzc0L1OkTU7Vd7vzaM+ybqHDXh67iyt7TGzXiYqRS2cfIyH8wPHI3jjNNNNrN0iW/R0fHO4lEWs93984qUkoO1mw2l0wOmBZZTaU9otNq6LRHdFKawp56puC2UlC0dEvZpOL5XJmO89+WdPKG5swpB7Obns8B06pPNisSUW5uTF1QlfFDQkJCzienYnlzgM8BfyKEuA/4EnCflNI//mavYOqXxvUkVqVySm7ToW3TkFC4+rr11O4eJLq8AaEq5PP5kxqrdKGwXZ+Pf/N5XujP8Q/vu4Lrl58/EXmucN0y4+P3MzzyHxQKzyGESnPzrXR1vofGxhsuygzRouuxuVTlgGlj+T7OnDH78q7L1rLJ1pJJyTu5r3dcVbgkEeOX2xt5Z1sDGzKnH/sYU5XZDMOQkJCQkKM5afEmpbxECHEt8BHgXcCbgFEhxFeBu6SUexemixcxdfFWrQbjvCWyJye6pO9jmu2IeJnueJqJkj2bZVooFFi8ePFC9fi4eL7kd77zIj/bNcFfvGMdd6x9+Qbc+75DLvckY+M/ZHz8PjyvSjy+hGVL/4D29rcRibSc7y7OS8Fx+dFEgZ2V2pxszCCmrOL6bC6bbCpW2Wtax9xHTAnKM7y9rYF1qTiXpmIsjUcoOB5jtsuY5TBmO+QdjyXxCGuTMXpjRmgZCwkJCTlHnFLMm5TySeBJIcRvA+8mEHKfBv5QCPEYgTXuP6WUx34yvJKYFW/B5Yif5KD0Y5ufoZBZTTSbw9qVAwHRlQ3UajUsyyJ7ioV+zwZSSj5zzxZ+tGWEz7xxNe+6quec92GhCQTbRsbG72di4kFcN4+qJmhr/SU6Ot9JJn3FBRm/VvN8Hp4u8t2xHA9OFrGlJKYILF9ypN2sM6KzPhXnl9sDYbYiESWm1MfsE8G4fceqkZVQVTqjL/9ki5CQkJALndNKWJBSVoGvAF8RQqwA/hfwXuAm4O+FEN8A/kZK2X/WenoxMiPeKoF4O9mhsV78yaM4+lUsuypBbcc0encKNWmQHwnGrDwf4u3/PLiLbz89wG/evJSP3rDknB9/IXGcAv0DdzE4+M26YEvS0nwrra2vp7HxBlR1/gKi56RvvmTCdhirD4k0YR8aT3BmbMHnihWKrk+LofHBribe3tbIZanA5ehIien5VH0fXSg0X8Bj9YWEhISEnByn/UsuhFCBNxNY3+4AJPAIYAGfAH5NCPErUsrvn42OXpTUxVulErhNTzbmbXK3BarPVddfQ+FvXyR96yIACoVgnMtM5txmdn7rqX7+7qd7ePeGHv7ra1ee02MvJDOibWDgq3hemZaW19HR8Q4aG65HVRe22OlMMsCWksnWssm47VByPcquT8kLquxPOS7Tjjfv9jMDOzfrGq9vzvK2tizXZ1NHJQcEowYovLJygUNCQkJe3pyyeBNCrCIQbO8HWoFx4K+Af5mJexNCLAP+HfgL4BUv3qoz4u0kLGa+9LHtHqLGEMpQFSREVwVjDObr46OeS8vbQy+N8Zl7tnDzyhY++7a1F6Tb8FSx7UkGB/+VgcGv4LolWlruYEnfb5FMLqwwnbAd7hqc5MlC+bBkAE1Ai6GTVBXSmkpKDbI6m3SNVkOn1dBoi+i01MezbNK1l9UAyyEhISEhp8aplAr5CHAncG190UPAF4HvSynduW2llHuEEH9HEAP3ymVWvJkYsRi6cWJrzovPP4EZ76WtcRe1XTmUlI7eGVRxz+fz6LpOPH5uBnx/vj/HJ779PJd2ZfjC+65Au4gFg+87TE09yvDI3UxNPYqULi0tr6Nv8SdJpVYv6LEnbId/6B/nq0OTWL7k8nR8NhlgbSrGqkT0qGGdQkJCQkJCjsWpWN7+BRgFPk9gZTtwgvYvAd84zX69PJhxm5bNk3aZbvvJs8BlrL1+DdYLeSJLsoi6K6xQKJDJZM6J9WvfRJmPfu1Z2tJRvvyhq4hfpLFS1ep+hoa+zcjoPTjOFIbRTE/Ph+joeCfJxPIFPfaE7fCP/RN8ZWgSy/d5e1sDv7O4jaXx8xdDFxISEhJy8XMqT+S3Az+QUs4fhHMEUsqngadPq1cvF+pFequV6klnmlYPauhOgSXrb2b8Z1uILDkUrZTP58+JyzRftfngV55GAF/78NU0Jxc2/utsI6Ukl3+Sgf67mJz6KULoNDffQmfHO2lsvBFFWTghOjfz86GpIo4veVtdtC0LRVtISEhIyFngVOq83bOA/Xh5Msfy1tR34qGxctU8nr+EBnc39pAJQKTvcPHW1dW1MH2dw2d/tJ2RfI3/+PirWNx88Qw07/s2Y2M/oH/gK5TL29H1RvoW/xZd3e8jYpx5MeGy6/FYrsQv8mU0IchqKhldI6up6ELw0FSRH03kKXlB5uevdjTxoa5mlidC0RYSEhIScvY4lZi3/w28Q0q59hjrNwP/LqX807PVuYueGctbuUrPSbhNH3vyCaQap60b7H0FlKSO1hKUfLAsC9M0FzzTdOPeSf7juUH+y2uWcvmii2PYKyklE5MPsGfP5zHNfhKJ5axe9Tna2t5yxlmjB02LB6eKPDhZZGO+jCMlMUVBIqn58rC2KVXhDS1Z3t7WwHXZ5CkPCxUSEhISEnIynIr/6G3Ag8dZ/yDwTiAUbzNIH08KambtpGLeBn52AFWuZO2N67FeKBDpOxTfNlMmZCHdpjXH479/byu9TXF++9aFjQc7W5RK29i1+7Pk80+RSCxn/bov0dT0mjOKC5RS8lShwt8fHOfh6SIQDIz+0e5mbm/KcFUmga4Iap5PwfXIux4Vz2N1IhYOmh4SEhISsuCcinjrA3YcZ/1O4KNn1p2XGdKn6uoAJE4guqSUyNEMmcI+MqvexsSjO4+Kd4OFFW//8Mge9k9W+OZHriGqqwt2nLOBZU+yd+9fMTJyN7rewMoVf0xn57vPKJ7Nl5IHp4r8/cExni1WadI1fr+vnbe1NtAXP9qCF1UVoqpCW0Q/k1MJCQkJCQk5JU71SZc9zroG4MJ+4p9r5oi3E1neNh98CZUuMt5DuJNBrNzceLeFLtC7e6zEPz62l7dd3nXBDzZfre7nhRc+gGVPsGjRR1jc+5voevqktj1oWjw0VeTFUhXHl7hS4slgJIIDpsWeqkVP1OBzK7p5T3tjaEkLCQkJCbngOBXxtg14C/DnR64QgY/qzRzfMvfKQ/pUvWAsyBNlmz755Bagle7FUax9BZS4htZ6qJ5bPp9HVVWSyeRZ76bvSz793S0kIhqfeePC1jw7U4qlrbz44ocB2LDhbtKpeUMwZ/Gk5Kl8hYemijw0VWRXNSiY3BHRSagKqhBoAlQhaDN0fndxO29uyYbxaiEhISEhFyynIt6+DPyzEOKrwKeklBMAQogWgpEUriUYFitkBulTmXWbHl+8lbZUyFo5el+7jtruAkZfZra+GwTiLZPJoCxAMdd/e2aAZw/m+Mt3rqPpAi4Lkss9xabNH0PX0lx++deJx/uO2/7ZQoVP7xpkS9lEF4JXZRP8amcntzVlWDKPGzQkJCQkJORi4FRKhfyLEOIm4APA+4UQI/VVHYAAviOl/MdTObgQ4g7gbwncrV+SUn7+iPWLgK8RuGtV4A+llPcJIRYD2wni7ACelFJ+/FSOfU6QPlU3sLydaFB6Ix8jWRokuuKXqDw9TPK6w0uCzBToPdsM500+d/92XrWkiXde2X3W93+2mJh8mK1bP0k02sPll32VaLTj2G1thz/dO8J3RqfpiOj87apFvLElQ1ILvfohISEhIRc/pxTzJqX8VSHEvcD7gGX1xc8A/yqlvPtU9lUf2P4LwO3AIPCMEOJeKeVLc5p9hqD8yD8KIdYA9wGL6+v2SikvO5VjnnOkpOrp6IaOHj1+rS/VSaHLvfhW4Badm6wAgeVt+fKzmwE6XbH5wF1PIyX82dsvvSDHLXWcHEND32Hf/r8hlbyE9eu/jGE0ztvW9SVfG57kz/ePYHqS31zUyu/2tpEIRVtISEhIyMuIU07Nk1L+O8Gg82fK1cAeKeU+ACHEvxHE1M0VbxKYiUTPAMNn4bjnDulTcQ3iqePHqU0ODoCSQLaqWPsLiKiG3n6oOK7jOJTL5bOaaVq2XD78lafpn67y9Tuvpu8CKsYrpU8u9yTDw99hfOIBpLRparqZtZf8XzTt6GtZ83z+Y2yaL/SPc8C0uakhxZ8u7wqL44aEhISEvCw5nwNWdgEDc94PAtcc0eaPgAeEEJ8EEsBtc9b1CSFeAIrAZ6SUjy9gX0+Puts03nh88db/7f8E1qFcswR7f4FIX/qweLdiMag1drbcppbr8evfeJatw0X+6Vev5NolTWdlv2eD4eG7OXDwC5hmP5qWpqvrPXR2vptUctVRbUuux9eGJvni4MT/3959h0dVbQ0c/u2Z9BB6KCH0mh4gqIAgRQS8oqAoIKKg6EWliF2xIOUTxYIFEfQiytWAdLxWUEAEpBo6hA6hhU56MjP7++PMDJkUyJCEkLDe55knmVP3SSGLtcsiMdNCdIAfX0fU4o4q5a/LLKIQQghRFNwO3pRSMRhBViUg5+h5rbUeWxQNs+sHzNBav6+Uag3MVEqFA8eBOlrrM0qplsBCpVSY1vpijrY+ATwBUKdOnSJsVgFpGylWTypdJvOms7JI/v0fqBdJYIP6WHal43+z63iuolzjzWrTjIiNY9XeM7x/fxRdQqsX+ppF5eDBz9i3/33Kl29Og/ojCQy8A7M5d/bMqjWfHznFR4dOcNFi47ZKAXwWWo22FctJ0CaEEKLMc6c8li8wH7gDY4KCtn8k2+caKGjwdhSone19sH1bdo8B3QC01muUUj5AVa11IpBh375RKbUPaAJsyH6y1noaMA0gJibGtZbRtaBtZNnMeHnn33138ZdfycwwZqTWsgQAZ/Ic7waFD9601rw6fyu/bD/B63eFct91MkFBa83+Ax9y8OBkalTvSUjIO/kutnswLYPhOw+z7kIKXaqU57l6NYgu75fnsUIIIURZ5M66E29gBG7jgY4YwdojQHdgJcbEhVA3rrceaKyUqq+U8gL6AotzHHMY6AyglAoBfIBTSqlA+4QHlFINgMbAfjfufW1oG1qDymd5D601Z7/+muSqQdiwUv6cGeVtxrOma6buwoULKKUICAgoVHN+3X6C2RuOMKxTIx679fLLbFwrWmv27n2bgwcnE1TzAUJD380zcNNaM/PYaTqt382ulDQmh9Thm4j6ErgJIYS44bgTvPUG5mit3wC22bcd1Vr/ijEWzQsYWNCLaa0tGOvC/Yqx7Mf3WuvtSqkxSqm77Yc9BzyulNoMxAIDtdYaaA9sUUrFAXOBIVrrs248y7WhbWhUvsFb2saNpG/bRmLtYNK8k7AcSsK7XnmU2bXr7/z585QvXx6zuXCzJlfvO4O/l5lnbm9SqOsUFa1t7I4fzeEj/yE4eADNmo3HHpO7OJGRxUNbDvDC7gRiyvuxrFUz7qtRWbpIhRBC3JDcGfNWG/jA/rnV/tELjEBMKRULPAm8UtALaq1/wlj+I/u2N7J9vgNom8d584B5brS9ZGijzJVSeQdvZ7/+GnOFCpz3DcDDloElMQ2/FrnHoJ0/f75IxrttOnyOqNoVMV8H1QO0trFr1yiOHf+eOnUep1HDl3IFY6cys/j0cCLfHD0NwPjGtRhUqyomCdqEEELcwNwJ3pKyHZ8E2ICgbPsvADWKqF1lg7ahtXKZOeqQeeQISUt/p8rjj6OO+FC9ohXScq/vBka3ad26dQvVlNRMCzuPJ/FUh4aFuk5RyB641as3lAb1n3EJ3E5lZjH5cCJfHz1Nhk3Tu0Ylnq1Xg3q+UhVBCCGEcCd4c0wKQGttVUptx+hKnW6vbXovrkt/CK2NmRx5ZN7OzpwJZjMV+vXDe8wWgsxZKC8TXrVcx7tZrVYuXrxY6Mzb5iMXsNo0LepcvkxXccseuNWvN4wGDZ5x2f/poZO8f/AkGTYb91Y3gjYpZSWEEEJc4k7wthR4VCn1jNbaCkwFPrXP9NRAfeDVYmhj6aVt2FCQY8ybNSmJC3PnUb57dy56emPWHgRneOHdsCLK7HrsxYsX0VoXOnjbdPgcAM3rFO46haG1jV27X7dn3J6mfv0RLvs/PXSScfuP071qBUY1rEkjP1lkVwghhMjJneBtAjAT+/IgWuvP7Et3PIQxBu4LjAL1wkHbII/ZpufnzsOWmkrlRx5hx7HjVPNQ+GaZ8WuZe7zbhQsXgMIv0PvP4XM0DPSnop9Xoa5ztYzJCW9y7Ngs6tV9kgb1R7p0lf732BnG7T9Oz2oVmRxaF7OMaxNCCCHy5E5h+mQuFYJ3bPuAS5MYRE722aamHMHbxR9/xDcqCt/wME4uWUldLxNWb/ANyV2zsyjWeNNas+nweTo3q3bV1ygMrTXx8WM4evQ76tYdQoMGz7kEbosTz/PC7iN0qhzAxyF1JHATQgghLqNAS4UopcoppfYppZ4p5vaULdqW55i3rCNH8A4xyj1dPJ5MDU8F4eVQHrm/HY7grTCZt4NnUjmbkkmLuiUz3m3/gUkkHJ1JnTqDadjgeZfAbdmZizy94xCtKvjzZXh9vPJZVkUIIYQQhgL9pbRn3aoAycXbnLJGo7XrmDdbSgrWCxfwDKoFQKWjGpNSVM1n0dwLFy5Qrlw5PDyuvgztpkPGeLeWJRC8HUn4hoMHP6Vmzftp1PBll8Bt/YUUHt12kKb+PsyMqI+fWQI3IYQQ4krc+Wv5NxBTXA0pkxyZt2zBW9axYwB4BgWhtSY4yYdEWwb+NSvmeYmiWONt4+FzBPh40Cgw/xqrxeHkyR+Jjx9D1aq306zpOGfgZtOaqUcS6R23l5rensRGNaCC59UHp0IIIcSNxJ3g7WXgAaXUICVL2xeMo8KCyjt4yzycRAWbJ/GeF/K9RFEEb5sOnSO6dkVM13Bx3rNnV7F9x3NUqNCS8LCPnCWvDqVlcF/cXt7ce4zbKgWwqEUjAr08r1m7hBBCiNLOnXTHB8A54EvgXfsSIak5jtFa685F1bhSz1nb9FLJJ2fwViuIpJUnsGjNwfLn8zzdZrNx8eJFQkPdKRnrKik9i/iTSXQLv3brJ1+8uJUtW5/Ez68+UZHTMJt90Frz3fGzvLH3KAr4sFlt+kqJKyGEEMJt7gRvDTDWcztsf597XQvhSutctU2zjh0DT09M5SuTtmUvRzM1HpXyToAmJydjtVoLlXnbfOQCNs01W5w3PeMEcZsfw9OzIs2jZ+DpWYEMm40ntx/ip9MXaFuxHJNC6lDbp2SWLBFCCCFKO3eWCqlXjO0om5yF6bNl3o4ew7NGDdK3nUFn2jicaSOgsm+epxd0mZBzKZnEn0zi5gZVcu3bdPgcSkH0NVic12bLYtu2YdhsabRo8S3e3tWx2LQzcHuzYRD/rh0otUmFEEKIQpDpfcVI26wALrVNs44dwzMoiJT1J7AEmDlr1VQODMjz/IIu0Pv5in30mfY3a/efybVv0+FzNKkWQHmf4h9XtnffO1y4sImQZm9Tzr8xNq15Ztdhfjp9gXGNa/FknWoSuAkhhBCFJMFbMdI2G5B7zJtHzcZkHk7iZFUjuKtRLXfGDAqeefvniHHcK/O3kp5ldW632TSbDp2jRd3Ln18UTib+xJEjXxEc/DDVq9+F1pqX4xOYe/Icr9SvyeDgwGJvgxBCCHEjKHC3qVJqfwEO01rrhoVoT5lyKfNmxMg6MxPLqVOYyjXDmqo44JGMxoPgGnlPJjh37hx+fn54eeU/Psxq02w/eoHwWuXZdvQin/yxhxe6GgsA7z+dzMV0C82LebxbSsp+du58mfLlm9O40StorRmz7xjfHDvDsDrVGFFPhkcKIYQQRcWdzNth4FCO11HAC6gHWLg0mUGQLfNmXyok68QJYxKDrRLeDSpw7mI6KV4XqRGQO7hJSUlh27Zt1KtX77L32H8qmZRMK4Pa1Oe+FsFMXbGfHccuArDp0HmgeBfntVpT2brtKUwmbyLCP8Fk8uLDQyeZcuQUg2pV5dUGNYvt3kIIIcSNyJ0JCx3y26eU6ge8DwwpgjaVGZcyb0a3qWOZELQn5vJeZCRo0nwu4uuRe8LCihUryMrKomPHjpe9x5YEY1xcZHAFOjWrxor4RF6ev4X5T7Zh46FzVPTzpEFV/yJ8qku01uza9TopKXuJjp6Bj09NPjh4gncPnOD+GpUY37iWLAUihLjuZGVlkZCQQHp6ekk3RQh8fHwIDg7G07PgY9OLZFl7rXWsUqodRgB3V1FcsyzI2W2addQI3rRFYfLzRCeZsZXPyHXemTNn2LBhAy1atCAw8PJjxbYevYCfl5kGgeUwmxRv9ghjWOw/fLXqIJsOn6N57YrFFkCdOvUbJ04upH79Z6hcqS3vHjjOBwdPcn+NSkxqVkcmJwghrksJCQkEBARQr149+Q+mKFFaa86cOUNCQgL16+ddJjMvRTlhIQ5oX4TXK/W0dp2wkHXsGJg80Fka5WPGI80Xc3lbrvP++OMPzGYzHTp0uOI9NiecJ7xWBcz2Ga13Rdbk9pBqvL9kN3sSk4uty9RiSSI+/i3KlQulbp0hTDhwgg8OnqRfzcpMalYHs/yDKIS4TqWnp1OlShUJ3ESJU0pRpUoVt7PARRm8RQO5I5EbmLZpwDV486hZGwCLSWGymfGt4Jr8TEhIYPv27bRp04aAgLyXEHHIstrYcewikbUuLSWilGJsz3A87Nm+4lqcd9++98nITKRZ03GMP3CKjw6d5KGaVXi/aW0J3IQQ1z0J3MT14mp+FgscvCml2ufz6qmU+hR4HPjV7RaUYbm6TY8dwzOoLgCpWVkALgv0aq1ZsmQJ/v7+tGnT5orXjz+ZRIbFRmTtii7ba1bw5c0eodSp7EdUjn1F4cKFf0g4+l9q1RrAB6eq8tmRRB4JqsK7TYOlq1QIIQqgXLlyubaNHj2aWrVqER0dTbNmzXjyySex2Se+DRw4kPr16xMdHU10dDQff/wxYFTiefLJJ2nYsCEtWrSgZcuWfPHFF4BRYnH48OGEh4cTERFBq1atOHDgQKHanZmZyaBBg4iIiCAqKorly5c798XGxhIREUFkZCTdunXj9OnTuc7ftWsXrVu3xtvbm/fee8+5PT09nZtuuomoqCjCwsJ48803nfv69+9PZGQkr776qnPbuHHjWLhwYaGepTRzZ8zbcozyWDk5/lovBYYVtkFlyaV13i4Fbz6RtwFwJiUJgCrVyjuP37NnD4cOHeLOO+/E29v7itff6pisUCv3Ir73x9Tm/pjahXuAPNhsWeza/Rre3tVZ5z+YqXtO8WitqjI5QQghisDIkSN5/vnnsdlstG/fnhUrVjgnrk2cOJHevXu7HD948GAaNGjAnj17MJlMnDp1iunTpwMwe/Zsjh07xpYtWzCZTCQkJODvX7gJbI7AcOvWrSQmJtK9e3fWr1+PzWZjxIgR7Nixg6pVq/Liiy/y6aefMnr0aJfzK1euzMcff5wr8PL29uaPP/6gXLlyZGVlceutt9K9e3f8/Pzw9fVly5YtdOnShQsXLpCamsratWt57bXXCvUspZk7wdugPLZp4CwQr7WOL5omlSH60lIh2mYj68QJynWsgeUinE5OBqBm9aqA8T+kJUuWULlyZVq2bFmgy29OuEB5Hw/qVvErnvbn4ciR6SQn78Kn8TTe2HeadpXKMVYCNyGEKFKZmZmkp6dTqVL+Q1/27dvHunXr+O677zDZkwSBgYG89NJLABw/fpyaNWs69wUHBxe6XTt27KBTp04AVKtWjYoVK7JhwwaaN2+O1pqUlBSqVKnCxYsXadSoUa7zq1WrRrVq1fjxxx9dtiulnNnIrKwssrKyUErh6elJWloaNpuNrKwszGYzb7zxBm+99Vahn6U0c2epkK+LsyFlkS1beSzLqVOQlYWpQlW4COeSU8kyWQmqYnSjxsXFcerUKe6//37MZvPlLuu09eh5IoOLbzZpTmlpR9h/4GP8q3TjhWNBlPew8lloXRnjJoQotd76YbtzbcyiEhpUnjd7hF3VuR9++CH//e9/OXToEN27dyc6Otq574UXXmDcuHEAzJw5kwMHDhAVFeUMznJ64IEHuPXWW1m5ciWdO3fmoYceonnz5rmOGzlyJMuWLcu1vW/fvrz88ssu26Kioli8eDH9+vXjyJEjbNy4kSNHjnDTTTcxZcoUIiIi8Pf3p3HjxkyePNmtZ7darbRs2ZK9e/fy9NNPc/PNNwNGQNqiRQsGDBjA3r17sdlstGjRwq1rlzXujHnzUEqVv8z+8kqpIll6pKzIvkivY5kQk39FAC5czCTJ+xw1/Y1FbLdu3UpgYCChoaEFunZ6lpVdx5OICL583dOiorVm1+7XUcrMN+Zh7E3N4LPQugR6FX/NVCGEuFGMHDmSuLg4EhMTSUlJYdasWc59EydOJC4ujri4OCIiInKdO378eKKjowkKCgKMTNvu3bt5++23MZlMdO7cmd9//z3XeR9++KHzutlfOQM3gEcffZTg4GBiYmJ45plnaNOmDWazmaysLKZMmcI///zDsWPHiIyM5O2333br2c1mM3FxcSQkJLBu3Tq2bdsGwKRJk4iLi+O5557j9ddfZ+zYsYwfP54HHnjA2Y17o3En2Hof6A40yWf/euB/wHOFbVRZkX3Mm2OBXpNvAKgUUi7aSPe5iJ+n0eWZnJzs1tT1XSeSsNg0UdcoeDt79i/Onl3J7uofMD8xnefqVefWSpefDSuEENe7q82QFTdPT0+6devGn3/+Sd++ffM8JjQ0lM2bN2Oz2TCZTIwaNYpRo0a5TIbw9vame/fudO/enerVq7Nw4UI6d+7sch13Mm8eHh58+OGHzvdt2rShSZMmxMXFAdCwoVEh84EHHmDChAlX9ewVK1akY8eO/PLLL4SHhzu3L1q0iJYtW5KcnMy+ffv4/vvv6dq1K/3798fP79oNH7oeuBO8dQXmXWb/PKAnErxd4sy8KWfwpjz8UD4ZcNYTW7VM56EpKSnUrVu3wJfemnAegIjgikXW3Ms5eHAyiV7RTDxdj7YV/Xm2Xt71WIUQQhSe1ppVq1bl2c3p0KhRI2JiYnjttdcYO3YsZrOZ9PR0tDbmFm7atIkaNWoQFBSEzWZjy5YtREZG5rpO9mDsSlJTU9Fa4+/vz5IlS/Dw8CA0NJRjx46xY8cOTp06RWBgIEuWLCEkJKTA1z116hSenp5UrFiRtLQ0lixZ4hy7B8Y4uEmTJvHjjz+yZ88eZ6LDarWSmZkpwdtl1Ab2XWb/fvsxBaaU6gZ8BJiBL7XWE3LsrwN8DVS0H/Oy1von+75XgMcAKzBca33dLVNyaZFeE1nHjmKuUAFbFph8PfDI8MajvPELZrVaSU1NdWsW0OaEC1Tx9yKogk+xtD27c+fWcfLCZj7xno6/2Szj3IQQopBSU1NdJhA8++yzwKUxb1lZWURGRvLUU09d9jpffvklL7zwAo0aNaJKlSr4+vry7rvvApCYmMjjjz9ORoZRyeemm25i6NChhWp3YmIiXbt2xWQyUatWLWbOnAlAUFAQb775Ju3bt8fT05O6desyY8YMAD7//HMAhgwZwokTJ4iJieHixYuYTCYmTZrEjh07OH78OI888ghWqxWbzcYDDzzAXXddKtg0efJkHnnkEfz8/IiMjCQ1NZWIiAjuvPNOKlasWKhnKo3cCd4ygctVGa+BG4v0KqXMwGSgC5AArFdKLdZa78h22GvA91rrKUqpUOAnoJ79875AGBAELFVKNdFaW914nmLnXKTXnnnzqBWELdWC9jSGGvpVNMaLpaamArgVvG1NuEBkcIVrMlnh4MHJ/Nf0FAcyfZkVVZfq3jLOTQghCsOxfltOOZfWcHAEQjmVL1+eqVOn5rmvW7dudOvW7Wqal6969eqxe/fuPPcNGTKEIUNylzjPvq1GjRokJCTkOiYyMpJ//vkn3/s+88wzzs+VUsTGxrrR6rLHnQoLccADSimvnDuUUp5AH2CLG9e7Cdirtd6vtc4EZgH35DhGA45JEhUAe2V37gFmaa0ztNYHgL32611XnJk3e/DmGRSELc2CxT6ZtEJlI82bkpIC5L1oY15SMy3sSUy6Jl2mFy7E8cM5xR+6HSPqVue2yjLOTQghhChJ7gRvn2Jkun5USsUopbyUUp5KqRjgRyDUfkxB1QKOZHufYN+W3WjgIaVUAkbWzbEIcEHOLXHO/1kpRdax43gGBaHTLKRZLQAEVqsIGJMVoOCZt+3HLmLTXJPJCn/t/5bpagg3lffheRnnJoQQQpS4AgdvWut5wNtAZ2AtkGp/rQVuB97VWs8u4vb1A2ZorYOBO4GZSil3ljd5Qim1QSm14dSpU0XctAKwB286LQ2dmmpk3lKzSLFmorFRs1ogcCnzVtDgbfOR8wBE5FFZoSidvrCDMeda420y83lYAzxMMs5NCCGEKGlurcumtR6llFoIPAQ4lk6OB77TWq93895HcZ3gEGzflt1jQDf7vdcopXyAqgU8F631NGAaQExMTF6lvYqVY6kQ2/nzmAGPmkGk7baQ4pFFqmcSNSvUB9zvNt169AI1yvtQrXzxTlZ4dUcch1QoM5rVIMgnV2+5EEIIIUqA24vq2oM0dwO1vKwHGiul6mMEXn2BB3Mccxgj0zdDKRUC+ACngMXAd0qpDzAmLDQG1hVBm4qUY8yb9Zw9eAusCfo8qelWkr3PUd2vOmAEb2azuUD1TOHSZIXiNO/ILhanh9Iv4BDdqkcX672EEEIIUXDudEFWVkrlXiDm0v5IpVT+Rdhy0FpbgKHAr8BOjFml25VSY5RSd9sPew54XCm1GYgFBmrDduB7YAfwC/D09TbTFLJl3s6dA8BcqRoAaZk2MrxTKOdlZNqSk5Px9/cv0MzRC2lZ7D+dUqzB25H0TF7cd5GG7GVseNtiu48QQggh3OfOhIV3gRmX2f8Vxpi4AtNa/6S1bqK1bqi1Hm/f9obWerH98x1a67Za6yitdbTW+rds5463n9dUa/2zO/e9Vi5l3s6ifH1RHr4AZGaCyffSNPGUlJQCd5luP3oBKL7Fea1a8/S23di0hf+rcYRyPlWL5T5CCHEjy+vf/NGjR1OrVi2io6Np1qwZTz75pHPi28CBA6lfvz7R0dFER0fz8ccfA8Z//p988kkaNmxIixYtaNmypbNklM1mY/jw4YSHhxMREUGrVq04cOCAyz0XLVpEz549ne/ffvttl4LyP/zwA3fffTfHjh2jd+/egFGL+6effnJp93vvvXfFZ65Xrx6nT5922Xby5EnuuusuoqKiCA0N5c4777zida7k0KFDdO7cmcjISDp06OCyNMmLL75IWFgYISEhDB8+3LmgcXZz5swhLCwMk8nEhg0bnNvXrVvn/PpHRUWxYMECwFhg+NZbbyU8PJyFCxc6j7/nnns4duxYzssXCXeCt47AD5fZvxhj4oKwc6zzZjt7zphpmm4kBy2ZHnj6XfrSp6SkFHyyQoIRvEUW02SFqYcTWZdkZaD6jlsaDiiWewghhMibo7bpjh072Lp1KytWrHDuy17bdPjw4QAMHjyYSpUqsWfPHjZt2sQvv/zC2bNnAZg9ezbHjh1jy5YtbN26lQULFuRa0LZNmzb8/fffzvdr1qyhfPnyJCYmArB69WratGlDUFAQc+fOBXIHb4Xxxhtv0KVLFzZv3syOHTuuuqRWds8//zwPP/wwW7Zs4Y033uCVV14BjGdZtWoVW7ZsYdu2baxfv97l6+sQHh7O/Pnzad++fa7tGzZsIC4ujl9++YV///vfWCwWYmNjGTJkCOvWrWPSpEmAEfQ2b97cWWe2qLkTvAVhjEHLT4L9GGHnzLydOWOfaWosEWKxKbzLXRpu6Og2LYij51Op5OdJJf+in0CwMzmNtw8cJUavZXDj9nh7SdZNCCFKQmZmJunp6VSqlP9opH379rFu3TrGjRuHyWT8OQ8MDHSWlTp+/Dg1a9Z07gsODs51vcDAQMqXL8/evXsBOHr0KPfddx+rV68GjICnbdu2HDx4kPDwcDIzM3njjTeYPXs20dHRzJ5tLDKxY8cOOnToQIMGDZxZwYI4fvy4S6WJvMp3uWvHjh106tQJgI4dO7Jo0SLAWHM1PT2dzMxMMjIyyMrKonr16rnODwkJoWnTprm2+/n54eFh/O1OT093DnXy9PQkNTWVjIwMzGYzFouFSZMm8eKLLxb6WfLjzoSFFOByxTfrAhmFa07Z4hjzZj1zFs/waGxpWQBkavAtZwRfWmu3uk0zsmz4eJqLvK0ZNhtPbd+Hn07i2fLrCAr6ssjvIYQQ152fX4YTW4v2mjUioPvVZZAc5bEOHTpE9+7diY6Odu574YUXGDduHAAzZ87kwIEDREVFOYOznB544AFuvfVWVq5cSefOnXnooYfyrJXatm1bVq9ejdVqpXHjxtxyyy38+uuv3HXXXWzevJlWrVpx4sQJALy8vBgzZgwbNmzg00+NpV1Hjx7Nrl27WLZsGUlJSTRt2pQnn3wST88rV+N5+umn6dOnD59++im33347gwYNyjNb1a5dO5KSknJtf++997j9dtdOv6ioKObPn8+IESNYsGABSUlJnDlzhtatW9OxY0dq1qyJ1pqhQ4e6VX8VYO3atTz66KMcOnSImTNn4uHhwYMPPsiDDz7ItGnTeOedd/jss88YMGBAsdZbdSfzthZ4RCmVa4l9+7aHuQ5nfJYkR1+6LTnZJfOWpcE/wFjmIz09HZvNVuDMW6bVhpeHO9+2gnn3wAl2plp4gqncEvraNSm7JYQQwpWj2zQxMZGUlBRmzZrl3Je92zQiIiLXuePHjyc6OtoZ/AQHB7N7927efvttTCYTnTt35vfff891Xps2bVi9ejWrV6+mdevW3HTTTaxdu5Z//vmHZs2a4eNz5WWp/vWvf+Ht7U3VqlWpVq0aJ0+eLNDzdu3alf379/P444+za9cumjdvTl7rsq5cudL57NlfOQM3MAK6FStW0Lx5c1asWEGtWrUwm83s3buXnTt3kpCQwNGjR/njjz9YuXJlgdrpcPPNN7N9+3bWr1/P22+/TXp6OhUqVODHH39kw4YNtGjRgh9++IHevXvz+OOP07t3b9asWePWPQrCnczbe8BSYLVS6i2MclkA0cCbGGutDS7KxpV2jsybAmfwps1GAdhKFS7NNIWCL9CbkWXDy1y0wdvf55P57PBJOuql3NegHX5+9Yv0+kIIcd26ygxZcfP09KRbt278+eef9O3bN89jQkND2bx5MzabDZPJxKhRoxg1apRLT463tzfdu3ene/fuVK9enYULF9K5c2eX67Rt25ZPPvkEq9XK448/TkBAAOnp6Sxfvpw2bdoUqL3Zl7pydB0WVOXKlZ3Zq7vuuos///yT++67z+UYdzJvQUFBzJ8/HzD+xs6bN4+KFSvyxRdfcMsttzi/Pt27d2fNmjW0a9euwG11CAkJoVy5cmzbto2YmBjn9rFjxzJq1ChiY2O59dZb6d27N/feey+//vqr2/e4HHcqLCwDnsJYU202sNv+mm3fNlRrvbRIW1fKOWubao1nLXtdU3u4XKmCkcB0d4Heos68JVusDNtxkGqc5t/+q6lTR+JvIYQoaVprVq1aRcOGDfM9plGjRsTExPDaa69htRoT4tLT0529Pps2bXLOdrTZbGzZsoW6dXOPfgoJCeHYsWP89ddfzm7V6OhoPv/8c9q2zb1cVEBAQJ6B1NX4448/SE1NBSApKYl9+/ZRp06dXMe5k3k7ffq0c5bu22+/zaOPPgpAnTp1WLFiBRaLhaysLFasWOFWt+mBAwecQemhQ4fYtWsX9erVc+7fs2cPCQkJdOjQgdTUVEwmE0op0tLSCnyPgnIrCtBaTwUaAs8Dn9tfzwINtdafF3nrSjnHbFPAWZQ+02Rsq1rZGDTqbmmsTIsN7yIM3madOMuRDAtP6I9pEfIWJtOVxygIIYQonNTUVIKDg52vDz74ADDGvEVHRxMeHo7VauWpp5667HW+/PJLzpw54wzkunTpwrvvvgtAYmIiPXr0IDw8nMjISDw8PBg6dGiuayiluPnmm6lSpYpznFrr1q3Zv39/npm3jh07smPHDpcJCwUVGRnpfOZnn32WjRs3EhMTQ2RkJK1bt2bw4MG0atXKrWvmtHz5cpo2bUqTJk04efIko0aNAqB37940bNiQiIgIoqKiiIqKokePHoAxa9exLMiCBQsIDg5mzZo1/Otf/6Jr164A/PXXX0RFRREdHU2vXr347LPPqFr10sS+UaNGMX78eAD69evHlClTaNWqFSNGjCjU8+RF5bXGyVVdSCkv4F6t9awrHlwCYmJidPb1Wq6FQ5/0Ze5fydxy4ARt1qzl1BfbOHnyLMtOWOg5oSl1KtRh7dq1/Pzzzzz//PMFyr7d//lqzCbFrCdaF7p9Wms6rt1MRupevq69myaNRxX6mkIIcb3buXOn2wPVhShO+fxM5jv4vNApHKVUc6XUJ8Bx4NvCXq8scXSbelSujDKbsaVZSNc2MjxSqOxbGTAyb0qpAs9KybTY8PIomtmmW5PT2JUGnUxraFC/6P9nIIQQQoii53ZtUwClVEWM4vSPAlEY0eFGYF6RtawMsMdueNrTqrZUCxlWKxmeqfh7Gt2kKSkp+Pn55TvVO6eMIuw2/ebwPjx1Bg/UboiHR8HG3AkhhBCiZLkVvCmlbgceA+7BKBKvganAO1rrQ0XfvNLNmXmrZGTZbGkW0m02LF4ZzqU43FmgF4puwkK61cbCU6ncpDYSWrd/oa8nhBBCiGvjilGAUqqOUupNpdQBjCLynTAmKtyHkXFbKoFb3hwTFpSHGZ1lBYuNDAvgY3Ue484CvWAsFeJdBEuFLDq2h2Ttzf2Bnnh6Fl+ReyGEEEIUrctm3pRSSzBqmlqB/wHDgZ+11halVP7zlwUAGnvwZjJdWqA3S2HyvTRJJCUl5bLlT3IqqszbzMMHqIqZexr3LPS1hBBCCHHtXKnbtDOwF+ijtf7nGrSnTHEs0msymbClGcGb1eKJp9+lCSRud5sWwZi3vReOsDGzGgMDduPrHVioawkhhBDi2rpSFDAHqAOsV0otUUo9pJQqvmJdZY1jGRZlwpZq1DW1aIV3OWMdnczMTLKystzrNrVYC515+88eo+Dwo41yL74ohBCi+JnNZud6bj169OD8+fMAHDx4EKUUr732mvPY06dP4+np6Vyjbffu3XTo0IHo6GhCQkJ44oknAGN9swoVKji3v/XWW4Vu5+bNm2ndujURERH06NGDixcvAvDtt98SHR3tfJlMJuLi4vK8xieffEKzZs0ICwvLVaz98OHDlCtXjvfeew+AU6dOceuttxIeHs7ChQudx91zzz3OBYfFFYI3rXUfIAh4DqgGfAOcUEpNB9yvJ3GDcayh59JtqjX+5YwyIu4u0AuOpUKuPnhLzzjND0mVaeF1ksYVc69iLYQQovj5+voSFxfHtm3bqFy5MpMnT3buq1+/Pj/++KPz/Zw5cwgLC3O+Hz58uLMG6s6dOxk2bJhzX7t27YiLi2PDhg3897//ZdOmTYVq5+DBg5kwYQJbt26lV69eTJw4EYD+/fs7qxzMnDmT+vXrEx0dnev8ZcuWsWjRIjZv3sz27dt5/vnnXfY/++yzdO/e3fk+NjaWIUOGsG7dOiZNmgTADz/8QPPmzfMsWH+jumIUoLU+q7X+SGsdBdyMsZZbL2A6xmzTnkqpqOJtZulky6PbNNMGAeWN5KW7dU0tVhs2Dd6FWOdt0d5FnCaQh2pL/VIhhLgetG7dmqNHjzrf+/n5ERIS4lzxf/bs2TzwwAPO/cePHyc4ONj5Pq8i9f7+/rRs2ZK9e/cWqm3x8fG0b98egC5dujBvXu4VwWJjY/OtvzplyhRefvllZ+3TatWqOfctXLiQ+vXruwSmnp6epKamkpGR4ayROmnSpFwZuxudW0uFaK3XY3ShjgTux1jnrT/QXyl1EJintZavsJ2zeIXJ7AzesjTUKERdU+CqM28WSxLfJ2ZQTmXQs1bkVV1DCCHKknfWvcOus7uK9JrNKjfjpZteKtCxVquV33//nccee8xle9++fZk1axbVq1fHbDYTFBTk7DYcOXIknTp1ok2bNtxxxx0MGjSIihUrupx/5swZ/v77b15//XWX7UlJSfkWYv/uu+8IDQ112RYWFsaiRYvo2bMnc+bM4ciRI7nOmz17NosWLcrzmvHx8axcuZJRo0bh4+PDe++9R6tWrUhOTuadd95hyZIlzi5TwFmgftq0abzzzjt89tlnDBgwoMAL2d8ormqRXq11OjATmKmUaoCx9ttAjO5VCd4ctA0wocwKW6oFrTQWoEolY2kOd7tNM7LswdtVLhWy9cB01unWPBDog28RLDcihBDi6qSlpREdHc3Ro0cJCQmhS5cuLvu7devG66+/TvXq1enTp4/LvkGDBtG1a1d++eUXFi1axNSpU9m8eTNgFHBv3rw5JpOJl19+2SWrBUZR+fzGpuVl+vTpDB8+nLFjx3L33Xfj5eXlsn/t2rX4+fkRHh6e5/kWi4WzZ8/y999/s379eh544AH279/P6NGjGTlyZK7kRYUKFZxdxufOnWPChAksWLCAxx9/nHPnzvHcc8/RunXhy0OWdlcVvGWntd4PjFJKvQ50K3yTyg7HmDeTyYwtLYsss/E+sKKxaK+73aaOzJu3p/uBV1raUaYlnCFLefFw3UZuny+EEGVRQTNkRc0x5i01NZWuXbsyefJkhg8f7tzv5eVFy5Ytef/999mxYweLFy92OT8oKIhHH32URx99lPDwcLZt2wYYY97+97//5XtfdzNvzZo147fffgOMLFr2sXgAs2bNol+/fvneLzg4mHvvvRelFDfddBMmk4nTp0+zdu1a5s6dy4svvsj58+cxmUz4+Pg4J2UAjB07llGjRhEbG8utt95K7969uffee/n111/zvd+NotDBm4M2ygn8VFTXKwuci/TaJyxkKhtWZaVaJaNcVkpKCj4+Pnh4FOzbkGm5+szbL7u+YBH3cG+gD1EBkn4WQojrgZ+fHx9//DE9e/bkqaeectn33HPPcdttt1G5cmWX7b/88gudO3fG09OTEydOcObMGWrVqsWuXVfu/nU385aYmEi1atWw2WyMGzeOIUOGOPfZbDa+//57Vq5cme/5PXv2ZNmyZXTs2JH4+HgyMzOpWrWqyzmjR4+mXLlyLoHbnj17SEhIoEOHDmzevBkfHx+UUqSlpRW47WWZ9J0VI5fZpmkWMjCK0meva+rOTNMMi1GZwd0xb6fObeDtc1FUMlsY31SybkIIcT1p3rw5kZGRxMbGumwPCwvjkUceyXX8b7/9Rnh4OFFRUXTt2pWJEydSo0aNYmlbbGwsTZo0oVmzZgQFBTFo0CDnvj///JPatWvToEEDl3MGDx7snGzx6KOPsn//fsLDw+nbty9ff/21szzk5YwaNYrx48cD0K9fP6ZMmUKrVq0YMWJEET5d6aW01lc+qgyIiYnRjh+ma2Xr6C78ttObe6Pb4leuGwdPnOb39DO8+r4xK+err75Ca82jjz5aoOttP3aBf338F58/1IJu4TULdI7WNp5bPYnvMjsxPTSIO6tXu/JJQghRhu3cuZOQkJCSboYQTvn8TOYb5UrmrRhdyrwpbKlZZNpsaG+Lc7+7dU0d3abuLBXy58H/MTujHd3Kp0jgJoQQQpQBErwVI2fwZjYbY96soHxdi9K7123q3lIh6VnJvHJIU86UyXvhrdxouRBCCCGuV0U2YUHkZnNMWFBmdIaVLIvC7GtkQa1WK2lpaW5XV4CCB28Ttv7Mft2YSfU1Vb29rnyCEEIIIa57VxW82eubViGP/lit9eHCNqqsuDTb1KhlarV44O1vdHlebWksoECF6TefOch/LtSlnfch+ta7x612CyGEEOL6VeDgTSllwliAdxhwuWktBR6QpZTqBnxkP+dLrfWEHPs/BDra3/oB1bTWFe37rMBW+77DWuu7C3rfa8XZbaqNrJdFK3zKGZ+7W10BCl5h4UymhUHbj+CLjQ/CW7rdbiGEEEJcv9zJvE0Ange2A/OAM4W5sVLKDEwGugAJGGW3FmutdziO0VqPzHb8MKB5tkukaa2jC9OG4ubMvOGFBjI1BJT3Ba4u8+ZcKuQy67xl2Gw8vHknpyzefFxtHbXL33aVrRdCCCHE9cidCQsPAb9orSO01sO11m/l9XLjejcBe7XW+7XWmcAs4HL9e/2A2Mvsv+44M2/2GDlLQ/nyRrDmbnUFyNZt6pl3clNrzbO7jrAx2cqTaip3Nu6T53FCCCFKVkJCAvfccw+NGzemYcOGjBgxgszMzEJdc+DAgdSvX5+oqCiaNGnCww8/TEJCQhG1uPhs3ryZ1q1bExERQY8ePbh48SIA3377LdHR0c6XyWTKc4Hh0aNHU6tWLedxP/3kWi/g8OHDlCtXzllD9dSpU9x6662Eh4ezcOFC53H33HOPs37s9c6d4K0SkHfl2atTC8he4TbBvi0XpVRdoD7wR7bNPkqpDUqpv5VSPYuwXUXGMWEBbYx5y9SaShXLA1fZbXqFCgvvHzzJvJPnuF/Hcn9wQ7y9A6+26UIIIYqJ1pp7772Xnj17smfPHuLj40lOTmbUqFFuXcdqtebaNnHiRDZv3szu3btp3rw5nTp1KnRQWNwGDx7MhAkT2Lp1K7169WLixIkA9O/fn7i4OOLi4pg5cyb169cnOjo6z2uMHDnSeeydd97psu/ZZ5+le/fuzvexsbEMGTKEdevWMWnSJAB++OEHmjdvTlBQULE8Y1FzJ3jbChRsZdii1xeYq7XO/pNaV2sdAzwITFJKNcx5klLqCXuAt+HUqVPXqq1O2ub47FLmrWqlSoARvHl4eOQq8ns5l1sqZN6Js7x38AR3+Oyll/qRunWfKFTbhRBCFI8//vgDHx8fZ7UCs9nMhx9+yPTp00lNTWXGjBkupaLuuusuli9fDhj/4X/uueeIiopizZo1+d5DKcXIkSOpUaMGP//8M2BUZmjdujUtWrTg/vvvd/YArV+/njZt2hAVFcVNN91EUlISBw8epF27drRo0YIWLVqwevVqAB5++GGXbFX//v1ZtKhweZ34+Hjat28PQJcuXZg3b16uY2JjY+nbt6/b1164cCH169cnLCzMuc3T05PU1FQyMjIwm81YLBYmTZrEiy++ePUPcY25M+btLeA/Sqn/aK2PXPHoKzsK1M72Pti+LS99gaezb9BaH7V/3K+UWo4xHm5fjmOmAdPAqLBQBG12i7Pb1HYpeKteuQpgdJv6+/sXqEyIQ0Y+s003XUhh5K4j3Bxgov/F16hdZyBeXlWL4hGEEKJMO/F//0fGzivXBHWHd0gzarz6ar77t2/fTsuWrpPJypcvT506ddi7d+9lr52SksLNN9/M+++/X6C2tGjRgl27dtG2bVvGjRvH0qVL8ff355133uGDDz7g5Zdfpk+fPsyePZtWrVpx8eJFfH19qVatGkuWLMHHx4c9e/bQr18/NmzYwGOPPcaHH35Iz549uXDhAqtXr+brr792uWdSUhLt2rXLsz3fffcdoaGhLtvCwsJYtGgRPXv2ZM6cORw5kjvEmD179mWDxE8//ZRvvvmGmJgY3n//fSpVqkRycjLvvPMOS5YscXaZAjz44IM8+OCDTJs2jXfeeYfPPvuMAQMG4OdXeup+uxO8tQQOATuUUguAA0DOnK3WWo8t4PXWA42VUvUxgra+GFk0F0qpZhhdtmuybasEpGqtM5RSVYG2wLtuPMs14ZiwgM2DTGXDoixUKBcAuF9dAfLuNtVa89reo1T18uBFr6/JMntSt87jRfMAQgghritms5n77ruvwMc7kgh///03O3bsoG3btgBkZmbSunVrdu/eTc2aNWnVyljIvXz5S0N7hg4dSlxcHGazmfj4eABuu+02nnrqKU6dOsW8efO477778PBwDSUCAgLyHJuWn+nTpzN8+HDGjh3L3XffnatHau3atfj5+REeHp7n+U8++SSvv/46Silef/11nnvuOaZPn87o0aMZOXJkrr+1FSpU4McffwTg3LlzTJgwgQULFvD4449z7tw5nnvuOVq3bl3g9pcEd4K30dk+fyifYzRQoOBNa21RSg0FfsVYKmS61nq7UmoMsEFrvdh+aF9glnYtwhoCTFVK2TC6fidkn6V6vXA0WGszmcpKpmcaJpMReKWkpDh/SQoqw2LD06wwmS5l65aeucimi6mMq+dF+oH51K3zBF5eVYrqEYQQoky7XIasuISGhjJ37lyXbRcvXuTw4cM0atSILVu2YLM5x92Qnp7u/NzHxwezueAlEv/55x86d+6M1pouXboQG+s672/r1q15nvfhhx9SvXp1Nm/ejM1mw8fHx7nv4Ycf5r///S+zZs3iq6++ynWuu5m3Zs2a8dtvvwFGF6ojsHKYNWsW/fr1y/cZq1ev7vz88ccf56677gKMoG/u3Lm8+OKLnD9/HpPJhI+Pj0uX9NixYxk1ahSxsbHceuut9O7dm3vvvZdff/013/tdD9wJ3uoX9c211j8BP+XY9kaO96PzOG81EFHU7Slqzsyb1UyGtmH1vjRoNDk5mZo13RtCmGmx5cq6TTxwgjo+XrRM/pwLZj/q1BlcJG0XQghRPDp37szLL7/MN998w8MPP4zVauW5555j4MCB+Pn5Ua9ePT777DNsNhtHjx5l3bp1bt9Da80nn3zC8ePH6datGxcuXODpp59m7969NGrUiJSUFI4ePUrTpk05fvw469evp1WrViQlJeHr68uFCxcIDg7GZDLx9ddfu0yOGDhwIDfddBM1atTIFYiB+5m3xMREqlWrhs1mY9y4cQwZMsS5z2az8f3337Ny5cp8zz9+/Ljz7+mCBQucGbrs54wePZpy5cq5BG579uwhISGBDh06sHnzZnx8fFBKkZaWVuC2l5QCT1jQWh8qyKs4G1vaOHOF9uANH+OH32azXV23qdXqskzIr6cvsiU5jadras6e+ong4Ifx8qpcVM0XQghRDJRSLFiwgDlz5tC4cWOaNGmCj48P//d//wdA27ZtqV+/PqGhoQwfPpwWLVoU+NovvPCCc6mQ9evXs2zZMry8vAgMDGTGjBn069ePyMhIWrduza5du/Dy8mL27NkMGzaMqKgounTpQnp6Ok899RRff/01UVFR7Nq1y2VZq+rVqxMSEuKccFFYsbGxNGnShGbNmhEUFORy3T///JPatWvToEEDl3MGDx7Mhg0bAHjxxReJiIggMjKSZcuW8eGHHxbovqNGjWL8+PEA9OvXjylTptCqVStGjBhRJM9VnJRrb2TZFRMTox3f6Gvlz6fasP50JfqGPs+BlCz+rnSG51/tR2pqKu+++y7dunXjlltuKfD1Xpy7mT/jT/P3q52xac3t63eTZrMx2fcjLp7/m7ZtluPpWakYn0gIIUq/nTt3EhISUtLNKLVSU1OJiIhg06ZNVKhQoaSbUybk8zOZ74zGfLtNlVJvYAzbGq+1ttnfX4k7ExbKPK218ZW3mLDYTHj4GYnOq1mgF4wxb45lQn48dYEdKelMqJPJuUNLadjgBQnchBBCFKulS5fy2GOPMXLkSAncStDlxryNxgje3gEycZ2wkJ8CT1i4Edi0RmmNtiisVjM+5Ywv99Us0Av2MW8eJqz2sW6N/LxpevpNbN5B1K5dNOlrIYQQIj+33347hw7JCKmSdrngrT6AvXSV871wgwYP5QUosrTCv5wxW+dq6pqCEbx5e5hYnHie+NR0JgSdIPXoNsJCP8Rs9i7q1gshhBDiOpRv8JZz8oFMRnCfTYO3yShEn6U1AeWNBQAL023q6WHivQMnaObnRYNT4/ANiKR69buKtuFCCCGEuG65Ux5LuElr8DIZ2bZMDRUrXlqgVymFr6+vW9fLtNg4X9GTfWkZPOwfR1bmcRo3HoVS8m0UQgghbhTurPMGgFIqBrgZo+pBzqhBJixkpzVeZiN4y7JBlYrG4M6UlBT8/f2dC/YWVIbVRmJFbxr4mKl3egJVA7tRsWJMkTdbCCGEENevAkcPSilfpdTPwFrgE4xap6PtrzezfS7sjG5TR+ZNE1jJWIPNUdfUXSk2K+d8FLeYt4LOpFHD0lNEVwghxCXjx48nLCyMyMhIoqOjWbt2LQAWi4VXX32Vxo0bEx0dTXR0tHMtMjDKY0VHRxMWFkZUVBTvv/++sxrD8uXLUUrx5ZdfOo+Pi4tDKeVS2/NqffTRR4SHhxMWFsakSZOc2/v06eNsa7169YiOjs7z/PPnz9O7d2+aNWtGSEgIa9ascdn//vvvo5Ti9OnTAMybN4+wsDDatWvHmTNnANi3bx99+vQp9LOUdu5k3t4A7gDGA78Dy4BHgETgFcAXeLioG1iaGd2mjjFvUKmiUQ4rNTX1qoK3s+XMaKVomjyT4NoD8POrW6TtFUIIUfzWrFnD//73PzZt2oS3tzenT58mM9OYG/jaa69x4sQJtm7dio+PD0lJSS5F6H19fZ3VCxITE3nwwQe5ePEib731FgDh4eF8//33DB5sVNuJjY0lKiqq0G3etm0bX3zxBevWrcPLy4tu3bpx11130ahRI2bPnu087rnnnst3CZERI0bQrVs35s6dS2ZmJqmpqc59R44c4bfffqNOnTrObZ988gnr169n/vz5fPfddwwbNozXXnuNcePGFfp5Sjt3+u16A3Ps5au22bcd1Vr/CtwOeAEDi7Z5pVv2MW9pWPDyMWJli8WCp6en29e7UN6T8jqZJuaT1K/3dJG2VQghxLVx/Phxqlatire3sUpA1apVCQoKIjU1lS+++IJPPvnEWUs0ICCA0aNH53mdatWqMW3aND799FNnAfq6deuSnp7OyZMn0Vrzyy+/0L1790K3eefOndx88834+fnh4eHBbbfdxvz5812O0Vrz/fff51mH9MKFC/z555889thjAHh5eVGxYkXn/pEjR/Luu++i1KV1aU0mExkZGaSmpuLp6cnKlSupUaMGjRs3LvTzlHbuZN5qAx/YP3cUOfMCZ5H5WOBJjCycwAjevM0+WLWNTK8M5w+l1Wp1e7xbutVGagUPOrKc4KDeeHpWLIYWCyHEjWXl9/GcPpJcpNesWrsc7R5oku/+O+64gzFjxtCkSRNuv/12+vTpw2233cbevXupU6cOAQEBBb5XgwYNsFqtJCYmOrf17t2bOXPm0Lx5c1q0aOEMEnP69ttvmThxYq7tjRo1Yu7cuS7bwsPDGTVqFGfOnMHX15effvqJmBjXMdcrV66kevXqeQZXBw4cIDAwkEGDBrF582ZatmzJRx99hL+/P4sWLaJWrVq5MoSvvPIKt99+O0FBQfz3v//l/vvvZ9asWQX+2pRl7kQQSVwK9pIAGxCUbf8FoEYRtatM0FrjafYlAys2nyzndpvNhtlsvsyZua08l4Q2m4hhLUFBfYu6qUIIIa6RcuXKsXHjRqZNm0ZgYCB9+vRhxowZuY776quviI6Opnbt2hw5cqTA13/ggQeYM2cOsbGxeWbBHPr3709cXFyuV87ADSAkJISXXnqJO+64g27duhEdHZ3r79jl7mexWNi0aRNPPvkk//zzD/7+/kyYMIHU1FT+7//+jzFjxuQ6p0uXLmzcuJEffviBRYsWceeddxIfH0/v3r15/PHHXbpdbzTuZN72AU0AtNZWpdR2jK7U6cpIKd0LFPyn6wagMbpNM7UNk6/Nuf1qMm8/nz6Pt06jllXh79/gyicIIYS4ostlyIqT2WymQ4cOdOjQgYiICL7++mseeOABDh8+TFJSEgEBAQwaNIhBgwYRHh6O1WrN8zr79+/HbDZTrVo1du7cCUCNGjXw9PRkyZIlfPTRR6xevTrPc93JvAE89thjzm7PV199leDgYOc+i8XC/Pnz2bhxY573Cg4OJjg4mJtvvhkwsoMTJkxg3759HDhwwJl1S0hIoEWLFqxbt44aNYx8UGpqKjNmzODXX3/lrrvuYv78+cydO5dvv/2Wxx9/PM/7lXXuBG9LgUeVUs9ora3AVOBTpdQ+jDilPvBqMbSxdNIarRVeZl8yNZj9Lu1yN/Nm1ZpfTp2hORu5qLsWQ2OFEEJcK7t378ZkMjm7F+Pi4qhbty5+fn489thjDB06lKlTp+Lj44PVanVOZsjp1KlTDBkyhKFDh7qMFQMYM2YMiYmJl/1b079/f/r371/gdicmJlKtWjUOHz7M/Pnz+fvvv537li5dSrNmzVwCuuxq1KhB7dq12b17N02bNuX3338nNDSUiIgIly7fevXqsWHDBqpWrercNnHiRIYPH46npydpaWkopTCZTJJ5K6AJwEzsVe611p8ppXyAhzDGwH0BvFvkLSyttHZm3pJsCm//S19qdzNvmy6mctZiIjRrK2nmEcXQWCGEENdKcnIyw4YN4/z583h4eNCoUSOmTZsGGEuIvP7664SHhxMQEICvry+PPPIIQUHGKKW0tDSio6PJysrCw8ODAQMG8Oyzz+a6R5s2bYq83ffddx9nzpzB09OTyZMnu0w4mDVrVq4u02PHjjF48GB++uknwJg92r9/fzIzM2nQoAFfffXVFe957Ngx1q1bx5tvvgnAsGHDaNWqFRUrVmThwoVF9myljXLMUCnrYmJi9IYNG67dDa0WFg+8laaBozhLAPGRqTwy8E4A3nnnHSIiIrjzzjsLdKk3d8fz5dGL9Dr4NWENnuHJDg2Ls+VCCFGm7dy5k5CQkJJuhhBO+fxMqryOhQJOWFBKlVNK7VNKPVOItt1YtA0NKKXQKMoFXCqF5U7mTWvNT4mnCWUbfx+JwdtDSmEJIYQQN7ICRQJa62SgClC086nLNGPMm0KhNVSocGlRXnfGvMUnp3DE4kdbnzOcTquKlwRvQgghxA3NnUjgb0AKaRaUS+btUnUFcC/zNv9IHACdqhrpVAnehBBCiBubO5HAy8ADSqlBKue0FpGbttkzbyY0l+qaaq3RWhc48/bL6WQaqYPUrGAMPpVuUyGEEOLGdtnZpkqpOsAprXUaRnWFc8CXwLv2JUJyztPVWuvOxdLS0saeeXOMN6xQoRyAc62egmTeDl44xG5rDf5d8QBZVuN4Cd6EEEKIG9uVlgo5gLEUSCzQAGM9t8P2fdWLsV2ln7ahUShlQgO+5bwAY7wbkCvzNnnZXlIyLLzYrZlz29wDa4Bm3Fc3hoxkI+iTblMhhBDixnalSEBxaV23elrr+ld6FX+TSwlnt6nChsbT2wjW8su8/bbjJMt3n3LZtjpJU12dJ6JSMJkWI+jzcrOslhBCiOvTwoULUUqxa9eufI/p0KED13SZqzwcOnSIzp07ExkZSYcOHUhISABg2bJlREdHO18+Pj75rr32/fffExoaSlhYGA8++KBzu9lsdp5/9913O7f379+fyMhIXn310tr/48aNu6HXdsvOnUV6hTvsi/SiFNpkca5+nV/m7XRShktWTWsrBy3laeKTilKKTKtxnrenZN6EEKIsiI2N5dZbbyU2Npa33nqrpJuTr+eff56HH36YRx55hD/++INXXnmFmTNn0rFjR+Li4gA4e/YsjRo14o477sh1/p49e3j77bdZtWoVlSpVcqmo4Ovr67yGw5YtW/D19WXLli106dKFCxcukJqaytq1a3nttdeK81FLDYkEiotjtikKbXKtawqumTetNaeSMkjNtDi3nU8+wAldgyb+PgBkZDkyb/ItE0KI0i45OZm//vqL//znP8yaNcu5PS0tjb59+xISEkKvXr1IS0tz7nvyySeJiYkhLCzMWXEAjJJSr7zyCtHR0cTExLBp0ya6du1Kw4YN+fzzzwvd1h07dtCpUycAOnbsyKJFi3IdM3fuXLp3746fn1+ufV988QVPP/00lSpVAqBatWqXvZ+jDJbNZiMrKwuz2cwbb7xxXQe411pBMm/tlFIFztBprb8p6LFKqW7AR4AZ+FJrPSHH/g+Bjva3fkA1rXVF+75HAEcIPk5r/XVB73tNOMa8odDmSwWF88q8XUjLItNqIzXz0nHbz+7BpmoSWt74IXdk3mTMmxBCFJ1lM6aReGh/kV6zWt0GdBz4xGWPWbRoEd26daNJkyZUqVKFjRs30rJlS6ZMmYKfnx87d+5ky5YttGjRwnnO+PHjqVy5Mlarlc6dO7NlyxYiIyMBqFOnDnFxcYwcOZKBAweyatUq0tPTCQ8PZ8iQIbnu365dO5KSknJtf++997j99ttdtkVFRTF//nxGjBjBggULSEpK4syZM1SpUsV5zKxZs/Is0wUQHx8PQNu2bbFarYwePZpu3boBkJ6eTkxMDB4eHrz88sv07NmTkJAQAgMDadGiBQMGDGDv3r3YbDaXr8WNriBB2RP215UojAkNBQrelFJmYDLQBUgA1iulFmutdziO0VqPzHb8MKC5/fPKwJsY685pYKP93HMFufc14RjzphTafPnM26mkDADSsgVvOy6cAGoSUbkOgHPMm8w2FUKI0i82NpYRI4xa1X379iU2NpaWLVvy559/Mnz4cAAiIyOdwRkY48amTZuGxWLh+PHj7Nixw7nfMV4sIiKC5ORkAgICCAgIwNvbm/Pnz7vUIQVYuXJlgdv63nvvMXToUGbMmEH79u2pVauWSwLi+PHjbN26la5du+Z5vsViYc+ePSxfvpyEhATat2/P1q1bqVixIocOHaJWrVrs37+fTp06ERERQcOGDZk0aZLz/B49ejB16lTGjx/P5s2b6dKlC48//niB218WFSR4m4axQG9RuwnYq7XeD6CUmgXcA+zI5/h+GAEbQFdgidb6rP3cJUA3jFmx1wdtBFsKhVaX6sfmlXlzBG8WmybLasPTbGJ3ShoKG439jSVGnBMWJHgTQogic6UMWXE4e/Ysf/zxB1u3bkUphdVqRSnFxIkT8z3nwIEDvPfee6xfv55KlSoxcOBA0tPTnfu9vb0BIzHg+Nzx3mKx5LqeO5m3oKAg5s+fDxjdvfPmzXMJBr///nt69eqFp6dnnm0PDg7m5ptvxtPTk/r169OkSRP27NlDq1atqFWrFgANGjSgQ4cO/PPPPzRseKl+96JFi2jZsiXJycns27eP77//nq5du9K/f/88u2hvFAUJ3lZqrb8rhnvXAo5ke58A3JzXgUqpukB94I/LnFurGNp49ZwVFkwuwVuembfkDOfnqZlWyvso9md4UNOcgq99jFuGRZYKEUKIsmDu3LkMGDCAqVOnOrfddtttrFy5kvbt2/Pdd9/RqVMntm3bxpYtWwC4ePEi/v7+VKhQgZMnT/Lzzz/ToUOHq26DO5m306dPU7lyZUwmE2+//TaPPvqoy/7Y2FjefvvtfM/v2bMnsbGxDBo0iNOnTxMfH0+DBg04d+4cfn5+eHt7c/r0aVatWsWLL77oPC8rK4tJkybx448/smfPHufEP6vVSmZm5g0dvJWWSKAvMFdrbb3ikdkopZ5QSm1QSm04derUlU8oStqGTdu/vNnqUVwu8wZG12l6+jGO2KrT0OdS0Jfh6DaVpUKEEKJUi42NpVevXi7b7rvvPmJjY3nyySdJTk4mJCSEN954g5YtWwLGuLPmzZvTrFkzHnzwQdq2bXvN2rt8+XKaNm1KkyZNOHnyJKNGjXLuO3jwIEeOHOG2225zOeeNN95g8eLFAHTt2pUqVaoQGhpKx44dmThxIlWqVGHnzp3ExMQQFRVFx44defnllwkNDXVeY/LkyTzyyCP4+fkRGRlJamoqERERtGzZMlc38I2mJJcKOQrUzvY+2L4tL32Bp3Oc2yHHuctznqS1nobR7UtMTIzOub9YaRvKHhvrbMHb5ca8AaRmWrBlbOM4QXQvdykFLUuFCCFE2bBs2bJc2xzj3ACX2afZzZgxI8/tBw8edH4+cOBABg4cmOe+q9W7d2969+6d57569epx9GjuP91jxoxxfq6U4oMPPuCDDz5wOaZNmzZs3bo13/s+88wzLteIjb1+RkaVtJKMBNYDjZVS9ZVSXhgB2uKcBymlmgGVgDXZNv8K3KGUqqSUqgTcYd92/bDPNgXcyrylZlrZde4AVuVJWMUazu2yVIgQQggh4AqZN611sUUKWmuLUmooRtBlBqZrrbcrpcYAG7TWjkCuLzBLa62znXtWKTUWIwAEGOOYvHDd0BqUI/NW8DFv6VlWdl40HqVZufLO7ZlWGx4mhcmULRIUQgghxA2nRCssaK1/An7Kse2NHO9H53PudGB6sTWusLQNnGPeLgVc+WXeqvh7cSYlk9RMK3tTjZlBjf0uzRjKtNhkmRAhhBBClJoJC6VPtm7T7PnLvDJviUkZ1KlizJpJTT/FIWtFanpk4O9xKcDLsFhlpqkQQgghJHgrNtrm7Da93Ji3LKuNsymZ1K1sBG+Z6Ts5SjCNfF2TopkWmwRvQgghhJDgrdhoGxRgtumZ5EwA6tiDN0v6bo5Ri5DylV0uZ3SbyjIhQgghxI1Ogrfiki14y/5Vzpl5c8w0rVPFH4Cz1pNkKW+aBVyarADGhAXJvAkhRNlgNpuJjo4mPDycHj16cP78+SK57owZMxg6dGiRXCu7rKwsXn75ZRo3bkyLFi1o3bo1P//8MwB33nnnZds/evRo3nvvPcBY/23p0qVF3r7L2bx5M61btyYiIoIePXpw8eJF574tW7bQunVrwsLCiIiIcKla4RAXF8ctt9xCdHQ0MTExrFu3DjCqP0RGRjq3//XXXwDs3r2bli1bEhkZyZo1xkIZFouF22+/ndTU1CJ5JokGiovWzokKl8u8nUo2flDq2se8nbIZwVxTPx+Xy2Vk2WSZECGEKCN8fX2Ji4tj27ZtVK5cmcmTJ5d0ky7r9ddf5/jx42zbto1NmzaxcOFCZ3mtn376qcCL5o4ZMyZX+a3iNnjwYCZMmMDWrVvp1auXswyZxWLhoYce4vPPP2f79u0sX748zxJfL774Im+++SZxcXGMGTPGWQWic+fObN68mbi4OKZPn87gwYMBmDp1Kh999BE//fSTM2idMmUKDz30UJFVhZBooLhoG86VVkz5zzZ1ZN6CKvpS3juNk8rIwDX2dw3eJPMmhBBlU+vWrZ0L3a5bt47WrVvTvHlz2rRpw+7duwEjo3bvvffSrVs3Gjdu7FJG6quvvqJJkybcdNNNrFq1yrn94MGDdOrUicjISDp37szhw4cBYyHfJ598kltuuYUGDRqwfPlyHn30UUJCQlwW+HVITU3liy++4JNPPnHWTa1evToPPPAAYCzUe/r0aQC++eYbIiMjiYqKYsCAAbmuNXDgQObOnQvA+vXradOmDVFRUdx0000kJSWRnp7OoEGDiIiIoHnz5nkuaOyu+Ph42rdvD0CXLl2YN28eAL/99puzrQBVqlRxWQnCQSnlzNZduHCBoKAgAMqVK+cs2ZWSkuL83NPTk9TUVFJTU/H09OT8+fP88MMPPPzww4V+FocSXSqkTNM2HDMVVLbgLVfmzR68VS3nRcOKxzlKMNU9bZTPMb4tQ5YKEUKIInf+h31kHksp0mt6BflTsUfDKx+I8Tfh999/57HHHgOgWbNmrFy5Eg8PD5YuXcqrr77qDDbi4uL4559/8Pb2pmnTpgwbNgwPDw/efPNNNm7cSIUKFejYsSPNmzcHYNiwYTzyyCM88sgjTJ8+neHDh7Nw4UIAzp07x5o1a1i8eDF33303q1at4ssvv6RVq1bExcURHR3tbOPevXupU6cO5cu7DufJafv27YwbN47Vq1dTtWpVzp7Nf/nVzMxM+vTpw+zZs2nVqhUXL17E19eXjz76CKUUW7duZdeuXdxxxx3Ex8fj43MpoZGUlES7du3yvO53333nUmILICwsjEWLFtGzZ0/mzJnDkSNGafT4+HiUUnTt2pVTp07Rt29fl6DYYdKkSXTt2pXnn38em83G6tWrnfsWLFjAK6+8QmJiIj/++CMATz/9NA8//DAZGRlMnTqVsWPH8uqrr7qsMlFYEg0Ul+yL9F5hzFsFX0+8PczUr3CUo9Smib9vrstlyGxTIYQoM9LS0oiOjqZGjRqcPHmSLl26AEZm5/777yc8PJyRI0eyfft25zmdO3emQoUK+Pj4EBoayqFDh1i7di0dOnQgMDAQLy8v+vTp4zx+zZo1PPjggwAMGDDAOSYLoEePHiiliIiIoHr16kRERGAymQgLC7vqklp//PEH999/P1WrVgWgcuXK+R67e/duatasSatWrQAoX748Hh4e/PXXXzz00EOAEcjWrVuX+Ph4l3MDAgKIi4vL85UzcAOYPn06n332GS1btiQpKQkvLy/A6Db966+/+Pbbb/nrr79YsGABv//+e67zp0yZwocffsiRI0f48MMPnYE2QK9evdi1axcLFy7k9ddfB6BOnTosX76cNWvW4OfnR0JCAiEhIQwYMIA+ffrkep6rIZm34pJ9woK6TOYtOYPAACMNXTvgCPPoSedyAbkuJ4v0CiFE0StohqyoOca8paam0rVrVyZPnszw4cN5/fXX6dixIwsWLODgwYN06NDBeY6jyxKMBIDFYrnq+zuuZTKZXK5rMplyXbdRo0YcPnyYixcvXjH7di24m3lr1qwZv/32G2Bk2xwZsuDgYNq3b+8MNu+88042bdpE586dXc7/+uuv+eijjwC4//77nWPbsmvfvj379+/n9OnTzusBjBo1inHjxvHxxx8zePBg6tWrx6uvvsq33357lU9vkGiguBRwtmnixQwCyxm/OD7lkslQPjTJMd4NINNilaVChBCijPHz8+Pjjz/m/fffx2KxcOHCBWrVqgXkX4g+u5tvvpkVK1Zw5swZsrKymDNnjnNfmzZtnEXuv/3223wDnoK08bHHHmPEiBFkZhrLW506dcrlXgCdOnVizpw5nDlzBuCy3aZNmzbl+PHjrF9vVLlMSkrCYrHQrl07Z2ATHx/P4cOHadq0qcu57mbeEhMTAePv77hx4xgyZAgAXbt2ZevWraSmpmKxWFixYkWe5wcFBbFixQrAyC42btwYMLqTHZU7N23aREZGBlWqVHGet2LFCoKCgmjcuDGpqamYTCZMJlORzDiVzFtxyb5I72UqLJxKziAquCJWaxop9lRuE7/cwZt0mwohRNnUvHlzIiMjiY2N5cUXX+SRRx5h3Lhx/Otf/7riuTVr1mT06NG0bt2aihUruoxV++STTxg0aBATJ04kMDCQr7766qrbOG7cOF577TVCQ0Px8fHB39+fMWPGuBwTFhbGqFGjuO222zCbzTRv3jzfANTLy4vZs2czbNgw0tLS8PX1ZenSpTz11FM8+eSTRERE4OHhwYwZM1wyg1cjNjbWOZv33nvvZdCgQQBUqlSJZ599llatWqGU4s4773R+zQcPHsyQIUOIiYnhiy++YMSIEVgsFnx8fJg2bRoA8+bN45tvvsHT0xNfX19mz57tnLSgtWbcuHHMnj0bgCeeeIL+/ftjsViYMmVKoZ4HQGWr916mxcTE6A0bNly7Gx5cxTejPqNT7SHE1U7irqfvBIyofeXKlbz55psAhL7xC/1uqsPwdpm8tXEG36mB7Lg1nMqernH1TeOX0rFpNd7pHXntnkEIIcqgnTt3EhISUtLNEMIpn59JldexIN2mxSdbt6nKsc6bI+uWkmEhNdNKYIA3SUnbOUptPLMsuQI3MJYK8faUb5cQQghxo5NooLhoG8rebapyrPOWc423wHLeJCVvJ4G6eKTlnQnNtMgivUIIIYSQ4K34aBvakfHMMeYt+3g3gGrlvUlJOchRgjGl5D17SMa8CSGEEAIkeCs+Lpm3S1/mPDNvAd6czLSQrnzgYmauS1ltGqtNS/AmhBBCCAneio3WaOc6b5c2u2TesnWbHsg0ZphmXcwk5ySSTIuxvIgsFSKEEEIICd6Ki7ahnN2m+Y95M5sUFX3NHLJWBEAlW8iwB2sOGRZjeRHJvAkhhBBCooHikq22ab5j3pIyqFrOC6v1PEcJxp9MyLSRlml1uZQj8ybBmxBClA0nTpygb9++NGzYkJYtW3LnnXcSHx/PsWPH6N2792XP7dChA46lr+68807Onz9/DVp8yezZs4mMjCQsLIyXXnrJZd/3339PaGgoYWFhztJcBT3/gw8+IDQ0lMjISDp37syhQ4cAo5RWy5YtiYyMZM2aNYBR2ur2228vkgVvSyOJBopLtkV685ttmpiUTmCAN5mZZzlJDaqpLBSQmuUavGU4u03l2yWEEKWd1ppevXrRoUMH9u3bx8aNG3n77bc5efIkQUFBzJ07t8DX+umnn6hYsWLxNTaHM2fO8MILL/D777+zfft2Tpw44awHumfPHt5++21WrVrF9u3bmTRpklvnN2/enA0bNrBlyxZ69+7tLBI/depUPvroI3766Sfee+89wKg3+tBDD+Hn53dtHvw6I9FAccnWbZo9eMs52zSwnDeZWWdIIoDy9u1pma4zTiV4E0KIsmPZsmV4eno6yzQBREVF0a5dOw4ePEh4eDhg/L14/vnnCQ8PJzIykk8++STXterVq8fp06cB+Oabb4iMjCQqKooBAwYAcPDgQTp16uTMZh0+fLhQbd+/fz+NGzcmMDAQgNtvv5158+YB8MUXX/D0009TqVIlAKpVq+bW+R07dnQGY7fccgsJCQkAeHp6kpqaSmpqKp6enpw/f54ffviBhx9+uFDPUppJeaziom3O1Xkvt85baM3yZGUmkER56po9AUjNr9tU1nkTQogi9fPPP3PixIkivWaNGjXo3r17vvu3bdtGy5Ytr3idadOmcfDgQeLi4vDw8LhsrdDt27czbtw4Vq9eTdWqVZ3HDhs2jEceeYRHHnmE6dOnM3z4cBYuXOhy7rJlyxg5cmSua/r5+bF69WqXbY0aNWL37t0cPHiQ4OBgFi5c6Kx3Gh8fD0Dbtm2xWq2MHj2abt26Ffj87P7zn/84v4ZPP/00Dz/8MBkZGUydOpWxY8fy6quvOhMhNyIJ3orLFTJvNpvmdHIm1QJ8yMw6QzJNqeRpzDjNNebNKmPehBDiRrN06VKGDBmCh4fxp7py5cr5HvvHH39w//33U7VqVZdj16xZw/z58wEYMGCAsysyu44dOxIXF1egNlWqVIkpU6bQp08fTCYTbdq0Yd++fYAxDm3Pnj0sX76chIQE2rdvz9atW126dS93vsN///tfNmzY4CwGX6dOHZYvXw4YxeATEhIICQlhwIABZGZmMnbsWJo0aVKg9pcVErwVl+zlsfLIvJ1LzcRq00ZprPTzZClvKnkb6eKcY95kqRAhhCgel8uQFZewsDC3xrUVN3cybwA9evSgR48egJEddPQmBQcHc/PNN+Pp6Un9+vVp0qQJe/bsoVWrVgU6H4yAdfz48axYsSLPgvSjRo1i3LhxfPzxxwwePJh69erx6quv8u233179F6AUklROMdE2KyqPblNH5s1RXSEwwJvTmcnG515eQO7MmywVIoQQZUenTp3IyMhg2rRpzm1btmxh5cqVLsd16dKFqVOnYrEY46Av123aqVMn5syZw5kzZ1yObdOmDbNmzQLg22+/pV27drnOdWTecr7yCtwAEhMTATh37hyfffYZgwcPBqBnz57ODNnp06eJj4+nQYMGBT7/n3/+4d///jeLFy/Oc7zcihUrCAoKonHjxqSmpmIymTCZTDfkjFPJvBUjR4UFzLkzb9mrKxw5l2587n2FMW8SvAkhRKmnlGLBggU888wzvPPOO/j4+FCvXr1cszMHDx5MfHw8kZGReHp68vjjjzN06NA8rxkWFsaoUaO47bbbMJvNNG/enBkzZvDJJ58waNAgJk6cSGBgIF999VWh2z9ixAg2b94MwBtvvOHssuzatSu//fYboaGhmM1mJk6cSJUqVQCIjo52ds3md/4LL7xAcnIy999/P2B0ly5evBgwZuiOGzeO2bNnA/DEE0/Qv39/LBYLU6ZMKfQzlTYSvBUTbbM6x7yZ1KWgy5l5y1ZdYfNJe41TH0fmzXW2aabMNhVCiDIlKCiI77//Ps9927ZtA8DDw4MPPviADz74wGW/I7sFxmxSB8fEhOzq1q3LH3/8UTSNtouNjc1zu1Iqz/YCLmPq8jt/6dKl+d5TKcWSJUuc70NCQti0aVMBW1z2lGg0oJTqppTarZTaq5R6OZ9jHlBK7VBKbVdKfZdtu1UpFWd/Lb52rS6Y7MGbukLm7VyWEZxV9zUyb2n5rPMmmTchhBBClFjmTSllBiYDXYAEYL1SarHWeke2YxoDrwBttdbnlFLZO8HTtNbR17LN7tC2SxUWsgdvjsxbYlIGfl5m/L09OG81apnW9DUyb7JUiBBCCCHyU5LRwE3AXq31fq11JjALuCfHMY8Dk7XW5wC01onXuI1XzZiwYHx5s3ebZs+8BQZ4Y7NZOG81YugqXh54e5hyT1iwLxXi7SnBmxBCCHGjK8looBZwJNv7BPu27JoATZRSq5RSfyulsq/256OU2mDf3rOY2+o2o9vUoDzymG2alEG1AG+yLOdJJgB/kxUvkwk/L3O+mTdvsywVIoQQQtzorvcJCx5AY6ADEAz8qZSK0FqfB+pqrY8qpRoAfyiltmqtXVb6U0o9ATwBxqyVa0nbbM7Mm2PJEMiWeUvOoEn1cmRlniGZclQ0G12nfl4euYI3WSpECCGEEA4lGQ0cBWpnex9s35ZdArBYa52ltT4AxGMEc2itj9o/7geWA81z3kBrPU1rHaO1jnHUUbtWXGabeuQ92zSwnDeZmUZd00r2Y3w8TaTns0ivBG9CCCGEKMloYD3QWClVXynlBfQFcs4aXYiRdUMpVRWjG3W/UqqSUso72/a2wA6uI9p2qTxW9vprNpsNlIkLaVkEBnjbS2MFUMnLmGlqZN5yLxXiYVKYsy32K4QQovQym81ER0c7XwcPHqRNmzYAHDt2jN69exfbvTdv3kzr1q2JiIigR48eXLx4EYAlS5bQsmVLIiIiaNmyZb5LjMyZM4ewsDBMJhMbNmxwbj948CC+vr7OZxoyZAgAGRkZdOvWjfDwcD777DPn8U888cQNvdxHYZRYt6nW2qKUGgr8CpiB6Vrr7UqpMcAGrfVi+747lFI7ACvwgtb6jFKqDTBVKeWoQTUh+yzV60H2blOT2TXzlmGfXRoY4E1W5lmSqEEVT6MMiG8eY94yLDbJugkhRBni6+ubq56oo6JBUFBQsZbPGjx4MO+99x633XYb06dPZ+LEiYwdO5aqVavyww8/EBQUxLZt2+jatStHj+bsEIPw8HDmz5/Pv//971z7GjZsmOu5fv31V2699VZeffVV2rZty1NPPcXmzZuxWq20aNGiuB6zTCvRiEBr/ZPWuonWuqHWerx92xv2wA1teFZrHaq1jtBaz7JvX21/H2X/+J+SfI68GJk3Q/bgzWazkW65FLwZmbdyVPH2BcDPy5xrnbdMCd6EEKLMK1euHGBksMLDwwFIT09n0KBBRERE0Lx5c5YtW1bo+8THx9O+fXvAKME1b948AJo3b05QUBBgVGxIS0sjIyMj1/khISE0bdq0wPfz9PQkNTWVrKwstDb+/r3++uuMHTu2sI9yw7reJyyUWsaYN3vmzd5tqrXGZrORlqUBRWA5H9KSzpGm/Kns6eg2NZNwLnfwJtUVhBCi6MXHjyUpeWeRXjOgXAhNmrx+2WPS0tKIjo4GoH79+ixYsCDP4yZPnoxSiq1bt7Jr1y7uuOMO4uPj8fHxcR6TlJSUZ81SgO+++47Q0FCXbWFhYSxatIiePXsyZ84cjhw5kuu8efPm0aJFizyLw1/OgQMHaN68OeXLl2fcuHG0a9eOLl26MHPmTG655RZeeOEFFi9eTIsWLZyBonCfBG/FROvsi/QagZfNZkw8SM2yAWYCA7zZfSYFgEqexjIgPp7mPAvTS+ZNCCHKjry6TfPy119/MWzYMACaNWtG3bp1nfVOHQICAgp0LYfp06czfPhwxo4dy913342Xl5fL/u3bt/PSSy/x22+/FfiaADVr1uTw4cNUqVKFjRs30rNnT7Zv30758uX57jujQFJWVhZdu3Zl0aJFPPvssxw+fJiHH36Yu+++26173egkeCsm2mp1LhHi6Da1Wo2gLCXLhlJmqpTz4rQ9JV3Z0/hW5NltarVJdQUhhCgGV8qQlQbuZt6aNWvmDMzi4+P58ccfnfsSEhLo1asX33zzDQ0bNnSrHd7e3s5MXcuWLWnYsCHx8fHExMQ4j/nss894+OGH+fvvv6lQoQKzZ8+mU6dOEry5SYK3YqK1LddSIY7MW0qmjcp+XniaTZzLygKgkjN4y3u2qbeHLNArhBA3mnbt2vHtt9/SqVMn4uPjOXz4cK7xZu5m3hITE6lWrRo2m41x48Y5Z4WeP3+ef/3rX0yYMIG2bdu63dZTp05RuXJlzGYz+/fvZ8+ePTRo0MC5/9y5c/zvf//j119/5YcffsBkMqGUIi0tze173egknVNMjAkLxpfXbHLNvCVlWAkMMP53cs6+hltle7epr6eZ9CwbNpt2XktmmwohxI3F0XPz1FNPYbPZiIiIoE+fPsyYMcPtcWg5xcbG0qRJE5o1a0ZQUBCDBg0C4NNPP2Xv3r2MGTPGudxHYqJRlXLw4MHOZUEWLFhAcHAwa9as4V//+hddu3YF4M8//yQyMpLo6Gh69+7N559/TuXKlZ33HTNmDKNGjcJkMtG1a1dWrlxJREQEAwYMKNTz3Igk81ZMjNqmxudme1krR+YtOdNGlQpe2GxZXLCaQGXPvBnHpmVZ8fc2tknwJoQQZUtycnK+286cOeMMenx8fPjqq6+K9N4jRoxgxIgRuba/9tprvPbaa3me8+WXXzo/79WrF7169cp1zH333cd9992X730//PBD5+c+Pj5uj6kTl0hEUEyMblP7bFN7l6cj85ZlMzJsWVnnSKI8cGnCgm+24M1BZpsKIcSNYcOGDfTr1y/P4EoIB8m8FRNtM5YDATDnmG1q1eCtFJlZZ0kmAC+l8bN3rfrag7jsM04leBNCiBtDTEwM8fHxJd0McZ2TiKC42GzOMQvmHLNNrVrhYVbOovSVPC6Nb/DzMuLp7FUWZKkQIYQQQjhIRFBMbC6F6V3HvFm1wmwyZStKf2kmqWPMW/YZp7JUiBBCCCEcJCIoJlprFCa01phNrmPeLBrMCjKzzpBEeSrbi9JDtjFvubpNZakQIYQQQkjwVmyMwvSgyWvMm5F5y8o0xrxV9rpU5sQ55i0re7epzDYVQgghhEEiguJiX+dNo51Lhbhk3kxG5i1ZlXdWV4Ds3aaumTcJ3oQQouwwm81ER0cTFhZGVFQU77//vvM/+NfSsWPH6N2791WfP2nSJFJTU4uwRbm9+OKLhIWFERISwvDhw53F7WfPnk1kZCRhYWG89NJLeZ67ZMkSWrZsSUREBC1btuSPP/4AjKoUjrXsoqOjqVq1Ks888wwAn3zyCeHh4dx5551kZmYCRpmykSNHFutzukMigmLiqLCgAZNyzbxZbEbmLSPjLCn4uwRv+XWbSvAmhBBlh6O26fbt21myZAk///wzb731VqGva7FYrnxQNkFBQcydO/eq71fcwdvq1atZtWoVW7ZsYdu2baxfv54VK1Zw5swZXnjhBX7//Xe2b9/OiRMn+P3333OdX7VqVX744Qe2bt3K119/7VwQ2FGVwvGqW7cu9957LwDffvstW7ZsoU2bNvz6669orRk7diyvv379lFKTiKCY6GyzTT1yZN6s9szb+awUbJica7xB9tmmxi+g1aax2LQsFSKEEGVUtWrVmDZtGp9++ilaa6xWKy+88AKtWrUiMjKSqVOnOo995513iIiIICoqipdffhmADh068MwzzxATE8NHH33Exo0bue2222jZsiVdu3bl+PHjAOzdu5fbb7+dqKgoWrRowb59+zh48CDh4eEA+d53+fLldOjQgd69e9OsWTP69++P1pqPP/6YY8eO0bFjRzp27AjAb7/9RuvWrWnRogX3339/nosRu0MpRXp6OpmZmWRkZJCVlUX16tXZv38/jRs3JjAwEIDbb7+defPm5Tq/efPmBAUFARAWFkZaWhoZ9priDvHx8SQmJjrrw2qtycrKIjU1FU9PT/773//SvXt3l2oRJU3WeSsmjkV6s09YcGTesmzgYTJxOsNIx1bKq9vUPuYt014+SzJvQghR9F7fk8C25KKtrRlezpexjYPdOqdBgwZYrVYSExNZtGgRFSpUYP369WRkZNC2bVvuuOMOdu3axaJFi1i7di1+fn6cPXvWeX5mZiYbNmwgKyuL2267jUWLFhEYGMjs2bMZNWoU06dPp3///rz88sv06tWL9PR0bDabs/wVwH/+85887wvwzz//sH37doKCgmjbti2rVq1i+PDhfPDBByxbtoyqVaty+vRpxo0bx9KlS/H39+edd97hgw8+4I033nB51okTJ/Ltt9/m+hq0b9+ejz/+2GVb69at6dixIzVr1kRrzdChQwkJCeHcuXPs3r2bgwcPEhwczMKFC51dnPmZN28eLVq0yFVebNasWfTp08eZcBk6dCi33HILYWFhtG3blnvuuYdff/21AN/Fa0eCt2LiqE1qTFjImXlTmJTinD29nX2pEG8PE0pBemaO4E2WChFCiBvCb7/9xpYtW5zdmRcuXGDPnj0sXbqUQYMG4efnB+CSCerTpw8Au3fvZtu2bXTp0gUw/u7UrFmTpKQkjh496ixr5ePjQ0753dfLy4ubbrqJ4GAjII2OjubgwYPceuutLuf//fff7Nixw1nUPjMzk9atW+e6zwsvvMALL7xQoK/F3r172blzJwkJCQB06dKFlStX0q5dO6ZMmUKfPn0wmUy0adOGffv25Xud7du389JLL+VZkmvWrFnMnDnT+X7AgAHO7tUxY8YwfPhwfv75Z7755htq167N+++/j8lUsn+TJXgrLjYbSpmM4M3kOuYtywaeZouzrmmVbJk3pRS+nmbnhIUMe8Dn7SlLhQghRFFzN0NWXPbv34/ZbKZatWporfnkk0+cBd8dLpf98ff3B4wuv7CwMNasWeOyPykp6YptyO++y5cvd8lWmc3mPMfWaa3p0qULsbGxl72PO5m3BQsWcMstt1CuXDkAunfvzpo1a2jXrh09evSgR48eAEybNs2ZKMkpISGBXr168c0339CwYUOXfZs3b8ZisdCyZctc5x07dox169bxxhtvcNttt/HHH38wbtw4fv/9d2dwXFIknVNMLk1Y0JhyVFiwaPBSSSQTALh2m4LRderoNs3IMgI+b8m8CSFEmXTq1CmGDBnC0KFDUUrRtWtXpkyZQlZWFmCMyUpJSaFLly589dVXzgkC2btNHZo2bcqpU6ecwVtWVhbbt28nICDA2b0IkJGRkWuiQX73vZyAgABnYHjLLbewatUq9u7dC0BKSkqepb5eeOEFl8kCjlfOwA2gTp06rFixAovFQlZWFitWrCAkJATA2eV77tw5PvvsMwYPHpzr/PPnz/Ovf/2LCRMmODOC2cXGxtKvX788n+31119nzJgxAKSlpaGUwmQyFfvs2oKQiKCYaJsRvKHB3o3uMtvUx3QhV1F6B18vs3O2aaZVxrwJIURZk5aW5lwq5Pbbb+eOO+7gzTffBGDw4MGEhobSokULwsPD+fe//43FYqFbt27cfffdxMTEEB0dzXvvvZfrul5eXsydO5eXXnqJqKgooqOjWb16NQAzZ87k448/JjIykjZt2nDixAmXc/O77+U88cQTdOvWjY4dOxIYGMiMGTPo168fkZGRtG7dml27dhXq69S7d28aNmzonKQRFRXlzLaNGDGC0NBQ2rZty8svv0yTJk0AWLx4sXOc3aeffsrevXsZM2aMc1mQ7OP8vv/++zyDt3/++QeAFi1aAPDggw8SERHBqlWr6NatW6GeqSgox3opZV1MTIzesGHDNbvfoS/+zaG4CGr6hdF4ojELZ+PGjfzwww98nx7FM50z2Gjezg/qXhI6RGNyRHhA1w//pF5VP6YOiGHn8Yt0/2glU/q3oHtEzWvWfiGEKKt27tzpzN4IcT3I52dS5XUsSOat2GibvTxWtm2OzJsNhbfpAkmUo6KHySVwA/DxMpNm7y7NkNmmQgghhMhGIoJiorURdOls4ZtjzJsNhae6YJTG8sw9Z8TP00yafZ03WSpECCGEENlJRFBMdLbZpg7ZM2+e6gLJqjyVPD1znevndWm2qSwVIoQQQojsJCIoJlprY7apzp150yg8uEAyFanslTvz5jphQZYKEUKIonajjPcW17+r+VmU4K2YGGPeXMeyZc+8eXCeZBVAJY88uk2zZd4cS4VI5k0IIYqGj48PZ86ckQBOlDitNWfOnMlz0eTLkUV6i4nWRm3T7P80ZM+8mbhAkvbPc8ybr6eZtCxZKkQIIYpDcHAwCQkJnDp1qqSbIgQ+Pj7O6hUFVaLBm1KqG/ARYAa+1FpPyOOYB4DRGJWmNmutH7RvfwR4zX7YOK3119ek0QWUfZFeB5vNhsm+ArSFVLLwyLXGG4Cvl4ez29Qx21QK0wshRNHw9PSkfv36Jd0MIa5aiQVvSikzMBnoAiQA65VSi7XWO7Id0xh4BWirtT6nlKpm314ZeBOIwQjqNtrPPXetnyM/2moDcmfeHPXQUrUNFHnPNvUyk2m1YbHaJHgTQgghhIuSjAhuAvZqrfdrrTOBWcA9OY55HJjsCMq01o5lkbsCS7TWZ+37lgAlv+RxNtqmUcoEOTNvJhMeKosUjIxbXpk3Py9jW2qWVZYKEUIIIYSLkowIagFHsr1PsG/LrgnQRCm1Sin1t72btaDnlihHeazcmTczAV7J+dY1BWO2KUBapgRvQgghhHB1vU9Y8AAaAx2AYOBPpVREQU9WSj0BPGF/m66U2p7HYRWAC0W4rSpw2vj0e+PD+7mPi4MKsPBCm8tcr8Y7l7b5v1Osbc5rG7g8yzW9dzF+T4rkesXRxpJ6lpL8OlxPz1LUz3G9tfF6+p4UxzXLys9XfttL47MU5jlKso3X08/XRq11S/KitS6RF9Aa+DXb+1eAV3Ic8zkwKNv734FWQD9garbtU4F+V7jftIJuL+S2DdfgHsW+rSw9S1E/R1l6lhL+Olw3z1LUz3EdtvG6+Z6UpWe5hl+bUvcshXmO67Dd1833xPEqyb649UBjpVR9pZQX0BdYnOOYhRhZN5RSVTG6UfcDvwJ3KKUqKaUqAXfYt13OD25sL8y2a3GPa7EtP9dTG0vqe1LY86+nZynJr0NRX+96+p6UZHuu9+9JcVyzrPx8XW57SbSnpL4n16o9pfHnCwBlj+5KhFLqTmASxlIh07XW45VSYzAi2sVKKQW8jzEZwQqM11rPsp/7KPCq/VLjtdZfXfMHyINSaoPWOqak21EUysqzlJXnAHmW61FZeQ6QZ7lelZVnKSvPASX/LCU65k1r/RPwU45tb2T7XAPP2l85z50OTC/uNl6FaSXdgCJUVp6lrDwHyLNcj8rKc4A8y/WqrDxLWXkOKOFnKdHMmxBCCCGEcI+sPyGEEEIIUYpI8FZElFLdlFK7lVJ7lVIvl3R73KGUmq6USlRKbcu2rbJSaolSao/9Y6WSbGNBKaVqK6WWKaV2KKW2K6VG2LeXqudRSvkopdYppTbbn+Mt+/b6Sqm19p+z2fbJPqWCUsqslPpHKfU/+/tS+SxKqYNKqa1KqTil1Ab7tlL18+WglKqolJqrlNqllNqplGpd2p5FKdXU/r1wvC4qpZ4pbc/hoJQaaf+d36aUirX/W1Baf1dG2J9ju1LqGfu2UvF9cefvojJ8bP/+bFFKtSju9knwVgTUpVJf3YFQoJ9SKrRkW+WWGeSuUPEy8LvWujHGEi2lJSC1AM9prUOBW4Cn7d+L0vY8GUAnrXUUEA10U0rdArwDfKi1bgScAx4ruSa6bQSwM9v70vwsHbXW0dkGLJe2ny+Hj4BftNbNgCiM70+pehat9W779yIaaAmkAgsoZc8BoJSqBQwHYrTW4RiT+fpSCn9XlFLhGFWSbsL42bpLKdWI0vN9mUHB/y52x1iTtjHG2rJTir11+a0hIq+CvyjAmnXX+wuoB2zL9n43UNP+eU1gd0m38SqfaxFG/dxS+zyAH7AJuBljUUgP+3aXn7vr+YWxyPbvQCfgf4Aqxc9yEKiaY1up+/nCWBT0APaxz6X5WbK1/Q5gVWl9Di5VD6qMMaHwfxjlIEvd7wpwP/CfbO9fB14sTd+Xgv5dJMdas9mPK66XZN6KxnVfrusqVNdaH7d/fgKoXpKNuRpKqXpAc2AtpfB57N2McUAiRv3efcB5rbXFfkhp+jmbhPEPt83+vgql91k08JtSaqMyqrhAKfz5AuoDp4Cv7N3ZXyql/Cmdz+LQF4i1f17qnkNrfRR4DzgMHMdYcX8jpfN3ZRvQTilVRSnlB9wJ1KYUfl+yya/t1zwGkOBNXJE2/itRqqYlK6XKAfOAZ7TWF7PvKy3Po7W2aqMrKBij66FZybbo6iil7gIStdYbS7otReRWrXULjK6Sp5VS7bPvLC0/XxiZnRbAFK11cyCFHF1YpehZsI8DuxuYk3NfaXkO+xiqezAC6yDAn9xdd6WC1nonRnfvb8AvQBzGeq3ZjykV35e8lHTbJXgrGkcx/kfhEGzfVpqdVErVBLB/TCzh9hSYUsoTI3D7Vms937651D6P1vo8sAyju6SiUsqxPmNp+TlrC9ytlDoIzMLoOv2I0vksjuwIWutEjLFVN1E6f74SgASt9Vr7+7kYwVxpfBYwgulNWuuT9vel8TluBw5orU9prbOA+Ri/P6X1d+U/WuuWWuv2GGP14imd3xeH/Np+zWMACd6KRkFKfZU2i4FH7J8/gjF27LqnlFLAf4CdWusPsu0qVc+jlApUSlW0f+6LMW5vJ0YQ19t+2HX/HABa61e01sFa63oYvxt/aK37UwqfRSnlr5QKcHyOMcZqG6Xs5wtAa30COKKUamrf1BnYQSl8Frt+XOoyhdL5HIeBW5RSfvZ/yxzfk1L3uwKglKpm/1gHuBf4jtL5fXHIr+2LgYfts05vAS5k614tHiU9ILCsvDD68+MxxiWNKun2uNn2WIzxFVkY/xt/DGNM0u/AHmApULmk21nAZ7kVI5W9BSNNH2f/3pSq5wEigX/sz7ENeMO+vQGwDtiL0T3kXdJtdfO5OgD/K63PYm/zZvtru+N3vbT9fGV7nmhgg/3nbCFQqTQ+C0b34hmgQrZtpe457O1+C9hl/72fCXiXxt8V+7OsxAg+NwOdS9P3xZ2/ixgTsCbb//5vxZgtXKztkwoLQgghhBCliHSbCiGEEEKUIhK8CSGEEEKUIhK8CSGEEEKUIhK8CSGEEEKUIhK8CSGEEEKUIhK8CSHEdUwpdVAptbyk2yGEuH5I8CaEKFWUUouUUr9le/+TUmr+5c7Jcf5ApZS+zGtv8bRcCCGKhseVDxFCiOtKG+ATAKWUyf5+3FVc52OM6ig5JV1904QQovhJ8CaEKDWUUk2AqsAq+6YIoAKw+iout1JrPbeo2iaEENeKdJsKIa5rSqlySqmqSqmqGIW7bcA++/sugAU4ZD+mQhHfu4O9K3WgUmqYUipeKZVu/zgsn3PaK6WWKKUuKKXSlFKblFKP5XNsI6XUV0qpBKVUplLqmL1buGUexzZTSv2olEqyX3uuUqpGjmMqK6U+VErts7fzjFJqo1LqhaL5igghrgeSeRNCXO8+5VIxaIcDOd4n2D+uwKifWhAB9gAwpzStdUqObcOAGsBUjG7VfsDHSqnKWuu3HAcppXoAC4ATwPv2Y/sCXyqlGmitR2U7NgajTqIn8B+MWpaVgdswuoI3Zrt/LWC5/dovAFHAv4HywB3ZjpsDtAc+x6hX6guEYHxNJhbgayKEKAWktqkQ4rqmlAoFguxv5wD/A762v1+IUUB6tv39Oa31Ri5DKTUQ+Ooyh0zWWg+1H9sBWAYkAyFa6wT7di/gL6A5UF9rnaCUMgP7MbpxQ7XWx7Iduwy4BWimtd6jlFIYBawbATdprbfkaKNJa22zf34QqAv00Vp/n+2YycBT9mvutmcdzwNTtNZPXe5rIIQo3aTbVAhxXdNa79BaLwWOABWBr+3vEwF/4Cut9VL767KBWw5jMLpdc74+yePYbx2Bm71NmcCHGL0XPeybWwJ1gOmOwC3bse9i/Ht7j31zNBBmb7tL4GY/x5Zj07HsgZvdH/aPje0f04AM4GalVL08n1gIUSZIt6kQ4rqllCoH+Njf9sQITnbauzt7AClcGv+WrrVOduPyW+1BYEHszGPbDvvHBvaP9e0ft+dx7PYcxzoCrn8KeP/9eWw7Y/9YBYwgUSn1DPARcEAptQMjwFuotf69gPcRQpQCErwJIa5neY13S8jx/oT949fAwOJuUAmxXmafcnyitf5cKbUI+BfG2LnewFCl1Gytdd9ibqMQ4hqR4E0IcT17F/iv/fNFGAHafMCMMfbtM+AH+/5juc4uOiF5bAu1f9yf42NYAY6Nt3+MLnTLctBaHwe+xJgkYQZmAv2UUu9rrfNa104IUcrImDchxHUr23i3Y4AfxtizpcBZjP98fpNtvNuOy12rkPorpYIdb+yTEEZiZMT+Z9+8CTgMDMq+hIdSyhNjhqjGCEABNmN0pT6qlMoV7NknNLhFKeWnlPLLvk1rbcWYdQrGTFYhRBkgmTchRGlwG8aAfEfmqD1wEYgrxDXbKaV88tn3rXadih8PrFVKfY6x/MeDQCtgrNb6CBiBklJqKMZyHuuVUtPsx/bBmGn6f1rrPfZjtVJqEMZSIeuUUo6lQiran/UX8p44cTlNgBVKqQX2a53DyBg+ibG0yko3ryeEuE5J8CaEKA1uA9baZ26CEbyttmeWrtbwy+ybhbH4r8MnGGuqDcOYUXoYeEZr/VH2k7TWPyilOgOvYWTbvDAmOwzWWv8nx7HrlVKtgNeBB4AhwGlgHZcqSLjjCDAd6IgxucMbOAp8AbyjtU69imsKIa5Dss6bEELkI9s6b4O01jNKtDFCCGEnY96EEEIIIUoRCd6EEEIIIUoRCd6EEEIIIUoRGfMmhBBCCFGKSOZNCCGEEKIUkeBNCCGEEKIUkeBNCCGEEKIUkeBNCCGEEKIUkeBNCCGEEKIUkeBNCCGEEKIU+X+KvNU6DYDHmQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "bbox = dict(boxstyle =\"round\", fc =\"1\")\n",
        "arrowprops = dict(\n",
        "    arrowstyle = \"->\")\n",
        "offset = 72\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "\n",
        "for k1 in resultados_df.index:\n",
        "    ax.plot(range(len(resultados_df.loc[k1,'val_acc_list'])),\n",
        "        resultados_df.loc[k1,'val_acc_list'],\n",
        "        label='{name} = {acc}%'.format(name= resultados_df.loc[k1,'name'],\n",
        "                                       acc = round(resultados_df.loc[k1,'val_acc_list'][-1] * 100 , 2)))\n",
        "\n",
        "plt.title('Epochs vs Accuracy Train Set', fontsize = 18)\n",
        "\n",
        "#ax.set_xlim([0, 50])\n",
        "ax.set_ylim([0.6, 0.98])\n",
        "#plt.yscale('log')\n",
        "\n",
        "ax.set_xlabel('# Epochs', fontsize = 18)\n",
        "ax.set_ylabel('Train Accuracy', fontsize = 18)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.xaxis.set_major_locator(MultipleLocator(10))\n",
        "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "ax.legend()\n",
        "\n",
        "# ax.annotate('data = (%.1f, %.1f)'%(14, 0.95),\n",
        "#             (14, 0.95), xytext =(1 + 14,0.95),\n",
        "#             textcoords ='offset points',\n",
        "#             bbox = bbox, arrowprops = arrowprops)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY3jQ5IWgUu1"
      },
      "source": [
        "### Curvas de aprendizaje: pérdida en la función de costo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "244PkTh8t2hF",
        "outputId": "8b0284ed-8ea4-4e38-aee1-280a3765f6ab"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "bbox = dict(boxstyle =\"round\", fc =\"1\")\n",
        "arrowprops = dict(\n",
        "    arrowstyle = \"->\")\n",
        "offset = 72\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "\n",
        "for k1 in resultados_df.index:\n",
        "    ax.plot(range(len(resultados_df.loc[k1,'cost'])),\n",
        "        resultados_df.loc[k1,'cost'],\n",
        "        label='{name} = {acc}%'.format(name= resultados_df.loc[k1,'name'],\n",
        "                                       acc = resultados_df.loc[k1,'val_acc']))\n",
        "\n",
        "plt.title('Epochs vs Costo', fontsize = 18)\n",
        "\n",
        "\n",
        "ax.set_xlabel('# Epochs', fontsize = 18)\n",
        "ax.set_ylabel('Costo', fontsize = 18)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.xaxis.set_major_locator(MultipleLocator(10))\n",
        "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "ax.legend()\n",
        "\n",
        "# ax.annotate('data = (%.1f, %.1f)'%(14, 0.95),\n",
        "#             (14, 0.95), xytext =(1 + 14,0.95),\n",
        "#             textcoords ='offset points',\n",
        "#             bbox = bbox, arrowprops = arrowprops)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "L5Euazzd2NZp"
      },
      "outputs": [],
      "source": [
        "resultados_df.to_csv('Experimento1.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "ccfea65839ea7b4cb7611917847ae955f8a5d3f7496a05c88f3bf628abe673bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
