{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisPerez/NN_Tests_DG/blob/main/Experimento3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimento 3: Mejores métodos"
      ],
      "metadata": {
        "id": "AMNDFArszCDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Propósito:** Estudiar el desempeño y la velocidad de convergencia basado en epochs de los métodos cíclicos y el método decreciente (propio) combinados con la estrategia de Momentum\n",
        "\n",
        "\n",
        "> **Nota:** Si se utilizará Google Colab como ambiente para las pruebas, se debe tomar la referencia al repositorio para que la libreta tenga acceso a los archivos que requiere\n"
      ],
      "metadata": {
        "id": "XvG-xxkHzQ6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBCruOrtR_cV",
        "outputId": "d337604b-7d47-4e54-a6a6-74b645def5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NN_Tests_DG'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 99 (delta 44), reused 51 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (99/99), 15.23 MiB | 2.96 MiB/s, done.\n",
            "/content/NN_Tests_DG\n",
            "classes.py          get_images.py             LearningRateStudy.ipynb\n",
            "\u001b[0m\u001b[01;34mDataset\u001b[0m/            Iteracion1.ipynb          NN_from_Scratch.ipynb\n",
            "Decay.ipynb         Iteracion1_new.ipynb      NN_Pytorch.ipynb\n",
            "Experimento2.ipynb  Iteracion_2.ipynb         ResNet56_cifar10.ipynb\n",
            "Experimento3.ipynb  Iteracion3_Mejores.ipynb  SGD_Momentum_RMSProp_Adam.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DenisPerez/NN_Tests_DG.git\n",
        "%cd NN_Tests_DG\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al tener disponible los archivos a referenciar, se realizan las importaciones necesarias"
      ],
      "metadata": {
        "id": "DYSo5DylzTqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F4gP7LPQTtg7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from get_images import get_images\n",
        "from classes import CyclicLRGiselt_Denis\n",
        "\n",
        "# PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d3HzpTMzYgv"
      },
      "source": [
        "### Extracción del conjunto de datos: MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este conjundo de datos esta basado en 60.000 imá-\n",
        "genes en el conjunto de entrenamiento y 10.000 en el conjunto de prueba de 28x28 píxeles\n",
        "que representan dígitos del 0 al 9 escritos a mano y es considerado el \"Hola Mundo\" en el\n",
        "área de la ciencia de datos. Sin embargo, **10.000  de las muestras del conjunto de entrenamiento serán destinadas al conjunto de validación** con el que se te tomará la precisión en el entrenamiento."
      ],
      "metadata": {
        "id": "ATW7oodmzbf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9vdIQd58TthD"
      },
      "outputs": [],
      "source": [
        "MNIST_PATH = './Dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "slQPSqQeTthE"
      },
      "outputs": [],
      "source": [
        "x_train_num, y_train_num, x_test_num, y_test_num = get_images(MNIST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HFnaRwd-TthE"
      },
      "outputs": [],
      "source": [
        "# Segmento para el conjunto de entrenamiento\n",
        "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)/255 ##Convert the traint set into a (50000, 28x28) matrix normalized\n",
        "y_train = y_train_num[:50000].reshape(50000,1)\n",
        "\n",
        "# Segmento para el conjunto de validacion\n",
        "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)/255\n",
        "y_val = y_train_num[50000:].reshape(10000,1)\n",
        "\n",
        "# Segmento para el conjunto de prueba\n",
        "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)/255\n",
        "y_test = y_test_num.copy().reshape(10000,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZz8hG0OTthF"
      },
      "source": [
        "### Normalización de la muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_kFtDZs6TthG"
      },
      "outputs": [],
      "source": [
        "def normalize(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se toma la desviación estandar y la media de cada conjunto de datos y se llama a la función *normalize*"
      ],
      "metadata": {
        "id": "teFKYYq_z7Gi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KYhJenIZTthG"
      },
      "outputs": [],
      "source": [
        "# Calculo para el conjunto de entrenamiento\n",
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "x_train = normalize(x_mean, x_std, x_train)\n",
        "\n",
        "# Calculo para el conjunto de validación\n",
        "x_mean = x_val.mean()\n",
        "x_std = x_val.std()\n",
        "x_val = normalize(x_mean, x_std, x_val)\n",
        "\n",
        "# Calculo para el conjunto de prueba\n",
        "x_mean = x_test.mean()\n",
        "x_std = x_test.std()\n",
        "x_test = normalize(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMAv3EVXTthJ"
      },
      "source": [
        "### Visualización de la muestra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHHAe687TthJ",
        "outputId": "1cc0f772-dfee-47ab-fe6f-85d4160227a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Dimensiones del conjunto de datos de entrenamiento\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_FPmhofTthK",
        "outputId": "086c4509-4d45-4a96-c2fb-332d377d830f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Dimensiones del conjunto de datos de prueba:\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w4HfkSTqTthK"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "7TQtWTpZTthL",
        "outputId": "9d9db040-77ab-4b81-a6c6-097b2c1aa70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La imagen muestreada representa un: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
        "plot_number(x_test_num[rnd_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVo-PF6cTthM"
      },
      "source": [
        "### Creación de mini lotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ym639R_PTthM"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(x, y, mb_size, shuffle = True):\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle: \n",
        "        idxs = np.arange(total_data, dtype=float)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]  \n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversión de arreglo a tensores para todos los conjuntos de datos"
      ],
      "metadata": {
        "id": "ZaxOWK9T0Ku6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6quE_eQ9TthO"
      },
      "outputs": [],
      "source": [
        "# Conversion para el conjunto de entrenamiento\n",
        "x_train_tensor = torch.Tensor(x_train.copy())\n",
        "y_train_tensor = torch.Tensor(y_train.copy())\n",
        "\n",
        "# Conversion para el conjunto de validación\n",
        "x_val_tensor = torch.Tensor(x_val.copy())\n",
        "y_val_tensor = torch.Tensor(y_val.copy())\n",
        "\n",
        "# Conversion para el conjunto de prueba\n",
        "x_test_tensor = torch.Tensor(x_test.copy())\n",
        "y_test_tensor = torch.Tensor(y_test.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqPgXB1DTthP"
      },
      "source": [
        "### Habilitar el uso del CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se consulta si se tiene la plataforma CUDA disponible para la utilización de los recursos de GPU"
      ],
      "metadata": {
        "id": "8Qdu1Yvi0SVp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1oc0PTWTthQ",
        "outputId": "90b49475-2144-4388-fe36-fe5020befd5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En caso de no tenerse, se asigna el trabajo de computo al CPU"
      ],
      "metadata": {
        "id": "iuhjj7k40U2x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZebY-iBHTthQ",
        "outputId": "9e4a4819-a96b-4998-8ba9-a26c5af7b1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estamos usando: cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Estamos usando: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones "
      ],
      "metadata": {
        "id": "_XG0HhszpA-_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L66abJ9WTthR"
      },
      "source": [
        "### Función para calcular la precisión\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zt6iiZyuTthR"
      },
      "outputs": [],
      "source": [
        "def accuracy(model: nn.Sequential, x: torch.tensor, y: torch.tensor, mb_size: int):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) # mb_size, 10\n",
        "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
        "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
        "            num_total += pred.size(0)\n",
        "\n",
        "            return float(num_correct)/num_total  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4DuKf3TthR"
      },
      "source": [
        "### Función para realizar la propagación hacia atrás y la actualización de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HtRDD6Nu0507"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler: None, mb_size):\n",
        "    model = model.to(device=device)\n",
        "    epoch_acc = 0.0\n",
        "    i = 0\n",
        "    iter_found = 0\n",
        "    #plot lists\n",
        "    acc_list = [0.0]\n",
        "    cost_list = [0.0]\n",
        "    lr_list = [0.0]\n",
        "    while (i < 100):\n",
        "        if (epoch_acc >= 0.95 and unregistered):\n",
        "          iter_found = i\n",
        "          unregistered = False\n",
        "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "            # cost function\n",
        "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
        "            optimizer.zero_grad()\n",
        "            cost.backward()\n",
        "            for name, param in model.named_parameters():\n",
        "              ik = str(name)+'_'+str(i)\n",
        "              prev_ik = str(name)+'_'+str(i-1)\n",
        "            optimizer.step()\n",
        "        if (scheduler != None):\n",
        "          scheduler.step()\n",
        "          lr = scheduler.get_last_lr()\n",
        "          lr_list.append(lr[0])\n",
        "        else: \n",
        "          lr_list.append(optimizer.param_groups[0]['lr'])\n",
        "        i+=1\n",
        "        epoch_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
        "        epoch_cost = cost.item()\n",
        "\n",
        "        #append\n",
        "        acc_list.append(epoch_acc)\n",
        "        cost_list.append(epoch_cost)\n",
        "        # print(f'Epoch: {len(acc_list)}, learning_rate:{lr},costo: {epoch_cost}, accuracy: {epoch_acc}')\n",
        "    return acc_list, cost_list, lr_list, iter_found "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6xxVksqR95C"
      },
      "source": [
        "### Operaciones en las trazas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5aJV7jOTR95D"
      },
      "outputs": [],
      "source": [
        "def SumList(first: list, second: list) -> list:\n",
        "    return [x + y for x, y in zip(first[::-1], second[::-1])][::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I51hZdnHR95D"
      },
      "outputs": [],
      "source": [
        "def DivideList(dic_list: list, number: int) -> list:\n",
        "    return [x / number for x in dic_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y6ro6TQRR95E"
      },
      "outputs": [],
      "source": [
        "def DeleteZerosFromList(dic_list: list) -> list:\n",
        "    return list(filter(lambda num: num != 0, dic_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentos"
      ],
      "metadata": {
        "id": "fa7V0442o5yX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ2qa3c-eS1L"
      },
      "source": [
        "### Variables globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WBDuey1VQTm4"
      },
      "outputs": [],
      "source": [
        "MAX_ITERATIONS = 10\n",
        "layer1 = 1000 \n",
        "layer2 = 1000\n",
        "lr = 1e-2\n",
        "epochs = 100\n",
        "mb_size = 4096\n",
        "input_layer = 784\n",
        "first_i = 0\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "resultados = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhXFwQqymLvv"
      },
      "source": [
        "## Acelerador: Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\alpha: 1x10^{-2}$ \n",
        "\n",
        "$beta1: 0.9$\n",
        "\n",
        "$beta2: 0.999$"
      ],
      "metadata": {
        "id": "tSkGjEHQ0rG0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z9MBaYV0R95Q"
      },
      "outputs": [],
      "source": [
        "def Adam():\n",
        "    modelAdam = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimiserAdam = torch.optim.Adam(modelAdam.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "    start.record()\n",
        "    adam_acc_list, adam_cost_list,adam_lr_list, adam_epochs = train(modelAdam,optimiserAdam,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    adam_time = start.elapsed_time(end)\n",
        "\n",
        "    adam_acc = accuracy(modelAdam, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return adam_acc_list, adam_cost_list, adam_lr_list, adam_time, adam_acc, adam_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kZeKlCWWmNpH",
        "outputId": "3ddc8d90-cc92-445a-fcd7-f8ad2fe74173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c1e8c83f794a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_ITERATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0madam_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_cost_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_lr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresultados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSumList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_acc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresultados\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madam_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-fc8657158d3a>\u001b[0m in \u001b[0;36mAdam\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                         nn.Linear(in_features=layer2, out_features=10))\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimiserAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelAdam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0madam_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_cost_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madam_lr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelAdam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimiserAdam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/streams.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    177\u001b[0m         stream's device must match the event's device.\"\"\"\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_stream\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \"\"\"\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m     return Stream(_cdata=torch._C._cuda_getCurrentStream(\n\u001b[1;32m    593\u001b[0m         _get_device_index(device, optional=True)))\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "\n",
        "resultados['adam'] = {}\n",
        "resultados['adam']['val_acc_list'] = [0] * epochs\n",
        "resultados['adam']['test_acc'] = 0\n",
        "resultados['adam']['cost'] = [0] * epochs\n",
        "resultados['adam']['time'] = 0\n",
        "resultados['adam']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    adam_acc_list, adam_cost_list, adam_lr_list, adam_time, adam_acc, adam_epochs = Adam()\n",
        "    resultados['adam']['val_acc_list'] = SumList(resultados['adam']['val_acc_list'], adam_acc_list)\n",
        "    resultados['adam']['test_acc'] += adam_acc\n",
        "    resultados['adam']['cost'] = SumList(resultados['adam']['cost'], adam_cost_list)\n",
        "    resultados['adam']['time'] += adam_time\n",
        "    resultados['adam']['epochs'] += adam_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['adam']['name'] = 'Adam'\n",
        "resultados['adam']['lr'] = adam_lr_list\n",
        "resultados['adam']['test_acc'] = resultados['adam']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['adam']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['adam']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['adam']['cost'] = DeleteZerosFromList(DivideList(resultados['adam']['cost'], MAX_ITERATIONS))\n",
        "resultados['adam']['time'] = resultados['adam']['time']/ MAX_ITERATIONS\n",
        "resultados['adam']['epochs'] = resultados['adam']['epochs'] / MAX_ITERATIONS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy_ipT4cV40p"
      },
      "source": [
        "## Tasa de aprendizaje cíclica con Momentum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oscila entre una $base\\_ta$ y un $max\\_ta$ cada $n$ epochs en una proporción igual a \n",
        "\n",
        "$$\n",
        "proporción\\_de\\_cambio = \\frac{max\\_ta - base\\_ta}{n}\n",
        "$$\n",
        "\n",
        "Esta implementación facilitada por PyTorch, está basada en la publicación de Tasas de aprendizaje cíclico para la red neuronal de entrenamiento (*Cyclical Learning Rates for Training Neural Networks* o por sus siglas CLR) de Leslie Smith, 2017.\n",
        "\n",
        "$\\alpha: 1x10^{-2}$\n",
        "\n",
        "$beta: 0.9$"
      ],
      "metadata": {
        "id": "EztIjlX41MhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_1Gg-3eWMZr"
      },
      "outputs": [],
      "source": [
        "def CyclicMomentum():\n",
        "    modelCyclicMomentum = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelCyclicMomentum.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3,cycle_momentum=False )\n",
        "\n",
        "    start.record()\n",
        "    cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_epochs = train(modelCyclicMomentum, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    cyclicMomentum_time = start.elapsed_time(end)\n",
        "\n",
        "    cyclicMomentum_acc = accuracy(modelCyclicMomentum, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_time, cyclicMomentum_acc, cyclicMomentum_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPA1FfOOWOtV"
      },
      "outputs": [],
      "source": [
        "resultados['cyclicMomentum'] = {}\n",
        "resultados['cyclicMomentum']['val_acc_list'] = [0]* epochs\n",
        "resultados['cyclicMomentum']['test_acc'] = 0\n",
        "resultados['cyclicMomentum']['cost'] = [0] * epochs\n",
        "resultados['cyclicMomentum']['time'] = 0\n",
        "resultados['cyclicMomentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_time, cyclicMomentum_acc, cyclicMomentum_epochs = CyclicMomentum()\n",
        "    resultados['cyclicMomentum']['val_acc_list'] = SumList(resultados['cyclicMomentum']['val_acc_list'], cyclicMomentum_acc_list)\n",
        "    resultados['cyclicMomentum']['test_acc'] += cyclicMomentum_acc\n",
        "    resultados['cyclicMomentum']['cost'] = SumList(resultados['cyclicMomentum']['cost'], cyclicMomentum_cost_list)\n",
        "    resultados['cyclicMomentum']['time'] += cyclicMomentum_time\n",
        "    resultados['cyclicMomentum']['epochs'] += cyclicMomentum_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['cyclicMomentum']['name'] = 'Ciclico Con Momentum'\n",
        "resultados['cyclicMomentum']['lr'] = cyclicMomentum_lr_list\n",
        "resultados['cyclicMomentum']['test_acc'] = resultados['cyclicMomentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['cyclicMomentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['cyclicMomentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['cyclicMomentum']['cost'] = DeleteZerosFromList(DivideList(resultados['cyclicMomentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['cyclicMomentum']['time'] = resultados['cyclicMomentum']['time']/ MAX_ITERATIONS\n",
        "resultados['cyclicMomentum']['epochs'] = resultados['cyclicMomentum']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28gylOT-cNL5"
      },
      "source": [
        "## Tasa de aprendizaje cíclico aleatorio con Momentum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Oscila entre una $base\\_ta$ y un $max\\_ta$ cada $n$ epochs en una proporción aleatoria.\n",
        "\n",
        "$base\\_ta: 1x10^{-2}$\n",
        "\n",
        "$max\\_ta: 1x10^{-1}$\n",
        "\n",
        "$n: 3$ epochs"
      ],
      "metadata": {
        "id": "sGXAiCnX1XfI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_7uf-LUcQuE"
      },
      "outputs": [],
      "source": [
        "def CyclicGD_Momentum():\n",
        "    \n",
        "    modelRandomCyclic_Momentum= nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelRandomCyclic_Momentum.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=2, scale_fn=clr_fn,scale_mode='chipichipi', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_epochs= train(modelRandomCyclic_Momentum, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    random_cyclic_Momentum_time = start.elapsed_time(end)\n",
        "\n",
        "    random_cyclic_Momentum_acc = accuracy(modelRandomCyclic_Momentum, x_test_tensor,  y_test_tensor, mb_size) \n",
        "\n",
        "    return random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_Momentum_time, random_cyclic_Momentum_acc, random_cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zikwca8lcrI-"
      },
      "outputs": [],
      "source": [
        "resultados['random_cyclic_Momentum'] = {}\n",
        "resultados['random_cyclic_Momentum']['val_acc_list'] = [0] * epochs\n",
        "resultados['random_cyclic_Momentum']['test_acc'] = 0\n",
        "resultados['random_cyclic_Momentum']['cost'] = [0] * epochs\n",
        "resultados['random_cyclic_Momentum']['time'] = 0\n",
        "resultados['random_cyclic_Momentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_Momentum_time, random_cyclic_Momentum_acc, random_cyclic_epochs = CyclicGD_Momentum()\n",
        "    a = SumList(resultados['random_cyclic_Momentum']['val_acc_list'], random_cyclic_Momentum_acc_list)\n",
        "    resultados['random_cyclic_Momentum']['val_acc_list'] = SumList(resultados['random_cyclic_Momentum']['val_acc_list'], random_cyclic_Momentum_acc_list)\n",
        "    resultados['random_cyclic_Momentum']['test_acc'] += random_cyclic_Momentum_acc\n",
        "    resultados['random_cyclic_Momentum']['cost'] = SumList(resultados['random_cyclic_Momentum']['cost'], random_cyclic_Momentum_cost_list)\n",
        "    resultados['random_cyclic_Momentum']['time'] += random_cyclic_Momentum_time\n",
        "    resultados['random_cyclic_Momentum']['epochs'] += random_cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['random_cyclic_Momentum']['name'] = 'Random Ciclico con Momentum'\n",
        "resultados['random_cyclic_Momentum']['lr'] = random_cyclic_Momentum_lr_list\n",
        "resultados['random_cyclic_Momentum']['test_acc'] = resultados['random_cyclic_Momentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['random_cyclic_Momentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['random_cyclic_Momentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic_Momentum']['cost'] = DeleteZerosFromList(DivideList(resultados['random_cyclic_Momentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic_Momentum']['time'] = resultados['random_cyclic_Momentum']['time']/ MAX_ITERATIONS\n",
        "resultados['random_cyclic_Momentum']['epochs'] = resultados['random_cyclic_Momentum']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasa de aprendizaje decreciente con Momentum"
      ],
      "metadata": {
        "id": "ThNy9BizqjnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicia con una tasa de aprendizaje $\\alpha$ inicial y posee una disminución de 0.001 cada $p$ epochs.\n",
        "\n",
        "$\\alpha: 1x10^{-2}$\n",
        "\n",
        "$beta: 0.9$"
      ],
      "metadata": {
        "id": "Kj0uhSHy2F-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Our_Decay():\n",
        "    modelOurDecay = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelOurDecay.parameters(), lr=1, momentum=0.9)\n",
        "\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.0001, max_lr=0.1,scale_fn=clr_fn, step_size_up=1,scale_mode='decrecimiento', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_epochs = train(modelOurDecay,optimizer, scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    our_decay_time = start.elapsed_time(end)\n",
        "\n",
        "    our_decay_acc = accuracy(modelOurDecay, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs"
      ],
      "metadata": {
        "id": "numrEQ8GqmLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados['our_decay'] = {}\n",
        "resultados['our_decay']['val_acc_list'] = [0] * epochs\n",
        "resultados['our_decay']['test_acc'] = 0\n",
        "resultados['our_decay']['cost'] = [0] * epochs\n",
        "resultados['our_decay']['time'] = 0\n",
        "resultados['our_decay']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs = Our_Decay()\n",
        "    resultados['our_decay']['val_acc_list'] = SumList(resultados['our_decay']['val_acc_list'], our_decay_acc_list)\n",
        "    resultados['our_decay']['test_acc'] += our_decay_acc\n",
        "    resultados['our_decay']['cost'] = SumList(resultados['our_decay']['cost'], our_decay_cost_list)\n",
        "    resultados['our_decay']['time'] += our_decay_time\n",
        "    resultados['our_decay']['epochs'] += our_decay_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['our_decay']['name'] = 'Nuestro decreciente con Momentum'\n",
        "resultados['our_decay']['lr'] = our_decay_lr_list\n",
        "resultados['our_decay']['test_acc'] = resultados['our_decay']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['our_decay']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['our_decay']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['our_decay']['cost'] = DeleteZerosFromList(DivideList(resultados['our_decay']['cost'], MAX_ITERATIONS))\n",
        "resultados['our_decay']['time'] = resultados['our_decay']['time'] / MAX_ITERATIONS\n",
        "resultados['our_decay']['epochs'] = resultados['our_decay']['epochs'] / MAX_ITERATIONS"
      ],
      "metadata": {
        "id": "hhakL46SqsIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_h21aMdgsB"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al guardar todos los resultados de cada método en sus respectivos diccionarios, se procede a crear un dataframe con estos resultados. Adicionalmente, se generan nuevas columnas derivadas de datos que ya disponemos y se hacen tratamiento de formato para su análisis."
      ],
      "metadata": {
        "id": "lVY-ZbnF22H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key, _ in resultados.items():\n",
        "    if( resultados[key]['val_acc_list'][0] == 0 ):\n",
        "        continue\n",
        "    resultados[key]['val_acc_list'].insert(0,0)"
      ],
      "metadata": {
        "id": "d2P3wp7YqyNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S5hiFtm-9xj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "resultados_df = pd.DataFrame(resultados.copy()).T\n",
        "\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: round(row['val_acc_list'][-1]* 100,2), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: round(row['test_acc']*100,2), axis=1)\n",
        "resultados_df['time'] = resultados_df.apply(lambda row: round(row['time']/(1000),2), axis=1)\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['val_acc']), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['test_acc']), axis=1)\n",
        "\n",
        "resultados_df = resultados_df.sort_values(by=['test_acc'],ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Qelt3wIs3T"
      },
      "source": [
        "## Velocidad de convergencia basado en epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lruyulJ5C4SR"
      },
      "outputs": [],
      "source": [
        "resultados_df[['name','val_acc', 'test_acc', 'epochs']].style.hide_index()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "ccfea65839ea7b4cb7611917847ae955f8a5d3f7496a05c88f3bf628abe673bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}