{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgNAaM97oPwU"
      },
      "source": [
        "Tomar referencia de los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBCruOrtR_cV",
        "outputId": "5c01b074-6305-4712-95ff-a283ad8e62de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NN_Tests_DG'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 51 (delta 17), reused 36 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), 12.64 MiB | 6.71 MiB/s, done.\n",
            "/content/NN_Tests_DG/NN_Tests_DG/NN_Tests_DG/NN_Tests_DG\n",
            "\u001b[0m\u001b[01;34mDataset\u001b[0m/          Iteracion1_new.ipynb     NN_Pytorch.ipynb\n",
            "Decay.ipynb       Iteracion_2.ipynb        requirement.txt\n",
            "get_images.py     LearningRateStudy.ipynb  SGD_Momentum_RMSProp_Adam.ipynb\n",
            "Iteracion1.ipynb  NN_from_Scratch.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DenisPerez/NN_Tests_DG.git\n",
        "%cd NN_Tests_DG\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "F4gP7LPQTtg7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from get_images import get_images\n",
        "\n",
        "# PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mULGvWTthB"
      },
      "source": [
        "# Preparación de la entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "9vdIQd58TthD"
      },
      "outputs": [],
      "source": [
        "MNIST_PATH = './Dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "slQPSqQeTthE"
      },
      "outputs": [],
      "source": [
        "x_train_num, y_train_num, x_test_num, y_test_num = get_images(MNIST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "HFnaRwd-TthE"
      },
      "outputs": [],
      "source": [
        "#Training set\n",
        "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)/255 ##Convert the traint set into a (50000, 28x28) matrix normalized\n",
        "y_train = y_train_num[:50000].reshape(50000,1)\n",
        "\n",
        "##Validation set\n",
        "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)/255\n",
        "y_val = y_train_num[50000:].reshape(10000,1)\n",
        "\n",
        "##Test set\n",
        "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)/255\n",
        "y_test = y_test_num.copy().reshape(10000,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZz8hG0OTthF"
      },
      "source": [
        "## Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "_kFtDZs6TthG"
      },
      "outputs": [],
      "source": [
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "KYhJenIZTthG"
      },
      "outputs": [],
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRx3THErTthH",
        "outputId": "7165daf6-c341-4462-de91-b89a292ecbb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.5686665e-08, 0.9999983)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMAv3EVXTthJ"
      },
      "source": [
        "## Show Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHHAe687TthJ",
        "outputId": "1d513d0c-a553-4143-ac24-2290e33da305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_FPmhofTthK",
        "outputId": "9c65fe23-8bc3-4345-98ee-48d85a2de1c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "w4HfkSTqTthK"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7TQtWTpZTthL",
        "outputId": "12ebd506-cfc4-4e7d-92ff-46b1d514fb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La imagen muestreada representa un: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEeCAYAAABcyXrWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAHHElEQVR4nO3cz4tOfx/H8fsS+VFqCk0NfwCFWSgbLGchs0GNhWSpbK0saPxIUbKTnZXELKTZWNkwG2JHSWExCwtJoomG893f9z3Ou++c63VdeDy28+pzTtLTKZ+m1zTNfwCSVgz6BYC/j/AAccIDxAkPECc8QJzwAHErf/XDXq/n/9qBf6Vpmt5SP/PFA8QJDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8QJDxC3ctAvwPAZGxsr7a5du1baTU1NtW6apimd1ev1SruXL1+WdtPT062bmZmZ0lnU+eIB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHier+6Mdrr9WrXSflt7Nmzp3Vz/fr10lnbt29f7usM3Ldv31o3ExMTpbPm5uaW+zp/lKZplrxm7osHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHiXCAcctVf9Xns2LHS7saNG62b1atXl86an58v7e7evdu6efLkSemsDRs2lHZnz54t7UZHR1s3s7OzpbMOHjxY2lV/zevvzgVCYKgIDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxLm5POQmJydLu/v375d2nz9/bt3cvn27dNbJkydLu0Go3iKemZlp3VRvj+/cubO0e/HiRWn3u3NzGRgqwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHErB/0Cf6vNmzeXdhcvXuz0uQ8ePGjdDPON5Kp79+6VdgsLC62bdevWLfd1+C++eIA44QHihAeIEx4gTniAOOEB4oQHiBMeIM4FwgHZvXt3abdjx45On3vz5s1Oz4N/wxcPECc8QJzwAHHCA8QJDxAnPECc8ABxwgPECQ8Q5+byX+br16+DfgXwxQPkCQ8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8S5uTwghw4d6vS8T58+lXYfPnzo9LnDanJysrRbs2ZNn9+E/8cXDxAnPECc8ABxwgPECQ8QJzxAnPAAccIDxAkPEOfm8oCMjY11et67d+9Ku1evXnX63GG1adOm0m7FCv/2DoI/dSBOeIA44QHihAeIEx4gTniAOOEB4oQHiHOBsA+2bNnSutm2bVunz3z//n2n50E/+eIB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHi3Fzug5GRkdbN6Oho6azFxcXS7vLly6Xd32Jqaqqzs549e1bavXnzprNn/ul88QBxwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHFuLg+5pmlKuy9fvvT5TYbD1q1bS7vx8fHOnnn16tXSbmFhobNn/ul88QBxwgPECQ8QJzxAnPAAccIDxAkPECc8QJwLhENu1apVpV31wtzz58+X8zoDNz09XdpVf7Xsx48fWzdzc3Ols6jzxQPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8S5udwHR44c6eysxcXF0u7169edPXMQ9u7dW9pNTEx0+tzKryudn5/v9Jn44gEGQHiAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiDOzeU+2LhxY2dnff/+vbR7/PhxZ88chOrvUh4ZGen0ucePH+/0PGp88QBxwgPECQ8QJzxAnPAAccIDxAkPECc8QJzwAHFuLtN3R48ebd3s27ev02c+fPiwtHv06FGnz6XGFw8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8S5QDjk1q5dW9qdOXOmtLtw4ULrZteuXaWzTp8+Xdrt37+/dbNyZbd/FS9dulTaLS4udvpcanzxAHHCA8QJDxAnPECc8ABxwgPECQ8QJzxAnPAAcb2maZb+Ya+39A9Z0pUrV1o3p06dCrzJ/6rc1F2xovbvUXVX8fPnz9Lu8OHDpd3s7Gxp96u//yxP0zS9pX7miweIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4hzc7kP1q9f37q5detW6awDBw4s93V+C+fOnSvtzp8/3+c3oStuLgNDRXiAOOEB4oQHiBMeIE54gDjhAeKEB4hzgXBAxsfHS7sTJ050uqt4+vRpaVf99aJ37txp3bx9+7Z01o8fP0o7Bs8FQmCoCA8QJzxAnPAAccIDxAkPECc8QJzwAHHCA8S5uQz0hZvLwFARHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiBOeIA44QHihAeIEx4gTniAOOEB4oQHiBMeIE54gDjhAeKEB4gTHiCu1zTNoN8B+Mv44gHihAeIEx4gTniAOOEB4oQHiPsHNv//RxaodxoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
        "plot_number(x_test_num[rnd_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVo-PF6cTthM"
      },
      "source": [
        "## Create Mini Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Ym639R_PTthM"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(x, y, mb_size, shuffle = True):\n",
        "    '''\n",
        "    x  #muestras, input_layer\n",
        "    y #muestras, 1\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle: \n",
        "        idxs = np.arange(total_data, dtype=float)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]  \n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "6quE_eQ9TthO"
      },
      "outputs": [],
      "source": [
        "x_train_tensor = torch.Tensor(x_train.copy())\n",
        "y_train_tensor = torch.Tensor(y_train.copy())\n",
        "\n",
        "x_val_tensor = torch.Tensor(x_val.copy())\n",
        "y_val_tensor = torch.Tensor(y_val.copy())\n",
        "\n",
        "x_test_tensor = torch.Tensor(x_test.copy())\n",
        "y_test_tensor = torch.Tensor(y_test.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqPgXB1DTthP"
      },
      "source": [
        "## Use GPU when available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1oc0PTWTthQ",
        "outputId": "58409768-9788-4a20-a817-b97222222363"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZebY-iBHTthQ",
        "outputId": "068674ea-f9a0-431b-91a1-622e150cf76a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estamos usando: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Estamos usando: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones"
      ],
      "metadata": {
        "id": "_XG0HhszpA-_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L66abJ9WTthR"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "Zt6iiZyuTthR"
      },
      "outputs": [],
      "source": [
        "def accuracy(model: nn.Sequential, x: torch.tensor, y: torch.tensor, mb_size: int):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) # mb_size, 10\n",
        "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
        "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
        "            num_total += pred.size(0)\n",
        "\n",
        "            return float(num_correct)/num_total  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4DuKf3TthR"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "HtRDD6Nu0507"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler: None, mb_size):\n",
        "    model = model.to(device=device)\n",
        "    epoch_acc = 0.0\n",
        "    i = 0\n",
        "    #plot lists\n",
        "    acc_list = [0.0]\n",
        "    cost_list = [0.0]\n",
        "    lr_list = [0.0]\n",
        "    while (i < 100):\n",
        "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "            # cost function\n",
        "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
        "            optimizer.zero_grad()\n",
        "            cost.backward()\n",
        "            for name, param in model.named_parameters():\n",
        "              ik = str(name)+'_'+str(i)\n",
        "              prev_ik = str(name)+'_'+str(i-1)\n",
        "            optimizer.step()\n",
        "        if (scheduler != None):\n",
        "          scheduler.step()\n",
        "          lr = scheduler.get_last_lr()\n",
        "          lr_list.append(lr[0])\n",
        "        else: \n",
        "          lr_list.append(optimizer.param_groups[0]['lr'])\n",
        "        i+=1\n",
        "        epoch_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
        "        epoch_cost = cost.item()\n",
        "\n",
        "        #append\n",
        "        acc_list.append(epoch_acc)\n",
        "        cost_list.append(epoch_cost)\n",
        "        # print(f'Epoch: {len(acc_list)}, learning_rate:{lr},costo: {epoch_cost}, accuracy: {epoch_acc}')\n",
        "    return acc_list, cost_list, lr_list, i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6xxVksqR95C"
      },
      "source": [
        "## List Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "5aJV7jOTR95D"
      },
      "outputs": [],
      "source": [
        "def SumList(first: list, second: list) -> list:\n",
        "    return [x + y for x, y in zip(first[::-1], second[::-1])][::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "I51hZdnHR95D"
      },
      "outputs": [],
      "source": [
        "def DivideList(dic_list: list, number: int) -> list:\n",
        "    return [x / number for x in dic_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "y6ro6TQRR95E"
      },
      "outputs": [],
      "source": [
        "def DeleteZerosFromList(dic_list: list) -> list:\n",
        "    return list(filter(lambda num: num != 0, dic_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentos"
      ],
      "metadata": {
        "id": "fa7V0442o5yX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ2qa3c-eS1L"
      },
      "source": [
        "## Variables globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "WBDuey1VQTm4"
      },
      "outputs": [],
      "source": [
        "MAX_ITERATIONS = 10\n",
        "layer1 = 1000 \n",
        "layer2 = 1000\n",
        "lr = 1e-2\n",
        "epochs = 100\n",
        "mb_size = 4096\n",
        "input_layer = 784\n",
        "first_i = 0\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "resultados = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj0arCxmZdxw"
      },
      "source": [
        "## Cyclic Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "9vrI2SE_3zaR"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Optimizer\n",
        "\n",
        "import types\n",
        "import math\n",
        "from torch._six import inf\n",
        "from functools import wraps\n",
        "import warnings\n",
        "import weakref\n",
        "import random\n",
        "\n",
        "class _LRSchedulerGiselt_Denis(object):\n",
        "\n",
        "    def __init__(self, optimizer, last_epoch=-1, verbose=False):\n",
        "\n",
        "        # Attach optimizer\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # Initialize epoch and base learning rates\n",
        "        if last_epoch == -1:\n",
        "            for group in optimizer.param_groups:\n",
        "                group.setdefault('initial_lr', group['lr'])\n",
        "        else:\n",
        "            for i, group in enumerate(optimizer.param_groups):\n",
        "                if 'initial_lr' not in group:\n",
        "                    raise KeyError(\"param 'initial_lr' is not specified \"\n",
        "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
        "        self.base_lrs = [group['initial_lr'] for group in optimizer.param_groups]\n",
        "        self.last_epoch = last_epoch\n",
        "\n",
        "        # Following https://github.com/pytorch/pytorch/issues/20124\n",
        "        # We would like to ensure that `lr_scheduler.step()` is called after\n",
        "        # `optimizer.step()`\n",
        "        def with_counter(method):\n",
        "            if getattr(method, '_with_counter', False):\n",
        "                # `optimizer.step()` has already been replaced, return.\n",
        "                return method\n",
        "\n",
        "            # Keep a weak reference to the optimizer instance to prevent\n",
        "            # cyclic references.\n",
        "            instance_ref = weakref.ref(method.__self__)\n",
        "            # Get the unbound method for the same purpose.\n",
        "            func = method.__func__\n",
        "            cls = instance_ref().__class__\n",
        "            del method\n",
        "\n",
        "            @wraps(func)\n",
        "            def wrapper(*args, **kwargs):\n",
        "                instance = instance_ref()\n",
        "                instance._step_count += 1\n",
        "                wrapped = func.__get__(instance, cls)\n",
        "                return wrapped(*args, **kwargs)\n",
        "\n",
        "            # Note that the returned function here is no longer a bound method,\n",
        "            # so attributes like `__func__` and `__self__` no longer exist.\n",
        "            wrapper._with_counter = True\n",
        "            return wrapper\n",
        "\n",
        "        self.optimizer.step = with_counter(self.optimizer.step)\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self._initial_step()\n",
        "\n",
        "    def _initial_step(self):\n",
        "        \"\"\"Initialize step counts and performs a step\"\"\"\n",
        "        self.optimizer._step_count = 0\n",
        "        self._step_count = 0\n",
        "        self.step()\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
        "\n",
        "        It contains an entry for every variable in self.__dict__ which\n",
        "        is not the optimizer.\n",
        "        \"\"\"\n",
        "        return {key: value for key, value in self.__dict__.items() if key != 'optimizer'}\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        \"\"\"Loads the schedulers state.\n",
        "\n",
        "        Args:\n",
        "            state_dict (dict): scheduler state. Should be an object returned\n",
        "                from a call to :meth:`state_dict`.\n",
        "        \"\"\"\n",
        "        self.__dict__.update(state_dict)\n",
        "\n",
        "    def get_last_lr(self):\n",
        "        \"\"\" Return last computed learning rate by current scheduler.\n",
        "        \"\"\"\n",
        "        return self._last_lr\n",
        "\n",
        "    def get_lr(self):\n",
        "        # Compute learning rate using chainable form of the scheduler\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def print_lr(self, is_verbose, group, lr, epoch=None):\n",
        "        \"\"\"Display the current learning rate.\n",
        "        \"\"\"\n",
        "        if is_verbose:\n",
        "            if epoch is None:\n",
        "                print('Adjusting learning rate'\n",
        "                      ' of group {} to {:.4e}.'.format(group, lr))\n",
        "            else:\n",
        "                epoch_str = (\"%.2f\" if isinstance(epoch, float) else\n",
        "                             \"%.5d\") % epoch\n",
        "                print('Epoch {}: adjusting learning rate'\n",
        "                      ' of group {} to {:.4e}.'.format(epoch_str, group, lr))\n",
        "\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        # Raise a warning if old pattern is detected\n",
        "        # https://github.com/pytorch/pytorch/issues/20124\n",
        "        if self._step_count == 1:\n",
        "            if not hasattr(self.optimizer.step, \"_with_counter\"):\n",
        "                warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
        "                              \"initialization. Please, make sure to call `optimizer.step()` before \"\n",
        "                              \"`lr_scheduler.step()`. See more details at \"\n",
        "                              \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
        "\n",
        "            # Just check if there were two first lr_scheduler.step() calls before optimizer.step()\n",
        "            elif self.optimizer._step_count < 1:\n",
        "                warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
        "                              \"In PyTorch 1.1.0 and later, you should call them in the opposite order: \"\n",
        "                              \"`optimizer.step()` before `lr_scheduler.step()`.  Failure to do this \"\n",
        "                              \"will result in PyTorch skipping the first value of the learning rate schedule. \"\n",
        "                              \"See more details at \"\n",
        "                              \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
        "        self._step_count += 1\n",
        "\n",
        "        class _enable_get_lr_call:\n",
        "\n",
        "            def __init__(self, o):\n",
        "                self.o = o\n",
        "\n",
        "            def __enter__(self):\n",
        "                self.o._get_lr_called_within_step = True\n",
        "                return self\n",
        "\n",
        "            def __exit__(self, type, value, traceback):\n",
        "                self.o._get_lr_called_within_step = False\n",
        "\n",
        "        with _enable_get_lr_call(self):\n",
        "            if epoch is None:\n",
        "                self.last_epoch += 1\n",
        "                values = self.get_lr()\n",
        "            else:\n",
        "                warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
        "                self.last_epoch = epoch\n",
        "                if hasattr(self, \"_get_closed_form_lr\"):\n",
        "                    values = self._get_closed_form_lr()\n",
        "                else:\n",
        "                    values = self.get_lr()\n",
        "\n",
        "        for i, data in enumerate(zip(self.optimizer.param_groups, values)):\n",
        "            param_group, lr = data\n",
        "            param_group['lr'] = lr\n",
        "            self.print_lr(self.verbose, i, lr, epoch)\n",
        "\n",
        "        self._last_lr = [group['lr'] for group in self.optimizer.param_groups]\n",
        "\n",
        "class CyclicLRGiselt_Denis(_LRSchedulerGiselt_Denis):\n",
        "    r\"\"\"Sets the learning rate of each parameter group according to\n",
        "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
        "    rate between two boundaries with a constant frequency, as detailed in\n",
        "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
        "    The distance between the two boundaries can be scaled on a per-iteration\n",
        "    or per-cycle basis.\n",
        "\n",
        "    Cyclical learning rate policy changes the learning rate after every batch.\n",
        "    `step` should be called after a batch has been used for training.\n",
        "\n",
        "    This class has three built-in policies, as put forth in the paper:\n",
        "\n",
        "    * \"triangular\": A basic triangular cycle without amplitude scaling.\n",
        "    * \"triangular2\": A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    * \"exp_range\": A cycle that scales initial amplitude by :math:`\\text{gamma}^{\\text{cycle iterations}}`\n",
        "      at each cycle iteration.\n",
        "\n",
        "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
        "\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        base_lr (float or list): Initial learning rate which is the\n",
        "            lower boundary in the cycle for each parameter group.\n",
        "        max_lr (float or list): Upper learning rate boundaries in the cycle\n",
        "            for each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size_up (int): Number of training iterations in the\n",
        "            increasing half of a cycle. Default: 2000\n",
        "        step_size_down (int): Number of training iterations in the\n",
        "            decreasing half of a cycle. If step_size_down is None,\n",
        "            it is set to step_size_up. Default: None\n",
        "        mode (str): One of {triangular, triangular2, exp_range}.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "            Default: 'triangular'\n",
        "        gamma (float): Constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "            Default: 1.0\n",
        "        scale_fn (function): Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            If specified, then 'mode' is ignored.\n",
        "            Default: None\n",
        "        scale_mode (str): {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle).\n",
        "            Default: 'cycle'\n",
        "        cycle_momentum (bool): If ``True``, momentum is cycled inversely\n",
        "            to learning rate between 'base_momentum' and 'max_momentum'.\n",
        "            Default: True\n",
        "        base_momentum (float or list): Lower momentum boundaries in the cycle\n",
        "            for each parameter group. Note that momentum is cycled inversely\n",
        "            to learning rate; at the peak of a cycle, momentum is\n",
        "            'base_momentum' and learning rate is 'max_lr'.\n",
        "            Default: 0.8\n",
        "        max_momentum (float or list): Upper momentum boundaries in the cycle\n",
        "            for each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_momentum - base_momentum).\n",
        "            The momentum at any cycle is the difference of max_momentum\n",
        "            and some scaling of the amplitude; therefore\n",
        "            base_momentum may not actually be reached depending on\n",
        "            scaling function. Note that momentum is cycled inversely\n",
        "            to learning rate; at the start of a cycle, momentum is 'max_momentum'\n",
        "            and learning rate is 'base_lr'\n",
        "            Default: 0.9\n",
        "        last_epoch (int): The index of the last batch. This parameter is used when\n",
        "            resuming a training job. Since `step()` should be invoked after each\n",
        "            batch instead of after each epoch, this number represents the total\n",
        "            number of *batches* computed, not the total number of epochs computed.\n",
        "            When last_epoch=-1, the schedule is started from the beginning.\n",
        "            Default: -1\n",
        "        verbose (bool): If ``True``, prints a message to stdout for\n",
        "            each update. Default: ``False``.\n",
        "\n",
        "    Example:\n",
        "        >>> # xdoctest: +SKIP\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n",
        "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     for batch in data_loader:\n",
        "        >>>         train_batch(...)\n",
        "        >>>         scheduler.step()\n",
        "\n",
        "\n",
        "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 optimizer,\n",
        "                 base_lr,\n",
        "                 max_lr,\n",
        "                 step_size_up=2000,\n",
        "                 step_size_down=None,\n",
        "                 mode='triangular',\n",
        "                 gamma=1.,\n",
        "                 scale_fn=None,\n",
        "                 scale_mode='cycle',\n",
        "                 cycle_momentum=True,\n",
        "                 base_momentum=0.8,\n",
        "                 max_momentum=0.9,\n",
        "                 last_epoch=-1,\n",
        "                 verbose=False):\n",
        "\n",
        "        # Attach optimizer\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "        self.direction_up = True\n",
        "        self.half_cycle_steps = 0\n",
        "\n",
        "        base_lrs = self._format_param('base_lr', optimizer, base_lr)\n",
        "        if last_epoch == -1:\n",
        "            for lr, group in zip(base_lrs, optimizer.param_groups):\n",
        "                group['lr'] = lr\n",
        "\n",
        "        self.max_lrs = self._format_param('max_lr', optimizer, max_lr)\n",
        "\n",
        "        self.step_size_up = float(step_size_up)\n",
        "        self.step_size_down = float(step_size_down) if step_size_down is not None else step_size_up\n",
        "        self.total_size = self.step_size_up + self.step_size_down\n",
        "        self.step_ratio = step_size_up / self.total_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            self._scale_fn_custom = None\n",
        "            if self.mode == 'triangular':\n",
        "                self._scale_fn_ref = weakref.WeakMethod(self._triangular_scale_fn)\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self._scale_fn_ref = weakref.WeakMethod(self._triangular2_scale_fn)\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self._scale_fn_ref = weakref.WeakMethod(self._exp_range_scale_fn)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self._scale_fn_custom = scale_fn\n",
        "            self._scale_fn_ref = None\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.cycle_momentum = cycle_momentum\n",
        "        if cycle_momentum:\n",
        "            if 'momentum' not in optimizer.defaults:\n",
        "                raise ValueError('optimizer must support momentum with `cycle_momentum` option enabled')\n",
        "\n",
        "            base_momentums = self._format_param('base_momentum', optimizer, base_momentum)\n",
        "            if last_epoch == -1:\n",
        "                for momentum, group in zip(base_momentums, optimizer.param_groups):\n",
        "                    group['momentum'] = momentum\n",
        "            self.base_momentums = [group['momentum'] for group in optimizer.param_groups]\n",
        "            self.max_momentums = self._format_param('max_momentum', optimizer, max_momentum)\n",
        "\n",
        "        super(CyclicLRGiselt_Denis, self).__init__(optimizer, last_epoch, verbose)\n",
        "        self.base_lrs = base_lrs\n",
        "\n",
        "    def _format_param(self, name, optimizer, param):\n",
        "        \"\"\"Return correctly formatted lr/momentum for each param group.\"\"\"\n",
        "        if isinstance(param, (list, tuple)):\n",
        "            if len(param) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} values for {}, got {}\".format(\n",
        "                    len(optimizer.param_groups), name, len(param)))\n",
        "            return param\n",
        "        else:\n",
        "            return [param] * len(optimizer.param_groups)\n",
        "\n",
        "    def scale_fn(self, x):\n",
        "        if self._scale_fn_custom is not None:\n",
        "            # print(self.half_cycle_steps, x)\n",
        "            return self._scale_fn_custom(x)\n",
        "\n",
        "        else:\n",
        "            return self._scale_fn_ref()(x)\n",
        "\n",
        "    def scale_fn_rand(self, x, y):\n",
        "        return random.uniform(x, y)\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        \"\"\"Calculates the learning rate at batch index. This function treats\n",
        "        `self.last_epoch` as the last batch index.\n",
        "\n",
        "        If `self.cycle_momentum` is ``True``, this function has a side effect of\n",
        "        updating the optimizer's momentum.\n",
        "        \"\"\"\n",
        "        \n",
        "\n",
        "        if not self._get_lr_called_within_step:\n",
        "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
        "                          \"please use `get_last_lr()`.\", UserWarning)\n",
        "\n",
        "        cycle = math.floor(1 + self.last_epoch / self.total_size)\n",
        "        x = 1. + self.last_epoch / self.total_size - cycle\n",
        "        if x <= self.step_ratio:\n",
        "            scale_factor = x / self.step_ratio\n",
        "        else:\n",
        "            scale_factor = (x - 1) / (self.step_ratio - 1)\n",
        "\n",
        "        lrs = []\n",
        "        for base_lr, max_lr in zip(self.base_lrs, self.max_lrs):\n",
        "            base_height = (max_lr - base_lr) * scale_factor\n",
        "            if self.scale_mode == 'cycle':\n",
        "\n",
        "                # print(\"cycle\")\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            elif self.scale_mode == 'iterations':\n",
        "\n",
        "                # print(\"iterations\")\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_epoch)\n",
        "\n",
        "            elif self.scale_mode == 'decrecimiento':\n",
        "                if (self.last_epoch == 0):\n",
        "                  lr = max_lr\n",
        "                else: \n",
        "                  lr = self.get_last_lr()[0] - base_lr\n",
        "                  if (lr<0):\n",
        "                    lr = base_lr\n",
        "\n",
        "            elif self.scale_mode == 'chipichipi':                               #<--------------------------\n",
        "                \n",
        "                '''\n",
        "                for x in optimizer.param_groups:\n",
        "                  for each in x['params']:\n",
        "                    print(each)\n",
        "                \n",
        "                for name, param in modelBB.named_parameters():\n",
        "                  print(param.grad.shape)\n",
        "                '''\n",
        "\n",
        "                # print(\"chipichipi\")\n",
        "                if (self.last_epoch == 0):\n",
        "                    last_lr = base_lr\n",
        "                else:\n",
        "                    last_lr = self.get_last_lr()[0]\n",
        "                    # print(f\"Esto es el ultimo lr {last_lr}\")\n",
        "\n",
        "                if (self.half_cycle_steps == self.step_size_up\n",
        "                    and self.direction_up == True):\n",
        "                    #print('Cambio de direccion: bajando')\n",
        "                    lr = random.uniform(last_lr, max_lr)\n",
        "                    self.direction_up = False\n",
        "                    self.half_cycle_steps = 1\n",
        "\n",
        "                elif (self.half_cycle_steps == self.step_size_down\n",
        "                    and self.direction_up == False):\n",
        "                    #print('Cambio de direccion: subiendo')\n",
        "                    lr = random.uniform(base_lr, last_lr)\n",
        "                    self.direction_up = True\n",
        "                    self.half_cycle_steps = 1\n",
        "\n",
        "                elif (self.direction_up == True):\n",
        "                    lr = random.uniform(last_lr, max_lr)\n",
        "                    self.half_cycle_steps += 1\n",
        "\n",
        "                elif(self.direction_up == False):\n",
        "                    lr = random.uniform(base_lr, last_lr)\n",
        "                    self.half_cycle_steps += 1\n",
        "            #print('base_lr: '+str(base_lr))\n",
        "            lrs.append(lr)\n",
        "\n",
        "        if self.cycle_momentum:\n",
        "            #print('wowo')\n",
        "            momentums = []\n",
        "            for base_momentum, max_momentum in zip(self.base_momentums, self.max_momentums):\n",
        "                base_height = (max_momentum - base_momentum) * scale_factor\n",
        "                if self.scale_mode == 'cycle':\n",
        "                    momentum = max_momentum - base_height * self.scale_fn(cycle)\n",
        "                else:\n",
        "                    momentum = max_momentum - base_height * self.scale_fn(self.last_epoch)\n",
        "                #print('momentum: '+str(max_momentum)+' '+str(base_momentum))\n",
        "                momentums.append(momentum)\n",
        "            for param_group, momentum in zip(self.optimizer.param_groups, momentums):\n",
        "                param_group['momentum'] = momentum\n",
        "            \n",
        "        return lrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhXFwQqymLvv"
      },
      "source": [
        "## Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "z9MBaYV0R95Q"
      },
      "outputs": [],
      "source": [
        "def Adam():\n",
        "    modelAdam = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimiserAdam = torch.optim.Adam(modelAdam.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "    start.record()\n",
        "    adam_acc_list, adam_cost_list,adam_lr_list, adam_epochs = train(modelAdam,optimiserAdam,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    adam_time = start.elapsed_time(end)\n",
        "\n",
        "    adam_acc = accuracy(modelAdam, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return adam_acc_list, adam_cost_list, adam_lr_list, adam_time, adam_acc, adam_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "kZeKlCWWmNpH"
      },
      "outputs": [],
      "source": [
        "\n",
        "resultados['adam'] = {}\n",
        "resultados['adam']['val_acc_list'] = [0] * epochs\n",
        "resultados['adam']['test_acc'] = 0\n",
        "resultados['adam']['cost'] = [0] * epochs\n",
        "resultados['adam']['time'] = 0\n",
        "resultados['adam']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    adam_acc_list, adam_cost_list, adam_lr_list, adam_time, adam_acc, adam_epochs = Adam()\n",
        "    resultados['adam']['val_acc_list'] = SumList(resultados['adam']['val_acc_list'], adam_acc_list)\n",
        "    resultados['adam']['test_acc'] += adam_acc\n",
        "    resultados['adam']['cost'] = SumList(resultados['adam']['cost'], adam_cost_list)\n",
        "    resultados['adam']['time'] += adam_time\n",
        "    resultados['adam']['epochs'] += adam_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['adam']['name'] = 'Adam'\n",
        "resultados['adam']['lr'] = adam_lr_list\n",
        "resultados['adam']['test_acc'] = resultados['adam']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['adam']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['adam']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['adam']['cost'] = DeleteZerosFromList(DivideList(resultados['adam']['cost'], MAX_ITERATIONS))\n",
        "resultados['adam']['time'] = resultados['adam']['time']\n",
        "resultados['adam']['epochs'] = resultados['adam']['epochs'] / MAX_ITERATIONS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy_ipT4cV40p"
      },
      "source": [
        "## Cíclico con Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "z_1Gg-3eWMZr"
      },
      "outputs": [],
      "source": [
        "def CyclicMomentum():\n",
        "    modelCyclicMomentum = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelCyclicMomentum.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3,cycle_momentum=False )\n",
        "\n",
        "    start.record()\n",
        "    cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_epochs = train(modelCyclicMomentum, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    cyclicMomentum_time = start.elapsed_time(end)\n",
        "\n",
        "    cyclicMomentum_acc = accuracy(modelCyclicMomentum, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_time, cyclicMomentum_acc, cyclicMomentum_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "GPA1FfOOWOtV"
      },
      "outputs": [],
      "source": [
        "resultados['cyclicMomentum'] = {}\n",
        "resultados['cyclicMomentum']['val_acc_list'] = [0]* epochs\n",
        "resultados['cyclicMomentum']['test_acc'] = 0\n",
        "resultados['cyclicMomentum']['cost'] = [0] * epochs\n",
        "resultados['cyclicMomentum']['time'] = 0\n",
        "resultados['cyclicMomentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_time, cyclicMomentum_acc, cyclicMomentum_epochs = CyclicMomentum()\n",
        "    resultados['cyclicMomentum']['val_acc_list'] = SumList(resultados['cyclicMomentum']['val_acc_list'], cyclicMomentum_acc_list)\n",
        "    resultados['cyclicMomentum']['test_acc'] += cyclicMomentum_acc\n",
        "    resultados['cyclicMomentum']['cost'] = SumList(resultados['cyclicMomentum']['cost'], cyclicMomentum_cost_list)\n",
        "    resultados['cyclicMomentum']['time'] += cyclicMomentum_time\n",
        "    resultados['cyclicMomentum']['epochs'] += cyclicMomentum_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['cyclicMomentum']['name'] = 'Ciclico Con Momentum'\n",
        "resultados['cyclicMomentum']['lr'] = cyclicMomentum_lr_list\n",
        "resultados['cyclicMomentum']['test_acc'] = resultados['cyclicMomentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['cyclicMomentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['cyclicMomentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['cyclicMomentum']['cost'] = DeleteZerosFromList(DivideList(resultados['cyclicMomentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['cyclicMomentum']['time'] = resultados['cyclicMomentum']['time']\n",
        "resultados['cyclicMomentum']['epochs'] = resultados['cyclicMomentum']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28gylOT-cNL5"
      },
      "source": [
        "## Cíclico aleatorio con Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "0_7uf-LUcQuE"
      },
      "outputs": [],
      "source": [
        "def CyclicGD_Momentum():\n",
        "    import random\n",
        "    modelRandomCyclic_Momentum= nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelRandomCyclic_Momentum.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=2, scale_fn=clr_fn,scale_mode='chipichipi', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_epochs= train(modelRandomCyclic_Momentum, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    random_cyclic_Momentum_time = start.elapsed_time(end)\n",
        "\n",
        "    random_cyclic_Momentum_acc = accuracy(modelRandomCyclic_Momentum, x_test_tensor,  y_test_tensor, mb_size) \n",
        "\n",
        "    return random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_Momentum_time, random_cyclic_Momentum_acc, random_cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Zikwca8lcrI-"
      },
      "outputs": [],
      "source": [
        "resultados['random_cyclic_Momentum'] = {}\n",
        "resultados['random_cyclic_Momentum']['val_acc_list'] = [0] * epochs\n",
        "resultados['random_cyclic_Momentum']['test_acc'] = 0\n",
        "resultados['random_cyclic_Momentum']['cost'] = [0] * epochs\n",
        "resultados['random_cyclic_Momentum']['time'] = 0\n",
        "resultados['random_cyclic_Momentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_Momentum_time, random_cyclic_Momentum_acc, random_cyclic_epochs = CyclicGD_Momentum()\n",
        "    a = SumList(resultados['random_cyclic_Momentum']['val_acc_list'], random_cyclic_Momentum_acc_list)\n",
        "    resultados['random_cyclic_Momentum']['val_acc_list'] = SumList(resultados['random_cyclic_Momentum']['val_acc_list'], random_cyclic_Momentum_acc_list)\n",
        "    resultados['random_cyclic_Momentum']['test_acc'] += random_cyclic_Momentum_acc\n",
        "    resultados['random_cyclic_Momentum']['cost'] = SumList(resultados['random_cyclic_Momentum']['cost'], random_cyclic_Momentum_cost_list)\n",
        "    resultados['random_cyclic_Momentum']['time'] += random_cyclic_Momentum_time\n",
        "    resultados['random_cyclic_Momentum']['epochs'] += random_cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['random_cyclic_Momentum']['name'] = 'Random Ciclico con Momentum'\n",
        "resultados['random_cyclic_Momentum']['lr'] = random_cyclic_Momentum_lr_list\n",
        "resultados['random_cyclic_Momentum']['test_acc'] = resultados['random_cyclic_Momentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['random_cyclic_Momentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['random_cyclic_Momentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic_Momentum']['cost'] = DeleteZerosFromList(DivideList(resultados['random_cyclic_Momentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic_Momentum']['time'] = resultados['random_cyclic_Momentum']['time']\n",
        "resultados['random_cyclic_Momentum']['epochs'] = resultados['random_cyclic_Momentum']['epochs'] / MAX_ITERATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L-BFGS con búsqueda lineal"
      ],
      "metadata": {
        "id": "PPiRXZt2pdNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LBFGS_LS():\n",
        "    modelLBFGS_LS = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "\n",
        "    optimizer = torch.optim.LBFGS(modelLBFGS_LS.parameters(),\n",
        "                                lr=1,\n",
        "                                history_size=10, #update history size. What's this?\n",
        "                                #max_eval (int) – maximal number of function evaluations per optimization step (default: max_iter * 1.25)\n",
        "                                #max_iter=1,\n",
        "                                line_search_fn=\"strong_wolfe\"\n",
        "                                )\n",
        "\n",
        "    lbfgs_ls_cost_list = [0.0]\n",
        "    lbfgs_ls_acc_list = [0.0]\n",
        "    modelLBFGS_LS = modelLBFGS_LS.to(device=device)\n",
        "    x_train_tensor_ = x_train_tensor.to(device=device, dtype=torch.float32)\n",
        "    y_train_tensor_ = y_train_tensor.to(device=device, dtype=torch.long)\n",
        "    i = 0\n",
        "\n",
        "    start.record()\n",
        "    #training\n",
        "    while (i<100):\n",
        "        #print('Iteracion: '+ str(i))\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            scores = modelLBFGS_LS(x_train_tensor_)\n",
        "            cost = F.cross_entropy(input= scores, target=y_train_tensor_.squeeze())\n",
        "            cost.backward()\n",
        "            #print(f'costo: {cost.item()}')  \n",
        "            lbfgs_ls_cost_list.append(cost.item())\n",
        "            return cost\n",
        "        optimizer.step(closure)\n",
        "        lbfgs_ls_acc_list.append(accuracy(modelLBFGS_LS, x_val_tensor, y_val_tensor, mb_size))\n",
        "        i+=1\n",
        "            \n",
        "    #print(f'accuracy: {lbfgs_ls_acc_list[-1]}')\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    lbfgs_ls_time = start.elapsed_time(end)\n",
        "\n",
        "    lbfgs_ls_acc = accuracy(modelLBFGS_LS, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return lbfgs_ls_acc_list, lbfgs_ls_cost_list, [0] ,lbfgs_ls_time, lbfgs_ls_acc"
      ],
      "metadata": {
        "id": "Uf2c7uz-pi_e"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados['lbfgs_ls'] = {}\n",
        "resultados['lbfgs_ls']['val_acc_list'] = [0] * epochs\n",
        "resultados['lbfgs_ls']['test_acc'] = 0\n",
        "resultados['lbfgs_ls']['cost'] = [0] * epochs\n",
        "resultados['lbfgs_ls']['time'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    lbfgs_ls_acc_list, lbfgs_ls_cost_list, lbfgs_ls_lr_list ,lbfgs_ls_time, lbfgs_ls_acc = LBFGS_LS()\n",
        "    resultados['lbfgs_ls']['val_acc_list'] = SumList(resultados['lbfgs_ls']['val_acc_list'], lbfgs_ls_acc_list)\n",
        "    resultados['lbfgs_ls']['test_acc'] += lbfgs_ls_acc\n",
        "    resultados['lbfgs_ls']['cost'] = SumList(resultados['lbfgs_ls']['cost'], lbfgs_ls_cost_list)\n",
        "    resultados['lbfgs_ls']['time'] += lbfgs_ls_time\n",
        "\n",
        "#Saving results\n",
        "resultados['lbfgs_ls']['name'] = 'LBFGS With LS'\n",
        "resultados['lbfgs_ls']['lr'] = lbfgs_ls_lr_list\n",
        "resultados['lbfgs_ls']['test_acc'] = resultados['lbfgs_ls']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['lbfgs_ls']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['lbfgs_ls']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['lbfgs_ls']['cost'] = DeleteZerosFromList(DivideList(resultados['lbfgs_ls']['cost'], MAX_ITERATIONS))\n",
        "resultados['lbfgs_ls']['time'] = resultados['lbfgs_ls']['time'] "
      ],
      "metadata": {
        "id": "RKTaRrfCpo7m"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_h21aMdgsB"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJQ2_Q_q-s3a"
      },
      "source": [
        "Al guardar todos los resultados de cada método en sus respectivos diccionarios, se procede a crear un dataframe con estos resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "7S5hiFtm-9xj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "resultados_df = pd.DataFrame(resultados.copy()).T\n",
        "\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: round(row['val_acc_list'][-1]* 100,2), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: round(row['test_acc']*100,2), axis=1)\n",
        "resultados_df['epochs'] = resultados_df.apply(lambda row: len(row['val_acc_list']), axis=1)\n",
        "resultados_df['time'] = resultados_df.apply(lambda row: round(row['time']/(1000),2), axis=1)\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['val_acc']), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['test_acc']), axis=1)\n",
        "\n",
        "resultados_df = resultados_df.sort_values(by=['test_acc'],ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Qelt3wIs3T"
      },
      "source": [
        "## Tiempos por epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "lruyulJ5C4SR",
        "outputId": "55ad8147-4437-49b9-a39c-1613e3a69f1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f50ccdab880>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_ba097_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"col_heading level0 col0\" >name</th>\n",
              "      <th class=\"col_heading level0 col1\" >val_acc</th>\n",
              "      <th class=\"col_heading level0 col2\" >time</th>\n",
              "      <th class=\"col_heading level0 col3\" >epochs</th>\n",
              "      <th class=\"col_heading level0 col4\" >test_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_ba097_row0_col0\" class=\"data row0 col0\" >Random Ciclico con Momentum</td>\n",
              "      <td id=\"T_ba097_row0_col1\" class=\"data row0 col1\" >98.07%</td>\n",
              "      <td id=\"T_ba097_row0_col2\" class=\"data row0 col2\" >248.740000</td>\n",
              "      <td id=\"T_ba097_row0_col3\" class=\"data row0 col3\" >100</td>\n",
              "      <td id=\"T_ba097_row0_col4\" class=\"data row0 col4\" >98.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ba097_row1_col0\" class=\"data row1 col0\" >LBFGS With LS</td>\n",
              "      <td id=\"T_ba097_row1_col1\" class=\"data row1 col1\" >98.05%</td>\n",
              "      <td id=\"T_ba097_row1_col2\" class=\"data row1 col2\" >312.730000</td>\n",
              "      <td id=\"T_ba097_row1_col3\" class=\"data row1 col3\" >100</td>\n",
              "      <td id=\"T_ba097_row1_col4\" class=\"data row1 col4\" >98.17%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ba097_row2_col0\" class=\"data row2 col0\" >Ciclico Con Momentum</td>\n",
              "      <td id=\"T_ba097_row2_col1\" class=\"data row2 col1\" >98.08%</td>\n",
              "      <td id=\"T_ba097_row2_col2\" class=\"data row2 col2\" >246.510000</td>\n",
              "      <td id=\"T_ba097_row2_col3\" class=\"data row2 col3\" >100</td>\n",
              "      <td id=\"T_ba097_row2_col4\" class=\"data row2 col4\" >98.13%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ba097_row3_col0\" class=\"data row3 col0\" >Adam</td>\n",
              "      <td id=\"T_ba097_row3_col1\" class=\"data row3 col1\" >97.76%</td>\n",
              "      <td id=\"T_ba097_row3_col2\" class=\"data row3 col2\" >241.150000</td>\n",
              "      <td id=\"T_ba097_row3_col3\" class=\"data row3 col3\" >100</td>\n",
              "      <td id=\"T_ba097_row3_col4\" class=\"data row3 col4\" >97.7%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "resultados_df[['name','val_acc','time', 'epochs','test_acc']].style.hide_index()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "ccfea65839ea7b4cb7611917847ae955f8a5d3f7496a05c88f3bf628abe673bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}