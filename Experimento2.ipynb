{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisPerez/NN_Tests_DG/blob/main/Experimento2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgNAaM97oPwU"
      },
      "source": [
        "Tomar referencia de los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBCruOrtR_cV",
        "outputId": "0f3a9931-a845-4b27-fd2a-64c680f4e3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NN_Tests_DG'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 65 (delta 25), reused 45 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (65/65), 12.89 MiB | 7.18 MiB/s, done.\n",
            "/content/NN_Tests_DG/NN_Tests_DG/NN_Tests_DG/NN_Tests_DG/NN_Tests_DG\n",
            "\u001b[0m\u001b[01;34mDataset\u001b[0m/          Iteracion1_new.ipynb      NN_from_Scratch.ipynb\n",
            "Decay.ipynb       Iteracion_2.ipynb         NN_Pytorch.ipynb\n",
            "get_images.py     Iteracion3_Mejores.ipynb  SGD_Momentum_RMSProp_Adam.ipynb\n",
            "Iteracion1.ipynb  LearningRateStudy.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git clone https://ginpg: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@github.com/DenisPerez/NN_Tests_DG\n",
        "%cd NN_Tests_DG\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "F4gP7LPQTtg7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from get_images import get_images\n",
        "\n",
        "# PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mULGvWTthB"
      },
      "source": [
        "# Get Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "9vdIQd58TthD"
      },
      "outputs": [],
      "source": [
        "MNIST_PATH = './Dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "slQPSqQeTthE"
      },
      "outputs": [],
      "source": [
        "x_train_num, y_train_num, x_test_num, y_test_num = get_images(MNIST_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "HFnaRwd-TthE"
      },
      "outputs": [],
      "source": [
        "#Training set\n",
        "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)/255 ##Convert the traint set into a (50000, 28x28) matrix normalized\n",
        "y_train = y_train_num[:50000].reshape(50000,1)\n",
        "\n",
        "##Validation set\n",
        "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)/255\n",
        "y_val = y_train_num[50000:].reshape(10000,1)\n",
        "\n",
        "##Test set\n",
        "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)/255\n",
        "y_test = y_test_num.copy().reshape(10000,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZz8hG0OTthF"
      },
      "source": [
        "## Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "_kFtDZs6TthG"
      },
      "outputs": [],
      "source": [
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "KYhJenIZTthG"
      },
      "outputs": [],
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRx3THErTthH",
        "outputId": "e184726f-aa13-4843-b336-d6b8b05dd4fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.5686665e-08, 0.9999983)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMAv3EVXTthJ"
      },
      "source": [
        "## Show Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHHAe687TthJ",
        "outputId": "30e22f7b-dd5e-4147-8f8b-976e64e24a2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_FPmhofTthK",
        "outputId": "9a0c5ad8-b07f-4b80-938d-e74d35147302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "w4HfkSTqTthK"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7TQtWTpZTthL",
        "outputId": "46dbd2df-adcc-4568-ef92-cb8f7e70ffe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La imagen muestreada representa un: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
        "plot_number(x_test_num[rnd_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVo-PF6cTthM"
      },
      "source": [
        "## Create Mini Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "Ym639R_PTthM"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(x, y, mb_size, shuffle = True):\n",
        "    '''\n",
        "    x  #muestras, input_layer\n",
        "    y #muestras, 1\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle: \n",
        "        idxs = np.arange(total_data, dtype=float)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]  \n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Ypqe6nTthN"
      },
      "source": [
        "# Pytorch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "6quE_eQ9TthO"
      },
      "outputs": [],
      "source": [
        "x_train_tensor = torch.Tensor(x_train.copy())\n",
        "y_train_tensor = torch.Tensor(y_train.copy())\n",
        "\n",
        "x_val_tensor = torch.Tensor(x_val.copy())\n",
        "y_val_tensor = torch.Tensor(y_val.copy())\n",
        "\n",
        "x_test_tensor = torch.Tensor(x_test.copy())\n",
        "y_test_tensor = torch.Tensor(y_test.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqPgXB1DTthP"
      },
      "source": [
        "## Use GPU when available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1oc0PTWTthQ",
        "outputId": "5457de33-4028-4c09-a65e-52814668fafc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZebY-iBHTthQ",
        "outputId": "e0bf7a94-038f-4133-a08c-14112ccefaa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estamos usando: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Estamos usando: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L66abJ9WTthR"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "Zt6iiZyuTthR"
      },
      "outputs": [],
      "source": [
        "def accuracy(model: nn.Sequential, x: torch.tensor, y: torch.tensor, mb_size: int):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) # mb_size, 10\n",
        "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
        "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
        "            num_total += pred.size(0)\n",
        "\n",
        "            return float(num_correct)/num_total  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4DuKf3TthR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "HtRDD6Nu0507"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler: None, mb_size):\n",
        "    model = model.to(device=device)\n",
        "    epoch_acc = 0.0\n",
        "    i = 0\n",
        "    #plot lists\n",
        "    acc_list = [0.0]\n",
        "    cost_list = [0.0]\n",
        "    lr_list = [0.0]\n",
        "    while (epoch_acc < 0.95 and i < 100):\n",
        "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "            # cost function\n",
        "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
        "            optimizer.zero_grad()\n",
        "            cost.backward()\n",
        "            for name, param in model.named_parameters():\n",
        "              ik = str(name)+'_'+str(i)\n",
        "              prev_ik = str(name)+'_'+str(i-1)\n",
        "            optimizer.step()\n",
        "        if (scheduler != None):\n",
        "          scheduler.step()\n",
        "          lr = scheduler.get_last_lr()\n",
        "          lr_list.append(lr[0])\n",
        "        else: \n",
        "          lr_list.append(optimizer.param_groups[0]['lr'])\n",
        "        i+=1\n",
        "        epoch_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
        "        epoch_cost = cost.item()\n",
        "\n",
        "        #append\n",
        "        acc_list.append(epoch_acc)\n",
        "        cost_list.append(epoch_cost)\n",
        "        # print(f'Epoch: {len(acc_list)}, learning_rate:{lr},costo: {epoch_cost}, accuracy: {epoch_acc}')\n",
        "    return acc_list, cost_list, lr_list, i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6xxVksqR95C"
      },
      "source": [
        "## List Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "5aJV7jOTR95D"
      },
      "outputs": [],
      "source": [
        "def SumList(first: list, second: list) -> list:\n",
        "    return [x + y for x, y in zip(first[::-1], second[::-1])][::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "I51hZdnHR95D"
      },
      "outputs": [],
      "source": [
        "def DivideList(dic_list: list, number: int) -> list:\n",
        "    return [x / number for x in dic_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "y6ro6TQRR95E"
      },
      "outputs": [],
      "source": [
        "def DeleteZerosFromList(dic_list: list) -> list:\n",
        "    return list(filter(lambda num: num != 0, dic_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "015SGTIaTthS"
      },
      "source": [
        "# Experimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ2qa3c-eS1L"
      },
      "source": [
        "Global var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "WBDuey1VQTm4"
      },
      "outputs": [],
      "source": [
        "MAX_ITERATIONS = 5\n",
        "layer1 = 1000 \n",
        "layer2 = 1000\n",
        "lr = 1e-2\n",
        "epochs = 100\n",
        "mb_size = 4096\n",
        "input_layer = 784\n",
        "first_i = 0\n",
        "\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "resultados = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mAWn11Vmc6-"
      },
      "source": [
        "## Cíclico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "_DdXVK_ZR95I"
      },
      "outputs": [],
      "source": [
        "def Cyclic():\n",
        "    modelCyclic = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelCyclic.parameters(), lr=lr)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3,cycle_momentum=False )\n",
        "\n",
        "    start.record()\n",
        "    cyclic_acc_list, cyclic_cost_list, cyclic_lr_list, cyclic_epochs= train(modelCyclic, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    cyclic_time = start.elapsed_time(end)\n",
        "\n",
        "    cyclic_acc = accuracy(modelCyclic, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return cyclic_acc_list, cyclic_cost_list, cyclic_lr_list, cyclic_time, cyclic_acc, cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "qWp659FGmhDK"
      },
      "outputs": [],
      "source": [
        "resultados['cyclic'] = {}\n",
        "resultados['cyclic']['val_acc_list'] = [0]* epochs\n",
        "resultados['cyclic']['test_acc'] = 0\n",
        "resultados['cyclic']['cost'] = [0] * epochs\n",
        "resultados['cyclic']['time'] = 0\n",
        "resultados['cyclic']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    cyclic_acc_list, cyclic_cost_list, cyclic_lr_list, cyclic_time, cyclic_acc, cyclic_epochs = Cyclic()\n",
        "    resultados['cyclic']['val_acc_list'] = SumList(resultados['cyclic']['val_acc_list'], cyclic_acc_list)\n",
        "    resultados['cyclic']['test_acc'] += cyclic_acc\n",
        "    resultados['cyclic']['cost'] = SumList(resultados['cyclic']['cost'], cyclic_cost_list)\n",
        "    resultados['cyclic']['time'] += cyclic_time\n",
        "    resultados['cyclic']['time'] += cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['cyclic']['name'] = 'Ciclico'\n",
        "resultados['cyclic']['lr'] = cyclic_lr_list\n",
        "resultados['cyclic']['test_acc'] = resultados['cyclic']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['cyclic']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['cyclic']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['cyclic']['cost'] = DeleteZerosFromList(DivideList(resultados['cyclic']['cost'], MAX_ITERATIONS))\n",
        "resultados['cyclic']['time'] = resultados['cyclic']\n",
        "resultados['cyclic']['epochs'] = resultados['cyclic']['epochs']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj0arCxmZdxw"
      },
      "source": [
        "## Cyclic Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "9vrI2SE_3zaR"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Optimizer\n",
        "\n",
        "import types\n",
        "import math\n",
        "from torch._six import inf\n",
        "from functools import wraps\n",
        "import warnings\n",
        "import weakref\n",
        "import random\n",
        "\n",
        "class _LRSchedulerGiselt_Denis(object):\n",
        "\n",
        "    def __init__(self, optimizer, last_epoch=-1, verbose=False):\n",
        "\n",
        "        # Attach optimizer\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # Initialize epoch and base learning rates\n",
        "        if last_epoch == -1:\n",
        "            for group in optimizer.param_groups:\n",
        "                group.setdefault('initial_lr', group['lr'])\n",
        "        else:\n",
        "            for i, group in enumerate(optimizer.param_groups):\n",
        "                if 'initial_lr' not in group:\n",
        "                    raise KeyError(\"param 'initial_lr' is not specified \"\n",
        "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
        "        self.base_lrs = [group['initial_lr'] for group in optimizer.param_groups]\n",
        "        self.last_epoch = last_epoch\n",
        "\n",
        "        # Following https://github.com/pytorch/pytorch/issues/20124\n",
        "        # We would like to ensure that `lr_scheduler.step()` is called after\n",
        "        # `optimizer.step()`\n",
        "        def with_counter(method):\n",
        "            if getattr(method, '_with_counter', False):\n",
        "                # `optimizer.step()` has already been replaced, return.\n",
        "                return method\n",
        "\n",
        "            # Keep a weak reference to the optimizer instance to prevent\n",
        "            # cyclic references.\n",
        "            instance_ref = weakref.ref(method.__self__)\n",
        "            # Get the unbound method for the same purpose.\n",
        "            func = method.__func__\n",
        "            cls = instance_ref().__class__\n",
        "            del method\n",
        "\n",
        "            @wraps(func)\n",
        "            def wrapper(*args, **kwargs):\n",
        "                instance = instance_ref()\n",
        "                instance._step_count += 1\n",
        "                wrapped = func.__get__(instance, cls)\n",
        "                return wrapped(*args, **kwargs)\n",
        "\n",
        "            # Note that the returned function here is no longer a bound method,\n",
        "            # so attributes like `__func__` and `__self__` no longer exist.\n",
        "            wrapper._with_counter = True\n",
        "            return wrapper\n",
        "\n",
        "        self.optimizer.step = with_counter(self.optimizer.step)\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self._initial_step()\n",
        "\n",
        "    def _initial_step(self):\n",
        "        \"\"\"Initialize step counts and performs a step\"\"\"\n",
        "        self.optimizer._step_count = 0\n",
        "        self._step_count = 0\n",
        "        self.step()\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
        "\n",
        "        It contains an entry for every variable in self.__dict__ which\n",
        "        is not the optimizer.\n",
        "        \"\"\"\n",
        "        return {key: value for key, value in self.__dict__.items() if key != 'optimizer'}\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        \"\"\"Loads the schedulers state.\n",
        "\n",
        "        Args:\n",
        "            state_dict (dict): scheduler state. Should be an object returned\n",
        "                from a call to :meth:`state_dict`.\n",
        "        \"\"\"\n",
        "        self.__dict__.update(state_dict)\n",
        "\n",
        "    def get_last_lr(self):\n",
        "        \"\"\" Return last computed learning rate by current scheduler.\n",
        "        \"\"\"\n",
        "        return self._last_lr\n",
        "\n",
        "    def get_lr(self):\n",
        "        # Compute learning rate using chainable form of the scheduler\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def print_lr(self, is_verbose, group, lr, epoch=None):\n",
        "        \"\"\"Display the current learning rate.\n",
        "        \"\"\"\n",
        "        if is_verbose:\n",
        "            if epoch is None:\n",
        "                print('Adjusting learning rate'\n",
        "                      ' of group {} to {:.4e}.'.format(group, lr))\n",
        "            else:\n",
        "                epoch_str = (\"%.2f\" if isinstance(epoch, float) else\n",
        "                             \"%.5d\") % epoch\n",
        "                print('Epoch {}: adjusting learning rate'\n",
        "                      ' of group {} to {:.4e}.'.format(epoch_str, group, lr))\n",
        "\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        # Raise a warning if old pattern is detected\n",
        "        # https://github.com/pytorch/pytorch/issues/20124\n",
        "        if self._step_count == 1:\n",
        "            if not hasattr(self.optimizer.step, \"_with_counter\"):\n",
        "                warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
        "                              \"initialization. Please, make sure to call `optimizer.step()` before \"\n",
        "                              \"`lr_scheduler.step()`. See more details at \"\n",
        "                              \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
        "\n",
        "            # Just check if there were two first lr_scheduler.step() calls before optimizer.step()\n",
        "            elif self.optimizer._step_count < 1:\n",
        "                warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
        "                              \"In PyTorch 1.1.0 and later, you should call them in the opposite order: \"\n",
        "                              \"`optimizer.step()` before `lr_scheduler.step()`.  Failure to do this \"\n",
        "                              \"will result in PyTorch skipping the first value of the learning rate schedule. \"\n",
        "                              \"See more details at \"\n",
        "                              \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
        "        self._step_count += 1\n",
        "\n",
        "        class _enable_get_lr_call:\n",
        "\n",
        "            def __init__(self, o):\n",
        "                self.o = o\n",
        "\n",
        "            def __enter__(self):\n",
        "                self.o._get_lr_called_within_step = True\n",
        "                return self\n",
        "\n",
        "            def __exit__(self, type, value, traceback):\n",
        "                self.o._get_lr_called_within_step = False\n",
        "\n",
        "        with _enable_get_lr_call(self):\n",
        "            if epoch is None:\n",
        "                self.last_epoch += 1\n",
        "                values = self.get_lr()\n",
        "            else:\n",
        "                warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
        "                self.last_epoch = epoch\n",
        "                if hasattr(self, \"_get_closed_form_lr\"):\n",
        "                    values = self._get_closed_form_lr()\n",
        "                else:\n",
        "                    values = self.get_lr()\n",
        "\n",
        "        for i, data in enumerate(zip(self.optimizer.param_groups, values)):\n",
        "            param_group, lr = data\n",
        "            param_group['lr'] = lr\n",
        "            self.print_lr(self.verbose, i, lr, epoch)\n",
        "\n",
        "        self._last_lr = [group['lr'] for group in self.optimizer.param_groups]\n",
        "\n",
        "class CyclicLRGiselt_Denis(_LRSchedulerGiselt_Denis):\n",
        "    r\"\"\"Sets the learning rate of each parameter group according to\n",
        "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
        "    rate between two boundaries with a constant frequency, as detailed in\n",
        "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
        "    The distance between the two boundaries can be scaled on a per-iteration\n",
        "    or per-cycle basis.\n",
        "\n",
        "    Cyclical learning rate policy changes the learning rate after every batch.\n",
        "    `step` should be called after a batch has been used for training.\n",
        "\n",
        "    This class has three built-in policies, as put forth in the paper:\n",
        "\n",
        "    * \"triangular\": A basic triangular cycle without amplitude scaling.\n",
        "    * \"triangular2\": A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    * \"exp_range\": A cycle that scales initial amplitude by :math:`\\text{gamma}^{\\text{cycle iterations}}`\n",
        "      at each cycle iteration.\n",
        "\n",
        "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
        "\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        base_lr (float or list): Initial learning rate which is the\n",
        "            lower boundary in the cycle for each parameter group.\n",
        "        max_lr (float or list): Upper learning rate boundaries in the cycle\n",
        "            for each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size_up (int): Number of training iterations in the\n",
        "            increasing half of a cycle. Default: 2000\n",
        "        step_size_down (int): Number of training iterations in the\n",
        "            decreasing half of a cycle. If step_size_down is None,\n",
        "            it is set to step_size_up. Default: None\n",
        "        mode (str): One of {triangular, triangular2, exp_range}.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "            Default: 'triangular'\n",
        "        gamma (float): Constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "            Default: 1.0\n",
        "        scale_fn (function): Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            If specified, then 'mode' is ignored.\n",
        "            Default: None\n",
        "        scale_mode (str): {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle).\n",
        "            Default: 'cycle'\n",
        "        cycle_momentum (bool): If ``True``, momentum is cycled inversely\n",
        "            to learning rate between 'base_momentum' and 'max_momentum'.\n",
        "            Default: True\n",
        "        base_momentum (float or list): Lower momentum boundaries in the cycle\n",
        "            for each parameter group. Note that momentum is cycled inversely\n",
        "            to learning rate; at the peak of a cycle, momentum is\n",
        "            'base_momentum' and learning rate is 'max_lr'.\n",
        "            Default: 0.8\n",
        "        max_momentum (float or list): Upper momentum boundaries in the cycle\n",
        "            for each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_momentum - base_momentum).\n",
        "            The momentum at any cycle is the difference of max_momentum\n",
        "            and some scaling of the amplitude; therefore\n",
        "            base_momentum may not actually be reached depending on\n",
        "            scaling function. Note that momentum is cycled inversely\n",
        "            to learning rate; at the start of a cycle, momentum is 'max_momentum'\n",
        "            and learning rate is 'base_lr'\n",
        "            Default: 0.9\n",
        "        last_epoch (int): The index of the last batch. This parameter is used when\n",
        "            resuming a training job. Since `step()` should be invoked after each\n",
        "            batch instead of after each epoch, this number represents the total\n",
        "            number of *batches* computed, not the total number of epochs computed.\n",
        "            When last_epoch=-1, the schedule is started from the beginning.\n",
        "            Default: -1\n",
        "        verbose (bool): If ``True``, prints a message to stdout for\n",
        "            each update. Default: ``False``.\n",
        "\n",
        "    Example:\n",
        "        >>> # xdoctest: +SKIP\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n",
        "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     for batch in data_loader:\n",
        "        >>>         train_batch(...)\n",
        "        >>>         scheduler.step()\n",
        "\n",
        "\n",
        "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 optimizer,\n",
        "                 base_lr,\n",
        "                 max_lr,\n",
        "                 step_size_up=2000,\n",
        "                 step_size_down=None,\n",
        "                 mode='triangular',\n",
        "                 gamma=1.,\n",
        "                 scale_fn=None,\n",
        "                 scale_mode='cycle',\n",
        "                 cycle_momentum=True,\n",
        "                 base_momentum=0.8,\n",
        "                 max_momentum=0.9,\n",
        "                 last_epoch=-1,\n",
        "                 verbose=False):\n",
        "\n",
        "        # Attach optimizer\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "        self.direction_up = True\n",
        "        self.half_cycle_steps = 0\n",
        "\n",
        "        base_lrs = self._format_param('base_lr', optimizer, base_lr)\n",
        "        if last_epoch == -1:\n",
        "            for lr, group in zip(base_lrs, optimizer.param_groups):\n",
        "                group['lr'] = lr\n",
        "\n",
        "        self.max_lrs = self._format_param('max_lr', optimizer, max_lr)\n",
        "\n",
        "        self.step_size_up = float(step_size_up)\n",
        "        self.step_size_down = float(step_size_down) if step_size_down is not None else step_size_up\n",
        "        self.total_size = self.step_size_up + self.step_size_down\n",
        "        self.step_ratio = step_size_up / self.total_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            self._scale_fn_custom = None\n",
        "            if self.mode == 'triangular':\n",
        "                self._scale_fn_ref = weakref.WeakMethod(self._triangular_scale_fn)\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self._scale_fn_ref = weakref.WeakMethod(self._triangular2_scale_fn)\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self._scale_fn_ref = weakref.WeakMethod(self._exp_range_scale_fn)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self._scale_fn_custom = scale_fn\n",
        "            self._scale_fn_ref = None\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.cycle_momentum = cycle_momentum\n",
        "        if cycle_momentum:\n",
        "            if 'momentum' not in optimizer.defaults:\n",
        "                raise ValueError('optimizer must support momentum with `cycle_momentum` option enabled')\n",
        "\n",
        "            base_momentums = self._format_param('base_momentum', optimizer, base_momentum)\n",
        "            if last_epoch == -1:\n",
        "                for momentum, group in zip(base_momentums, optimizer.param_groups):\n",
        "                    group['momentum'] = momentum\n",
        "            self.base_momentums = [group['momentum'] for group in optimizer.param_groups]\n",
        "            self.max_momentums = self._format_param('max_momentum', optimizer, max_momentum)\n",
        "\n",
        "        super(CyclicLRGiselt_Denis, self).__init__(optimizer, last_epoch, verbose)\n",
        "        self.base_lrs = base_lrs\n",
        "\n",
        "    def _format_param(self, name, optimizer, param):\n",
        "        \"\"\"Return correctly formatted lr/momentum for each param group.\"\"\"\n",
        "        if isinstance(param, (list, tuple)):\n",
        "            if len(param) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} values for {}, got {}\".format(\n",
        "                    len(optimizer.param_groups), name, len(param)))\n",
        "            return param\n",
        "        else:\n",
        "            return [param] * len(optimizer.param_groups)\n",
        "\n",
        "    def scale_fn(self, x):\n",
        "        if self._scale_fn_custom is not None:\n",
        "            # print(self.half_cycle_steps, x)\n",
        "            return self._scale_fn_custom(x)\n",
        "\n",
        "        else:\n",
        "            return self._scale_fn_ref()(x)\n",
        "\n",
        "    def scale_fn_rand(self, x, y):\n",
        "        return random.uniform(x, y)\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        \"\"\"Calculates the learning rate at batch index. This function treats\n",
        "        `self.last_epoch` as the last batch index.\n",
        "\n",
        "        If `self.cycle_momentum` is ``True``, this function has a side effect of\n",
        "        updating the optimizer's momentum.\n",
        "        \"\"\"\n",
        "        \n",
        "\n",
        "        if not self._get_lr_called_within_step:\n",
        "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
        "                          \"please use `get_last_lr()`.\", UserWarning)\n",
        "\n",
        "        cycle = math.floor(1 + self.last_epoch / self.total_size)\n",
        "        x = 1. + self.last_epoch / self.total_size - cycle\n",
        "        if x <= self.step_ratio:\n",
        "            scale_factor = x / self.step_ratio\n",
        "        else:\n",
        "            scale_factor = (x - 1) / (self.step_ratio - 1)\n",
        "\n",
        "        lrs = []\n",
        "        for base_lr, max_lr in zip(self.base_lrs, self.max_lrs):\n",
        "            base_height = (max_lr - base_lr) * scale_factor\n",
        "            if self.scale_mode == 'cycle':\n",
        "\n",
        "                # print(\"cycle\")\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            elif self.scale_mode == 'iterations':\n",
        "\n",
        "                # print(\"iterations\")\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_epoch)\n",
        "\n",
        "            elif self.scale_mode == 'decrecimiento':\n",
        "                if (self.last_epoch == 0):\n",
        "                  lr = max_lr\n",
        "                else: \n",
        "                  lr = self.get_last_lr()[0] - base_lr\n",
        "                  if (lr<0):\n",
        "                    lr = base_lr\n",
        "\n",
        "            elif self.scale_mode == 'chipichipi':                               #<--------------------------\n",
        "                \n",
        "                '''\n",
        "                for x in optimizer.param_groups:\n",
        "                  for each in x['params']:\n",
        "                    print(each)\n",
        "                \n",
        "                for name, param in modelBB.named_parameters():\n",
        "                  print(param.grad.shape)\n",
        "                '''\n",
        "\n",
        "                # print(\"chipichipi\")\n",
        "                if (self.last_epoch == 0):\n",
        "                    last_lr = base_lr\n",
        "                else:\n",
        "                    last_lr = self.get_last_lr()[0]\n",
        "                    # print(f\"Esto es el ultimo lr {last_lr}\")\n",
        "\n",
        "                if (self.half_cycle_steps == self.step_size_up\n",
        "                    and self.direction_up == True):\n",
        "                    #print('Cambio de direccion: bajando')\n",
        "                    lr = random.uniform(last_lr, max_lr)\n",
        "                    self.direction_up = False\n",
        "                    self.half_cycle_steps = 1\n",
        "\n",
        "                elif (self.half_cycle_steps == self.step_size_down\n",
        "                    and self.direction_up == False):\n",
        "                    #print('Cambio de direccion: subiendo')\n",
        "                    lr = random.uniform(base_lr, last_lr)\n",
        "                    self.direction_up = True\n",
        "                    self.half_cycle_steps = 1\n",
        "\n",
        "                elif (self.direction_up == True):\n",
        "                    lr = random.uniform(last_lr, max_lr)\n",
        "                    self.half_cycle_steps += 1\n",
        "\n",
        "                elif(self.direction_up == False):\n",
        "                    lr = random.uniform(base_lr, last_lr)\n",
        "                    self.half_cycle_steps += 1\n",
        "            #print('base_lr: '+str(base_lr))\n",
        "            lrs.append(lr)\n",
        "\n",
        "        if self.cycle_momentum:\n",
        "            #print('wowo')\n",
        "            momentums = []\n",
        "            for base_momentum, max_momentum in zip(self.base_momentums, self.max_momentums):\n",
        "                base_height = (max_momentum - base_momentum) * scale_factor\n",
        "                if self.scale_mode == 'cycle':\n",
        "                    momentum = max_momentum - base_height * self.scale_fn(cycle)\n",
        "                else:\n",
        "                    momentum = max_momentum - base_height * self.scale_fn(self.last_epoch)\n",
        "                #print('momentum: '+str(max_momentum)+' '+str(base_momentum))\n",
        "                momentums.append(momentum)\n",
        "            for param_group, momentum in zip(self.optimizer.param_groups, momentums):\n",
        "                param_group['momentum'] = momentum\n",
        "            \n",
        "        return lrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f8ZZZ1Hcg2R"
      },
      "source": [
        "## Cíclico aleatoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "jywqBaWVR95N"
      },
      "outputs": [],
      "source": [
        "def CyclicGD():\n",
        "    import random\n",
        "    modelRandomCyclic = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelRandomCyclic.parameters(), lr=lr)\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3, scale_fn=clr_fn,scale_mode='chipichipi', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    random_cyclic_acc_list, random_cyclic_cost_list, random_cyclic_lr_list, random_cyclic_epochs= train(modelRandomCyclic, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    random_cyclic_time = start.elapsed_time(end)\n",
        "\n",
        "    random_cyclic_acc = accuracy(modelRandomCyclic, x_test_tensor,  y_test_tensor, mb_size) \n",
        "\n",
        "    return random_cyclic_acc_list, random_cyclic_cost_list, random_cyclic_lr_list, random_cyclic_time, random_cyclic_acc, random_cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "acBgxgGkZdL6"
      },
      "outputs": [],
      "source": [
        "resultados['random_cyclic'] = {}\n",
        "resultados['random_cyclic']['val_acc_list'] = [0] * epochs\n",
        "resultados['random_cyclic']['test_acc'] = 0\n",
        "resultados['random_cyclic']['cost'] = [0] * epochs\n",
        "resultados['random_cyclic']['time'] = 0\n",
        "resultados['random_cyclic']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    random_cyclic_acc_list, random_cyclic_cost_list, random_cyclic_lr_list, random_cyclic_time, random_cyclic_acc, random_cyclic_epochs = CyclicGD()\n",
        "    a = SumList(resultados['random_cyclic']['val_acc_list'], random_cyclic_acc_list)\n",
        "    resultados['random_cyclic']['val_acc_list'] = SumList(resultados['random_cyclic']['val_acc_list'], random_cyclic_acc_list)\n",
        "    resultados['random_cyclic']['test_acc'] += random_cyclic_acc\n",
        "    resultados['random_cyclic']['cost'] = SumList(resultados['random_cyclic']['cost'], random_cyclic_cost_list)\n",
        "    resultados['random_cyclic']['time'] += random_cyclic_time\n",
        "    resultados['random_cyclic']['epochs'] += random_cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['random_cyclic']['name'] = 'Random Ciclico'\n",
        "resultados['random_cyclic']['lr'] = random_cyclic_lr_list\n",
        "resultados['random_cyclic']['test_acc'] = resultados['random_cyclic']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['random_cyclic']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['random_cyclic']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic']['cost'] = DeleteZerosFromList(DivideList(resultados['random_cyclic']['cost'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic']['time'] = resultados['random_cyclic']['time']\n",
        "resultados['random_cyclic']['epochs'] = resultados['random_cyclic']['epochs']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzehV-6emhDY"
      },
      "source": [
        "## Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "Bt6bkSegR95R"
      },
      "outputs": [],
      "source": [
        "def SGDM():\n",
        "    modelSGDM = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimiserSGDM = torch.optim.SGD(modelSGDM.parameters(), lr=lr, momentum=0.9)\n",
        "    start.record()\n",
        "    SGDM_acc_list, SGDM_cost_list,SGDM_lr_list, SGDM_epochs = train(modelSGDM, optimiserSGDM,None, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    SGDM_time = start.elapsed_time(end)\n",
        "\n",
        "    SGDM_acc = accuracy(modelSGDM, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return SGDM_acc_list, SGDM_cost_list, SGDM_lr_list, SGDM_time, SGDM_acc, SGDM_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "U4bdgJL-mkx3"
      },
      "outputs": [],
      "source": [
        "resultados['SGDM'] = {}\n",
        "resultados['SGDM']['val_acc_list'] = [0] * epochs\n",
        "resultados['SGDM']['test_acc'] = 0\n",
        "resultados['SGDM']['cost'] = [0] * epochs\n",
        "resultados['SGDM']['time'] = 0\n",
        "resultados['SGDM']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    SGDM_acc_list, SGDM_cost_list, SGDM_lr_list, SGDM_time, SGDM_acc, SGDM_epochs = SGDM()\n",
        "    resultados['SGDM']['val_acc_list'] = SumList(resultados['SGDM']['val_acc_list'], SGDM_acc_list)\n",
        "    resultados['SGDM']['test_acc'] += SGDM_acc\n",
        "    resultados['SGDM']['cost'] = SumList(resultados['SGDM']['cost'], SGDM_cost_list)\n",
        "    resultados['SGDM']['time'] += SGDM_time\n",
        "    resultados['SGDM']['epochs'] += SGDM_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['SGDM']['name'] = 'Momentum'\n",
        "resultados['SGDM']['lr'] = SGDM_lr_list\n",
        "resultados['SGDM']['test_acc'] = resultados['SGDM']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['SGDM']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['SGDM']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['SGDM']['cost'] = DeleteZerosFromList(DivideList(resultados['SGDM']['cost'], MAX_ITERATIONS))\n",
        "resultados['SGDM']['time'] = resultados['SGDM']['time']\n",
        "resultados['SGDM']['epochs'] = resultados['SGDM']['epochs']\n",
        "\n",
        "# #Saving results\n",
        "# resultados['SGDM'] = {}\n",
        "# resultados['SGDM']['name'] = 'Momentum'\n",
        "# resultados['SGDM']['lr'] = [0]\n",
        "# resultados['SGDM']['val_acc_list'] = SGDM_acc_list\n",
        "# resultados['SGDM']['test_acc'] = SGDM_acc\n",
        "# resultados['SGDM']['cost'] = SGDM_cost_list\n",
        "# resultados['SGDM']['time'] = SGDM_time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nuestro decreciente"
      ],
      "metadata": {
        "id": "VWVaAGYywZbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Our_Decay():\n",
        "    modelOurDecay = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelOurDecay.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.0001, max_lr=0.1,scale_fn=clr_fn, step_size_up=1,scale_mode='decrecimiento', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_epochs = train(modelOurDecay,optimizer, scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    our_decay_time = start.elapsed_time(end)\n",
        "\n",
        "    our_decay_acc = accuracy(modelOurDecay, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs"
      ],
      "metadata": {
        "id": "874_mQHJwb3X"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados['our_decay'] = {}\n",
        "resultados['our_decay']['val_acc_list'] = [0] * epochs\n",
        "resultados['our_decay']['test_acc'] = 0\n",
        "resultados['our_decay']['cost'] = [0] * epochs\n",
        "resultados['our_decay']['time'] = 0\n",
        "resultados['our_decay']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs = Our_Decay()\n",
        "    resultados['our_decay']['val_acc_list'] = SumList(resultados['our_decay']['val_acc_list'], our_decay_acc_list)\n",
        "    resultados['our_decay']['test_acc'] += our_decay_acc\n",
        "    resultados['our_decay']['cost'] = SumList(resultados['our_decay']['cost'], our_decay_cost_list)\n",
        "    resultados['our_decay']['time'] += our_decay_time\n",
        "    resultados['our_decay']['epochs'] += our_decay_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['our_decay']['name'] = 'Nuestro decreciente'\n",
        "resultados['our_decay']['lr'] = our_decay_lr_list\n",
        "resultados['our_decay']['test_acc'] = resultados['our_decay']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['our_decay']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['our_decay']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['our_decay']['cost'] = DeleteZerosFromList(DivideList(resultados['our_decay']['cost'], MAX_ITERATIONS))\n",
        "resultados['our_decay']['time'] = resultados['our_decay']['time'] \n",
        "resultados['our_decay']['epochs'] = resultados['our_decay']['epochs'] / MAX_ITERATIONS"
      ],
      "metadata": {
        "id": "9f3dwRmBwe-2"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy_ipT4cV40p"
      },
      "source": [
        "## Cíclico con Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "z_1Gg-3eWMZr"
      },
      "outputs": [],
      "source": [
        "def CyclicMomentum():\n",
        "    modelCyclicMomentum = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelCyclicMomentum.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=3,cycle_momentum=False )\n",
        "\n",
        "    start.record()\n",
        "    cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_epochs = train(modelCyclicMomentum, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    cyclicMomentum_time = start.elapsed_time(end)\n",
        "\n",
        "    cyclicMomentum_acc = accuracy(modelCyclicMomentum, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_time, cyclicMomentum_acc, cyclicMomentum_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "GPA1FfOOWOtV"
      },
      "outputs": [],
      "source": [
        "resultados['cyclicMomentum'] = {}\n",
        "resultados['cyclicMomentum']['val_acc_list'] = [0]* epochs\n",
        "resultados['cyclicMomentum']['test_acc'] = 0\n",
        "resultados['cyclicMomentum']['cost'] = [0] * epochs\n",
        "resultados['cyclicMomentum']['time'] = 0\n",
        "resultados['cyclicMomentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    cyclicMomentum_acc_list, cyclicMomentum_cost_list, cyclicMomentum_lr_list, cyclicMomentum_time, cyclicMomentum_acc, cyclicMomentum_epochs = CyclicMomentum()\n",
        "    resultados['cyclicMomentum']['val_acc_list'] = SumList(resultados['cyclicMomentum']['val_acc_list'], cyclicMomentum_acc_list)\n",
        "    resultados['cyclicMomentum']['test_acc'] += cyclicMomentum_acc\n",
        "    resultados['cyclicMomentum']['cost'] = SumList(resultados['cyclicMomentum']['cost'], cyclicMomentum_cost_list)\n",
        "    resultados['cyclicMomentum']['time'] += cyclicMomentum_time\n",
        "    resultados['cyclicMomentum']['epochs'] += cyclicMomentum_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['cyclicMomentum']['name'] = 'Ciclico Con Momentum'\n",
        "resultados['cyclicMomentum']['lr'] = cyclicMomentum_lr_list\n",
        "resultados['cyclicMomentum']['test_acc'] = resultados['cyclicMomentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['cyclicMomentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['cyclicMomentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['cyclicMomentum']['cost'] = DeleteZerosFromList(DivideList(resultados['cyclicMomentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['cyclicMomentum']['time'] = resultados['cyclicMomentum']['time']\n",
        "resultados['cyclicMomentum']['epochs'] = resultados['cyclicMomentum']['epochs']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28gylOT-cNL5"
      },
      "source": [
        "## Cíclico aleatorio con Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "0_7uf-LUcQuE"
      },
      "outputs": [],
      "source": [
        "def CyclicGD_Momentum():\n",
        "    import random\n",
        "    modelRandomCyclic_Momentum= nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                        nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelRandomCyclic_Momentum.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.01, max_lr=0.1,step_size_up=2, scale_fn=clr_fn,scale_mode='chipichipi', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_epochs= train(modelRandomCyclic_Momentum, optimizer,scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    random_cyclic_Momentum_time = start.elapsed_time(end)\n",
        "\n",
        "    random_cyclic_Momentum_acc = accuracy(modelRandomCyclic_Momentum, x_test_tensor,  y_test_tensor, mb_size) \n",
        "\n",
        "    return random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_Momentum_time, random_cyclic_Momentum_acc, random_cyclic_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "Zikwca8lcrI-"
      },
      "outputs": [],
      "source": [
        "resultados['random_cyclic_Momentum'] = {}\n",
        "resultados['random_cyclic_Momentum']['val_acc_list'] = [0] * epochs\n",
        "resultados['random_cyclic_Momentum']['test_acc'] = 0\n",
        "resultados['random_cyclic_Momentum']['cost'] = [0] * epochs\n",
        "resultados['random_cyclic_Momentum']['time'] = 0\n",
        "resultados['random_cyclic_Momentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    random_cyclic_Momentum_acc_list, random_cyclic_Momentum_cost_list, random_cyclic_Momentum_lr_list, random_cyclic_Momentum_time, random_cyclic_Momentum_acc, random_cyclic_epochs = CyclicGD_Momentum()\n",
        "    a = SumList(resultados['random_cyclic_Momentum']['val_acc_list'], random_cyclic_Momentum_acc_list)\n",
        "    resultados['random_cyclic_Momentum']['val_acc_list'] = SumList(resultados['random_cyclic_Momentum']['val_acc_list'], random_cyclic_Momentum_acc_list)\n",
        "    resultados['random_cyclic_Momentum']['test_acc'] += random_cyclic_Momentum_acc\n",
        "    resultados['random_cyclic_Momentum']['cost'] = SumList(resultados['random_cyclic_Momentum']['cost'], random_cyclic_Momentum_cost_list)\n",
        "    resultados['random_cyclic_Momentum']['time'] += random_cyclic_Momentum_time\n",
        "    resultados['random_cyclic_Momentum']['epochs'] += random_cyclic_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['random_cyclic_Momentum']['name'] = 'Random Ciclico con Momentum'\n",
        "resultados['random_cyclic_Momentum']['lr'] = random_cyclic_Momentum_lr_list\n",
        "resultados['random_cyclic_Momentum']['test_acc'] = resultados['random_cyclic_Momentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['random_cyclic_Momentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['random_cyclic_Momentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic_Momentum']['cost'] = DeleteZerosFromList(DivideList(resultados['random_cyclic_Momentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['random_cyclic_Momentum']['time'] = resultados['random_cyclic_Momentum']['time']\n",
        "resultados['random_cyclic_Momentum']['epochs'] = resultados['random_cyclic_Momentum']['epochs']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nuestro decreciente con Momentum"
      ],
      "metadata": {
        "id": "YH7jqvDOkCBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Our_DecayMomentum():\n",
        "    modelOurDecay = nn.Sequential(nn.Linear(in_features=input_layer, out_features=layer1), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer1, out_features=layer2), nn.ReLU(),\n",
        "                       nn.Linear(in_features=layer2, out_features=10))\n",
        "    optimizer = torch.optim.SGD(modelOurDecay.parameters(), lr=1, momentum=0.9)\n",
        "\n",
        "\n",
        "    clr_fn = lambda x, y: random.uniform(x, y)\n",
        "    scheduler = CyclicLRGiselt_Denis(optimizer, base_lr=0.0001, max_lr=0.1,scale_fn=clr_fn, step_size_up=1,scale_mode='decrecimiento', cycle_momentum=False)\n",
        "\n",
        "    start.record()\n",
        "    our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_epochs = train(modelOurDecay,optimizer, scheduler, mb_size)\n",
        "    end.record()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    our_decay_time = start.elapsed_time(end)\n",
        "\n",
        "    our_decay_acc = accuracy(modelOurDecay, x_test_tensor,  y_test_tensor, mb_size)\n",
        "\n",
        "    return our_decay_acc_list, our_decay_cost_list, our_decay_lr_list, our_decay_time, our_decay_acc, our_decay_epochs"
      ],
      "metadata": {
        "id": "49T-DodfkFXZ"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados['our_decay_momentum'] = {}\n",
        "resultados['our_decay_momentum']['val_acc_list'] = [0] * epochs\n",
        "resultados['our_decay_momentum']['test_acc'] = 0\n",
        "resultados['our_decay_momentum']['cost'] = [0] * epochs\n",
        "resultados['our_decay_momentum']['time'] = 0\n",
        "resultados['our_decay_momentum']['epochs'] = 0\n",
        "\n",
        "for _ in range(MAX_ITERATIONS):\n",
        "    our_decay_momentum_acc_list, our_decay_momentum_cost_list, our_decay_momentum_lr_list, our_decay_momentum_time, our_decay_momentum_acc, our_decay_momentum_epochs = Our_DecayMomentum()\n",
        "    resultados['our_decay_momentum']['val_acc_list'] = SumList(resultados['our_decay_momentum']['val_acc_list'], our_decay_momentum_acc_list)\n",
        "    resultados['our_decay_momentum']['test_acc'] += our_decay_momentum_acc\n",
        "    resultados['our_decay_momentum']['cost'] = SumList(resultados['our_decay_momentum']['cost'], our_decay_momentum_cost_list)\n",
        "    resultados['our_decay_momentum']['time'] += our_decay_momentum_time\n",
        "    resultados['our_decay_momentum']['epochs'] += our_decay_momentum_epochs\n",
        "\n",
        "#Saving results\n",
        "resultados['our_decay_momentum']['name'] = 'Nuestro decreciente con Momentum'\n",
        "resultados['our_decay_momentum']['lr'] = our_decay_momentum_lr_list\n",
        "resultados['our_decay_momentum']['test_acc'] = resultados['our_decay_momentum']['test_acc'] / MAX_ITERATIONS\n",
        "resultados['our_decay_momentum']['val_acc_list'] = DeleteZerosFromList(DivideList(resultados['our_decay_momentum']['val_acc_list'], MAX_ITERATIONS))\n",
        "resultados['our_decay_momentum']['cost'] = DeleteZerosFromList(DivideList(resultados['our_decay_momentum']['cost'], MAX_ITERATIONS))\n",
        "resultados['our_decay_momentum']['time'] = resultados['our_decay_momentum']['time'] \n",
        "resultados['our_decay_momentum']['epochs'] = resultados['our_decay_momentum']['epochs'] / MAX_ITERATIONS"
      ],
      "metadata": {
        "id": "pmom3iiZkJP6"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_h21aMdgsB"
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJQ2_Q_q-s3a"
      },
      "source": [
        "Al guardar todos los resultados de cada método en sus respectivos diccionarios, se procede a crear un dataframe con estos resultados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, _ in resultados.items():\n",
        "    if( resultados[key]['val_acc_list'][0] == 0 ):\n",
        "        continue\n",
        "    resultados[key]['val_acc_list'].insert(0,0)"
      ],
      "metadata": {
        "id": "niADA484gEHD"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "7S5hiFtm-9xj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "resultados_df = pd.DataFrame(resultados.copy()).T\n",
        "\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: round(row['val_acc_list'][-1]* 100,2), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: round(row['test_acc']*100,2), axis=1)\n",
        "resultados_df['epochs'] = resultados_df.apply(lambda row: len(row['val_acc_list']), axis=1)\n",
        "resultados_df['val_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['val_acc']), axis=1)\n",
        "resultados_df['test_acc'] = resultados_df.apply(lambda row: '{acc}%'.format(acc = row['test_acc']), axis=1)\n",
        "\n",
        "resultados_df = resultados_df.sort_values(by=['epochs'],ascending=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Qelt3wIs3T"
      },
      "source": [
        "## Tiempos por epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "lruyulJ5C4SR",
        "outputId": "27e76ae8-2f6a-47bc-e7e1-c6213c575ef1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f707ef6feb0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_437c1_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"col_heading level0 col0\" >name</th>\n",
              "      <th class=\"col_heading level0 col1\" >test_acc</th>\n",
              "      <th class=\"col_heading level0 col2\" >val_acc</th>\n",
              "      <th class=\"col_heading level0 col3\" >epochs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row0_col0\" class=\"data row0 col0\" >Nuestro decreciente con Momentum</td>\n",
              "      <td id=\"T_437c1_row0_col1\" class=\"data row0 col1\" >94.95%</td>\n",
              "      <td id=\"T_437c1_row0_col2\" class=\"data row0 col2\" >95.59%</td>\n",
              "      <td id=\"T_437c1_row0_col3\" class=\"data row0 col3\" >5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row1_col0\" class=\"data row1 col0\" >Random Ciclico con Momentum</td>\n",
              "      <td id=\"T_437c1_row1_col1\" class=\"data row1 col1\" >94.94%</td>\n",
              "      <td id=\"T_437c1_row1_col2\" class=\"data row1 col2\" >95.47%</td>\n",
              "      <td id=\"T_437c1_row1_col3\" class=\"data row1 col3\" >6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row2_col0\" class=\"data row2 col0\" >Ciclico Con Momentum</td>\n",
              "      <td id=\"T_437c1_row2_col1\" class=\"data row2 col1\" >94.64%</td>\n",
              "      <td id=\"T_437c1_row2_col2\" class=\"data row2 col2\" >95.32%</td>\n",
              "      <td id=\"T_437c1_row2_col3\" class=\"data row2 col3\" >8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row3_col0\" class=\"data row3 col0\" >Nuestro decreciente</td>\n",
              "      <td id=\"T_437c1_row3_col1\" class=\"data row3 col1\" >94.48%</td>\n",
              "      <td id=\"T_437c1_row3_col2\" class=\"data row3 col2\" >95.29%</td>\n",
              "      <td id=\"T_437c1_row3_col3\" class=\"data row3 col3\" >24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row4_col0\" class=\"data row4 col0\" >Momentum</td>\n",
              "      <td id=\"T_437c1_row4_col1\" class=\"data row4 col1\" >94.62%</td>\n",
              "      <td id=\"T_437c1_row4_col2\" class=\"data row4 col2\" >95.2%</td>\n",
              "      <td id=\"T_437c1_row4_col3\" class=\"data row4 col3\" >27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row5_col0\" class=\"data row5 col0\" >Random Ciclico</td>\n",
              "      <td id=\"T_437c1_row5_col1\" class=\"data row5 col1\" >94.41%</td>\n",
              "      <td id=\"T_437c1_row5_col2\" class=\"data row5 col2\" >95.16%</td>\n",
              "      <td id=\"T_437c1_row5_col3\" class=\"data row5 col3\" >40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_437c1_row6_col0\" class=\"data row6 col0\" >Ciclico</td>\n",
              "      <td id=\"T_437c1_row6_col1\" class=\"data row6 col1\" >94.52%</td>\n",
              "      <td id=\"T_437c1_row6_col2\" class=\"data row6 col2\" >95.16%</td>\n",
              "      <td id=\"T_437c1_row6_col3\" class=\"data row6 col3\" >41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "resultados_df[['name','test_acc','val_acc', 'epochs']].style.hide_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhAah9L2cmoj"
      },
      "source": [
        "## Convergencia en iteraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "bP3C7xC1vql8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "21f1ed81-9997-4189-de7e-60ad4c146b11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "bbox = dict(boxstyle =\"round\", fc =\"1\")\n",
        "arrowprops = dict(\n",
        "    arrowstyle = \"->\")\n",
        "offset = 72\n",
        "\n",
        "x_axis = range(100)\n",
        "y_axis = np.linspace(0,5,10)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "for k1, _ in resultados.items():\n",
        "    ax.plot(range(len(resultados[k1]['val_acc_list'])),\n",
        "        resultados[k1]['val_acc_list'],\n",
        "        label='{name} = {acc}%'.format(name= resultados[k1]['name'],\n",
        "                                       acc = round(resultados[k1]['val_acc_list'][-1] * 100 , 2)))\n",
        "\n",
        "plt.title('Epochs vs Accuracy Train Set', fontsize = 18)\n",
        "\n",
        "\n",
        "ax.set_xlabel('# Epochs', fontsize = 18)\n",
        "ax.set_ylabel('Train Accuracy', fontsize = 18)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.xaxis.set_major_locator(MultipleLocator(10))\n",
        "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "ccfea65839ea7b4cb7611917847ae955f8a5d3f7496a05c88f3bf628abe673bf"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}