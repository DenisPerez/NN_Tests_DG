{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from get_images import get_images\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_PATH = './Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(MNIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set\n",
    "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)/255 ##Convert the traint set into a (50000, 28x28) matrix normalized\n",
    "y_train = y_train_num[:50000].reshape(50000,1)\n",
    "\n",
    "##Validation set\n",
    "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)/255\n",
    "y_val = y_train_num[50000:].reshape(10000,1)\n",
    "\n",
    "##Test set\n",
    "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)/255\n",
    "y_test = y_test_num.copy().reshape(10000,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.5686665e-08, 0.9999983)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mini Batches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify if we need this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(x, y, mb_size, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data, dtype=float)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigar que es un tensor. Vamos a tener que poner esto en el marco teorico\n",
    "\n",
    "https://stackabuse.com/numpy-array-to-tensor-and-tensor-to-numpy-array-with-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.Tensor(x_train.copy())\n",
    "y_train_tensor = torch.Tensor(y_train.copy())\n",
    "\n",
    "x_val_tensor = torch.Tensor(x_val.copy())\n",
    "y_val_tensor = torch.Tensor(y_val.copy())\n",
    "\n",
    "x_test_tensor = torch.Tensor(x_test.copy())\n",
    "y_test_tensor = torch.Tensor(y_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        ...,\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245],\n",
       "        [-0.4245, -0.4245, -0.4245,  ..., -0.4245, -0.4245, -0.4245]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = np.arange(x_train_tensor.shape[0], dtype=float)\n",
    "print(idxs[-1])\n",
    "o = [0,1,2,3,4]\n",
    "np.random.shuffle(idxs)\n",
    "x_train_tensor[idxs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to research about how we can use the GPU to process the models\n",
    "\n",
    "https://stackoverflow.com/questions/60987997/why-torch-cuda-is-available-returns-false-even-after-installing-pytorch-with"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPU when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos usando: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Estamos usando: {device}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model: nn.Sequential, x: torch.tensor, y: torch.tensor, mb_size: int):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
    "            xi = xi.to(device=device, dtype = torch.float32)\n",
    "            yi = yi.to(device=device, dtype = torch.long)\n",
    "            scores = model(xi) # mb_size, 10\n",
    "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
    "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "            return float(num_correct)/num_total  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Sequential, optimiser: torch.optim.SGD, mb_size: int, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            # cost function\n",
    "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {accuracy(model, x_val_tensor, y_val_tensor, mb_size)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, costo: 1.8925318717956543, accuracy: 0.720458984375\n",
      "Epoch: 1, costo: 1.2621209621429443, accuracy: 0.786865234375\n",
      "Epoch: 2, costo: 0.8846130967140198, accuracy: 0.847900390625\n",
      "Epoch: 3, costo: 0.6270560622215271, accuracy: 0.871337890625\n",
      "Epoch: 4, costo: 0.5465323328971863, accuracy: 0.88720703125\n",
      "Epoch: 5, costo: 0.508352518081665, accuracy: 0.88671875\n",
      "Epoch: 6, costo: 0.4556998908519745, accuracy: 0.8984375\n",
      "Epoch: 7, costo: 0.3985271453857422, accuracy: 0.892578125\n",
      "Epoch: 8, costo: 0.4072956144809723, accuracy: 0.906982421875\n",
      "Epoch: 9, costo: 0.3504480719566345, accuracy: 0.9052734375\n",
      "Epoch: 10, costo: 0.3408338725566864, accuracy: 0.906494140625\n",
      "Epoch: 11, costo: 0.3256221413612366, accuracy: 0.912109375\n",
      "Epoch: 12, costo: 0.3118875324726105, accuracy: 0.912841796875\n",
      "Epoch: 13, costo: 0.3089389204978943, accuracy: 0.91455078125\n",
      "Epoch: 14, costo: 0.32218441367149353, accuracy: 0.921875\n",
      "Epoch: 15, costo: 0.36270222067832947, accuracy: 0.91552734375\n",
      "Epoch: 16, costo: 0.3058478832244873, accuracy: 0.9150390625\n",
      "Epoch: 17, costo: 0.2637675702571869, accuracy: 0.922607421875\n",
      "Epoch: 18, costo: 0.30702024698257446, accuracy: 0.919189453125\n",
      "Epoch: 19, costo: 0.2728644013404846, accuracy: 0.92578125\n",
      "Epoch: 20, costo: 0.23619753122329712, accuracy: 0.91943359375\n",
      "Epoch: 21, costo: 0.3045869767665863, accuracy: 0.930419921875\n",
      "Epoch: 22, costo: 0.23983874917030334, accuracy: 0.923828125\n",
      "Epoch: 23, costo: 0.2236110270023346, accuracy: 0.9296875\n",
      "Epoch: 24, costo: 0.24745666980743408, accuracy: 0.926025390625\n",
      "Epoch: 25, costo: 0.2603674829006195, accuracy: 0.931884765625\n",
      "Epoch: 26, costo: 0.23282788693904877, accuracy: 0.9248046875\n",
      "Epoch: 27, costo: 0.204859659075737, accuracy: 0.92822265625\n",
      "Epoch: 28, costo: 0.20846010744571686, accuracy: 0.934326171875\n",
      "Epoch: 29, costo: 0.2896161377429962, accuracy: 0.931396484375\n",
      "Epoch: 30, costo: 0.27650099992752075, accuracy: 0.9365234375\n",
      "Epoch: 31, costo: 0.21006400883197784, accuracy: 0.93603515625\n",
      "Epoch: 32, costo: 0.2588098347187042, accuracy: 0.936767578125\n",
      "Epoch: 33, costo: 0.23843209445476532, accuracy: 0.935791015625\n",
      "Epoch: 34, costo: 0.20207931101322174, accuracy: 0.938232421875\n",
      "Epoch: 35, costo: 0.26936760544776917, accuracy: 0.941162109375\n",
      "Epoch: 36, costo: 0.20652468502521515, accuracy: 0.941650390625\n",
      "Epoch: 37, costo: 0.23530466854572296, accuracy: 0.940185546875\n",
      "Epoch: 38, costo: 0.20556557178497314, accuracy: 0.944580078125\n",
      "Epoch: 39, costo: 0.24693414568901062, accuracy: 0.947265625\n",
      "Epoch: 40, costo: 0.24018409848213196, accuracy: 0.943115234375\n",
      "Epoch: 41, costo: 0.2236921787261963, accuracy: 0.947021484375\n",
      "Epoch: 42, costo: 0.18598498404026031, accuracy: 0.943359375\n",
      "Epoch: 43, costo: 0.20759840309619904, accuracy: 0.94384765625\n",
      "Epoch: 44, costo: 0.21730397641658783, accuracy: 0.953125\n",
      "Epoch: 45, costo: 0.18306304514408112, accuracy: 0.9482421875\n",
      "Epoch: 46, costo: 0.18230819702148438, accuracy: 0.947998046875\n",
      "Epoch: 47, costo: 0.17339132726192474, accuracy: 0.946044921875\n",
      "Epoch: 48, costo: 0.18014399707317352, accuracy: 0.94873046875\n",
      "Epoch: 49, costo: 0.17261148989200592, accuracy: 0.952392578125\n",
      "Epoch: 50, costo: 0.22910872101783752, accuracy: 0.948974609375\n",
      "Epoch: 51, costo: 0.16982924938201904, accuracy: 0.954345703125\n",
      "Epoch: 52, costo: 0.22016747295856476, accuracy: 0.95263671875\n",
      "Epoch: 53, costo: 0.22599592804908752, accuracy: 0.95556640625\n",
      "Epoch: 54, costo: 0.1908828467130661, accuracy: 0.95166015625\n",
      "Epoch: 55, costo: 0.19528457522392273, accuracy: 0.9580078125\n",
      "Epoch: 56, costo: 0.14320532977581024, accuracy: 0.954833984375\n",
      "Epoch: 57, costo: 0.19303835928440094, accuracy: 0.956787109375\n",
      "Epoch: 58, costo: 0.1495790332555771, accuracy: 0.956298828125\n",
      "Epoch: 59, costo: 0.17818231880664825, accuracy: 0.9541015625\n",
      "Epoch: 60, costo: 0.16613858938217163, accuracy: 0.958984375\n",
      "Epoch: 61, costo: 0.1554366648197174, accuracy: 0.95703125\n",
      "Epoch: 62, costo: 0.14919961988925934, accuracy: 0.9560546875\n",
      "Epoch: 63, costo: 0.17730571329593658, accuracy: 0.959716796875\n",
      "Epoch: 64, costo: 0.18948225677013397, accuracy: 0.9541015625\n",
      "Epoch: 65, costo: 0.16837430000305176, accuracy: 0.96142578125\n",
      "Epoch: 66, costo: 0.14254935085773468, accuracy: 0.96142578125\n",
      "Epoch: 67, costo: 0.17218999564647675, accuracy: 0.963623046875\n",
      "Epoch: 68, costo: 0.1626090109348297, accuracy: 0.9619140625\n",
      "Epoch: 69, costo: 0.1435908079147339, accuracy: 0.958251953125\n",
      "Epoch: 70, costo: 0.12632012367248535, accuracy: 0.959228515625\n",
      "Epoch: 71, costo: 0.14225901663303375, accuracy: 0.96044921875\n",
      "Epoch: 72, costo: 0.15371617674827576, accuracy: 0.961181640625\n",
      "Epoch: 73, costo: 0.14983856678009033, accuracy: 0.958740234375\n",
      "Epoch: 74, costo: 0.1372576355934143, accuracy: 0.960693359375\n",
      "Epoch: 75, costo: 0.1316303014755249, accuracy: 0.963134765625\n",
      "Epoch: 76, costo: 0.1392599493265152, accuracy: 0.9619140625\n",
      "Epoch: 77, costo: 0.13217975199222565, accuracy: 0.96337890625\n",
      "Epoch: 78, costo: 0.12440139800310135, accuracy: 0.959228515625\n",
      "Epoch: 79, costo: 0.14683665335178375, accuracy: 0.962646484375\n",
      "Epoch: 80, costo: 0.11528937518596649, accuracy: 0.9619140625\n",
      "Epoch: 81, costo: 0.10658677667379379, accuracy: 0.963623046875\n",
      "Epoch: 82, costo: 0.11732808500528336, accuracy: 0.964111328125\n",
      "Epoch: 83, costo: 0.10893760621547699, accuracy: 0.965087890625\n",
      "Epoch: 84, costo: 0.14166176319122314, accuracy: 0.964111328125\n",
      "Epoch: 85, costo: 0.12620411813259125, accuracy: 0.963623046875\n",
      "Epoch: 86, costo: 0.10901077091693878, accuracy: 0.96533203125\n",
      "Epoch: 87, costo: 0.10005483031272888, accuracy: 0.960205078125\n",
      "Epoch: 88, costo: 0.12416131794452667, accuracy: 0.960693359375\n",
      "Epoch: 89, costo: 0.14081545174121857, accuracy: 0.96728515625\n",
      "Epoch: 90, costo: 0.13332466781139374, accuracy: 0.960693359375\n",
      "Epoch: 91, costo: 0.11373452097177505, accuracy: 0.964599609375\n",
      "Epoch: 92, costo: 0.12390146404504776, accuracy: 0.967041015625\n",
      "Epoch: 93, costo: 0.09831552952528, accuracy: 0.966796875\n",
      "Epoch: 94, costo: 0.09691093862056732, accuracy: 0.965576171875\n",
      "Epoch: 95, costo: 0.11342353373765945, accuracy: 0.965576171875\n",
      "Epoch: 96, costo: 0.14238953590393066, accuracy: 0.9638671875\n",
      "Epoch: 97, costo: 0.09673787653446198, accuracy: 0.96875\n",
      "Epoch: 98, costo: 0.11922591924667358, accuracy: 0.96728515625\n",
      "Epoch: 99, costo: 0.10317865759134293, accuracy: 0.97021484375\n"
     ]
    }
   ],
   "source": [
    "#Instanciar modelo\n",
    "hidden1 = 1000 \n",
    "hidden = 1000\n",
    "lr = 5e-2\n",
    "epochs = 100\n",
    "mb_size = 4096\n",
    "model1 = nn.Sequential(nn.Linear(in_features=784, out_features=hidden1), nn.ReLU(),\n",
    "                       nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
    "                       nn.Linear(in_features=hidden, out_features=10))\n",
    "optimiser = torch.optim.SGD(model1.parameters(), lr=lr)\n",
    "\n",
    "train(model1, optimiser, mb_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96240234375"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model1, x_test_tensor,  y_test_tensor, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccfea65839ea7b4cb7611917847ae955f8a5d3f7496a05c88f3bf628abe673bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
